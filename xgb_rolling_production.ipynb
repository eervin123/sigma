{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c69786c2-7c5b-4b1e-bd0c-52380c8df261",
   "metadata": {},
   "source": [
    "# XGBoost with Cross Validation and PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2751478-95ce-47d2-9e80-4d47ed0c7b36",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from numba import njit\n",
    "import vectorbtpro as vbt\n",
    "vbt.settings.set_theme(\"dark\")\n",
    "vbt.settings.plotting[\"layout\"][\"width\"] = 800\n",
    "vbt.settings.plotting['layout']['height'] = 200\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.linear_model import Ridge, Lasso, ElasticNet, LinearRegression, LogisticRegression\n",
    "from sklearn.svm import SVR, SVC\n",
    "from xgboost import XGBRegressor\n",
    "from xgboost import plot_importance\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "clf = RandomForestClassifier(random_state=42) # random forest classifier\n",
    "from joblib import dump, load\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "935ca582-ef09-40f9-b6ff-c303c98989b1",
   "metadata": {},
   "source": [
    "### Modeling\n",
    "The class Splitter can also be helpful in cross-validating ML models. In particular, you can casually step upon a class SKLSplitter that acts as a regular cross-validator from scikit-learn by subclassing BaseCrossValidator. We'll demonstrate its usage on a simple classification problem of predicting the best entry and exit timings.\n",
    "\n",
    "Before we start, we need to decide on features and labels that should act as predictor and response variables respectively. Features are usually multi-columnar time-series DataFrames where each row contains multiple data points (one per column) that should predict the same row in labels. Labels are usually a single-columnar time-series Series that should be predicted. Ask yourself the following questions to easily come up with a decision:\n",
    "\n",
    "\"How can the future performance be represented, preferably as a single number? Should it be the price at the next bar, the average price change over the next week, a vector of weights for rebalancing, a boolean containing a signal, or something else?\"\n",
    "\"What kind of data that encompasses the past performance is likely to predict the future performance? Should it be indicators, news sentiment index, past backtesting results, or something else?\"\n",
    "\"Which ML model can handle such a task?\" (remember that most models are limited to just a couple of specific feature and label formats!)\n",
    "For the sake of an example, we'll fit a random forest classifier on all TA-Lib indicators stacked along columns to predict the binary labels generated by the label generator TRENDLB, where 1 means an uptrend and 0 means a downtrend. Sounds like fun ðŸ˜Œ"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "41119985",
   "metadata": {},
   "source": [
    "Build a pipeline to impute and (standard-)normalize the data, [reduce the dimensionality](https://scikit-learn.org/stable/auto_examples/compose/plot_digits_pipe.html) of the features, as well as fit one of the [linear](https://scikit-learn.org/stable/modules/linear_model.html) models to predict the average price change over the next n bars (i.e., regression task!). Based on each prediction, you can then decide whether a position is worth opening or closing out. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "767f3215",
   "metadata": {},
   "source": [
    "# Helper functions\n",
    "Create dollar bars and add them to the original df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d6acc72",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def dollar_bar_func(ohlc_df, dollar_bar_size):\n",
    "    # Calculate dollar value traded for each row\n",
    "    ohlc_df['DollarValue'] = ohlc_df['Close'] * ohlc_df['Volume']\n",
    "    \n",
    "    # Calculate cumulative dollar value\n",
    "    ohlc_df['CumulativeDollarValue'] = ohlc_df['DollarValue'].cumsum()\n",
    "    \n",
    "    # Determine the number of dollar bars\n",
    "    num_bars = int(ohlc_df['CumulativeDollarValue'].iloc[-1] / dollar_bar_size)\n",
    "    \n",
    "    # Generate index positions for dollar bars\n",
    "    bar_indices = [0]\n",
    "    cumulative_value = 0\n",
    "    for i in range(1, len(ohlc_df)):\n",
    "        cumulative_value += ohlc_df['DollarValue'].iloc[i]\n",
    "        if cumulative_value >= dollar_bar_size:\n",
    "            bar_indices.append(i)\n",
    "            cumulative_value = 0\n",
    "    \n",
    "    # Create a new dataframe with dollar bars\n",
    "    dollar_bars = []\n",
    "    for i in range(len(bar_indices) - 1):\n",
    "        start_idx = bar_indices[i]\n",
    "        end_idx = bar_indices[i + 1]\n",
    "        \n",
    "        dollar_bar = {\n",
    "            'Open': ohlc_df['Open'].iloc[start_idx],\n",
    "            'High': ohlc_df['High'].iloc[start_idx:end_idx].max(),\n",
    "            'Low': ohlc_df['Low'].iloc[start_idx:end_idx].min(),\n",
    "            'Close': ohlc_df['Close'].iloc[end_idx],\n",
    "            'Volume': ohlc_df['Volume'].iloc[start_idx:end_idx].sum(),\n",
    "            'Quote volume': ohlc_df['Quote volume'].iloc[start_idx:end_idx].sum(),\n",
    "            'Trade count': ohlc_df['Trade count'].iloc[start_idx:end_idx].sum(),\n",
    "            'Taker base volume': ohlc_df['Taker base volume'].iloc[start_idx:end_idx].sum(),\n",
    "            'Taker quote volume': ohlc_df['Taker quote volume'].iloc[start_idx:end_idx].sum()\n",
    "        }\n",
    "        \n",
    "        if isinstance(ohlc_df.index, pd.DatetimeIndex):\n",
    "            dollar_bar['Open Time'] = ohlc_df.index[start_idx]\n",
    "            dollar_bar['Close Time'] = ohlc_df.index[end_idx] - pd.Timedelta(milliseconds=1)\n",
    "        elif 'Open Time' in ohlc_df.columns:\n",
    "            dollar_bar['Open Time'] = ohlc_df['Open Time'].iloc[start_idx]\n",
    "            dollar_bar['Close Time'] = ohlc_df['Open Time'].iloc[end_idx] - pd.Timedelta(milliseconds=1)\n",
    "        \n",
    "        dollar_bars.append(dollar_bar)\n",
    "    \n",
    "    dollar_bars_df = pd.concat([pd.DataFrame([bar]) for bar in dollar_bars], ignore_index=True)\n",
    "    \n",
    "    return dollar_bars_df\n",
    "\n",
    "# Create a simple function to simplify the number so we can use it in our column names\n",
    "def simplify_number(num):\n",
    "    \"\"\"\n",
    "    Simplifies a large number by converting it to a shorter representation with a suffix (K, M, B).\n",
    "    simplify_number(1000) -> 1K\n",
    "    \"\"\"\n",
    "    suffixes = ['', 'K', 'M', 'B']\n",
    "    suffix_index = 0\n",
    "\n",
    "    while abs(num) >= 1000 and suffix_index < len(suffixes) - 1:\n",
    "        num /= 1000.0\n",
    "        suffix_index += 1\n",
    "\n",
    "    suffix = suffixes[suffix_index] if suffix_index > 0 else ''\n",
    "    simplified_num = f'{int(num)}{suffix}'\n",
    "\n",
    "    return simplified_num\n",
    "\n",
    "def merge_and_fill_dollar_bars(original_df, dollar_bars_df, dollar_bar_size):\n",
    "    # Add prefix to column names in dollar bars dataframe\n",
    "    dollar_bar_prefix = f'db_{simplify_number(dollar_bar_size)}_'\n",
    "    dollar_bars_df_renamed = dollar_bars_df.add_prefix(dollar_bar_prefix)\n",
    "\n",
    "    # Convert 'Open Time' columns to pandas datetime format and set them as index\n",
    "    dollar_bars_df_renamed.index = pd.to_datetime(dollar_bars_df_renamed[dollar_bar_prefix + 'Open Time'])\n",
    "\n",
    "    # Merge the dataframes on the index\n",
    "    merged_df = original_df.merge(dollar_bars_df_renamed, how='left', left_index=True, right_index=True)\n",
    "\n",
    "    # Set the flag for a new dollar bar with prefix\n",
    "    merged_df[dollar_bar_prefix + 'NewDBFlag'] = ~merged_df[dollar_bar_prefix + 'Close'].isna()\n",
    "\n",
    "    # Forward fill the NaN values for all columns except the new dollar bar flag\n",
    "    columns_to_ffill = [col for col in merged_df.columns if col != dollar_bar_prefix + 'NewDBFlag']\n",
    "    merged_df[columns_to_ffill] = merged_df[columns_to_ffill].fillna(method='ffill')\n",
    "\n",
    "    # Fill the remaining NaN values in the new dollar bar flag column with False\n",
    "    merged_df[dollar_bar_prefix + 'NewDBFlag'] = merged_df[dollar_bar_prefix + 'NewDBFlag'].fillna(False)\n",
    "    \n",
    "    # Assign the renamed 'Open Time' column back to the dataframe\n",
    "    merged_df[dollar_bar_prefix + 'Open Time'] = merged_df[dollar_bar_prefix + 'Open Time']\n",
    "\n",
    "    return merged_df\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "469e8b28",
   "metadata": {},
   "source": [
    "# Calculate Dollar Bars\n",
    "Calc Dollar bars and then add technical analysis features\n",
    "\n",
    "Uncomment this section if you want to run different size dollar bars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5c2b8de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dollar_bar_size = 90_000_000\n",
    "# btc_dollar_bars = dollar_bar_func(futures_1m.get(), dollar_bar_size=dollar_bar_size)\n",
    "# btc_dollar_bars.index = pd.to_datetime(btc_dollar_bars['Open Time'])\n",
    "# btc_dollar_bars.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "640f40b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the dataframe back into a vbt data object\n",
    "# btc_90M_db_vbt = vbt.BinanceData.from_data(btc_dollar_bars)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc8cee12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the dollarbars to a pickle file\n",
    "# btc_90M_db_vbt.save('btc_90M_db_vbt.pkl')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c770a46d",
   "metadata": {},
   "source": [
    "# Load the dollar bars from pickle file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15451db6",
   "metadata": {},
   "outputs": [],
   "source": [
    "btc_90M_db_vbt = vbt.BinanceData.load('data/btc_90M_db_vbt.pkl')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "78e34cf7",
   "metadata": {},
   "source": [
    "Take a small slice of the data for train/testing and leave some to be out of sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca083be1",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = btc_90M_db_vbt['2021-01-01':'2023-01-01']\n",
    "outofsample_data = btc_90M_db_vbt['2023-01-01':'2023-06-03']\n",
    "print(data.shape)\n",
    "print(outofsample_data.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "1cea4860",
   "metadata": {},
   "source": [
    "# Create the functions for the notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed275ec5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data(data, pivot_up_th=0.30, pivot_down_th=0.05, periods_future=150, drop_cols=['Open Time', 'Close Time']):\n",
    "    \"\"\"\n",
    "    This function prepares the data for training the model.\n",
    "    \n",
    "    Parameters:\n",
    "    data (DataFrame): The original DataFrame containing the data.\n",
    "    pivot_up_th (float): Threshold for upward trend.\n",
    "    pivot_down_th (float): Threshold for downward trend.\n",
    "    periods_future (int): Number of periods in the future to predict.\n",
    "    drop_cols (list): Columns to be dropped from the original DataFrame.\n",
    "    \n",
    "    Returns:\n",
    "    X (DataFrame): The feature matrix.\n",
    "    y (Series): The target vector.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Generate the features (X) and target (y) dataframes\n",
    "    X = data.get()\n",
    "    # Get pivot information\n",
    "    pivot_info = data.run(\"pivotinfo\", up_th=pivot_up_th, down_th=pivot_down_th)\n",
    "    binary_pivot_labels = np.where(data.close > pivot_info.conf_value,1,0) # Create binary labels for pivot points\n",
    "    X['trend'] = binary_pivot_labels # add pivot label as a feature\n",
    "    # Drop the time columns\n",
    "    X = X.drop(drop_cols, axis=1)\n",
    "    # Add time features\n",
    "    X['dayofmonth']  = X.index.day\n",
    "    X['month']       = X.index.month\n",
    "    X['year']        = X.index.year\n",
    "    X['hour']        = X.index.hour\n",
    "    X['minute']      = X.index.minute\n",
    "    X['dayofweek']   = X.index.dayofweek\n",
    "    X['dayofyear']   = X.index.dayofyear\n",
    "\n",
    "    # Now we are trying to generate future price predictions so we will set the y labels to the price change n periods in the future\n",
    "    y = (data.close.shift(-periods_future) / data.close - 1).rolling(periods_future).mean() # future price change we use rolling mean to smooth the data\n",
    "\n",
    "    # Preprocessing steps to handle NaNs\n",
    "    X = X.replace([-np.inf, np.inf], np.nan) # replace inf with nan\n",
    "    invalid_column_mask = X.isnull().all(axis=0)\n",
    "    X = X.loc[:, ~invalid_column_mask] # drop invalid columns\n",
    "    invalid_row_mask = X.isnull().any(axis=1) | y.isnull() # drop rows that have nan in any column or in y\n",
    "\n",
    "    # Drop invalid rows in X and y\n",
    "    X = X.loc[~invalid_row_mask]\n",
    "    y = y.loc[~invalid_row_mask]\n",
    "\n",
    "    return X, y\n",
    "\n",
    "def create_pipeline(model='xgb'):\n",
    "    \"\"\"\n",
    "    Create a scikit-learn pipeline.\n",
    "\n",
    "    Parameters:\n",
    "    model (str): The model to use in the pipeline. Default is 'xgb' (XGBoost).\n",
    "\n",
    "    Returns:\n",
    "    pipeline (Pipeline): The scikit-learn pipeline.\n",
    "    \"\"\"\n",
    "\n",
    "    # Construct the pipeline\n",
    "    steps = [\n",
    "        ('imputation', SimpleImputer(strategy='mean')),  # Imputation replaces missing values\n",
    "        ('scaler', StandardScaler()),  # StandardScaler normalizes the data\n",
    "        # ('pca', PCA(n_components=15))  # PCA reduces dimensionality\n",
    "    ]\n",
    "\n",
    "    if model == 'xgb':\n",
    "        steps.append(('model', XGBRegressor(objective='reg:squarederror')))  # XGBoost regression is used as the prediction model\n",
    "    elif model == 'ridge':\n",
    "        steps.append(('model', Ridge()))  # Ridge regression\n",
    "    elif model == 'linear':\n",
    "        steps.append(('model', LinearRegression()))  # Linear regression\n",
    "    elif model == 'logistic':\n",
    "        steps.append(('model', LogisticRegression()))  # Logistic regression\n",
    "    elif model == 'lasso':\n",
    "        steps.append(('model', Lasso()))  # Lasso regression\n",
    "    elif model == 'elasticnet':\n",
    "        steps.append(('model', ElasticNet()))  # ElasticNet regression\n",
    "    elif model == 'svr':\n",
    "        steps.append(('model', SVR()))  # Support Vector Regression\n",
    "    else:\n",
    "        raise ValueError(\"Invalid model name. Choose from 'xgb', 'ridge', 'linear', 'logistic', 'lasso', 'elasticnet', 'svr'.\")\n",
    "\n",
    "    pipeline = Pipeline(steps)\n",
    "    \n",
    "    return pipeline\n",
    "\n",
    "def create_cv(X, min_length=600, offset=200, split=-200, set_labels=[\"train\", \"test\"]):\n",
    "    \"\"\"\n",
    "    Create a cross-validation splitter.\n",
    "\n",
    "    Parameters:\n",
    "    X (DataFrame): The feature matrix.\n",
    "    min_length (int): The minimum length of a sample for cross-validation.\n",
    "    offset (int): The offset used in cross-validation splitting.\n",
    "    split (int): Index at which to split the data in cross-validation.\n",
    "    set_labels (list): Labels for the train and test sets in cross-validation.\n",
    "\n",
    "    Returns:\n",
    "    cv_splitter (SKLSplitter): The cross-validation splits created from cv.get_splitter(X).\n",
    "    cv (SKLSplitter): The cross-validation object.\n",
    "    \"\"\"\n",
    "\n",
    "    # Cross-validate Creates a cross-validation object with all the indexes for each cv split\n",
    "    cv = vbt.SKLSplitter(\"from_expanding\", min_length=min_length, offset=offset, split=split, set_labels=set_labels)\n",
    "    cv_splitter = cv.get_splitter(X)\n",
    "    \n",
    "    return cv_splitter, cv\n",
    "\n",
    "def create_rolling_cv(X, length=2000, split=0.90, set_labels=[\"train\", \"test\"]):\n",
    "    \"\"\"\n",
    "    Create a cross-validation splitter.\n",
    "\n",
    "    Parameters:\n",
    "    X (DataFrame): The feature matrix.\n",
    "    min_length (int): The minimum length of a sample for cross-validation.\n",
    "    offset (int): The offset used in cross-validation splitting.\n",
    "    split (int): Index at which to split the data in cross-validation.\n",
    "    set_labels (list): Labels for the train and test sets in cross-validation.\n",
    "\n",
    "    Returns:\n",
    "    cv_splitter (SKLSplitter): The cross-validation splits created from cv.get_splitter(X).\n",
    "    cv (SKLSplitter): The cross-validation object.\n",
    "    \"\"\"\n",
    "\n",
    "    # Cross-validate Creates a cross-validation object with all the indexes for each cv split\n",
    "    cv = vbt.SKLSplitter(\"from_rolling\", length=length, split=split, set_labels=set_labels)\n",
    "    cv_splitter = cv.get_splitter(X)\n",
    "    \n",
    "    return cv_splitter, cv\n",
    "\n",
    "def cross_validate_and_train(pipeline, X, y, cv_splitter, model_name=\"\"):\n",
    "\n",
    "    # Predictions\n",
    "    X_slices = cv_splitter.take(X)\n",
    "    y_slices = cv_splitter.take(y)\n",
    "\n",
    "    test_labels = []\n",
    "    test_preds = []\n",
    "    for split in X_slices.index.unique(level=\"split\"):  \n",
    "        X_train_slice = X_slices[(split, \"train\")]  \n",
    "        y_train_slice = y_slices[(split, \"train\")]\n",
    "        X_test_slice = X_slices[(split, \"test\")]\n",
    "        y_test_slice = y_slices[(split, \"test\")]\n",
    "        pipeline.fit(X_train_slice, y_train_slice)  \n",
    "        test_pred = pipeline.predict(X_test_slice)  \n",
    "        test_pred = pd.Series(test_pred, index=y_test_slice.index)\n",
    "        test_labels.append(y_test_slice)\n",
    "        test_preds.append(test_pred)\n",
    "        print(f\"{model_name} Split {split} Mean Squared Error: {mean_squared_error(y_test_slice, test_pred)}\")\n",
    "\n",
    "    test_labels = pd.concat(test_labels).rename(\"labels\")  \n",
    "    test_preds = pd.concat(test_preds).rename(\"preds\")\n",
    "    \n",
    "    return pipeline, test_labels, test_preds\n",
    "\n",
    "def evaluate_predictions(test_labels, test_preds, model_name=\"\"):\n",
    "    # Show the accuracy of the predictions\n",
    "    mse = mean_squared_error(test_labels, test_preds)\n",
    "    rmse = np.sqrt(mse)  # or use mean_squared_error with squared=False\n",
    "    mae = mean_absolute_error(test_labels, test_preds)\n",
    "    r2 = r2_score(test_labels, test_preds)\n",
    "\n",
    "    print(f\"{model_name} Mean Squared Error (MSE): {mse}\")\n",
    "    print(f\"{model_name} Root Mean Squared Error (RMSE): {rmse}\")\n",
    "    print(f\"{model_name} Mean Absolute Error (MAE): {mae}\")\n",
    "    print(f\"{model_name} R-squared: {r2}\")\n",
    "\n",
    "    return mse, rmse, mae, r2\n",
    "\n",
    "\n",
    "\n",
    "def extract_feature_importance(pipeline, X):\n",
    "    \"\"\"\n",
    "    Extract the feature importance from a fitted XGBoost model in a pipeline.\n",
    "\n",
    "    Parameters:\n",
    "    pipeline (Pipeline): The fitted scikit-learn pipeline containing an XGBoost model.\n",
    "    X (DataFrame): The feature matrix used to fit the pipeline.\n",
    "\n",
    "    Returns:\n",
    "    None.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Extract the fitted XGBRegressor model from the pipeline\n",
    "    fitted_model = pipeline.named_steps['model']\n",
    "\n",
    "    # Get feature importance\n",
    "    importance = fitted_model.feature_importances_\n",
    "\n",
    "    # Summarize feature importance\n",
    "    for i, j in enumerate(importance):\n",
    "        print('Feature: %0d, Score: %.5f' % (i,j))\n",
    "\n",
    "    # Plot feature importance\n",
    "    plot_importance(fitted_model)\n",
    "    plt.show()\n",
    "\n",
    "    # Assuming `X` is your feature matrix\n",
    "    feature_names = X.columns.tolist()\n",
    "\n",
    "    # If you use PCA in your pipeline, the output feature names would be the principal components, not the original feature names.\n",
    "    # If that's the case, you should generate new names for the principal components\n",
    "    if 'pca' in pipeline.named_steps:\n",
    "        n_components = pipeline.named_steps['pca'].n_components_\n",
    "        feature_names = [f'PC{i+1}' for i in range(n_components)]\n",
    "\n",
    "    # Print feature importance with names\n",
    "    for name, importance in zip(feature_names, fitted_model.feature_importances_):\n",
    "        print(f'Feature: {name}, Score: {importance}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "73779d28",
   "metadata": {},
   "source": [
    "# Prepare the insample data and out of sample data for training and testing\n",
    "Add features and pre process the data to make sure we have the same shapes and remove any problem columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8703400c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prep In Sample Data\n",
    "X, y = prepare_data(data, pivot_up_th=0.10, pivot_down_th=0.10)\n",
    "# Prep Out of Sample Data\n",
    "Xoos, yoos = prepare_data(outofsample_data)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e7c06760",
   "metadata": {},
   "source": [
    "# Construct a pipeline and set up your cross validations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1053c853",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = create_pipeline(model='xgb')\n",
    "cv_splitter, cv = create_rolling_cv(X, length=200, split=0.90, set_labels=[\"train\", \"test\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cea057a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train and cross-validate\n",
    "final_pipeline, test_labels, test_preds = cross_validate_and_train(pipeline, X, y, cv_splitter, model_name=\"In-Sample\")\n",
    "\n",
    "# Evaluate\n",
    "mse, rmse, mae, r2 = evaluate_predictions(test_labels, test_preds, model_name=\"In-Sample\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "9df7cc0b",
   "metadata": {},
   "source": [
    "Save the model trained up to 2023 on \"in sample\" data using cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84262055",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "filename = 'models/model_upto_2023_rolling.joblib'\n",
    "dump(pipeline, filename)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ec2b6a55",
   "metadata": {},
   "source": [
    "### Load the model from storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f4262dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'models/model_upto_2023_rolling.joblib'\n",
    "# Load the model from the .joblib file\n",
    "final_pipeline = load(filename) \n",
    "\n",
    "# Make predictions on the entire dataset\n",
    "insample_predictions = final_pipeline.predict(X)\n",
    "insample_predictions = pd.Series(insample_predictions, index=y.index)\n",
    "# Calculate the R-squared score on the entire dataset\n",
    "r2 = r2_score(y, insample_predictions)\n",
    "print(\"This is how well the model is at fitting to the original data it was trained and tested on\")\n",
    "print(f\"R-squared on the entire dataset: {r2}\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "429527a3",
   "metadata": {},
   "source": [
    "#### Check out the fit on in sample data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d319a581",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the predictions versus the actuals\n",
    "# yoos is the actuals and outofsample_predictions is the predictions\n",
    "plt.scatter(y, insample_predictions, alpha=0.2)\n",
    "# Add a line of best fit\n",
    "m, b = np.polyfit(y, insample_predictions, 1)\n",
    "plt.plot(y, m*y + b, color='red')\n",
    "\n",
    "# Add the formula for the slope and intercept\n",
    "plt.text(0.05, 0.95, f\"y = {m:.2f}x + {b:.2f}\", transform=plt.gca().transAxes)\n",
    "\n",
    "# Add the y and x axis labels\n",
    "plt.xlabel(\"Actuals\")\n",
    "plt.ylabel(\"Predictions\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "9436f31c",
   "metadata": {},
   "source": [
    "# Walk Forward Cross Validation on Out of sample data\n",
    "#### Retrain the model every 200 bars\n",
    "- Load the model\n",
    "- Preprocess the data\n",
    "- Create Cross Validations for training and testing on newly seen data\n",
    "- Train the model\n",
    "- Make predictions\n",
    "- Test and evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e4d728a",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'models/model_upto_2023_rolling.joblib'\n",
    "# Load the model from the .joblib file\n",
    "final_pipeline = load(filename) \n",
    "\n",
    "# Create your cross validation splits\n",
    "cv_splitter_oos, cv_oos = create_rolling_cv(Xoos, length=200, split=0.9, set_labels=[\"train\", \"test\"])\n",
    "\n",
    "# Train and cross-validate\n",
    "final_pipeline, oos_test_labels, oos_test_preds = cross_validate_and_train(final_pipeline, Xoos, yoos, cv_splitter_oos, model_name=\"Out-Of-Sample\")\n",
    "\n",
    "# Evaluate\n",
    "mse, rmse, mae, r2 = evaluate_predictions(oos_test_labels, oos_test_preds, model_name=\"Out-Of-Sample\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6014dbdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model\n",
    "total_filename = 'models/out_of_sample_rolling.joblib'\n",
    "dump(final_pipeline, total_filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "427cb20e",
   "metadata": {},
   "source": [
    "### Simulate a portfolio in 2023 with retraining the model every 200 bars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "078913c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "oos_retraining_pf = vbt.Portfolio.from_signals(\n",
    "    outofsample_data.close[oos_test_preds.index], # use only the test set\n",
    "    entries         = oos_test_preds > 0.05, # long entry when prediction is greater than X%\n",
    "    exits           = oos_test_preds < 0.00, # exit long when prediction is negative\n",
    "    short_entries   = oos_test_preds < -0.04, # enter short when prediction is less than -X%\n",
    "    short_exits     = oos_test_preds > 0.0, # exit short when prediction is positive\n",
    "    # direction=\"both\" # long and short\n",
    ")\n",
    "print(oos_retraining_pf.stats())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa09a30f",
   "metadata": {},
   "outputs": [],
   "source": [
    "oos_retraining_pf.plot().show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "74fff484",
   "metadata": {},
   "source": [
    "ðŸ‘† better drawdowns than a buy and hold, and almost the same results."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "1f256503",
   "metadata": {},
   "source": [
    "# Look at the Portfolio on Test Data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "101dd472",
   "metadata": {},
   "source": [
    "and Simulate a portfolio?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b4e6246",
   "metadata": {},
   "outputs": [],
   "source": [
    "insample_pf = vbt.Portfolio.from_signals(\n",
    "    data.close[test_preds.index],  # use only the test set\n",
    "    entries         = test_preds > 0.0,  # long when probability of price increase is greater than 2%\n",
    "    exits           = test_preds < 0.00,  # long when probability of price increase is greater than 2%\n",
    "    short_entries   = test_preds < 0.0,  # long when probability of price increase is greater than 2%\n",
    "    short_exits     = test_preds > 0.0,  # short when probability prediction is less than -5%\n",
    "    # direction=\"both\" # long and short\n",
    ")\n",
    "print(insample_pf.stats())\n",
    "\n",
    "# pf.plot().show_svg()\n",
    "# Show first period\n",
    "# pf['2018':'2021'].plot().show_svg()\n",
    "# Show second period\n",
    "# pf['2021':'2023'].plot().show_svg()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a3419a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "insample_pf.plot().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a2dce4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "insample_pf.orders.records_readable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e04cfc78",
   "metadata": {},
   "outputs": [],
   "source": [
    "insample_pf.trades.records_readable"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60a487d1",
   "metadata": {},
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ed1f2a44",
   "metadata": {},
   "source": [
    "# Combine insample with out of sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a82c4832",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = insample_pf.cumulative_returns.vbt.plot(trace_kwargs=dict(name='Insample')) # plot the in sample equity curve from test data not trained data\n",
    "oos = insample_pf.cumulative_returns[-1] *(1+ oos_retraining_pf.returns).cumprod() # append the out of sample equity curve to the in sample equity curve\n",
    "# Add the out of sample equity curve to the plot\n",
    "oos.vbt.plot(fig=fig, trace_kwargs=dict(name='Out of Sample'))\n",
    "normalized_price = data.close/data.close[0]\n",
    "oos_normalized_price = outofsample_data.close/outofsample_data.close[0] * normalized_price[-1] # normalize the out of sample data to the last price of the in sample data\n",
    "normalized_price.rename('Normalized Price').vbt.plot(fig=fig)\n",
    "oos_normalized_price.rename('Out of Sample Normalized Price').vbt.plot(fig=fig)\n",
    "# The gap is the warmup period for the new model to start making predictions"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a164b3e2",
   "metadata": {},
   "source": [
    "## Save everything to the models folder for later analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8106222f",
   "metadata": {},
   "outputs": [],
   "source": [
    "insample_pf.save('models/insample_test_portfolio_rolling.pkl')\n",
    "insample_pf.stats().to_csv('models/insample_stats_test_rolling.csv')\n",
    "insample_pf.trades.records_readable.to_csv('models/insample_trades_test_rolling.csv')\n",
    "X.to_csv('models/insample_X_test_rolling.csv')\n",
    "y.to_csv('models/insample_y_test_rolling.csv')\n",
    "Xoos.to_csv('models/oos_X_test_rolling.csv')\n",
    "yoos.to_csv('models/oos_y_test_rolling.csv')\n",
    "test_preds.to_csv('models/insample_preds_test_rolling.csv')\n",
    "oos_preds.to_csv('models/oos_preds_test_rolling.csv')\n",
    "oos_retraining_pf.save('models/oos_retrained_portfolio_rolling.pkl')\n",
    "oos_retraining_pf.stats().to_csv('models/oos_retrained_stats_rolling.csv')\n",
    "oos_retraining_pf.trades.records_readable.to_csv('models/oos_retrained_trades_rolling.csv')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8e522850",
   "metadata": {},
   "source": [
    "# Explore which features are impacting the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7460cca",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "        \n",
    "extract_feature_importance(final_pipeline, X)\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "bb8c76a3",
   "metadata": {},
   "source": [
    "A lot to unpack up above. Why are the feature scores so much different than the fscores of the features?"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "9f1a93d2",
   "metadata": {},
   "source": [
    "# Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f429f2b",
   "metadata": {},
   "source": [
    "### Randomized Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bb34aef",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from scipy.stats import uniform, randint\n",
    "\n",
    "# Specify hyperparameters to tune and their respective distributions\n",
    "param_dist = {\n",
    "    'model__learning_rate': uniform(0.01, 0.2),\n",
    "    'model__n_estimators': randint(100, 1000),\n",
    "    'model__max_depth': randint(3, 10),\n",
    "    'model__min_child_weight': randint(1, 10),\n",
    "    'model__subsample': uniform(0.5, 0.5),\n",
    "    'model__colsample_bytree': uniform(0.5, 0.5),\n",
    "    # add other parameters here\n",
    "}\n",
    "\n",
    "# Perform randomized search\n",
    "random_search = RandomizedSearchCV(pipeline, param_dist, n_iter=10, cv=cv, scoring=\"neg_mean_squared_error\", n_jobs=-1, verbose=10, random_state=42)\n",
    "random_search.fit(X, y)\n",
    "\n",
    "# Best parameters and score from random search\n",
    "print(f\"Best parameters: {random_search.best_params_}\")\n",
    "print(f\"Best score: {random_search.best_score_}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4368877a",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_splitter, cv = create_rolling_cv(X, length=200, split=0.9)\n",
    "\n",
    "# The slices are obtained by using your cv_splitter on your X and y.\n",
    "X_slices = cv_splitter.take(X)\n",
    "y_slices = cv_splitter.take(y)\n",
    "\n",
    "# Fit and predict with the best estimator\n",
    "test_labels = []\n",
    "test_preds = []\n",
    "for split in X_slices.index.unique(level=\"split\"):  \n",
    "    X_train_slice = X_slices[(split, \"train\")]  \n",
    "    y_train_slice = y_slices[(split, \"train\")]\n",
    "    X_test_slice = X_slices[(split, \"test\")]\n",
    "    y_test_slice = y_slices[(split, \"test\")]\n",
    "\n",
    "    slice_pipeline = random_search.best_estimator_.fit(X_train_slice, y_train_slice)  # uses the best estimator from the random search\n",
    "    test_pred = slice_pipeline.predict(X_test_slice)  \n",
    "    test_pred = pd.Series(test_pred, index=y_test_slice.index)\n",
    "    test_labels.append(y_test_slice)\n",
    "    test_preds.append(test_pred)\n",
    "    print(f\"MSE for split {split}: {mean_squared_error(y_test_slice, test_pred)}\")\n",
    "\n",
    "\n",
    "test_labels = pd.concat(test_labels).rename(\"labels\")  \n",
    "test_preds = pd.concat(test_preds).rename(\"preds\")\n",
    "\n",
    "# Show the accuracy of the predictions\n",
    "# Assuming test_labels and test_preds are your true and predicted values\n",
    "mse = mean_squared_error(test_labels, test_preds)\n",
    "rmse = np.sqrt(mse)  # or use mean_squared_error with squared=False\n",
    "mae = mean_absolute_error(test_labels, test_preds)\n",
    "r2 = r2_score(test_labels, test_preds)\n",
    "\n",
    "print(f\"Mean Squared Error (MSE): {mse}\")\n",
    "print(f\"Root Mean Squared Error (RMSE): {rmse}\")\n",
    "print(f\"Mean Absolute Error (MAE): {mae}\")\n",
    "print(f\"R-squared: {r2}\")\n",
    "\n",
    "# Visualize the predictions as a heatmap plotted against the price\n",
    "# data.close.vbt.overlay_with_heatmap(test_preds).show_svg()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ba88ef3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model with the best parameters\n",
    "import json\n",
    "\n",
    "# Save the model with the best parameters\n",
    "dump(random_search.best_estimator_, 'models/xgboost_best_estimator_rolling.joblib')\n",
    "\n",
    "# Save best params dictionary \n",
    "with open('models/xgboost_best_params_rolling.json', 'w') as fp:\n",
    "    json.dump(random_search.best_params_, fp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27f07697",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "hyperopt_pf = vbt.Portfolio.from_signals(\n",
    "    data.close[test_preds.index],  # use only the test set\n",
    "    entries         = test_preds > 0.05,  # long when probability of price increase is greater than 2%\n",
    "    exits           = test_preds < 0.00,  # long when probability of price increase is greater than 2%\n",
    "    short_entries   = test_preds < -0.05,  # long when probability of price increase is greater than 2%\n",
    "    short_exits     = test_preds > 0.0,  # short when probability prediction is less than -5%\n",
    "    # direction=\"both\" # long and short\n",
    ")\n",
    "print(hyperopt_pf.stats())\n",
    "hyperopt_pf.plot().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9e6d01e",
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperopt_pf.save('models/hyperopt_portfolio_rolling.pkl')\n",
    "hyperopt_pf.trades.records_readable.to_csv('models/hyperopt_trades_rolling.csv')\n",
    "hyperopt_pf.orders.records_readable.to_csv('models/hyperopt_orders_rolling.csv')\n",
    "test_preds.to_csv('models/hyperopt_preds_rolling.csv')\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "6fd079e2",
   "metadata": {},
   "source": [
    "### Grid Search Method\n",
    "#### DONT RUN WITHOUT GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80c7709d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# # Specify hyperparameters to tune and their respective ranges\n",
    "# param_grid = {\n",
    "#     'model__learning_rate': [0.01, 0.1, 0.2],\n",
    "#     'model__n_estimators': [100, 500, 1000],\n",
    "#     'model__max_depth': [3, 5, 7],\n",
    "#     'model__min_child_weight': [1, 5, 10],\n",
    "#     'model__subsample': [0.5, 0.7, 1.0],\n",
    "#     'model__colsample_bytree': [0.5, 0.7, 1.0]\n",
    "#     # add other parameters here\n",
    "# }\n",
    "\n",
    "# # Perform grid search\n",
    "# grid_search = GridSearchCV(pipeline, param_grid, cv=cv, scoring=\"r2\", n_jobs=-1, verbose=10)\n",
    "# grid_search.fit(X, y)\n",
    "\n",
    "# # Best parameters and score from grid search\n",
    "# print(f\"Best parameters: {grid_search.best_params_}\")\n",
    "# print(f\"Best score: {grid_search.best_score_}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95d3f992",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cv_splitter, cv = create_rolling_cv(X, length=200, split=.9)\n",
    "\n",
    "# # The slices are obtained by using your cv_splitter on your X and y.\n",
    "# X_slices = cv_splitter.take(X)\n",
    "# y_slices = cv_splitter.take(y)\n",
    "\n",
    "# # Here, we train the model using the slices and the best estimator from your RandomizedSearchCV\n",
    "# test_labels, test_preds, final_pipeline = cross_validate_and_train(random_search.best_estimator_, X_slices, y_slices, cv_splitter, model_name=\"Random Search Best Estimator\")\n",
    "\n",
    "# # And now we evaluate the predictions.\n",
    "# mse, rmse, mae, r2 = evaluate_predictions(test_labels, test_preds, model_name=\"Random Search Best Estimator\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58082fd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# grid_pf = vbt.Portfolio.from_signals(\n",
    "#     data.close[test_preds.index], # use only the test set\n",
    "#     entries         = test_preds > 0.05, # long when prediction > X%\n",
    "#     exits           = test_preds < 0.00, # exit when prediction is negative\n",
    "#     short_entries   = test_preds < -0.05, # short when prediction < -X%\n",
    "#     short_exits     = test_preds > 0.00, # exit when prediction is positive\n",
    "# )\n",
    "# print(grid_pf.stats())\n",
    "# grid_pf.plot().show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08fdcb48",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
