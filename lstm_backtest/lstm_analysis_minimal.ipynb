{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import vectorbtpro as vbt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "vbt.settings.wrapping [\"freq\"]                = \"1m\"\n",
    "vbt.settings.portfolio['init_cash']           = 10000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Local Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "sys.path.append(os.getcwd())\n",
    "\n",
    "from lstm_analysis_utils import (read_pickle_files_into_df, add_forward_prices_to_df, generate_fwd_actual_column\n",
    "                                 , generate_df_with_euclidean_distances, calculate_slopes, calculate_correlation_slopes\n",
    "                                )\n",
    "from settings_and_params import extract_prediction_window_size, generate_excel_output_file_path, generate_dataframe_csv_output_file_path\n",
    "from output_utils import export_raw_dataframe_to_csv\n",
    "from lstm_results_utils import (export_results, store_backtest_results)\n",
    "from lstm_only_backtests import run_backtest_lstm_recommendations_reversal_exits, run_backtests_lstm_recommendations_prediction_size_exit\n",
    "from lstm_analysis_constants import EntryType\n",
    "from quantile_value import generate_quantile_bands, extract_boundary_values_from_quantile_bands\n",
    "from prediction_window_slopes import PredictionWindowSlopes\n",
    "from long_slope_short_slope_backtests import run_backtest_long_slope_short_slope_prediction_size_exit, run_backtest_long_slope_short_slope_fractional_exits\n",
    "from long_minus_short_backtests import run_backtest_long_minus_short_entry_type_long_only, run_backtest_long_minus_short_entry_type_short_only, run_backtest_long_minus_short_entry_type_long_short"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Settings and Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle_files_path               = \"../data/RID0036_LSTM_pw18_lb250_bt1000_mem5000/*.pkl\"\n",
    "\n",
    "model_name                      = pickle_files_path.split('/')[-2]\n",
    "prediction_window               = extract_prediction_window_size(model_name)\n",
    "min_num_entries                 = 100\n",
    "excel_output_file_name          = generate_excel_output_file_path(model_name)\n",
    "dataframe_csv_output_file_name  = generate_dataframe_csv_output_file_path(model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = read_pickle_files_into_df(pickle_files_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "add_forward_prices_to_df(df, prediction_window)\n",
    "df = df.copy()  # for large prediction_window size, the copy() call eliminates the fragmented dataframe warning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_fwd_actual_column(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = generate_df_with_euclidean_distances(df, prediction_window)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "calculate_slopes(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correlation between Euclidean distance between long array and short array and future actual results:  0.10156542440852774\n",
      "Correlation between difference in long minus short predictions and future actual results for longs:  0.7231040768105375\n",
      "Correlation between difference in long minus short predictions and future actual results for shorts:  0.7225434965352817\n",
      "Correlation between long slopes and future results: 0.0027161081521049108\n",
      "Correlation between short slopes and future results: -0.0021124028628880655\n"
     ]
    }
   ],
   "source": [
    "calculate_correlation_slopes(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.index = pd.to_datetime(df[\"close_time\"], utc=True, unit=\"s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Running backtest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ### Storing the results of the backtests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_as_list  = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ### Baseline backtest - just listen to LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_backtest_lstm_recommendations_reversal_exits(df, results_as_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_backtests_lstm_recommendations_prediction_size_exit(df, results_as_list, prediction_window)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ### Using different slopes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_long_slope  = df[\"long_slope\"].min()\n",
    "max_long_slope  = df[\"long_slope\"].max()\n",
    "min_short_slope = df[\"short_slope\"].min()\n",
    "max_short_slope = df[\"short_slope\"].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_quantiles               = 5\n",
    "threshold_increment         = 0.001\n",
    "quantiles                   = np.linspace(0, 1, num=num_quantiles + 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- #### long_slope and short_slope"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_backtest_long_slope_short_slope_prediction_size_exit(df, results_as_list, prediction_window, threshold_increment, min_num_entries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_backtest_long_slope_short_slope_fractional_exits(df, results_as_list, threshold_increment, min_num_entries) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- #### long_minus_short"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "long_minus_short_min = df['long_minus_short'].min()\n",
    "long_minus_short_max = df['long_minus_short'].max()\n",
    "\n",
    "long_minus_short_thresholds = [x for x in np.arange(long_minus_short_min, long_minus_short_max, threshold_increment)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_backtest_long_minus_short_entry_type_long_only(df, results_as_list, prediction_window, threshold_increment, min_num_entries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_backtest_long_minus_short_entry_type_short_only(df, results_as_list, prediction_window, threshold_increment, min_num_entries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for threshold in long_minus_short_thresholds:  \n",
    "  entries       = pd.Series(np.where((df['long_minus_short'] < threshold) & (df['long_slope'] > 0), True, False))\n",
    "  short_entries = pd.Series(np.where((df['long_minus_short'] < threshold) & (df['short_slope'] < 0), True, False))\n",
    "\n",
    "  num_entries = (entries == True).sum() + (short_entries == True).sum()\n",
    "\n",
    "  if num_entries > min_num_entries:\n",
    "    pf = vbt.Portfolio.from_signals(\n",
    "        high              = df['BTCUSDT_High'],\n",
    "        low               = df['BTCUSDT_Low'],\n",
    "        open              = df['BTCUSDT_Open'],\n",
    "        close             = df['BTCUSDT_Close'],\n",
    "        entries           = entries, # commented out for a short only backtest    \n",
    "        short_entries     = short_entries,\n",
    "        td_stop           = prediction_window, # Hold on to the position for 8 bars\n",
    "        time_delta_format = 'Rows', # Use the row index to calculate the time delta    \n",
    "        accumulate        = False,    \n",
    "        )\n",
    "\n",
    "    key = f\"Long minus short with slopes\"    \n",
    "    slopes = PredictionWindowSlopes(0, 0, None, None, threshold, EntryType.LONG_SHORT)\n",
    "    store_backtest_results(key, pf, results_as_list, slopes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for threshold in long_minus_short_thresholds:    \n",
    "  entries       = pd.Series(np.where((df['long_minus_short'] < threshold) & (df['long_slope'] > 0.001), True, False))\n",
    "  short_entries = pd.Series(np.where((df['long_minus_short'] < threshold) & (df['short_slope'] < 0.001), True, False))\n",
    "\n",
    "  num_entries = (entries == True).sum() + (short_entries == True).sum()\n",
    "\n",
    "  if num_entries > min_num_entries:\n",
    "    pf = vbt.Portfolio.from_signals(\n",
    "        high              = df['BTCUSDT_High'],\n",
    "        low               = df['BTCUSDT_Low'],\n",
    "        open              = df['BTCUSDT_Open'],\n",
    "        close             = df['BTCUSDT_Close'],\n",
    "        entries           = entries, # commented out for a short only backtest    \n",
    "        short_entries     = short_entries,\n",
    "        td_stop           = prediction_window, # Hold on to the position for 8 bars\n",
    "        time_delta_format = 'Rows', # Use the row index to calculate the time delta    \n",
    "        accumulate        = False,    \n",
    "        )\n",
    "\n",
    "    key = f\"Long minus short with slopes - type 3\"    \n",
    "    slopes = PredictionWindowSlopes(0.001, 0.001, None, None, threshold, EntryType.LONG_SHORT)\n",
    "    store_backtest_results(key, pf, results_as_list, slopes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for threshold in long_minus_short_thresholds:  \n",
    "  entries       = pd.Series(np.where((df['long_minus_short'] < threshold) & (df['long_slope' ] > 0) & (df['short_slope'] > 0), True, False))\n",
    "  short_entries = pd.Series(np.where((df['long_minus_short'] < threshold) & (df['short_slope'] < 0) & (df['long_slope' ] < 0), True, False))\n",
    "\n",
    "  num_entries = (entries == True).sum() + (short_entries == True).sum()\n",
    "\n",
    "  if num_entries > min_num_entries:\n",
    "    pf = vbt.Portfolio.from_signals(\n",
    "        high              = df['BTCUSDT_High'],\n",
    "        low               = df['BTCUSDT_Low'],\n",
    "        open              = df['BTCUSDT_Open'],\n",
    "        close             = df['BTCUSDT_Close'],\n",
    "        entries           = entries, # commented out for a short only backtest    \n",
    "        short_entries     = short_entries,\n",
    "        td_stop           = prediction_window, # Hold on to the position for 8 bars\n",
    "        time_delta_format = 'Rows', # Use the row index to calculate the time delta    \n",
    "        accumulate        = False,    \n",
    "        )\n",
    "\n",
    "    key = f\"Long minus short with slopes - type 2\"    \n",
    "    slopes = PredictionWindowSlopes(0, 0, None, None, threshold, EntryType.LONG_SHORT)\n",
    "    store_backtest_results(key, pf, results_as_list, slopes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_backtest_long_minus_short_entry_type_long_short(df, results_as_list, prediction_window, threshold_increment, min_num_entries, quantiles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "long_minus_short_quantiles  = np.linspace(0, 1, num=101)\n",
    "long_minus_short_thresholds = [entry for entry in df[\"long_minus_short\"].quantile(long_minus_short_quantiles)]\n",
    "long_slope_thresholds       = [entry for entry in df[\"long_slope\"].quantile(quantiles)]\n",
    "short_slope_thresholds      = [entry for entry in df[\"short_slope\"].quantile(quantiles)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(long_minus_short_thresholds) * len(long_slope_thresholds) * len(short_slope_thresholds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lms_threshold       =np.arange(long_minus_short_min, long_minus_short_max, threshold_increment)\n",
    "long_slope_thresh   =np.arange(min_long_slope, max_long_slope, threshold_increment)\n",
    "short_slope_thresh  =np.arange(min_short_slope, max_short_slope, threshold_increment)\n",
    "\n",
    "print(len(lms_threshold) * len(long_slope_thresh) * len(short_slope_thresh))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(results_as_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ### Using hyper param optimization feature of VBT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def lms_with_slopes_indicator_func(  long_minus_short, long_slope, short_slope            # input names\n",
    "#                                    , lms_threshold, long_slope_thresh, short_slope_thresh # param names\n",
    "#                                   ):\n",
    "#     entries       = pd.Series(np.where((long_minus_short < lms_threshold) & (long_slope  > long_slope_thresh ), True, False))\n",
    "#     short_entries = pd.Series(np.where((long_minus_short < lms_threshold) & (short_slope < short_slope_thresh), True, False))\n",
    "    \n",
    "#     return entries, short_entries\n",
    "\n",
    "# lms_with_slopes_indicator = vbt.IndicatorFactory(\n",
    "#     class_name  ='LongMinusShortwithSlopes', # name of the class\n",
    "#     short_name  ='LMSWithSlopes', # name of the indicator\n",
    "#     input_names =['long_minus_short', 'long_slope', 'short_slope'], # names of input arguments\n",
    "#     param_names =['lms_threshold', 'long_slope_thresh', 'short_slope_thresh'], # names of parameters\n",
    "#     output_names=['entries', 'short_entries'], # names of output values\n",
    "# ).with_apply_func(\n",
    "#     lms_with_slopes_indicator_func, # function to apply\n",
    "#     takes_1d=True, # whether the function takes 1-dim. arrays as input\n",
    "#     lms_threshold=0.5, # default value for parameter 'lms_threshold'\n",
    "#     long_slope_thresh=0.0, # default value for parameter 'long_slope_thresh'\n",
    "#     short_slope_thresh=0.0, # default value for parameter 'short_slope_thresh'\n",
    "# )\n",
    "\n",
    "# lms_strategy = lms_with_slopes_indicator.run(\n",
    "#     long_minus_short    =df['long_minus_short'],\n",
    "#     long_slope          =df['long_slope'],\n",
    "#     short_slope         =df['short_slope'],\n",
    "#     lms_threshold       =np.arange(long_minus_short_min, long_minus_short_max, threshold_increment),\n",
    "#     long_slope_thresh   =np.arange(min_long_slope, max_long_slope, threshold_increment),\n",
    "#     short_slope_thresh  =np.arange(min_short_slope, max_short_slope, threshold_increment),\n",
    "#     param_product       =True, # True: all combinations of parameters, False: only one combination for each parameter\n",
    "# )\n",
    "# multiple_pf = vbt.Portfolio.from_signals(\n",
    "#     close               =df['BTCUSDT_Close'],\n",
    "#     high                =df['BTCUSDT_High'],\n",
    "#     low                 =df['BTCUSDT_Low'],\n",
    "#     open                =df['BTCUSDT_Open'],\n",
    "#     entries             =lms_strategy.entries,\n",
    "#     short_entries       =lms_strategy.short_entries,\n",
    "#     td_stop             =prediction_window,\n",
    "#     time_delta_format   ='Rows',\n",
    "#     accumulate          =False,\n",
    "    \n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#multiple_pf.trades.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(multiple_pf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# For Joseph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ### Run the specific backtest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# threshold = 0.356388669788838\n",
    "# long_threshold  = 0.001\n",
    "# short_threshold = 0.001\n",
    "\n",
    "# entries       = pd.Series(np.where((df['long_minus_short'] < threshold) & (df['long_slope'] > long_threshold), True, False))\n",
    "# short_entries = pd.Series(np.where((df['long_minus_short'] < threshold) & (df['short_slope'] < short_threshold), True, False))\n",
    "\n",
    "# num_entries = (entries == True).sum() + (short_entries == True).sum()\n",
    "\n",
    "# if num_entries > min_num_entries:\n",
    "#   pf = vbt.Portfolio.from_signals(\n",
    "#       high              = df['BTCUSDT_High'],\n",
    "#       low               = df['BTCUSDT_Low'],\n",
    "#       open              = df['BTCUSDT_Open'],\n",
    "#       close             = df['BTCUSDT_Close'],\n",
    "#       entries           = entries, # commented out for a short only backtest    \n",
    "#       short_entries     = short_entries,\n",
    "#       td_stop           = prediction_window, # Hold on to the position for 8 bars\n",
    "#       time_delta_format = 'Rows', # Use the row index to calculate the time delta    \n",
    "#       accumulate        = False,    \n",
    "#       )\n",
    "  \n",
    "#   key = f\"Long minus short with slopes\"\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pf.stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# threshold = 0.442388669788838\n",
    "\n",
    "# entries       = pd.Series(np.where((df['long_minus_short'] < threshold) & (df['long_slope'] > 0.001), True, False))\n",
    "# short_entries = pd.Series(np.where((df['long_minus_short'] < threshold) & (df['short_slope'] < 0.001), True, False))\n",
    "\n",
    "# num_entries = (entries == True).sum() + (short_entries == True).sum()\n",
    "\n",
    "# if num_entries > min_num_entries:\n",
    "#   pf = vbt.Portfolio.from_signals(\n",
    "#       high              = df['BTCUSDT_High'],\n",
    "#       low               = df['BTCUSDT_Low'],\n",
    "#       open              = df['BTCUSDT_Open'],\n",
    "#       close             = df['BTCUSDT_Close'],\n",
    "#       entries           = entries, # commented out for a short only backtest    \n",
    "#       short_entries     = short_entries,\n",
    "#       td_stop           = prediction_window, # Hold on to the position for 8 bars\n",
    "#       time_delta_format = 'Rows', # Use the row index to calculate the time delta    \n",
    "#       accumulate        = False,    \n",
    "#       )\n",
    "\n",
    "#   key = f\"Long minus short with slopes - type 3\"    \n",
    "#   slopes = PredictionWindowSlopes(0.001, 0.001, None, None, threshold, EntryType.LONG_SHORT)\n",
    "#   store_backtest_results(key, pf, results_as_list, slopes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# threshold = 0.500388669788838\n",
    "# entries = pd.Series(np.where((df['long_minus_short'] < threshold), True, False))\n",
    "\n",
    "# num_entries = (entries == True).sum()\n",
    "\n",
    "# if num_entries > min_num_entries:\n",
    "#     pf = vbt.Portfolio.from_signals(\n",
    "#         high              = df['BTCUSDT_High'],\n",
    "#         low               = df['BTCUSDT_Low'],\n",
    "#         open              = df['BTCUSDT_Open'],\n",
    "#         close             = df['BTCUSDT_Close'],\n",
    "#         entries           = entries, # commented out for a short only backtest    \n",
    "#         td_stop           = prediction_window, # Hold on to the position for 8 bars\n",
    "#         time_delta_format = 'Rows', # Use the row index to calculate the time delta    \n",
    "#         accumulate        = False,    \n",
    "#         )\n",
    "    \n",
    "#     key = f\"Long minus short\"    \n",
    "#     slopes = PredictionWindowSlopes(None, None, None, None, threshold, EntryType.LONG_ONLY)\n",
    "#     store_backtest_results(key, pf, results_as_list, slopes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ### Output the CSV file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pf.trades.records_readable.to_csv('../results/RID0029_136_trades.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pf.trades.records_readable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pf.trades.records_readable[pf.trades.records_readable[\"Direction\"] == \"Long\"].count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ### Output Excel file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#output_df.to_csv('../results/RID0029_dataframe.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exporting the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = export_results(results_as_list)\n",
    "results_df.to_excel(excel_output_file_name)\n",
    "export_raw_dataframe_to_csv(df, dataframe_csv_output_file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use groupby on the index (date) to calculate statistics\n",
    "# bars_per_day = df.groupby(df.index.date).size()\n",
    "# min_bars_per_day = df.groupby(df.index.date).size().min()\n",
    "# max_bars_per_day = df.groupby(df.index.date).size().max()\n",
    "# average_bars_per_day = df.groupby(df.index.date).size().mean()\n",
    "\n",
    "# print(\"Number of bars per day:\")\n",
    "# print(bars_per_day)\n",
    "\n",
    "# print(\"\\nMinimum bars per day:\", min_bars_per_day)\n",
    "# print(\"Maximum bars per day:\", max_bars_per_day)\n",
    "# print(\"Average bars per day:\", average_bars_per_day)\n",
    "# bars_per_day.to_csv(\"bars_per_day.csv\")\n",
    "\n",
    "# pf.trades.records_readable.to_csv(\"records_readable.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: for Joe\n",
    "# entries       = pd.Series(np.where((df['long_minus_short'] < 0.615659479451176) & (df['long_slope' ] > 0) & (df['short_slope'] > 0), True, False))\n",
    "# short_entries = pd.Series(np.where((df['long_minus_short'] < 0.615659479451176) & (df['short_slope'] < 0) & (df['long_slope' ] < 0), True, False))\n",
    "# clean_entries, clean_short_entries = entries.vbt.signals.clean(short_entries)\n",
    "# clean_entries.sum() + clean_short_entries.sum()\n",
    "# pf.trades.records_readable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ### Other backtests - work in progress and code may not execute at all!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['long_slope'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['short_slope'].quantile(quantiles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['actual_slope'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['long_minus_short'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(f\"Num entries = {(entries == True).sum()}\")\n",
    "# print(f\"Num short entries = {(short_entries == True).sum()}\")\n",
    "# new_df[\"long_slope\"].describe()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
