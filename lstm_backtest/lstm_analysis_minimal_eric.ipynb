{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import vectorbtpro as vbt\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vbt.settings.wrapping [\"freq\"]                  = \"1m\"\n",
    "vbt.settings.portfolio['init_cash']             = 10000\n",
    "vbt.settings.set_theme(\"dark\")\n",
    "vbt.settings.plotting[\"layout\"][\"width\"]        = 800\n",
    "vbt.settings.plotting['layout']['height']       = 300"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Settings and Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pickle_files_path = \"../data/RID0029_LSTM_pw38_lb250_bt2000_mem6000/*.pkl\"\n",
    "pickle_files_path = \"../data/RID0028_LSTM_pw75_lb250_bt2000_mem5000\"\n",
    "prediction_window = 75\n",
    "filename_prefix = pickle_files_path.split('/')[-1]\n",
    "min_num_entries          = 100\n",
    "excel_output_file_name  = f\"../results/{filename_prefix + '.xlsx'}\"\n",
    "lstm_output_file_name   = f\"../results/{filename_prefix + '_convert_to_excel.csv'}\"\n",
    "lstm_results_file_name  = f\"../results/{filename_prefix + 'lstm_model_results.csv'}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Local Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "sys.path.append(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lstm_analysis_utils import (read_pickle_files_into_df, add_forward_prices_to_df, generate_fwd_actual_column\n",
    "                                 , generate_df_with_euclidean_distances, calculate_slopes, calculate_correlation_slopes\n",
    "                                )\n",
    "from lstm_results_utils import (export_results, store_backtest_results)\n",
    "from lstm_only_backtests import run_backtest_lstm_recommendations_reversal_exits, run_backtests_lstm_recommendations_prediction_size_exit\n",
    "from lstm_analysis_constants import EntryType\n",
    "from quantile_value import generate_quantile_bands, extract_boundary_values_from_quantile_bands\n",
    "from prediction_window_slopes import PredictionWindowSlopes\n",
    "from long_slope_short_slope_backtests import run_backtest_long_slope_short_slope_prediction_size_exit, run_backtest_long_slope_short_slope_fractional_exits\n",
    "from long_minus_short_backtests import run_backtest_long_minus_short_entry_type_long_only, run_backtest_long_minus_short_entry_type_short_only, run_backtest_long_minus_short_entry_type_long_short"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_LSTM_model_results(pickle_files_path, prediction_window):\n",
    "    df = read_pickle_files_into_df(pickle_files_path)\n",
    "    add_forward_prices_to_df(df, prediction_window)\n",
    "    df= df.copy()\n",
    "    generate_fwd_actual_column(df)\n",
    "    df= generate_df_with_euclidean_distances(df, prediction_window)\n",
    "    calculate_slopes(df)\n",
    "    calculate_correlation_slopes(df)\n",
    "    df.index = pd.to_datetime(df['close_time'], utc=True, unit='s')\n",
    "    return df\n",
    "\n",
    "df = process_LSTM_model_results(pickle_files_path, prediction_window)\n",
    "# df.to_csv(lstm_results_file_name)\n",
    "# df = pd.read_csv(lstm_output_file_name, index_col=0, parse_dates=True, infer_datetime_format=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_results_file_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(lstm_results_file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Define mapping from old names to new ones\n",
    "# column_mapping = {\n",
    "#     'BTCUSDT_Open': 'Open',\n",
    "#     'BTCUSDT_High': 'High',\n",
    "#     'BTCUSDT_Low': 'Low',\n",
    "#     'BTCUSDT_Close': 'Close',\n",
    "#     'long_minus_short': 'long_minus_short',\n",
    "#     'long_slope': 'long_slope',\n",
    "#     'short_slope': 'short_slope'\n",
    "# }\n",
    "\n",
    "# # Rename columns using the mapping\n",
    "# df = df.rename(columns=column_mapping)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Paramater Combinations in VBT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lms_slope_type_3(long_minus_short, long_slope, short_slope, lms_threshold, long_slope_thresh, short_slope_thresh):\n",
    "    entries       = pd.Series(np.where((long_minus_short < lms_threshold) & (long_slope > long_slope_thresh), True, False))\n",
    "    short_entries = pd.Series(np.where((long_minus_short < lms_threshold) & (short_slope < short_slope_thresh), True, False))\n",
    "    \n",
    "    return entries, short_entries\n",
    "\n",
    "\n",
    "\n",
    "# Create an indicator factory\n",
    "lms_slope_type_3_indicator = vbt.IndicatorFactory(\n",
    "    class_name  ='LongMinusShortSlopeType3', # name of the class\n",
    "    short_name  ='lmsSlope3', # name of the indicator\n",
    "    input_names =['long_minus_short', 'long_slope', 'short_slope'], # names of input arguments\n",
    "    param_names =['lms_threshold', 'long_slope_thresh', 'short_slope_thresh'], # names of parameters\n",
    "    output_names=['entries', 'short_entries'], # names of output values\n",
    ").with_apply_func(\n",
    "    lms_slope_type_3, # function to apply\n",
    "    takes_1d=True, # whether the function takes 1-dim. arrays as input\n",
    "    lms_threshold=0.5, # default value for parameter 'lms_threshold'\n",
    "    long_slope_thresh=0.0, # default value for parameter 'long_slope_thresh'\n",
    "    short_slope_thresh=0.0, # default value for parameter 'short_slope_thresh'\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You created the strategy up above but you haven't run it yet. In this next cell we run it with a lot of different combinations. This basically builds a big matrix of all the different strategy combinations with each having a different `lms_threshold` and `long_slope_thresh` and `short_slope_thresh`. We will use these to simulate a portfolio after this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_increments         = 20\n",
    "\n",
    "lms_min                 = df.long_minus_short.min() # To narrow the range Try 0.6\n",
    "lms_max                 = df.long_minus_short.max() # and Try 1.1\n",
    "long_slope_min          = df.long_slope.min()\n",
    "long_slope_max          = df.long_slope.max()\n",
    "short_slope_min         = df.short_slope.min()\n",
    "short_slope_max         = df.short_slope.max()\n",
    "lms_increment           = abs((lms_max-lms_min)/num_increments)\n",
    "long_slope_increment    = abs((long_slope_max-long_slope_min)/num_increments)\n",
    "short_slope_increment   = abs((short_slope_max-short_slope_min)/num_increments)\n",
    "\n",
    "lms_strategy = lms_slope_type_3_indicator.run(\n",
    "    long_minus_short    =df['long_minus_short'],\n",
    "    long_slope          =df['long_slope'],\n",
    "    short_slope         =df['short_slope'],\n",
    "    lms_threshold       =np.arange(lms_min, lms_max, lms_increment),\n",
    "    long_slope_thresh   =np.arange(long_slope_min, long_slope_max, long_slope_increment),\n",
    "    short_slope_thresh  =np.arange(short_slope_min, short_slope_max, short_slope_increment),   \n",
    "    param_product=True, # True: all combinations of parameters, False: only one combination for each parameter\n",
    "    execute_kwargs=dict(\n",
    "        engine=\"threadpool\",\n",
    "        chunk_len=\"auto\",\n",
    "        show_progress=True,\n",
    "    )\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's run a portfolio simulation on all of those different parameter combinations. Note, the first time you run this it might take a bit but as you play and run it again it will get really fast."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "multiple_pf = vbt.Portfolio.from_signals(\n",
    "    close               =df['BTCUSDT_Close'],\n",
    "    high                =df['BTCUSDT_High'],\n",
    "    low                 =df['BTCUSDT_Low'],\n",
    "    open                =df['BTCUSDT_Open'],\n",
    "    entries             =lms_strategy.entries,\n",
    "    short_entries       =lms_strategy.short_entries,\n",
    "    td_stop             =prediction_window,\n",
    "    time_delta_format   ='Rows',\n",
    "    # tp_stop             =0.003,\n",
    "    # sl_stop             =0.01,\n",
    "    \n",
    "    accumulate          =False,\n",
    "    \n",
    ")\n",
    "\n",
    "print(multiple_pf.stats()) # Prints the average of all of the simulations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Show the best sharpe ratio portfolio simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_sharpe = multiple_pf.sharpe_ratio.idxmax()\n",
    "print(multiple_pf[best_sharpe].stats())\n",
    "multiple_pf[best_sharpe].plot().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a large dataframe with all of the metrics we care about"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "num_trade_filter = multiple_pf.trades.count() > 100\n",
    "\n",
    "# Use these indexes to filter multiple_pf\n",
    "filtered_pf = multiple_pf.loc[:, num_trade_filter]\n",
    "filtered_pf.trades.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a large dataframe with all of the metrics we care about"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = [\n",
    "    filtered_pf.total_return,\n",
    "    filtered_pf.trades.win_rate,\n",
    "    filtered_pf.sharpe_ratio,\n",
    "    filtered_pf.sortino_ratio,\n",
    "    filtered_pf.max_drawdown,\n",
    "    filtered_pf.trades.profit_factor,\n",
    "    filtered_pf.trades.direction_long.count(),\n",
    "    filtered_pf.trades.direction_short.count(),\n",
    "    filtered_pf.trades.direction_long.pnl.sum(),\n",
    "    filtered_pf.trades.direction_short.pnl.sum()\n",
    "]\n",
    "\n",
    "keys = [\n",
    "    'total_return',\n",
    "    'win_rate',\n",
    "    'sharpe_ratio',\n",
    "    'sortino_ratio',\n",
    "    'max_drawdown',\n",
    "    'profit_factor',\n",
    "    'long_count',\n",
    "    'short_count',\n",
    "    'long_pnl_sum',\n",
    "    'short_pnl_sum'\n",
    "]\n",
    "\n",
    "combined_stats = pd.concat(metrics, axis=1, keys=keys)\n",
    "combined_stats.to_csv(lstm_results_file_name)\n",
    "combined_stats\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sort by a metric, eg. Total Return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_stats.sort_values(by='win_rate', ascending=False).head(20)\n",
    "# combined_stats.sort_values(by='total_return', ascending=False).head(20)\n",
    "# combined_stats.sort_values(by='sortino_ratio', ascending=False).head(20)\n",
    "# combined_stats.sort_values(by='profit_factor', ascending=False).head(20)\n",
    "# combined_stats.sort_values(by='max_drawdown', ascending=False).head(20)\n",
    "# combined_stats.sort_values(by='sharpe_ratio', ascending=False).head(20)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create a dataframe for visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Stack the DataFrame to move metrics to an index level\n",
    "stacked_df = combined_stats.stack().rename(\"value\")\n",
    "\n",
    "# The resulting DataFrame (stacked_df) will have the metrics as an additional level\n",
    "# This will be appended to the end of the current multi-index\n",
    "\n",
    "# 2. If you wish to rearrange the index levels, you can use `reorder_levels`:\n",
    "# For example, if you want the metrics level (now at the end) to be the first level:\n",
    "stacked_df = stacked_df.reorder_levels(\n",
    "    [-1, 'lmsSlope3_lms_threshold', 'lmsSlope3_long_slope_thresh', 'lmsSlope3_short_slope_thresh']\n",
    ")\n",
    "\n",
    "# 3. Use the volume method\n",
    "stacked_df.vbt.volume(\n",
    "    x_level='lmsSlope3_lms_threshold',\n",
    "    y_level='lmsSlope3_long_slope_thresh',\n",
    "    z_level='lmsSlope3_short_slope_thresh',\n",
    "    slider_level=0,  # assuming the metric became the first level after rearranging\n",
    ").show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the best combination of parameters for the LSTM model\n",
    "\n",
    "# Isolate the best total return portfolio\n",
    "best_total_return = filtered_pf.total_return.max()\n",
    "print(f'The best total return of all the combinations is {best_total_return:.2%}')\n",
    "best_total_return_combination = filtered_pf.total_return.idxmax()\n",
    "print(f'The best combination for Total Return is {best_total_return_combination}')\n",
    "\n",
    "# Isolate the best max drawdown\n",
    "best_max_drawdown = filtered_pf.max_drawdown.max()\n",
    "print(f'The best max drawdown of all the combinations is {best_max_drawdown:.2%}')\n",
    "best_max_drawdown_combination = filtered_pf.max_drawdown.idxmax()\n",
    "print(f'The best combination for max drawdown is {best_max_drawdown_combination}')\n",
    "\n",
    "# Isolate the best Sharpe ratio portfolio\n",
    "best_sharpe = filtered_pf.sharpe_ratio.max()\n",
    "print(f'The best Sharpe ratio of all the combinations is {best_sharpe:.2f}')\n",
    "best_sharpe_combination = filtered_pf.sharpe_ratio.idxmax()\n",
    "print(f'The best combination for Sharpe Ratio is {best_sharpe_combination}')\n",
    "\n",
    "# Isolate the best Win Rate\n",
    "best_win_rate = filtered_pf.trades.win_rate.max()\n",
    "print(f'The best Win Rate of all the combinations is {best_win_rate:.2%}')\n",
    "best_win_rate_combination = filtered_pf.trades.win_rate.idxmax()\n",
    "print(f'The best combination for Win Rate is {best_win_rate_combination}')\n",
    "\n",
    "# isolate the best Profit Factor\n",
    "best_profit_factor = filtered_pf.trades.profit_factor.max()\n",
    "print(f'The best Profit Factor of all the combinations is {best_profit_factor:.2f}')\n",
    "best_profit_factor_combination = filtered_pf.trades.profit_factor.idxmax()\n",
    "print(f'The best combination for Profit Factor is {best_profit_factor_combination}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(multiple_pf[best_total_return_combination].stats())\n",
    "multiple_pf[best_total_return_combination].plot().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(multiple_pf[best_win_rate_combination].stats())\n",
    "multiple_pf[best_win_rate_combination].plot().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(multiple_pf[best_sharpe_combination].stats())\n",
    "print(multiple_pf[best_sharpe_combination].trades.direction_long.count())\n",
    "print(multiple_pf[best_sharpe_combination].trades.direction_short.count())\n",
    "multiple_pf[best_sharpe_combination].plot().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "multiple_pf[best_sharpe_combination].trades.records_readable #.to_csv('best_sharpe_combination.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run best profit factor sim\n",
    "\n",
    "print(multiple_pf[best_profit_factor_combination].stats())\n",
    "multiple_pf[best_profit_factor_combination].plot(height=900).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now let's run the alternate strategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clear up some memory\n",
    "\n",
    "# del lms_strategy\n",
    "# del multiple_pf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_increments         = 15\n",
    "\n",
    "lms_min                 = df.long_minus_short.min() # Try 0.6\n",
    "lms_mid                 = df.long_minus_short.median()\n",
    "lms_max                 = df.long_minus_short.max() # Try 1.1\n",
    "long_slope_min          = df.long_slope.min()\n",
    "long_slope_max          = df.long_slope.max()\n",
    "short_slope_min         = df.short_slope.min()\n",
    "short_slope_max         = df.short_slope.max()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lms_slope_type_4(long_minus_short, long_slope, short_slope, lms_threshold, long_slope_thresh, short_slope_thresh):\n",
    "    entries       = pd.Series(np.where((long_minus_short < lms_threshold) & (long_slope > long_slope_thresh), True, False))\n",
    "    exits         = pd.Series(np.where((long_minus_short > lms_threshold*1.2), True, False))\n",
    "    \n",
    "    short_entries = pd.Series(np.where((long_minus_short < lms_threshold) & (short_slope < short_slope_thresh), True, False))\n",
    "    short_exits   = pd.Series(np.where((long_minus_short > lms_threshold*1.2), True, False))\n",
    "    \n",
    "    return entries, exits, short_entries, short_exits\n",
    "\n",
    "# Create an indicator factory\n",
    "lms_slope_type_4_indicator = vbt.IndicatorFactory(\n",
    "    class_name  ='LongMinusShortSlopeType4', # name of the class\n",
    "    short_name  ='lmsSlope4', # name of the indicator\n",
    "    input_names =['long_minus_short', 'long_slope', 'short_slope'], # names of input arguments\n",
    "    param_names =['lms_threshold','long_slope_thresh', 'short_slope_thresh'], # names of parameters\n",
    "    output_names=['entries', 'exits', 'short_entries', 'short_exits'], # names of output values\n",
    ").with_apply_func(\n",
    "    lms_slope_type_4, # function to apply\n",
    "    takes_1d=True, # whether the function takes 1-dim. arrays as input\n",
    "    lms_threshold=0.7, # default value for parameter 'lms_threshold'\n",
    "    # lms_lower_threshold=0.4, # default value for parameter 'lms_lower_threshold'\n",
    "    long_slope_thresh=0.0, # default value for parameter 'long_slope_thresh'\n",
    "    short_slope_thresh=0.0, # default value for parameter 'short_slope_thresh'\n",
    ")\n",
    "lms_4_strategy = lms_slope_type_4_indicator.run(\n",
    "    long_minus_short    =df['long_minus_short'],\n",
    "    long_slope          =df['long_slope'],\n",
    "    short_slope         =df['short_slope'],\n",
    "    lms_threshold       =np.linspace(lms_min, lms_max, num_increments), \n",
    "    long_slope_thresh   =np.linspace(long_slope_min, long_slope_max, num_increments),\n",
    "    short_slope_thresh  =np.linspace(short_slope_min, short_slope_max, num_increments),\n",
    "    param_product=True, # True: all combinations of parameters, False: only one combination for each parameter\n",
    "    execute_kwargs=dict(\n",
    "        engine=\"threadpool\",\n",
    "        chunk_len=\"auto\",\n",
    "        show_progress=True,\n",
    "    )\n",
    ")\n",
    "\n",
    "multiple_pf = vbt.Portfolio.from_signals(\n",
    "    close               =df['BTCUSDT_Close'],\n",
    "    high                =df['BTCUSDT_High'],\n",
    "    low                 =df['BTCUSDT_Low'],\n",
    "    open                =df['BTCUSDT_Open'],\n",
    "    entries             =lms_4_strategy.entries,\n",
    "    exits               =lms_4_strategy.exits,\n",
    "    short_entries       =lms_4_strategy.short_entries,\n",
    "    short_exits         =lms_4_strategy.short_exits,\n",
    "    # td_stop             =prediction_window,\n",
    "    # time_delta_format   ='Rows',\n",
    "    accumulate          =False,\n",
    "    \n",
    ")\n",
    "\n",
    "print(multiple_pf.stats()) # Prints the average of all of the simulations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "multiple_pf.sortino_ratio\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "multiple_pf.sortino_ratio.idxmax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_sharpe = multiple_pf.sharpe_ratio.idxmax()\n",
    "print(multiple_pf[best_sharpe].stats())\n",
    "multiple_pf[best_sharpe].plot().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "num_trade_filter = multiple_pf.trades.count() > 100\n",
    "# Use these indexes to filter multiple_pf\n",
    "filtered_pf = multiple_pf.loc[:, num_trade_filter]\n",
    "\n",
    "metrics = [\n",
    "    filtered_pf.total_return,\n",
    "    filtered_pf.trades.win_rate,\n",
    "    filtered_pf.sharpe_ratio,\n",
    "    filtered_pf.sortino_ratio,\n",
    "    filtered_pf.max_drawdown,\n",
    "    filtered_pf.trades.profit_factor,\n",
    "    filtered_pf.trades.direction_long.count(),\n",
    "    filtered_pf.trades.direction_short.count(),\n",
    "    filtered_pf.trades.direction_long.pnl.sum(),\n",
    "    filtered_pf.trades.direction_short.pnl.sum()\n",
    "]\n",
    "\n",
    "keys = [\n",
    "    'total_return',\n",
    "    'win_rate',\n",
    "    'sharpe_ratio',\n",
    "    'sortino_ratio',\n",
    "    'max_drawdown',\n",
    "    'profit_factor',\n",
    "    'long_count',\n",
    "    'short_count',\n",
    "    'long_pnl_sum',\n",
    "    'short_pnl_sum'\n",
    "]\n",
    "\n",
    "combined_stats = pd.concat(metrics, axis=1, keys=keys)\n",
    "combined_stats.to_csv(\"combined_stats.csv\")\n",
    "combined_stats\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_stats.to_csv('combined_stats.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sort by a metric, eg. Total Return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combined_stats.sort_values(by='win_rate', ascending=False).head(20)\n",
    "combined_stats.sort_values(by='total_return', ascending=False).head(20)\n",
    "# combined_stats.sort_values(by='sortino_ratio', ascending=False).head(20)\n",
    "# combined_stats.sort_values(by='profit_factor', ascending=False).head(20)\n",
    "# combined_stats.sort_values(by='max_drawdown', ascending=False).head(20)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create a dataframe for visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Stack the DataFrame to move metrics to an index level\n",
    "stacked_df = combined_stats.stack().rename(\"value\")\n",
    "\n",
    "# The resulting DataFrame (stacked_df) will have the metrics as an additional level\n",
    "# This will be appended to the end of the current multi-index\n",
    "\n",
    "# 2. If you wish to rearrange the index levels, you can use `reorder_levels`:\n",
    "# For example, if you want the metrics level (now at the end) to be the first level:\n",
    "stacked_df = stacked_df.reorder_levels(\n",
    "    [-1, 'lmsSlope4_lms_threshold', 'lmsSlope4_long_slope_thresh', 'lmsSlope4_short_slope_thresh']\n",
    ")\n",
    "\n",
    "# 3. Use the volume method\n",
    "stacked_df.vbt.volume(\n",
    "    x_level='lmsSlope4_lms_threshold',\n",
    "    y_level='lmsSlope4_long_slope_thresh',\n",
    "    z_level='lmsSlope4_short_slope_thresh',\n",
    "    slider_level=0,  # assuming the metric became the first level after rearranging\n",
    ").show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the best combination of parameters for the LSTM model\n",
    "\n",
    "# Isolate the best total return portfolio\n",
    "best_total_return = filtered_pf.total_return.max()\n",
    "print(f'The best total return of all the combinations is {best_total_return:.2%}')\n",
    "best_total_return_combination = filtered_pf.total_return.idxmax()\n",
    "print(f'The best combination for Total Return is {best_total_return_combination}')\n",
    "\n",
    "# Isolate the best max drawdown\n",
    "best_max_drawdown = filtered_pf.max_drawdown.max()\n",
    "print(f'The best max drawdown of all the combinations is {best_max_drawdown:.2%}')\n",
    "best_max_drawdown_combination = filtered_pf.max_drawdown.idxmax()\n",
    "print(f'The best combination for max drawdown is {best_max_drawdown_combination}')\n",
    "\n",
    "# Isolate the best Sharpe ratio portfolio\n",
    "best_sharpe = filtered_pf.sharpe_ratio.max()\n",
    "print(f'The best Sharpe ratio of all the combinations is {best_sharpe:.2f}')\n",
    "best_sharpe_combination = filtered_pf.sharpe_ratio.idxmax()\n",
    "print(f'The best combination for Sharpe Ratio is {best_sharpe_combination}')\n",
    "\n",
    "# Isolate the best Win Rate\n",
    "best_win_rate = filtered_pf.trades.win_rate.max()\n",
    "print(f'The best Win Rate of all the combinations is {best_win_rate:.2%}')\n",
    "best_win_rate_combination = filtered_pf.trades.win_rate.idxmax()\n",
    "print(f'The best combination for Win Rate is {best_win_rate_combination}')\n",
    "\n",
    "# isolate the best Profit Factor\n",
    "best_profit_factor = filtered_pf.trades.profit_factor.max()\n",
    "print(f'The best Profit Factor of all the combinations is {best_profit_factor:.2f}')\n",
    "best_profit_factor_combination = filtered_pf.trades.profit_factor.idxmax()\n",
    "print(f'The best combination for Profit Factor is {best_profit_factor_combination}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(multiple_pf[best_total_return_combination].stats())\n",
    "multiple_pf[best_total_return_combination].plot().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(multiple_pf[best_win_rate_combination].stats())\n",
    "multiple_pf[best_win_rate_combination].plot().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(multiple_pf[best_sharpe_combination].stats())\n",
    "print(multiple_pf[best_sharpe_combination].trades.direction_long.count())\n",
    "print(multiple_pf[best_sharpe_combination].trades.direction_short.count())\n",
    "multiple_pf[best_sharpe_combination].plot().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "multiple_pf[best_sharpe_combination].trades.records_readable #.to_csv('best_sharpe_combination.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run best profit factor sim\n",
    "\n",
    "print(multiple_pf[best_profit_factor_combination].stats())\n",
    "multiple_pf[best_profit_factor_combination].plot(height=900).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
