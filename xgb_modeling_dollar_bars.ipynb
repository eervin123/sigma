{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c69786c2-7c5b-4b1e-bd0c-52380c8df261",
   "metadata": {},
   "source": [
    "# XGBoost with Cross Validation and PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2751478-95ce-47d2-9e80-4d47ed0c7b36",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from numba import njit\n",
    "import vectorbtpro as vbt\n",
    "vbt.settings.set_theme(\"dark\")\n",
    "vbt.settings.plotting[\"layout\"][\"width\"] = 800\n",
    "vbt.settings.plotting['layout']['height'] = 200\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.linear_model import Ridge, Lasso, ElasticNet, LinearRegression, LogisticRegression\n",
    "from sklearn.svm import SVR, SVC\n",
    "from xgboost import XGBRegressor, XGBClassifier\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "clf = RandomForestClassifier(random_state=42) # random forest classifier\n",
    "from joblib import dump, load\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "935ca582-ef09-40f9-b6ff-c303c98989b1",
   "metadata": {},
   "source": [
    "### Modeling\n",
    "The class Splitter can also be helpful in cross-validating ML models. In particular, you can casually step upon a class SKLSplitter that acts as a regular cross-validator from scikit-learn by subclassing BaseCrossValidator. We'll demonstrate its usage on a simple classification problem of predicting the best entry and exit timings.\n",
    "\n",
    "Before we start, we need to decide on features and labels that should act as predictor and response variables respectively. Features are usually multi-columnar time-series DataFrames where each row contains multiple data points (one per column) that should predict the same row in labels. Labels are usually a single-columnar time-series Series that should be predicted. Ask yourself the following questions to easily come up with a decision:\n",
    "\n",
    "\"How can the future performance be represented, preferably as a single number? Should it be the price at the next bar, the average price change over the next week, a vector of weights for rebalancing, a boolean containing a signal, or something else?\"\n",
    "\"What kind of data that encompasses the past performance is likely to predict the future performance? Should it be indicators, news sentiment index, past backtesting results, or something else?\"\n",
    "\"Which ML model can handle such a task?\" (remember that most models are limited to just a couple of specific feature and label formats!)\n",
    "For the sake of an example, we'll fit a random forest classifier on all TA-Lib indicators stacked along columns to predict the binary labels generated by the label generator TRENDLB, where 1 means an uptrend and 0 means a downtrend. Sounds like fun ðŸ˜Œ"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "41119985",
   "metadata": {},
   "source": [
    "Build a pipeline to impute and (standard-)normalize the data, [reduce the dimensionality](https://scikit-learn.org/stable/auto_examples/compose/plot_digits_pipe.html) of the features, as well as fit one of the [linear](https://scikit-learn.org/stable/modules/linear_model.html) models to predict the average price change over the next n bars (i.e., regression task!). Based on each prediction, you can then decide whether a position is worth opening or closing out. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "eef4fc9a",
   "metadata": {},
   "source": [
    "# Let's experiment"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b42b8366",
   "metadata": {},
   "source": [
    "Smaller resolution but using dollar bars"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "767f3215",
   "metadata": {},
   "source": [
    "# Helper functions\n",
    "Create dollar bars and add them to the original df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d6acc72",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def dollar_bar_func(ohlc_df, dollar_bar_size):\n",
    "    # Calculate dollar value traded for each row\n",
    "    ohlc_df['DollarValue'] = ohlc_df['Close'] * ohlc_df['Volume']\n",
    "    \n",
    "    # Calculate cumulative dollar value\n",
    "    ohlc_df['CumulativeDollarValue'] = ohlc_df['DollarValue'].cumsum()\n",
    "    \n",
    "    # Determine the number of dollar bars\n",
    "    num_bars = int(ohlc_df['CumulativeDollarValue'].iloc[-1] / dollar_bar_size)\n",
    "    \n",
    "    # Generate index positions for dollar bars\n",
    "    bar_indices = [0]\n",
    "    cumulative_value = 0\n",
    "    for i in range(1, len(ohlc_df)):\n",
    "        cumulative_value += ohlc_df['DollarValue'].iloc[i]\n",
    "        if cumulative_value >= dollar_bar_size:\n",
    "            bar_indices.append(i)\n",
    "            cumulative_value = 0\n",
    "    \n",
    "    # Create a new dataframe with dollar bars\n",
    "    dollar_bars = []\n",
    "    for i in range(len(bar_indices) - 1):\n",
    "        start_idx = bar_indices[i]\n",
    "        end_idx = bar_indices[i + 1]\n",
    "        \n",
    "        dollar_bar = {\n",
    "            'Open': ohlc_df['Open'].iloc[start_idx],\n",
    "            'High': ohlc_df['High'].iloc[start_idx:end_idx].max(),\n",
    "            'Low': ohlc_df['Low'].iloc[start_idx:end_idx].min(),\n",
    "            'Close': ohlc_df['Close'].iloc[end_idx],\n",
    "            'Volume': ohlc_df['Volume'].iloc[start_idx:end_idx].sum(),\n",
    "            'Quote volume': ohlc_df['Quote volume'].iloc[start_idx:end_idx].sum(),\n",
    "            'Trade count': ohlc_df['Trade count'].iloc[start_idx:end_idx].sum(),\n",
    "            'Taker base volume': ohlc_df['Taker base volume'].iloc[start_idx:end_idx].sum(),\n",
    "            'Taker quote volume': ohlc_df['Taker quote volume'].iloc[start_idx:end_idx].sum()\n",
    "        }\n",
    "        \n",
    "        if isinstance(ohlc_df.index, pd.DatetimeIndex):\n",
    "            dollar_bar['Open Time'] = ohlc_df.index[start_idx]\n",
    "            dollar_bar['Close Time'] = ohlc_df.index[end_idx] - pd.Timedelta(milliseconds=1)\n",
    "        elif 'Open Time' in ohlc_df.columns:\n",
    "            dollar_bar['Open Time'] = ohlc_df['Open Time'].iloc[start_idx]\n",
    "            dollar_bar['Close Time'] = ohlc_df['Open Time'].iloc[end_idx] - pd.Timedelta(milliseconds=1)\n",
    "        \n",
    "        dollar_bars.append(dollar_bar)\n",
    "    \n",
    "    dollar_bars_df = pd.concat([pd.DataFrame([bar]) for bar in dollar_bars], ignore_index=True)\n",
    "    \n",
    "    return dollar_bars_df\n",
    "\n",
    "# Create a simple function to simplify the number so we can use it in our column names\n",
    "def simplify_number(num):\n",
    "    \"\"\"\n",
    "    Simplifies a large number by converting it to a shorter representation with a suffix (K, M, B).\n",
    "    simplify_number(1000) -> 1K\n",
    "    \"\"\"\n",
    "    suffixes = ['', 'K', 'M', 'B']\n",
    "    suffix_index = 0\n",
    "\n",
    "    while abs(num) >= 1000 and suffix_index < len(suffixes) - 1:\n",
    "        num /= 1000.0\n",
    "        suffix_index += 1\n",
    "\n",
    "    suffix = suffixes[suffix_index] if suffix_index > 0 else ''\n",
    "    simplified_num = f'{int(num)}{suffix}'\n",
    "\n",
    "    return simplified_num\n",
    "\n",
    "def merge_and_fill_dollar_bars(original_df, dollar_bars_df, dollar_bar_size):\n",
    "    # Add prefix to column names in dollar bars dataframe\n",
    "    dollar_bar_prefix = f'db_{simplify_number(dollar_bar_size)}_'\n",
    "    dollar_bars_df_renamed = dollar_bars_df.add_prefix(dollar_bar_prefix)\n",
    "\n",
    "    # Convert 'Open Time' columns to pandas datetime format and set them as index\n",
    "    dollar_bars_df_renamed.index = pd.to_datetime(dollar_bars_df_renamed[dollar_bar_prefix + 'Open Time'])\n",
    "\n",
    "    # Merge the dataframes on the index\n",
    "    merged_df = original_df.merge(dollar_bars_df_renamed, how='left', left_index=True, right_index=True)\n",
    "\n",
    "    # Set the flag for a new dollar bar with prefix\n",
    "    merged_df[dollar_bar_prefix + 'NewDBFlag'] = ~merged_df[dollar_bar_prefix + 'Close'].isna()\n",
    "\n",
    "    # Forward fill the NaN values for all columns except the new dollar bar flag\n",
    "    columns_to_ffill = [col for col in merged_df.columns if col != dollar_bar_prefix + 'NewDBFlag']\n",
    "    merged_df[columns_to_ffill] = merged_df[columns_to_ffill].fillna(method='ffill')\n",
    "\n",
    "    # Fill the remaining NaN values in the new dollar bar flag column with False\n",
    "    merged_df[dollar_bar_prefix + 'NewDBFlag'] = merged_df[dollar_bar_prefix + 'NewDBFlag'].fillna(False)\n",
    "    \n",
    "    # Assign the renamed 'Open Time' column back to the dataframe\n",
    "    merged_df[dollar_bar_prefix + 'Open Time'] = merged_df[dollar_bar_prefix + 'Open Time']\n",
    "\n",
    "    return merged_df\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "469e8b28",
   "metadata": {},
   "source": [
    "# Calculate Dollar Bars\n",
    "Calc Dollar bars and then add technical analysis features\n",
    "\n",
    "Uncomment this section if you want to run different size dollar bars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5c2b8de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dollar_bar_size = 90_000_000\n",
    "# btc_dollar_bars = dollar_bar_func(futures_1m.get(), dollar_bar_size=dollar_bar_size)\n",
    "# btc_dollar_bars.index = pd.to_datetime(btc_dollar_bars['Open Time'])\n",
    "# btc_dollar_bars.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "640f40b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the dataframe back into a vbt data object\n",
    "# btc_90M_db_vbt = vbt.BinanceData.from_data(btc_dollar_bars)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc8cee12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the dollarbars to a pickle file\n",
    "# btc_90M_db_vbt.save('btc_90M_db_vbt.pkl')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c770a46d",
   "metadata": {},
   "source": [
    "# Load the dollar bars from pickle file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15451db6",
   "metadata": {},
   "outputs": [],
   "source": [
    "btc_90M_db_vbt = vbt.BinanceData.load('data/btc_90M_db_vbt.pkl')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "78e34cf7",
   "metadata": {},
   "source": [
    "Take a small slice of the data for train/testing and leave some to be out of sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca083be1",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = btc_90M_db_vbt['2021-01-01':'2023-01-01']\n",
    "outofsample_data = btc_90M_db_vbt['2023-01-01':'2023-06-03']\n",
    "print(data.shape)\n",
    "print(outofsample_data.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "1cea4860",
   "metadata": {},
   "source": [
    "# Generate features for the model\n",
    "Note I originally tried adding all of the talib indicators with default params to the model this was pretty good on daily data but on dollar bars it seemed to confuse the model. In the below we are simply adding the trend binary classifier and the calendar features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76c3e730",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import talib\n",
    "# print(talib.get_function_groups())\n",
    "# # Not sure how to call just a single indicator group so I'll just call all of them\n",
    "# vbt.IF.list_indicators(\"psar\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c972edc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "n = 150 # number of periods in the future to predict\n",
    "\n",
    "# Generate the features (X) using TA-Lib indicators\n",
    "# X = data.run(\"talib\", periods=vbt.run_func_dict(mavp=n))\n",
    "X = data.get()\n",
    "# add trend label as a feature if the market is up 20% it is in a bullish trend and if it is down 5% it is in a bearish trend\n",
    "# Read more about the pivotinfo below in the next couple cells\n",
    "pivot_info = data.run(\"pivotinfo\", up_th=.30, down_th=0.05)\n",
    "binary_pivot_labels = np.where(data.close > pivot_info.conf_value,1,0) # Create binary labels for pivot points\n",
    "X['trend'] = binary_pivot_labels # add pivot label as a feature\n",
    "# Add time features\n",
    "X['dayofmonth'] = X.index.day\n",
    "X['month'] = X.index.month\n",
    "X['year'] = X.index.year\n",
    "X['hour'] = X.index.hour\n",
    "X['minute'] = X.index.minute\n",
    "X['dayofweek'] = X.index.dayofweek\n",
    "X['dayofyear'] = X.index.dayofyear\n",
    "\n",
    "# Now we are trying to generate future price predictions so we will set the y labels to the price change n periods in the future\n",
    "y = (data.close.shift(-n) / data.close - 1).rolling(n).mean() # future price change we use rolling mean to smooth the data\n",
    "\n",
    "# Preprocessing steps to handle NaNs\n",
    "X = X.replace([-np.inf, np.inf], np.nan) # replace inf with nan\n",
    "invalid_column_mask = X.isnull().all(axis=0) | (X.nunique() == 1) # drop columns that are all nan or have only one unique value\n",
    "X = X.loc[:, ~invalid_column_mask] # drop invalid columns\n",
    "invalid_row_mask = X.isnull().any(axis=1) | y.isnull() # drop rows that have nan in any column or in y\n",
    "\n",
    "# Drop invalid rows in X and y\n",
    "X = X.loc[~invalid_row_mask]\n",
    "y = y.loc[~invalid_row_mask]\n",
    "# Drop Open time and close time\n",
    "X = X.drop(['Open Time','Close Time'], axis=1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "fe24ff39",
   "metadata": {},
   "source": [
    "Previously I used the trendlb with great results, but unfortunately it has a look ahead bias DUH no wonder it had such great results."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "cc0d479d",
   "metadata": {},
   "source": [
    "## A replacement for TRENDLB - PIVOTINFO\n",
    "VBT has a pivotinfo method that avoids lookahead bias. Below we plot the pivot points and we create a similar binary version like trendlb\n",
    "\n",
    "IMPORTANT: Clear the plot outputs before pushing to Github"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcdb80bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fig = data.plot(plot_volume=False)\n",
    "trendwithlookahead = data.run('trendlb', 0.20, 0.05, mode='binary').labels\n",
    "trendwithlookahead.rename('trendlb', inplace=True)\n",
    "pivot_info = data.run(\"pivotinfo\", up_th=.20, down_th=0.05)\n",
    "binary_pivot_labels = np.where(data.close > pivot_info.conf_value,1,0) # Create binary labels for pivot points\n",
    "print('Trend with look ahead bias')\n",
    "data.close.vbt.overlay_with_heatmap(trendwithlookahead).show() # plot the trend labels\n",
    "print('Using pivot points no look ahead bias')\n",
    "data.close.vbt.overlay_with_heatmap(binary_pivot_labels).show() # plot the pivot labels\n",
    "print('Here are the actual pivot points')\n",
    "pivot_info.plot(fig=fig, conf_value_trace_kwargs=dict(visible=False))\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ad3fa61",
   "metadata": {},
   "outputs": [],
   "source": [
    "del fig # delete the figure to free up memory"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "60513cb3",
   "metadata": {},
   "source": [
    "### We now need to tinker with these params\n",
    "up_th and down_th to see if we can get the optimal params. but for now I'm just going to use the same ones that I used for trendlb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4be1d30f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Construct the pipeline\n",
    "steps = [\n",
    "    ('imputation', SimpleImputer(strategy='mean')),  # Imputation replaces missing values\n",
    "    ('scaler', StandardScaler()),  # StandardScaler normalizes the data\n",
    "    ('pca', PCA(n_components=15)),  # PCA reduces dimensionality\n",
    "    \n",
    "    # Choose one of the following models\n",
    "    # ('model', Ridge())  # Ridge regression is used as the prediction model\n",
    "    # ('model', LinearRegression())  # Linear regression is used as the prediction model\n",
    "    # ('model', LogisticRegression())  # Logistic regression is used as the prediction model\n",
    "    # ('model', Lasso())  # Lasso regression is used as the prediction model\n",
    "    # ('model', ElasticNet())  # ElasticNet regression is used as the prediction model\n",
    "    # ('model', SVR())  # Support Vector Regression is used as the prediction model\n",
    "    ('model', XGBRegressor(objective='reg:squarederror'))  # XGBoost regression is used as the prediction model\n",
    "]\n",
    "pipeline = Pipeline(steps)\n",
    "\n",
    "# Cross-validate Creates a cross-validation object with all the indexes for each cv split\n",
    "cv = vbt.SKLSplitter(\n",
    "    \"from_expanding\",\n",
    "    min_length=600,\n",
    "    offset=200,\n",
    "    split=-200,\n",
    "    set_labels=[\"train\", \"test\"]\n",
    ")\n",
    "\n",
    "cv_splitter = cv.get_splitter(X)\n",
    "# Plot the cross-validation splits\n",
    "# cv_splitter.plot().show_svg()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "99fb4fc3",
   "metadata": {},
   "source": [
    "drop the datetime columns the ML model doesn't like them. It prefers numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d10445b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fb3e4a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "X.columns"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "50332988",
   "metadata": {},
   "source": [
    "Run some predictions. NOTE: if you want to skip ahead to save time on your machine, just scroll down to where we load the model from disk. I've already trained a model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Use your pipeline to compress features and fit the model for predictions\n",
    "# print(f'Pipeline Steps :{pipeline.steps}')\n",
    "# pipeline.fit(X, y)  # Fit the pipeline on the entire dataset    \n",
    "# print(f'Pipeline Score :{pipeline.score(X, y)}')  # Score the pipeline on the entire dataset of training data\n",
    "# scores = cross_val_score(pipeline, X, y, cv=cv, scoring=\"r2\", n_jobs=-1, verbose=100) # how well the model generalizes to unseen data\n",
    "# average_score = np.mean(scores)\n",
    "# print(f'Average cross-validation score: {average_score}')\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "3792613e",
   "metadata": {},
   "source": [
    "## Run our cross validation\n",
    "Again to skip ahead just scroll down to load the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c471f680",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Predictions\n",
    "X_slices = cv_splitter.take(X)\n",
    "y_slices = cv_splitter.take(y)\n",
    "\n",
    "test_labels = []\n",
    "test_preds = []\n",
    "for split in X_slices.index.unique(level=\"split\"):  \n",
    "    X_train_slice = X_slices[(split, \"train\")]  \n",
    "    y_train_slice = y_slices[(split, \"train\")]\n",
    "    X_test_slice = X_slices[(split, \"test\")]\n",
    "    y_test_slice = y_slices[(split, \"test\")]\n",
    "    slice_pipeline = pipeline.fit(X_train_slice, y_train_slice)  \n",
    "    test_pred = slice_pipeline.predict(X_test_slice)  \n",
    "    test_pred = pd.Series(test_pred, index=y_test_slice.index)\n",
    "    test_labels.append(y_test_slice)\n",
    "    test_preds.append(test_pred)\n",
    "    print(f\"Split {split} R-squared: {r2_score(y_test_slice, test_pred)}\")\n",
    "\n",
    "test_labels = pd.concat(test_labels).rename(\"labels\")  \n",
    "test_preds = pd.concat(test_preds).rename(\"preds\")\n",
    "\n",
    "# Show the accuracy of the predictions\n",
    "# Assuming test_labels and test_preds are your true and predicted values\n",
    "mse = mean_squared_error(test_labels, test_preds)\n",
    "rmse = np.sqrt(mse)  # or use mean_squared_error with squared=False\n",
    "mae = mean_absolute_error(test_labels, test_preds)\n",
    "r2 = r2_score(test_labels, test_preds)\n",
    "\n",
    "print(f\"Mean Squared Error (MSE): {mse}\")\n",
    "print(f\"Root Mean Squared Error (RMSE): {rmse}\")\n",
    "print(f\"Mean Absolute Error (MAE): {mae}\")\n",
    "print(f\"R-squared: {r2}\")\n",
    "\n",
    "# Visualize the predictions as a heatmap plotted against the price\n",
    "# data.close.vbt.overlay_with_heatmap(test_preds).show_svg()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec35f948",
   "metadata": {},
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "514e99fe",
   "metadata": {},
   "source": [
    "### Save the model\n",
    "this just saves the last cross validation model. Uncomment the below if you ran a model and want to save it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84262055",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "filename = 'models/model_upto_2023_with_pivot.joblib'\n",
    "dump(slice_pipeline, filename)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ec2b6a55",
   "metadata": {},
   "source": [
    "# Load the model from storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f4262dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'models/model_upto_2023_with_pivot.joblib'\n",
    "# Load the model from the .joblib file\n",
    "final_pipeline = load(filename) \n",
    "\n",
    "# Make predictions on the entire dataset\n",
    "insample_predictions = final_pipeline.predict(X)\n",
    "\n",
    "# Calculate the R-squared score on the entire dataset\n",
    "r2 = r2_score(y, insample_predictions)\n",
    "\n",
    "print(f\"R-squared on the entire dataset: {r2}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d842c53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the predictions versus the actuals\n",
    "# yoos is the actuals and outofsample_predictions is the predictions\n",
    "plt.scatter(test_labels, test_preds, alpha=0.2)\n",
    "# Add a line of best fit\n",
    "m, b = np.polyfit(test_labels, test_preds, 1)\n",
    "plt.plot(y, m*y + b, color='red')\n",
    "\n",
    "# Add the formula for the slope and intercept\n",
    "plt.text(0.05, 0.95, f\"y = {m:.2f}x + {b:.2f}\", transform=plt.gca().transAxes)\n",
    "\n",
    "# Add the y and x axis labels\n",
    "plt.xlabel(\"Actuals\")\n",
    "plt.ylabel(\"Predictions\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ed07d6d6",
   "metadata": {},
   "source": [
    "Trained and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d319a581",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the predictions versus the actuals\n",
    "# yoos is the actuals and outofsample_predictions is the predictions\n",
    "plt.scatter(y, insample_predictions, alpha=0.2)\n",
    "# Add a line of best fit\n",
    "m, b = np.polyfit(y, insample_predictions, 1)\n",
    "plt.plot(y, m*y + b, color='red')\n",
    "\n",
    "# Add the formula for the slope and intercept\n",
    "plt.text(0.05, 0.95, f\"y = {m:.2f}x + {b:.2f}\", transform=plt.gca().transAxes)\n",
    "\n",
    "# Add the y and x axis labels\n",
    "plt.xlabel(\"Actuals\")\n",
    "plt.ylabel(\"Predictions\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "916f6d12",
   "metadata": {},
   "source": [
    "# Test it on out of sample data\n",
    "2023 Was never trained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3124064b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "n = 150 # number of periods in the future to predict\n",
    "\n",
    "# Generate the features (X) using TA-Lib indicators\n",
    "# X = data.run(\"talib\", periods=vbt.run_func_dict(mavp=n))\n",
    "Xoos = outofsample_data.get()\n",
    "# psar_vbt = outofsample_data.run(\"pandas_ta:PSAR\", append=True, acceleration=0.02, maximum=0.2) # I didn't end up using this\n",
    "# add trend label as a feature\n",
    "# Read more about the pivotinfo below in the next couple cells\n",
    "pivot_info = outofsample_data.run(\"pivotinfo\", up_th=.30, down_th=0.05)\n",
    "binary_pivot_labels = np.where(outofsample_data.close > pivot_info.conf_value,1,0) # Create binary labels for pivot points\n",
    "Xoos['trend'] = binary_pivot_labels # add pivot label as a feature\n",
    "# X['psar_cross'] = psar_vbt.psarr\n",
    "# Drop the time columns\n",
    "# Drop Open time and close time\n",
    "Xoos = Xoos.drop(['Open Time','Close Time'], axis=1)\n",
    "# Add time features\n",
    "Xoos['dayofmonth']  = Xoos.index.day\n",
    "Xoos['month']       = Xoos.index.month\n",
    "Xoos['year']        = Xoos.index.year\n",
    "Xoos['hour']        = Xoos.index.hour\n",
    "Xoos['minute']      = Xoos.index.minute\n",
    "Xoos['dayofweek']   = Xoos.index.dayofweek\n",
    "Xoos['dayofyear']   = Xoos.index.dayofyear\n",
    "\n",
    "# Now we are trying to generate future price predictions so we will set the y labels to the price change n periods in the future\n",
    "yoos = (outofsample_data.close.shift(-n) / outofsample_data.close - 1).rolling(n).mean() # future price change we use rolling mean to smooth the data\n",
    "\n",
    "# Preprocessing steps to handle NaNs\n",
    "Xoos = Xoos.replace([-np.inf, np.inf], np.nan) # replace inf with nan\n",
    "invalid_column_mask = Xoos.isnull().all(axis=0) #| (Xoos.nunique() == 1) # removed the second condition because `year` column is always the same for 2023\n",
    "Xoos = Xoos.loc[:, ~invalid_column_mask] # drop invalid columns\n",
    "invalid_row_mask = Xoos.isnull().any(axis=1) | yoos.isnull() # drop rows that have nan in any column or in y\n",
    "\n",
    "# Drop invalid rows in X and y\n",
    "Xoos = Xoos.loc[~invalid_row_mask]\n",
    "yoos = yoos.loc[~invalid_row_mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04e7bbd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(yoos.shape)\n",
    "print(Xoos.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "cb2e6bff",
   "metadata": {},
   "source": [
    "### Test the model on data it has never seen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76e7ee74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions on the entire dataset\n",
    "outofsample_predictions = final_pipeline.predict(Xoos)\n",
    "\n",
    "# Calculate the R-squared score on the entire dataset\n",
    "r2 = r2_score(yoos, outofsample_predictions)\n",
    "\n",
    "print(f\"R-squared on the out of sample dataset: {r2}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a2aa3065",
   "metadata": {},
   "source": [
    "### Create a scatterplot of the predictions vs the actuals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdce16da",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Visualize the predictions versus the actuals\n",
    "# yoos is the actuals and outofsample_predictions is the predictions\n",
    "plt.scatter(yoos, outofsample_predictions)\n",
    "# Add a line of best fit\n",
    "m, b = np.polyfit(yoos, outofsample_predictions, 1)\n",
    "plt.plot(yoos, m*yoos + b, color='red')\n",
    "\n",
    "# Add the formula for the slope and intercept\n",
    "plt.text(0.05, 0.95, f\"y = {m:.2f}x + {b:.2f}\", transform=plt.gca().transAxes)\n",
    "\n",
    "# Add the y and x axis labels\n",
    "plt.xlabel(\"Actuals\")\n",
    "plt.ylabel(\"Predictions\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68199994",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a pandas dataframe or series with the predictions and the index from the out of sample data\n",
    "outofsample_predictions = pd.Series(outofsample_predictions, index=yoos.index)\n",
    "outofsample_predictions = outofsample_predictions.rename(\"outofsample_predictions\")\n",
    "outofsample_predictions"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "9436f31c",
   "metadata": {},
   "source": [
    "# Emulate a production scenario on out of sample data\n",
    "## Retrain the model every 200 bars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "512c62da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the model\n",
    "# Preprocess the data\n",
    "# Create Cross Validations for training and testing on newly seen data\n",
    "# Train the model\n",
    "# Make predictions\n",
    "# Test and evaluate the model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9d9e9ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'models/model_upto_2023_with_pivot.joblib'\n",
    "# Load the model from the .joblib file\n",
    "final_pipeline = load(filename) \n",
    "\n",
    "# Make predictions on the entire dataset\n",
    "insample_predictions = final_pipeline.predict(X)\n",
    "\n",
    "# Calculate the R-squared score on the entire dataset\n",
    "r2 = r2_score(y, insample_predictions)\n",
    "\n",
    "print(f\"R-squared on the entire dataset: {r2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e917d8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "n = 150 # number of periods in the future to predict\n",
    "\n",
    "# Generate the features (X) using TA-Lib indicators\n",
    "# X = data.run(\"talib\", periods=vbt.run_func_dict(mavp=n))\n",
    "Xoos = outofsample_data.get()\n",
    "# psar_vbt = outofsample_data.run(\"pandas_ta:PSAR\", append=True, acceleration=0.02, maximum=0.2) # I didn't end up using this\n",
    "# add trend label as a feature\n",
    "# Read more about the pivotinfo below in the next couple cells\n",
    "pivot_info = outofsample_data.run(\"pivotinfo\", up_th=.30, down_th=0.05)\n",
    "binary_pivot_labels = np.where(outofsample_data.close > pivot_info.conf_value,1,0) # Create binary labels for pivot points\n",
    "Xoos['trend'] = binary_pivot_labels # add pivot label as a feature\n",
    "# X['psar_cross'] = psar_vbt.psarr\n",
    "# Drop the time columns\n",
    "# Drop Open time and close time\n",
    "Xoos = Xoos.drop(['Open Time','Close Time'], axis=1)\n",
    "# Add time features\n",
    "Xoos['dayofmonth']  = Xoos.index.day\n",
    "Xoos['month']       = Xoos.index.month\n",
    "Xoos['year']        = Xoos.index.year\n",
    "Xoos['hour']        = Xoos.index.hour\n",
    "Xoos['minute']      = Xoos.index.minute\n",
    "Xoos['dayofweek']   = Xoos.index.dayofweek\n",
    "Xoos['dayofyear']   = Xoos.index.dayofyear\n",
    "\n",
    "# Now we are trying to generate future price predictions so we will set the y labels to the price change n periods in the future\n",
    "yoos = (outofsample_data.close.shift(-n) / outofsample_data.close - 1).rolling(n).mean() # future price change we use rolling mean to smooth the data\n",
    "\n",
    "# Preprocessing steps to handle NaNs\n",
    "Xoos = Xoos.replace([-np.inf, np.inf], np.nan) # replace inf with nan\n",
    "invalid_column_mask = Xoos.isnull().all(axis=0) #| (Xoos.nunique() == 1) # removed the second condition because `year` column is always the same for 2023\n",
    "Xoos = Xoos.loc[:, ~invalid_column_mask] # drop invalid columns\n",
    "invalid_row_mask = Xoos.isnull().any(axis=1) | yoos.isnull() # drop rows that have nan in any column or in y\n",
    "\n",
    "# Drop invalid rows in X and y\n",
    "Xoos = Xoos.loc[~invalid_row_mask]\n",
    "yoos = yoos.loc[~invalid_row_mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9adb0b4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Cross-validate Creates a cross-validation object with all the indexes for each cv split\n",
    "cv = vbt.SKLSplitter(\n",
    "    \"from_expanding\",\n",
    "    min_length=600,\n",
    "    offset=200,\n",
    "    split=-200,\n",
    "    set_labels=[\"train\", \"test\"]\n",
    ")\n",
    "\n",
    "cv_splitter = cv.get_splitter(Xoos)\n",
    "\n",
    "# Predictions\n",
    "X_slices = cv_splitter.take(Xoos)\n",
    "y_slices = cv_splitter.take(yoos)\n",
    "\n",
    "test_labels = []\n",
    "test_preds = []\n",
    "for split in X_slices.index.unique(level=\"split\"):  \n",
    "    X_train_slice = X_slices[(split, \"train\")]  \n",
    "    y_train_slice = y_slices[(split, \"train\")]\n",
    "    X_test_slice = X_slices[(split, \"test\")]\n",
    "    y_test_slice = y_slices[(split, \"test\")]\n",
    "    slice_pipeline = pipeline.fit(X_train_slice, y_train_slice)  \n",
    "    test_pred = slice_pipeline.predict(X_test_slice)  \n",
    "    test_pred = pd.Series(test_pred, index=y_test_slice.index)\n",
    "    test_labels.append(y_test_slice)\n",
    "    test_preds.append(test_pred)\n",
    "    print(f\"Split {split} R-squared: {r2_score(y_test_slice, test_pred)}\")\n",
    "\n",
    "oos_test_labels = pd.concat(test_labels).rename(\"labels\")  \n",
    "oos_test_preds = pd.concat(test_preds).rename(\"preds\")\n",
    "\n",
    "# Show the accuracy of the predictions\n",
    "# Assuming test_labels and test_preds are your true and predicted values\n",
    "mse = mean_squared_error(test_labels, test_preds)\n",
    "rmse = np.sqrt(mse)  # or use mean_squared_error with squared=False\n",
    "mae = mean_absolute_error(test_labels, test_preds)\n",
    "r2 = r2_score(test_labels, test_preds)\n",
    "\n",
    "print(f\"Mean Squared Error (MSE): {mse}\")\n",
    "print(f\"Root Mean Squared Error (RMSE): {rmse}\")\n",
    "print(f\"Mean Absolute Error (MAE): {mae}\")\n",
    "print(f\"R-squared: {r2}\")\n",
    "\n",
    "# Visualize the predictions as a heatmap plotted against the price\n",
    "# data.close.vbt.overlay_with_heatmap(test_preds).show_svg()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "427cb20e",
   "metadata": {},
   "source": [
    "### Simulate a portfolio in 2023 with retraining the model every 200 bars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "078913c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "oos_retraining_pf = vbt.Portfolio.from_signals(\n",
    "    outofsample_data.close[oos_test_preds.index], # use only the test set\n",
    "    entries         = oos_test_preds > 0.05, # long when probability of price increase is greater than 2%\n",
    "    exits           = oos_test_preds < 0.00, # long when probability of price increase is greater than 2%\n",
    "    short_entries   = oos_test_preds < -0.04, # long when probability of price increase is greater than 2%\n",
    "    short_exits     = oos_test_preds > 0.0, # short when probability prediction is less than -5%\n",
    "    # direction=\"both\" # long and short\n",
    ")\n",
    "print(oos_retraining_pf.stats())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa09a30f",
   "metadata": {},
   "outputs": [],
   "source": [
    "oos_retraining_pf.plot().show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "883b9515",
   "metadata": {},
   "source": [
    "Show that same model without retraining the model every 200 dollar bars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f829bdae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# oos_pf = vbt.Portfolio.from_signals(\n",
    "#     outofsample_data.close[outofsample_predictions.index], # use only the test set\n",
    "#     entries         = outofsample_predictions > 0.05, # long when probability of price increase is greater than 2%\n",
    "#     exits           = outofsample_predictions < 0.00, # long when probability of price increase is greater than 2%\n",
    "#     short_entries   = outofsample_predictions < -0.04, # long when probability of price increase is greater than 2%\n",
    "#     short_exits     = outofsample_predictions > 0.0, # short when probability prediction is less than -5%\n",
    "#     # direction=\"both\" # long and short\n",
    "# )\n",
    "# print(oos_pf.stats())\n",
    "# oos_pf.plot().show_svg()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "9c04483d",
   "metadata": {},
   "source": [
    "let's compare it to a long only strategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef0a1db7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For comparison run a buy and hold strategy\n",
    "buy_and_hold = vbt.Portfolio.from_holding(outofsample_data.close[outofsample_predictions.index])\n",
    "print(f'Total return: {buy_and_hold.total_return}')\n",
    "print(f'Max Drawdown: {buy_and_hold.max_drawdown}')\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "74fff484",
   "metadata": {},
   "source": [
    "ðŸ‘† better drawdowns than a buy and hold, and almost the same results."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "1f256503",
   "metadata": {},
   "source": [
    "# Look at the Portfolio on Test Data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "101dd472",
   "metadata": {},
   "source": [
    "and Simulate a portfolio?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b4e6246",
   "metadata": {},
   "outputs": [],
   "source": [
    "insample_pf = vbt.Portfolio.from_signals(\n",
    "    data.close[test_preds.index],  # use only the test set\n",
    "    entries         = test_preds > 0.05,  # long when probability of price increase is greater than 2%\n",
    "    exits           = test_preds < 0.00,  # long when probability of price increase is greater than 2%\n",
    "    short_entries   = test_preds < -0.04,  # long when probability of price increase is greater than 2%\n",
    "    short_exits     = test_preds > 0.0,  # short when probability prediction is less than -5%\n",
    "    # direction=\"both\" # long and short\n",
    ")\n",
    "print(insample_pf.stats())\n",
    "\n",
    "# pf.plot().show_svg()\n",
    "# Show first period\n",
    "# pf['2018':'2021'].plot().show_svg()\n",
    "# Show second period\n",
    "# pf['2021':'2023'].plot().show_svg()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a3419a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "insample_pf.plot().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a82c4832",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = insample_pf.cumulative_returns.vbt.plot(trace_kwargs=dict(name='Insample')) # plot the in sample equity curve from test data not trained data\n",
    "oos = insample_pf.cumulative_returns[-1] *(1+ oos_retraining_pf.returns).cumprod() # append the out of sample equity curve to the in sample equity curve\n",
    "# Add the out of sample equity curve to the plot\n",
    "oos.vbt.plot(fig=fig, trace_kwargs=dict(name='Out of Sample'))\n",
    "normalized_price = data.close/data.close[0]\n",
    "oos_normalized_price = outofsample_data.close/outofsample_data.close[0]\n",
    "normalized_price.rename('Normalized Price').vbt.plot(fig=fig)\n",
    "oos_normalized_price.rename('Out of Sample Normalized Price').vbt.plot(fig=fig)\n",
    "# The gap is the warmup period for the new model to start making predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "924106bb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "950a94b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "trades = insample_pf.trades.records_readable"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a164b3e2",
   "metadata": {},
   "source": [
    "## Save everything to the models folder for later analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8106222f",
   "metadata": {},
   "outputs": [],
   "source": [
    "insample_pf.save('models/insample_test_portfolio.pkl')\n",
    "insample_pf.stats().to_csv('models/insample_stats_test.csv')\n",
    "insample_pf.trades.records_readable.to_csv('models/insample_trades_test.csv')\n",
    "X.to_csv('models/insample_X_test.csv')\n",
    "y.to_csv('models/insample_y_test.csv')\n",
    "oos_pf.save('models/oos_test_portfolio.pkl')\n",
    "oos_pf.stats().to_csv('models/oos_stats_test.csv')\n",
    "oos_pf.trades.records_readable.to_csv('models/oos_trades_test.csv')\n",
    "Xoos.to_csv('models/oos_X_test.csv')\n",
    "yoos.to_csv('models/oos_y_test.csv')\n",
    "insample_predictions.to_csv('models/insample_predictions_test.csv')\n",
    "outofsample_predictions.to_csv('models/oos_predictions_test.csv')\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0752462b",
   "metadata": {},
   "source": [
    "Save the out of sample portfolio that was retrained every 200 bars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47f07dfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "oos_retraining_pf.save('models/oos_retrained_portfolio.pkl')\n",
    "oos_retraining_pf.stats().to_csv('models/oos_retrained_stats.csv')\n",
    "oos_retraining_pf.trades.records_readable.to_csv('models/oos_retrained_trades.csv')\n",
    "outofsample_retraining_predictions.to_csv('models/oos_retrained_predictions.csv')\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8e522850",
   "metadata": {},
   "source": [
    "# Explore which features are impacting the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7460cca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "# Extract the fitted XGBRegressor model from the pipeline\n",
    "fitted_model = pipeline.named_steps['model']\n",
    "\n",
    "# Get feature importance\n",
    "importance = fitted_model.feature_importances_\n",
    "\n",
    "# Summarize feature importance\n",
    "for i, j in enumerate(importance):\n",
    "    print('Feature: %0d, Score: %.5f' % (i,j))\n",
    "\n",
    "# Plot feature importance\n",
    "from xgboost import plot_importance\n",
    "plot_importance(fitted_model)\n",
    "plt.show()\n",
    "\n",
    "# Assuming `X` is your feature matrix\n",
    "feature_names = X.columns.tolist()\n",
    "\n",
    "# If you use PCA in your pipeline, the output feature names would be the principal components, not the original feature names.\n",
    "# If that's the case, you should generate new names for the principal components\n",
    "if 'pca' in pipeline.named_steps:\n",
    "    n_components = pipeline.named_steps['pca'].n_components_\n",
    "    feature_names = [f'PC{i+1}' for i in range(n_components)]\n",
    "\n",
    "# Print feature importance with names\n",
    "for name, importance in zip(feature_names, fitted_model.feature_importances_):\n",
    "    print(f'Feature: {name}, Score: {importance}')\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "bb8c76a3",
   "metadata": {},
   "source": [
    "A lot to unpack up above. Why are the feature scores so much different than the fscores of the features?"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "9f1a93d2",
   "metadata": {},
   "source": [
    "# Hyperparameter Tuning"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "6fd079e2",
   "metadata": {},
   "source": [
    "### Grid Search Method\n",
    "#### DONT RUN WITHOUT GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80c7709d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Specify hyperparameters to tune and their respective ranges\n",
    "param_grid = {\n",
    "    'model__learning_rate': [0.01, 0.1, 0.2],\n",
    "    'model__n_estimators': [100, 500, 1000],\n",
    "    'model__max_depth': [3, 5, 7],\n",
    "    'model__min_child_weight': [1, 5, 10],\n",
    "    'model__subsample': [0.5, 0.7, 1.0],\n",
    "    'model__colsample_bytree': [0.5, 0.7, 1.0]\n",
    "    # add other parameters here\n",
    "}\n",
    "\n",
    "# Perform grid search\n",
    "grid_search = GridSearchCV(pipeline, param_grid, cv=cv, scoring=\"r2\", n_jobs=-1, verbose=10)\n",
    "grid_search.fit(X, y)\n",
    "\n",
    "# Best parameters and score from grid search\n",
    "print(f\"Best parameters: {grid_search.best_params_}\")\n",
    "print(f\"Best score: {grid_search.best_score_}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f429f2b",
   "metadata": {},
   "source": [
    "### Randomized Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bb34aef",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from scipy.stats import uniform, randint\n",
    "\n",
    "# Specify hyperparameters to tune and their respective distributions\n",
    "param_dist = {\n",
    "    'model__learning_rate': uniform(0.01, 0.2),\n",
    "    'model__n_estimators': randint(100, 1000),\n",
    "    'model__max_depth': randint(3, 10),\n",
    "    'model__min_child_weight': randint(1, 10),\n",
    "    'model__subsample': uniform(0.5, 0.5),\n",
    "    'model__colsample_bytree': uniform(0.5, 0.5),\n",
    "    # add other parameters here\n",
    "}\n",
    "\n",
    "# Perform randomized search\n",
    "random_search = RandomizedSearchCV(pipeline, param_dist, n_iter=10, cv=cv, scoring=\"r2\", n_jobs=-1, verbose=10, random_state=42)\n",
    "random_search.fit(X, y)\n",
    "\n",
    "# Best parameters and score from random search\n",
    "print(f\"Best parameters: {random_search.best_params_}\")\n",
    "print(f\"Best score: {random_search.best_score_}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55f667d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit and predict with the best estimator\n",
    "test_labels = []\n",
    "test_preds = []\n",
    "for split in X_slices.index.unique(level=\"split\"):  \n",
    "    X_train_slice = X_slices[(split, \"train\")]  \n",
    "    y_train_slice = y_slices[(split, \"train\")]\n",
    "    X_test_slice = X_slices[(split, \"test\")]\n",
    "    y_test_slice = y_slices[(split, \"test\")]\n",
    "\n",
    "    slice_pipeline = random_search.best_estimator_.fit(X_train_slice, y_train_slice)  \n",
    "    test_pred = slice_pipeline.predict(X_test_slice)  \n",
    "    test_pred = pd.Series(test_pred, index=y_test_slice.index)\n",
    "    test_labels.append(y_test_slice)\n",
    "    test_preds.append(test_pred)\n",
    "\n",
    "test_labels = pd.concat(test_labels).rename(\"labels\")  \n",
    "test_preds = pd.concat(test_preds).rename(\"preds\")\n",
    "\n",
    "# Show the accuracy of the predictions\n",
    "# Assuming test_labels and test_preds are your true and predicted values\n",
    "mse = mean_squared_error(test_labels, test_preds)\n",
    "rmse = np.sqrt(mse)  # or use mean_squared_error with squared=False\n",
    "mae = mean_absolute_error(test_labels, test_preds)\n",
    "r2 = r2_score(test_labels, test_preds)\n",
    "\n",
    "print(f\"Mean Squared Error (MSE): {mse}\")\n",
    "print(f\"Root Mean Squared Error (RMSE): {rmse}\")\n",
    "print(f\"Mean Absolute Error (MAE): {mae}\")\n",
    "print(f\"R-squared: {r2}\")\n",
    "\n",
    "# Visualize the predictions as a heatmap plotted against the price\n",
    "data.close.vbt.overlay_with_heatmap(test_preds).show_svg()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58082fd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "pf = vbt.Portfolio.from_signals(\n",
    "    data.close[test_preds.index], # use only the test set\n",
    "    test_preds > 0.05, # long when probability of price increase is greater than 2%\n",
    "    test_preds < 0.02, # short when probability prediction is less than -5%\n",
    "    direction=\"LongOnly\" # long and short\n",
    ")\n",
    "print(pf.stats())\n",
    "pf.plot().show_svg()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b74572df",
   "metadata": {},
   "outputs": [],
   "source": [
    "pf.trades.records_readable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08fdcb48",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
