{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c69786c2-7c5b-4b1e-bd0c-52380c8df261",
   "metadata": {},
   "source": [
    "# Cross-validation\n",
    "Once we develop a rule-based or ML-based strategy, it's time to backtest it. The first time around we obtain a low Sharpe ratio we're unhappy with, we decide to tweak our strategy. Eventually, after multiple iterations of tweaking parameters, we end up with a \"flawless\" combination of parameters and a strategy with an exceptional Sharpe ratio. However, in live trading the performance took a different turn: we essentially tanked and lost money. What went wrong?\n",
    "\n",
    "Markets inherently have noise - small and frequent idiosyncrasies in the price data. When modelling a strategy, we want to avoid optimizing for one specific period because there is a chance the model adapts so closely to historical data that it becomes ineffective in predicting the future. It'd be like tuning a car specifically for one racetrack, while expecting it to perform well everywhere. Especially with vectorbt, which enables us to search extensive databases of historical market data for patterns, it is often possible to develop elaborate rules that appear to predict price development with close accuracy (see p-hacking) but make random guesses when applied to data outside the sample the model was constructed from.\n",
    "\n",
    "Overfitting (aka curve fitting) usually occurs for one or more of the following reasons: mistaking noise for signal, and overly tweaking too many parameters. To curb overfitting, we should use cross-validation (CV), which involves partitioning a sample of data into complementary subsets, performing the analysis on one subset of data called the training or in-sample (IS) set, and validating the analysis on the other subset of data called the validation or out-of-sample (OOS) set. This procedure is repeated until we have multiple OOS periods and can draw statistics from these results combined. The ultimate questions we need to ask ourselves: is our choice of parameters robust in the IS periods? Is our performance robust on the OOS periods? Because if not, we're shooting in the dark, and as a quant investor we should not leave room for second-guessing when real money is at stake.\n",
    "\n",
    "Consider a simple strategy around a moving average crossover.\n",
    "\n",
    "First, we'll pull some data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b2751478-95ce-47d2-9e80-4d47ed0c7b36",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ericervin/opt/anaconda3/envs/datascience/lib/python3.10/site-packages/numba/core/decorators.py:262: NumbaDeprecationWarning: \u001b[1mnumba.generated_jit is deprecated. Please see the documentation at: https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-generated-jit for more information and advice on a suitable replacement.\u001b[0m\n",
      "  warnings.warn(msg, NumbaDeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from numba import njit\n",
    "import vectorbtpro as vbt\n",
    "vbt.settings.set_theme(\"dark\")\n",
    "vbt.settings.plotting[\"layout\"][\"width\"] = 800\n",
    "vbt.settings.plotting['layout']['height'] = 200\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.linear_model import Ridge, Lasso, ElasticNet, LinearRegression, LogisticRegression\n",
    "from sklearn.svm import SVR, SVC\n",
    "from xgboost import XGBRegressor, XGBClassifier\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "clf = RandomForestClassifier(random_state=42) # random forest classifier\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "4a78505c",
   "metadata": {},
   "source": [
    "pull in some data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "6e3f9cf8",
   "metadata": {},
   "source": [
    "Let's construct a parameterized mini-pipeline that takes data and the parameters, and returns the Sharpe ratio that should reflect the performance of our strategy on that test period:"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "935ca582-ef09-40f9-b6ff-c303c98989b1",
   "metadata": {},
   "source": [
    "### Modeling\n",
    "The class Splitter can also be helpful in cross-validating ML models. In particular, you can casually step upon a class SKLSplitter that acts as a regular cross-validator from scikit-learn by subclassing BaseCrossValidator. We'll demonstrate its usage on a simple classification problem of predicting the best entry and exit timings.\n",
    "\n",
    "Before we start, we need to decide on features and labels that should act as predictor and response variables respectively. Features are usually multi-columnar time-series DataFrames where each row contains multiple data points (one per column) that should predict the same row in labels. Labels are usually a single-columnar time-series Series that should be predicted. Ask yourself the following questions to easily come up with a decision:\n",
    "\n",
    "\"How can the future performance be represented, preferably as a single number? Should it be the price at the next bar, the average price change over the next week, a vector of weights for rebalancing, a boolean containing a signal, or something else?\"\n",
    "\"What kind of data that encompasses the past performance is likely to predict the future performance? Should it be indicators, news sentiment index, past backtesting results, or something else?\"\n",
    "\"Which ML model can handle such a task?\" (remember that most models are limited to just a couple of specific feature and label formats!)\n",
    "For the sake of an example, we'll fit a random forest classifier on all TA-Lib indicators stacked along columns to predict the binary labels generated by the label generator TRENDLB, where 1 means an uptrend and 0 means a downtrend. Sounds like fun ðŸ˜Œ"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "41119985",
   "metadata": {},
   "source": [
    "Build a pipeline to impute and (standard-)normalize the data, [reduce the dimensionality](https://scikit-learn.org/stable/auto_examples/compose/plot_digits_pipe.html) of the features, as well as fit one of the [linear](https://scikit-learn.org/stable/modules/linear_model.html) models to predict the average price change over the next n bars (i.e., regression task!). Based on each prediction, you can then decide whether a position is worth opening or closing out. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "eef4fc9a",
   "metadata": {},
   "source": [
    "# Let's experiment"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b42b8366",
   "metadata": {},
   "source": [
    "Smaller resolution but using dollar bars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1293808d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = '/Users/ericervin/Documents/Coding/data-repository/data/BTCUSDT_1m_futures.pkl' \n",
    "\n",
    "futures_1m = vbt.BinanceData.load(data_path)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "767f3215",
   "metadata": {},
   "source": [
    "# Helper functions\n",
    "Create dollar bars and add them to the original df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7d6acc72",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def dollar_bar_func(ohlc_df, dollar_bar_size):\n",
    "    # Calculate dollar value traded for each row\n",
    "    ohlc_df['DollarValue'] = ohlc_df['Close'] * ohlc_df['Volume']\n",
    "    \n",
    "    # Calculate cumulative dollar value\n",
    "    ohlc_df['CumulativeDollarValue'] = ohlc_df['DollarValue'].cumsum()\n",
    "    \n",
    "    # Determine the number of dollar bars\n",
    "    num_bars = int(ohlc_df['CumulativeDollarValue'].iloc[-1] / dollar_bar_size)\n",
    "    \n",
    "    # Generate index positions for dollar bars\n",
    "    bar_indices = [0]\n",
    "    cumulative_value = 0\n",
    "    for i in range(1, len(ohlc_df)):\n",
    "        cumulative_value += ohlc_df['DollarValue'].iloc[i]\n",
    "        if cumulative_value >= dollar_bar_size:\n",
    "            bar_indices.append(i)\n",
    "            cumulative_value = 0\n",
    "    \n",
    "    # Create a new dataframe with dollar bars\n",
    "    dollar_bars = []\n",
    "    for i in range(len(bar_indices) - 1):\n",
    "        start_idx = bar_indices[i]\n",
    "        end_idx = bar_indices[i + 1]\n",
    "        \n",
    "        dollar_bar = {\n",
    "            'Open': ohlc_df['Open'].iloc[start_idx],\n",
    "            'High': ohlc_df['High'].iloc[start_idx:end_idx].max(),\n",
    "            'Low': ohlc_df['Low'].iloc[start_idx:end_idx].min(),\n",
    "            'Close': ohlc_df['Close'].iloc[end_idx],\n",
    "            'Volume': ohlc_df['Volume'].iloc[start_idx:end_idx].sum(),\n",
    "            'Quote volume': ohlc_df['Quote volume'].iloc[start_idx:end_idx].sum(),\n",
    "            'Trade count': ohlc_df['Trade count'].iloc[start_idx:end_idx].sum(),\n",
    "            'Taker base volume': ohlc_df['Taker base volume'].iloc[start_idx:end_idx].sum(),\n",
    "            'Taker quote volume': ohlc_df['Taker quote volume'].iloc[start_idx:end_idx].sum()\n",
    "        }\n",
    "        \n",
    "        if isinstance(ohlc_df.index, pd.DatetimeIndex):\n",
    "            dollar_bar['Open Time'] = ohlc_df.index[start_idx]\n",
    "            dollar_bar['Close Time'] = ohlc_df.index[end_idx] - pd.Timedelta(milliseconds=1)\n",
    "        elif 'Open Time' in ohlc_df.columns:\n",
    "            dollar_bar['Open Time'] = ohlc_df['Open Time'].iloc[start_idx]\n",
    "            dollar_bar['Close Time'] = ohlc_df['Open Time'].iloc[end_idx] - pd.Timedelta(milliseconds=1)\n",
    "        \n",
    "        dollar_bars.append(dollar_bar)\n",
    "    \n",
    "    dollar_bars_df = pd.concat([pd.DataFrame([bar]) for bar in dollar_bars], ignore_index=True)\n",
    "    \n",
    "    return dollar_bars_df\n",
    "\n",
    "# Create a simple function to simplify the number so we can use it in our column names\n",
    "def simplify_number(num):\n",
    "    \"\"\"\n",
    "    Simplifies a large number by converting it to a shorter representation with a suffix (K, M, B).\n",
    "    simplify_number(1000) -> 1K\n",
    "    \"\"\"\n",
    "    suffixes = ['', 'K', 'M', 'B']\n",
    "    suffix_index = 0\n",
    "\n",
    "    while abs(num) >= 1000 and suffix_index < len(suffixes) - 1:\n",
    "        num /= 1000.0\n",
    "        suffix_index += 1\n",
    "\n",
    "    suffix = suffixes[suffix_index] if suffix_index > 0 else ''\n",
    "    simplified_num = f'{int(num)}{suffix}'\n",
    "\n",
    "    return simplified_num\n",
    "\n",
    "def merge_and_fill_dollar_bars(original_df, dollar_bars_df, dollar_bar_size):\n",
    "    # Add prefix to column names in dollar bars dataframe\n",
    "    dollar_bar_prefix = f'db_{simplify_number(dollar_bar_size)}_'\n",
    "    dollar_bars_df_renamed = dollar_bars_df.add_prefix(dollar_bar_prefix)\n",
    "\n",
    "    # Convert 'Open Time' columns to pandas datetime format and set them as index\n",
    "    dollar_bars_df_renamed.index = pd.to_datetime(dollar_bars_df_renamed[dollar_bar_prefix + 'Open Time'])\n",
    "\n",
    "    # Merge the dataframes on the index\n",
    "    merged_df = original_df.merge(dollar_bars_df_renamed, how='left', left_index=True, right_index=True)\n",
    "\n",
    "    # Set the flag for a new dollar bar with prefix\n",
    "    merged_df[dollar_bar_prefix + 'NewDBFlag'] = ~merged_df[dollar_bar_prefix + 'Close'].isna()\n",
    "\n",
    "    # Forward fill the NaN values for all columns except the new dollar bar flag\n",
    "    columns_to_ffill = [col for col in merged_df.columns if col != dollar_bar_prefix + 'NewDBFlag']\n",
    "    merged_df[columns_to_ffill] = merged_df[columns_to_ffill].fillna(method='ffill')\n",
    "\n",
    "    # Fill the remaining NaN values in the new dollar bar flag column with False\n",
    "    merged_df[dollar_bar_prefix + 'NewDBFlag'] = merged_df[dollar_bar_prefix + 'NewDBFlag'].fillna(False)\n",
    "    \n",
    "    # Assign the renamed 'Open Time' column back to the dataframe\n",
    "    merged_df[dollar_bar_prefix + 'Open Time'] = merged_df[dollar_bar_prefix + 'Open Time']\n",
    "\n",
    "    return merged_df\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "469e8b28",
   "metadata": {},
   "source": [
    "# Calculate DB\n",
    "Calc Dollar bars and then add technical analysis features\n",
    "\n",
    "Uncomment this section if you want to run different size dollar bars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5c2b8de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dollar_bar_size = 90_000_000\n",
    "# btc_dollar_bars = dollar_bar_func(futures_1m.get(), dollar_bar_size=dollar_bar_size)\n",
    "# btc_dollar_bars.index = pd.to_datetime(btc_dollar_bars['Open Time'])\n",
    "# btc_dollar_bars.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "640f40b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the dataframe back into a vbt data object\n",
    "# btc_90M_db_vbt = vbt.BinanceData.from_data(btc_dollar_bars)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc8cee12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the dollarbars to a pickle file\n",
    "# btc_90M_db_vbt.save('btc_90M_db_vbt.pkl')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c770a46d",
   "metadata": {},
   "source": [
    "# Load the dollar bars from pickle file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "15451db6",
   "metadata": {},
   "outputs": [],
   "source": [
    "btc_90M_db_vbt = vbt.BinanceData.load('btc_90M_db_vbt.pkl')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "78e34cf7",
   "metadata": {},
   "source": [
    "Take a small slice of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "id": "ca083be1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(105949,)"
      ]
     },
     "execution_count": 255,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = btc_90M_db_vbt['2021-01-01':'2023-01-01']\n",
    "outofsample_data = btc_90M_db_vbt['2023-01-01':'2023-06-03']\n",
    "data.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "1cea4860",
   "metadata": {},
   "source": [
    "# Generate features for the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "id": "76c3e730",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Cycle Indicators': ['HT_DCPERIOD', 'HT_DCPHASE', 'HT_PHASOR', 'HT_SINE', 'HT_TRENDMODE'], 'Math Operators': ['ADD', 'DIV', 'MAX', 'MAXINDEX', 'MIN', 'MININDEX', 'MINMAX', 'MINMAXINDEX', 'MULT', 'SUB', 'SUM'], 'Math Transform': ['ACOS', 'ASIN', 'ATAN', 'CEIL', 'COS', 'COSH', 'EXP', 'FLOOR', 'LN', 'LOG10', 'SIN', 'SINH', 'SQRT', 'TAN', 'TANH'], 'Momentum Indicators': ['ADX', 'ADXR', 'APO', 'AROON', 'AROONOSC', 'BOP', 'CCI', 'CMO', 'DX', 'MACD', 'MACDEXT', 'MACDFIX', 'MFI', 'MINUS_DI', 'MINUS_DM', 'MOM', 'PLUS_DI', 'PLUS_DM', 'PPO', 'ROC', 'ROCP', 'ROCR', 'ROCR100', 'RSI', 'STOCH', 'STOCHF', 'STOCHRSI', 'TRIX', 'ULTOSC', 'WILLR'], 'Overlap Studies': ['BBANDS', 'DEMA', 'EMA', 'HT_TRENDLINE', 'KAMA', 'MA', 'MAMA', 'MAVP', 'MIDPOINT', 'MIDPRICE', 'SAR', 'SAREXT', 'SMA', 'T3', 'TEMA', 'TRIMA', 'WMA'], 'Pattern Recognition': ['CDL2CROWS', 'CDL3BLACKCROWS', 'CDL3INSIDE', 'CDL3LINESTRIKE', 'CDL3OUTSIDE', 'CDL3STARSINSOUTH', 'CDL3WHITESOLDIERS', 'CDLABANDONEDBABY', 'CDLADVANCEBLOCK', 'CDLBELTHOLD', 'CDLBREAKAWAY', 'CDLCLOSINGMARUBOZU', 'CDLCONCEALBABYSWALL', 'CDLCOUNTERATTACK', 'CDLDARKCLOUDCOVER', 'CDLDOJI', 'CDLDOJISTAR', 'CDLDRAGONFLYDOJI', 'CDLENGULFING', 'CDLEVENINGDOJISTAR', 'CDLEVENINGSTAR', 'CDLGAPSIDESIDEWHITE', 'CDLGRAVESTONEDOJI', 'CDLHAMMER', 'CDLHANGINGMAN', 'CDLHARAMI', 'CDLHARAMICROSS', 'CDLHIGHWAVE', 'CDLHIKKAKE', 'CDLHIKKAKEMOD', 'CDLHOMINGPIGEON', 'CDLIDENTICAL3CROWS', 'CDLINNECK', 'CDLINVERTEDHAMMER', 'CDLKICKING', 'CDLKICKINGBYLENGTH', 'CDLLADDERBOTTOM', 'CDLLONGLEGGEDDOJI', 'CDLLONGLINE', 'CDLMARUBOZU', 'CDLMATCHINGLOW', 'CDLMATHOLD', 'CDLMORNINGDOJISTAR', 'CDLMORNINGSTAR', 'CDLONNECK', 'CDLPIERCING', 'CDLRICKSHAWMAN', 'CDLRISEFALL3METHODS', 'CDLSEPARATINGLINES', 'CDLSHOOTINGSTAR', 'CDLSHORTLINE', 'CDLSPINNINGTOP', 'CDLSTALLEDPATTERN', 'CDLSTICKSANDWICH', 'CDLTAKURI', 'CDLTASUKIGAP', 'CDLTHRUSTING', 'CDLTRISTAR', 'CDLUNIQUE3RIVER', 'CDLUPSIDEGAP2CROWS', 'CDLXSIDEGAP3METHODS'], 'Price Transform': ['AVGPRICE', 'MEDPRICE', 'TYPPRICE', 'WCLPRICE'], 'Statistic Functions': ['BETA', 'CORREL', 'LINEARREG', 'LINEARREG_ANGLE', 'LINEARREG_INTERCEPT', 'LINEARREG_SLOPE', 'STDDEV', 'TSF', 'VAR'], 'Volatility Indicators': ['ATR', 'NATR', 'TRANGE'], 'Volume Indicators': ['AD', 'ADOSC', 'OBV']}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['pandas_ta:PSAR']"
      ]
     },
     "execution_count": 244,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import talib\n",
    "print(talib.get_function_groups())\n",
    "# Not sure how to call just a single indicator group so I'll just call all of them\n",
    "vbt.IF.list_indicators(\"psar\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "id": "8c972edc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "n = 150 # number of periods in the future to predict\n",
    "\n",
    "# Generate the features (X) using TA-Lib indicators\n",
    "# X = data.run(\"talib\", periods=vbt.run_func_dict(mavp=n))\n",
    "X = data.get()\n",
    "psar_vbt = data.run(\"pandas_ta:PSAR\", append=True, acceleration=0.02, maximum=0.2)\n",
    "# add trend label as a feature\n",
    "X['trend'] = data.run(\"trendlb\", .2, 0.05, mode=\"binary\").labels # add trend label as a feature\n",
    "# X['psar_cross'] = psar_vbt.psarr\n",
    "\n",
    "# Add time features\n",
    "X['dayofmonth'] = X.index.day\n",
    "X['month'] = X.index.month\n",
    "X['year'] = X.index.year\n",
    "X['hour'] = X.index.hour\n",
    "X['minute'] = X.index.minute\n",
    "X['dayofweek'] = X.index.dayofweek\n",
    "X['dayofyear'] = X.index.dayofyear\n",
    "\n",
    "# Now we are trying to generate future price predictions so we will set the y labels to the price change n periods in the future\n",
    "y = (data.close.shift(-n) / data.close - 1).rolling(n).mean() # future price change we use rolling mean to smooth the data\n",
    "\n",
    "# Preprocessing steps to handle NaNs\n",
    "X = X.replace([-np.inf, np.inf], np.nan) # replace inf with nan\n",
    "invalid_column_mask = X.isnull().all(axis=0) | (X.nunique() == 1) # drop columns that are all nan or have only one unique value\n",
    "X = X.loc[:, ~invalid_column_mask] # drop invalid columns\n",
    "invalid_row_mask = X.isnull().any(axis=1) | y.isnull() # drop rows that have nan in any column or in y\n",
    "\n",
    "# Drop invalid rows in X and y\n",
    "X = X.loc[~invalid_row_mask]\n",
    "y = y.loc[~invalid_row_mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "id": "37005abd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>...</th>\n",
       "      <th>hour</th>\n",
       "      <th>minute</th>\n",
       "      <th>dayofweek</th>\n",
       "      <th>dayofyear</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Open Time</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2021-01-02 16:21:00+00:00</th>\n",
       "      <td>32364.11</td>\n",
       "      <td>32455.00</td>\n",
       "      <td>32231.72</td>\n",
       "      <td>32383.03</td>\n",
       "      <td>...</td>\n",
       "      <td>16</td>\n",
       "      <td>21</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-01-02 16:25:00+00:00</th>\n",
       "      <td>32402.48</td>\n",
       "      <td>32432.38</td>\n",
       "      <td>32233.59</td>\n",
       "      <td>32349.34</td>\n",
       "      <td>...</td>\n",
       "      <td>16</td>\n",
       "      <td>25</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-01-02 16:29:00+00:00</th>\n",
       "      <td>32312.27</td>\n",
       "      <td>32555.98</td>\n",
       "      <td>32299.93</td>\n",
       "      <td>32521.29</td>\n",
       "      <td>...</td>\n",
       "      <td>16</td>\n",
       "      <td>29</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-01-02 16:32:00+00:00</th>\n",
       "      <td>32520.71</td>\n",
       "      <td>32814.23</td>\n",
       "      <td>32468.00</td>\n",
       "      <td>32765.93</td>\n",
       "      <td>...</td>\n",
       "      <td>16</td>\n",
       "      <td>32</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-01-02 16:34:00+00:00</th>\n",
       "      <td>32797.86</td>\n",
       "      <td>32835.93</td>\n",
       "      <td>32685.11</td>\n",
       "      <td>32998.69</td>\n",
       "      <td>...</td>\n",
       "      <td>16</td>\n",
       "      <td>34</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-11-21 20:57:00+00:00</th>\n",
       "      <td>15804.20</td>\n",
       "      <td>15843.80</td>\n",
       "      <td>15770.00</td>\n",
       "      <td>15804.10</td>\n",
       "      <td>...</td>\n",
       "      <td>20</td>\n",
       "      <td>57</td>\n",
       "      <td>0</td>\n",
       "      <td>325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-11-21 21:16:00+00:00</th>\n",
       "      <td>15813.90</td>\n",
       "      <td>15830.50</td>\n",
       "      <td>15764.80</td>\n",
       "      <td>15787.20</td>\n",
       "      <td>...</td>\n",
       "      <td>21</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-11-21 21:40:00+00:00</th>\n",
       "      <td>15789.40</td>\n",
       "      <td>15798.30</td>\n",
       "      <td>15780.00</td>\n",
       "      <td>15619.10</td>\n",
       "      <td>...</td>\n",
       "      <td>21</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-11-21 21:45:00+00:00</th>\n",
       "      <td>15788.10</td>\n",
       "      <td>15790.40</td>\n",
       "      <td>15611.00</td>\n",
       "      <td>15617.60</td>\n",
       "      <td>...</td>\n",
       "      <td>21</td>\n",
       "      <td>45</td>\n",
       "      <td>0</td>\n",
       "      <td>325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-11-21 21:46:00+00:00</th>\n",
       "      <td>15619.10</td>\n",
       "      <td>15646.30</td>\n",
       "      <td>15520.00</td>\n",
       "      <td>15574.80</td>\n",
       "      <td>...</td>\n",
       "      <td>21</td>\n",
       "      <td>46</td>\n",
       "      <td>0</td>\n",
       "      <td>325</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>103513 rows Ã— 19 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                               Open      High       Low     Close  ...  hour  \\\n",
       "Open Time                                                          ...         \n",
       "2021-01-02 16:21:00+00:00  32364.11  32455.00  32231.72  32383.03  ...    16   \n",
       "2021-01-02 16:25:00+00:00  32402.48  32432.38  32233.59  32349.34  ...    16   \n",
       "2021-01-02 16:29:00+00:00  32312.27  32555.98  32299.93  32521.29  ...    16   \n",
       "2021-01-02 16:32:00+00:00  32520.71  32814.23  32468.00  32765.93  ...    16   \n",
       "2021-01-02 16:34:00+00:00  32797.86  32835.93  32685.11  32998.69  ...    16   \n",
       "...                             ...       ...       ...       ...  ...   ...   \n",
       "2022-11-21 20:57:00+00:00  15804.20  15843.80  15770.00  15804.10  ...    20   \n",
       "2022-11-21 21:16:00+00:00  15813.90  15830.50  15764.80  15787.20  ...    21   \n",
       "2022-11-21 21:40:00+00:00  15789.40  15798.30  15780.00  15619.10  ...    21   \n",
       "2022-11-21 21:45:00+00:00  15788.10  15790.40  15611.00  15617.60  ...    21   \n",
       "2022-11-21 21:46:00+00:00  15619.10  15646.30  15520.00  15574.80  ...    21   \n",
       "\n",
       "                           minute  dayofweek  dayofyear  \n",
       "Open Time                                                \n",
       "2021-01-02 16:21:00+00:00      21          5          2  \n",
       "2021-01-02 16:25:00+00:00      25          5          2  \n",
       "2021-01-02 16:29:00+00:00      29          5          2  \n",
       "2021-01-02 16:32:00+00:00      32          5          2  \n",
       "2021-01-02 16:34:00+00:00      34          5          2  \n",
       "...                           ...        ...        ...  \n",
       "2022-11-21 20:57:00+00:00      57          0        325  \n",
       "2022-11-21 21:16:00+00:00      16          0        325  \n",
       "2022-11-21 21:40:00+00:00      40          0        325  \n",
       "2022-11-21 21:45:00+00:00      45          0        325  \n",
       "2022-11-21 21:46:00+00:00      46          0        325  \n",
       "\n",
       "[103513 rows x 19 columns]"
      ]
     },
     "execution_count": 246,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "id": "4be1d30f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "getting cv splits\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Construct the pipeline\n",
    "steps = [\n",
    "    ('imputation', SimpleImputer(strategy='mean')),  # Imputation replaces missing values\n",
    "    ('scaler', StandardScaler()),  # StandardScaler normalizes the data\n",
    "    ('pca', PCA(n_components=15)),  # PCA reduces dimensionality\n",
    "    \n",
    "    # Choose one of the following models\n",
    "    # ('model', Ridge())  # Ridge regression is used as the prediction model\n",
    "    # ('model', LinearRegression())  # Linear regression is used as the prediction model\n",
    "    # ('model', LogisticRegression())  # Logistic regression is used as the prediction model\n",
    "    # ('model', Lasso())  # Lasso regression is used as the prediction model\n",
    "    # ('model', ElasticNet())  # ElasticNet regression is used as the prediction model\n",
    "    # ('model', SVR())  # Support Vector Regression is used as the prediction model\n",
    "    ('model', XGBRegressor(objective='reg:squarederror'))  # XGBoost regression is used as the prediction model\n",
    "]\n",
    "pipeline = Pipeline(steps)\n",
    "\n",
    "# Cross-validate\n",
    "cv = vbt.SKLSplitter(\n",
    "    \"from_expanding\",\n",
    "    min_length=600,\n",
    "    offset=200,\n",
    "    split=-200,\n",
    "    set_labels=[\"train\", \"test\"]\n",
    ")\n",
    "print(\"getting cv splits\")\n",
    "cv_splitter = cv.get_splitter(X)\n",
    "# Plot the cross-validation splits\n",
    "# cv_splitter.plot().show_svg()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "id": "0d10445b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop Open time and close time\n",
    "X = X.drop(['Open Time','Close Time'], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "id": "6fb3e4a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Open', 'High', 'Low', 'Close', 'Volume', 'Quote volume', 'Trade count',\n",
       "       'Taker base volume', 'Taker quote volume', 'trend', 'dayofmonth',\n",
       "       'month', 'year', 'hour', 'minute', 'dayofweek', 'dayofyear'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 249,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline Steps :[('imputation', SimpleImputer()), ('scaler', StandardScaler()), ('pca', PCA(n_components=15)), ('model', XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
      "             colsample_bylevel=None, colsample_bynode=None,\n",
      "             colsample_bytree=None, early_stopping_rounds=None,\n",
      "             enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "             gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "             interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "             max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "             max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=None, ...))]\n",
      "Pipeline Score :0.7630888102150082\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[CV] START .....................................................................\n",
      "[CV] START .....................................................................\n",
      "[CV] START .....................................................................\n",
      "[CV] START .....................................................................\n",
      "[CV] START .....................................................................\n",
      "[CV] START .....................................................................\n",
      "[CV] START .....................................................................\n",
      "[CV] START .....................................................................\n",
      "[CV] START .....................................................................\n",
      "[CV] START .....................................................................\n",
      "[CV] START .....................................................................\n",
      "[CV] START .....................................................................\n",
      "[CV] END .............................. score: (test=-13.075) total time=   0.1s\n",
      "[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed:    2.4s\n",
      "[CV] END ............................... score: (test=-0.933) total time=   0.1s\n",
      "[Parallel(n_jobs=-1)]: Done   2 tasks      | elapsed:    2.4s\n",
      "[CV] START .....................................................................\n",
      "[CV] END .............................. score: (test=-15.273) total time=   0.2s\n",
      "[Parallel(n_jobs=-1)]: Done   3 tasks      | elapsed:    2.5s\n",
      "[CV] START .....................................................................\n",
      "[CV] START .....................................................................\n",
      "[CV] END .............................. score: (test=-16.469) total time=   0.3s\n",
      "[Parallel(n_jobs=-1)]: Done   4 tasks      | elapsed:    2.6s\n",
      "[CV] END .............................. score: (test=-15.315) total time=   0.4s\n",
      "[Parallel(n_jobs=-1)]: Done   5 tasks      | elapsed:    2.6s\n",
      "[CV] START .....................................................................\n",
      "[CV] START .....................................................................\n",
      "[CV] END ................................ score: (test=0.793) total time=   0.5s\n",
      "[Parallel(n_jobs=-1)]: Done   6 tasks      | elapsed:    2.8s\n",
      "[CV] END ............................... score: (test=-0.905) total time=   0.5s\n",
      "[Parallel(n_jobs=-1)]: Done   7 tasks      | elapsed:    2.8s\n",
      "[CV] START .....................................................................\n",
      "[CV] START .....................................................................\n",
      "[CV] END ............................... score: (test=-7.819) total time=   0.6s\n",
      "[Parallel(n_jobs=-1)]: Done   8 tasks      | elapsed:    2.9s\n",
      "[CV] START .....................................................................\n",
      "[CV] END ............................... score: (test=-0.355) total time=   0.7s\n",
      "[Parallel(n_jobs=-1)]: Done   9 tasks      | elapsed:    3.0s\n",
      "[CV] START .....................................................................\n",
      "[CV] END ............................... score: (test=-4.276) total time=   0.7s\n",
      "[Parallel(n_jobs=-1)]: Done  10 tasks      | elapsed:    3.1s\n",
      "[CV] START .....................................................................\n",
      "[CV] END ............................... score: (test=-6.988) total time=   0.8s\n",
      "[Parallel(n_jobs=-1)]: Done  11 tasks      | elapsed:    3.1s\n",
      "[CV] START .....................................................................\n",
      "[CV] END .............................. score: (test=-17.200) total time=   0.9s\n",
      "[Parallel(n_jobs=-1)]: Done  12 tasks      | elapsed:    3.2s\n",
      "[CV] START .....................................................................\n",
      "[CV] END ................................ score: (test=0.500) total time=   0.9s\n",
      "[Parallel(n_jobs=-1)]: Done  13 tasks      | elapsed:    3.4s\n",
      "[CV] START .....................................................................\n",
      "[CV] END ............................... score: (test=-0.359) total time=   1.0s\n",
      "[Parallel(n_jobs=-1)]: Done  14 tasks      | elapsed:    3.5s\n",
      "[CV] START .....................................................................\n",
      "[CV] END ............................... score: (test=-1.645) total time=   1.1s\n",
      "[Parallel(n_jobs=-1)]: Done  15 tasks      | elapsed:    3.6s\n",
      "[CV] START .....................................................................\n",
      "[CV] END ............................... score: (test=-0.488) total time=   1.1s\n",
      "[Parallel(n_jobs=-1)]: Done  16 tasks      | elapsed:    3.7s\n",
      "[CV] START .....................................................................\n",
      "[CV] END .............................. score: (test=-23.771) total time=   1.2s\n",
      "[Parallel(n_jobs=-1)]: Done  17 tasks      | elapsed:    3.8s\n",
      "[CV] START .....................................................................\n",
      "[CV] END ............................... score: (test=-8.018) total time=   1.2s\n",
      "[Parallel(n_jobs=-1)]: Done  18 tasks      | elapsed:    4.1s\n",
      "[CV] START .....................................................................\n",
      "[CV] END ............................... score: (test=-0.379) total time=   1.3s\n",
      "[Parallel(n_jobs=-1)]: Done  19 tasks      | elapsed:    4.2s\n",
      "[CV] START .....................................................................\n",
      "[CV] END ............................... score: (test=-4.264) total time=   1.3s\n",
      "[Parallel(n_jobs=-1)]: Done  20 tasks      | elapsed:    4.3s\n",
      "[CV] START .....................................................................\n",
      "[CV] END ............................... score: (test=-2.655) total time=   1.4s\n",
      "[Parallel(n_jobs=-1)]: Done  21 tasks      | elapsed:    4.4s\n",
      "[CV] START .....................................................................\n",
      "[CV] END ............................... score: (test=-0.652) total time=   1.5s\n",
      "[Parallel(n_jobs=-1)]: Done  22 tasks      | elapsed:    4.6s\n",
      "[CV] START .....................................................................\n",
      "[CV] END ............................... score: (test=-4.614) total time=   1.5s\n",
      "[Parallel(n_jobs=-1)]: Done  23 tasks      | elapsed:    4.7s\n",
      "[CV] START .....................................................................\n",
      "[CV] END ............................... score: (test=-4.092) total time=   1.6s\n",
      "[Parallel(n_jobs=-1)]: Done  24 tasks      | elapsed:    4.8s\n",
      "[CV] START .....................................................................\n",
      "[CV] END ............................... score: (test=-0.234) total time=   1.6s\n",
      "[Parallel(n_jobs=-1)]: Done  25 tasks      | elapsed:    5.0s\n",
      "[CV] START .....................................................................\n",
      "[CV] END ............................... score: (test=-9.955) total time=   1.7s\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:    5.2s\n",
      "[CV] START .....................................................................\n",
      "[CV] END ............................... score: (test=-3.861) total time=   1.8s\n",
      "[Parallel(n_jobs=-1)]: Done  27 tasks      | elapsed:    5.4s\n",
      "[CV] START .....................................................................\n",
      "[CV] END ............................... score: (test=-8.993) total time=   1.8s\n",
      "[Parallel(n_jobs=-1)]: Done  28 tasks      | elapsed:    5.6s\n",
      "[CV] START .....................................................................\n",
      "[CV] END ............................... score: (test=-8.956) total time=   1.9s\n",
      "[Parallel(n_jobs=-1)]: Done  29 tasks      | elapsed:    5.7s\n",
      "[CV] START .....................................................................\n",
      "[CV] END ............................... score: (test=-1.419) total time=   1.9s\n",
      "[Parallel(n_jobs=-1)]: Done  30 tasks      | elapsed:    6.0s\n",
      "[CV] START .....................................................................\n",
      "[CV] END ............................... score: (test=-0.164) total time=   2.1s\n",
      "[Parallel(n_jobs=-1)]: Done  31 tasks      | elapsed:    6.3s\n",
      "[CV] START .....................................................................\n",
      "[CV] END ............................... score: (test=-3.120) total time=   2.0s\n",
      "[Parallel(n_jobs=-1)]: Done  32 tasks      | elapsed:    6.3s\n",
      "[CV] START .....................................................................\n",
      "[CV] END ............................... score: (test=-1.923) total time=   2.1s\n",
      "[Parallel(n_jobs=-1)]: Done  33 tasks      | elapsed:    6.5s\n",
      "[CV] START .....................................................................\n",
      "[CV] END ............................... score: (test=-0.148) total time=   2.1s\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:    6.7s\n",
      "[CV] START .....................................................................\n",
      "[CV] END .............................. score: (test=-48.180) total time=   2.3s\n",
      "[Parallel(n_jobs=-1)]: Done  35 tasks      | elapsed:    7.0s\n",
      "[CV] START .....................................................................\n",
      "[CV] END ............................... score: (test=-2.292) total time=   2.4s\n",
      "[Parallel(n_jobs=-1)]: Done  36 tasks      | elapsed:    7.2s\n",
      "[CV] START .....................................................................\n",
      "[CV] END ............................... score: (test=-0.897) total time=   2.3s\n",
      "[Parallel(n_jobs=-1)]: Done  37 tasks      | elapsed:    7.4s\n",
      "[CV] START .....................................................................\n",
      "[CV] END ............................... score: (test=-3.897) total time=   2.4s\n",
      "[Parallel(n_jobs=-1)]: Done  38 tasks      | elapsed:    7.6s\n",
      "[CV] START .....................................................................\n",
      "[CV] END ................................ score: (test=0.379) total time=   2.5s\n",
      "[Parallel(n_jobs=-1)]: Done  39 tasks      | elapsed:    7.9s\n",
      "[CV] START .....................................................................\n",
      "[CV] END ............................... score: (test=-9.961) total time=   2.7s\n",
      "[Parallel(n_jobs=-1)]: Done  40 tasks      | elapsed:    8.2s\n",
      "[CV] START .....................................................................\n",
      "[CV] END ............................... score: (test=-0.377) total time=   2.7s\n",
      "[Parallel(n_jobs=-1)]: Done  41 tasks      | elapsed:    8.4s\n",
      "[CV] START .....................................................................\n",
      "[CV] END .............................. score: (test=-10.792) total time=   2.6s\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:    8.6s\n",
      "[CV] START .....................................................................\n",
      "[CV] END ............................... score: (test=-6.787) total time=   2.9s\n",
      "[Parallel(n_jobs=-1)]: Done  43 tasks      | elapsed:    9.2s\n",
      "[CV] START .....................................................................\n",
      "[CV] END ............................... score: (test=-8.882) total time=   2.9s\n",
      "[Parallel(n_jobs=-1)]: Done  44 tasks      | elapsed:    9.3s\n",
      "[CV] START .....................................................................\n",
      "[CV] END ............................... score: (test=-3.130) total time=   2.9s\n",
      "[Parallel(n_jobs=-1)]: Done  45 tasks      | elapsed:    9.4s\n",
      "[CV] START .....................................................................\n",
      "[CV] END .............................. score: (test=-11.348) total time=   2.9s\n",
      "[Parallel(n_jobs=-1)]: Done  46 tasks      | elapsed:    9.6s\n",
      "[CV] START .....................................................................\n",
      "[CV] END ............................... score: (test=-2.020) total time=   3.1s\n",
      "[Parallel(n_jobs=-1)]: Done  47 tasks      | elapsed:   10.1s\n",
      "[CV] START .....................................................................\n",
      "[CV] END ............................... score: (test=-0.015) total time=   3.1s\n",
      "[Parallel(n_jobs=-1)]: Done  48 tasks      | elapsed:   10.3s\n",
      "[CV] START .....................................................................\n",
      "[CV] END .............................. score: (test=-25.822) total time=   3.2s\n",
      "[Parallel(n_jobs=-1)]: Done  49 tasks      | elapsed:   10.6s\n",
      "[CV] START .....................................................................\n",
      "[CV] END ............................... score: (test=-4.835) total time=   3.2s\n",
      "[Parallel(n_jobs=-1)]: Done  50 tasks      | elapsed:   10.9s\n",
      "[CV] START .....................................................................\n",
      "[CV] END ............................... score: (test=-9.412) total time=   3.3s\n",
      "[Parallel(n_jobs=-1)]: Done  51 tasks      | elapsed:   11.2s\n",
      "[CV] START .....................................................................\n",
      "[CV] END ............................... score: (test=-1.237) total time=   3.3s\n",
      "[Parallel(n_jobs=-1)]: Done  52 tasks      | elapsed:   11.5s\n",
      "[CV] START .....................................................................\n",
      "[CV] END ............................... score: (test=-1.688) total time=   3.3s\n",
      "[Parallel(n_jobs=-1)]: Done  53 tasks      | elapsed:   11.7s\n",
      "[CV] START .....................................................................\n",
      "[CV] END ............................... score: (test=-5.797) total time=   3.3s\n",
      "[Parallel(n_jobs=-1)]: Done  54 tasks      | elapsed:   12.0s\n",
      "[CV] START .....................................................................\n",
      "[CV] END ............................... score: (test=-5.176) total time=   3.4s\n",
      "[Parallel(n_jobs=-1)]: Done  55 tasks      | elapsed:   12.6s\n",
      "[CV] START .....................................................................\n",
      "[CV] END ............................... score: (test=-6.952) total time=   3.5s\n",
      "[Parallel(n_jobs=-1)]: Done  56 tasks      | elapsed:   12.7s\n",
      "[CV] START .....................................................................\n",
      "[CV] END ............................... score: (test=-6.978) total time=   3.4s\n",
      "[Parallel(n_jobs=-1)]: Done  57 tasks      | elapsed:   12.9s\n",
      "[CV] START .....................................................................\n",
      "[CV] END ............................... score: (test=-1.543) total time=   3.6s\n",
      "[Parallel(n_jobs=-1)]: Done  58 tasks      | elapsed:   13.2s\n",
      "[CV] START .....................................................................\n",
      "[CV] END .............................. score: (test=-19.814) total time=   3.7s\n",
      "[Parallel(n_jobs=-1)]: Done  59 tasks      | elapsed:   13.8s\n",
      "[CV] START .....................................................................\n",
      "[CV] END ............................... score: (test=-4.608) total time=   3.7s\n",
      "[Parallel(n_jobs=-1)]: Done  60 tasks      | elapsed:   14.0s\n",
      "[CV] START .....................................................................\n",
      "[CV] END ............................... score: (test=-3.907) total time=   3.8s\n",
      "[Parallel(n_jobs=-1)]: Done  61 tasks      | elapsed:   14.4s\n",
      "[CV] START .....................................................................\n",
      "[CV] END .............................. score: (test=-14.633) total time=   3.8s\n",
      "[Parallel(n_jobs=-1)]: Done  62 tasks      | elapsed:   14.7s\n",
      "[CV] START .....................................................................\n",
      "[CV] END ............................... score: (test=-1.838) total time=   3.8s\n",
      "[Parallel(n_jobs=-1)]: Done  63 tasks      | elapsed:   15.0s\n",
      "[CV] START .....................................................................\n",
      "[CV] END .............................. score: (test=-34.245) total time=   4.0s\n",
      "[Parallel(n_jobs=-1)]: Done  64 tasks      | elapsed:   15.5s\n",
      "[CV] START .....................................................................\n",
      "[CV] END .............................. score: (test=-12.694) total time=   4.0s\n",
      "[Parallel(n_jobs=-1)]: Done  65 tasks      | elapsed:   15.8s\n",
      "[CV] START .....................................................................\n",
      "[CV] END ............................... score: (test=-1.218) total time=   4.1s\n",
      "[Parallel(n_jobs=-1)]: Done  66 tasks      | elapsed:   16.1s\n",
      "[CV] START .....................................................................\n",
      "[CV] END ............................... score: (test=-1.395) total time=   4.2s\n",
      "[Parallel(n_jobs=-1)]: Done  67 tasks      | elapsed:   16.8s\n",
      "[CV] START .....................................................................\n",
      "[CV] END ............................... score: (test=-0.475) total time=   4.2s\n",
      "[Parallel(n_jobs=-1)]: Done  68 tasks      | elapsed:   16.9s\n",
      "[CV] START .....................................................................\n",
      "[CV] END .............................. score: (test=-14.213) total time=   4.3s\n",
      "[Parallel(n_jobs=-1)]: Done  69 tasks      | elapsed:   17.2s\n",
      "[CV] START .....................................................................\n",
      "[CV] END .............................. score: (test=-20.009) total time=   4.3s\n",
      "[Parallel(n_jobs=-1)]: Done  70 tasks      | elapsed:   17.5s\n",
      "[CV] START .....................................................................\n",
      "[CV] END ............................... score: (test=-9.553) total time=   4.3s\n",
      "[Parallel(n_jobs=-1)]: Done  71 tasks      | elapsed:   18.2s\n",
      "[CV] START .....................................................................\n",
      "[CV] END ............................... score: (test=-1.080) total time=   4.4s\n",
      "[Parallel(n_jobs=-1)]: Done  72 tasks      | elapsed:   18.5s\n",
      "[CV] START .....................................................................\n",
      "[CV] END ............................... score: (test=-9.250) total time=   4.4s\n",
      "[Parallel(n_jobs=-1)]: Done  73 tasks      | elapsed:   18.9s\n",
      "[CV] START .....................................................................\n",
      "[CV] END ............................... score: (test=-0.810) total time=   4.6s\n",
      "[Parallel(n_jobs=-1)]: Done  74 tasks      | elapsed:   19.3s\n",
      "[CV] START .....................................................................\n",
      "[CV] END ............................... score: (test=-0.849) total time=   4.7s\n",
      "[Parallel(n_jobs=-1)]: Done  75 tasks      | elapsed:   19.7s\n",
      "[CV] START .....................................................................\n",
      "[CV] END ............................... score: (test=-4.107) total time=   4.9s\n",
      "[Parallel(n_jobs=-1)]: Done  76 tasks      | elapsed:   20.4s\n",
      "[CV] START .....................................................................\n",
      "[CV] END ............................... score: (test=-0.667) total time=   4.7s\n",
      "[Parallel(n_jobs=-1)]: Done  77 tasks      | elapsed:   20.6s\n",
      "[CV] START .....................................................................\n",
      "[CV] END ............................... score: (test=-6.975) total time=   4.8s\n",
      "[Parallel(n_jobs=-1)]: Done  78 tasks      | elapsed:   20.9s\n",
      "[CV] START .....................................................................\n",
      "[CV] END ............................... score: (test=-1.164) total time=   4.9s\n",
      "[Parallel(n_jobs=-1)]: Done  79 tasks      | elapsed:   21.7s\n",
      "[CV] START .....................................................................\n",
      "[CV] END ............................... score: (test=-1.313) total time=   4.9s\n",
      "[Parallel(n_jobs=-1)]: Done  80 tasks      | elapsed:   21.9s\n",
      "[CV] START .....................................................................\n",
      "[CV] END ............................... score: (test=-9.145) total time=   5.0s\n",
      "[Parallel(n_jobs=-1)]: Done  81 tasks      | elapsed:   22.2s\n",
      "[CV] START .....................................................................\n",
      "[CV] END ................................ score: (test=0.653) total time=   5.3s\n",
      "[Parallel(n_jobs=-1)]: Done  82 tasks      | elapsed:   22.9s\n",
      "[CV] START .....................................................................\n",
      "[CV] END ............................... score: (test=-2.239) total time=   5.3s\n",
      "[Parallel(n_jobs=-1)]: Done  83 tasks      | elapsed:   23.5s\n",
      "[CV] START .....................................................................\n",
      "[CV] END ............................... score: (test=-6.044) total time=   5.3s\n",
      "[Parallel(n_jobs=-1)]: Done  84 tasks      | elapsed:   23.8s\n",
      "[CV] START .....................................................................\n",
      "[CV] END ............................... score: (test=-0.599) total time=   5.4s\n",
      "[Parallel(n_jobs=-1)]: Done  85 tasks      | elapsed:   24.2s\n",
      "[CV] START .....................................................................\n",
      "[CV] END ............................... score: (test=-0.940) total time=   5.4s\n",
      "[Parallel(n_jobs=-1)]: Done  86 tasks      | elapsed:   24.7s\n",
      "[CV] START .....................................................................\n",
      "[CV] END ............................... score: (test=-0.517) total time=   5.4s\n",
      "[Parallel(n_jobs=-1)]: Done  87 tasks      | elapsed:   25.2s\n",
      "[CV] START .....................................................................\n",
      "[CV] END .............................. score: (test=-12.979) total time=   5.3s\n",
      "[Parallel(n_jobs=-1)]: Done  88 tasks      | elapsed:   25.8s\n",
      "[CV] START .....................................................................\n",
      "[CV] END ............................... score: (test=-0.520) total time=   5.5s\n",
      "[Parallel(n_jobs=-1)]: Done  89 tasks      | elapsed:   26.1s\n",
      "[CV] START .....................................................................\n",
      "[CV] END ............................... score: (test=-0.381) total time=   5.6s\n",
      "[Parallel(n_jobs=-1)]: Done  90 tasks      | elapsed:   26.5s\n",
      "[CV] START .....................................................................\n",
      "[CV] END ............................... score: (test=-2.544) total time=   5.5s\n",
      "[Parallel(n_jobs=-1)]: Done  91 tasks      | elapsed:   27.2s\n",
      "[CV] START .....................................................................\n",
      "[CV] END ............................... score: (test=-0.604) total time=   5.6s\n",
      "[Parallel(n_jobs=-1)]: Done  92 tasks      | elapsed:   27.5s\n",
      "[CV] START .....................................................................\n",
      "[CV] END ............................... score: (test=-1.225) total time=   5.6s\n",
      "[Parallel(n_jobs=-1)]: Done  93 tasks      | elapsed:   27.8s\n",
      "[CV] START .....................................................................\n",
      "[CV] END ............................... score: (test=-0.587) total time=   5.9s\n",
      "[Parallel(n_jobs=-1)]: Done  94 tasks      | elapsed:   28.7s\n",
      "[CV] START .....................................................................\n",
      "[CV] END ............................... score: (test=-1.143) total time=   5.9s\n",
      "[Parallel(n_jobs=-1)]: Done  95 tasks      | elapsed:   29.4s\n",
      "[CV] START .....................................................................\n",
      "[CV] END ................................ score: (test=0.316) total time=   6.0s\n",
      "[Parallel(n_jobs=-1)]: Done  96 tasks      | elapsed:   29.8s\n",
      "[CV] START .....................................................................\n",
      "[CV] END ............................... score: (test=-3.945) total time=   6.1s\n",
      "[Parallel(n_jobs=-1)]: Done  97 tasks      | elapsed:   30.4s\n",
      "[CV] START .....................................................................\n",
      "[CV] END ............................... score: (test=-1.354) total time=   6.1s\n",
      "[Parallel(n_jobs=-1)]: Done  98 tasks      | elapsed:   30.8s\n",
      "[CV] START .....................................................................\n",
      "[CV] END ............................... score: (test=-8.165) total time=   6.2s\n",
      "[Parallel(n_jobs=-1)]: Done  99 tasks      | elapsed:   31.4s\n",
      "[CV] START .....................................................................\n",
      "[CV] END .............................. score: (test=-30.455) total time=   6.3s\n",
      "[Parallel(n_jobs=-1)]: Done 100 tasks      | elapsed:   32.1s\n",
      "[CV] START .....................................................................\n",
      "[CV] END .............................. score: (test=-13.012) total time=   6.3s\n",
      "[Parallel(n_jobs=-1)]: Done 101 tasks      | elapsed:   32.4s\n",
      "[CV] START .....................................................................\n",
      "[CV] END ............................... score: (test=-1.853) total time=   6.4s\n",
      "[Parallel(n_jobs=-1)]: Done 102 tasks      | elapsed:   32.9s\n",
      "[CV] START .....................................................................\n",
      "[CV] END .............................. score: (test=-11.874) total time=   6.5s\n",
      "[Parallel(n_jobs=-1)]: Done 103 tasks      | elapsed:   33.8s\n",
      "[CV] START .....................................................................\n",
      "[CV] END .............................. score: (test=-13.786) total time=   6.6s\n",
      "[Parallel(n_jobs=-1)]: Done 104 tasks      | elapsed:   34.1s\n",
      "[CV] START .....................................................................\n",
      "[CV] END ............................... score: (test=-4.790) total time=   6.8s\n",
      "[Parallel(n_jobs=-1)]: Done 105 tasks      | elapsed:   34.6s\n",
      "[CV] START .....................................................................\n",
      "[CV] END ............................... score: (test=-8.785) total time=   6.9s\n",
      "[Parallel(n_jobs=-1)]: Done 106 tasks      | elapsed:   35.6s\n",
      "[CV] START .....................................................................\n",
      "[CV] END ............................... score: (test=-1.887) total time=   6.8s\n",
      "[Parallel(n_jobs=-1)]: Done 107 tasks      | elapsed:   36.2s\n",
      "[CV] START .....................................................................\n",
      "[CV] END ............................... score: (test=-2.366) total time=   6.8s\n",
      "[Parallel(n_jobs=-1)]: Done 108 tasks      | elapsed:   36.6s\n",
      "[CV] START .....................................................................\n",
      "[CV] END ............................... score: (test=-3.405) total time=   7.0s\n",
      "[Parallel(n_jobs=-1)]: Done 109 tasks      | elapsed:   37.3s\n",
      "[CV] START .....................................................................\n",
      "[CV] END .............................. score: (test=-41.810) total time=   6.9s\n",
      "[Parallel(n_jobs=-1)]: Done 110 tasks      | elapsed:   37.8s\n",
      "[CV] START .....................................................................\n",
      "[CV] END ............................... score: (test=-0.021) total time=   7.0s\n",
      "[Parallel(n_jobs=-1)]: Done 111 tasks      | elapsed:   38.4s\n",
      "[CV] START .....................................................................\n",
      "[CV] END ............................... score: (test=-0.036) total time=   7.2s\n",
      "[Parallel(n_jobs=-1)]: Done 112 tasks      | elapsed:   39.3s\n",
      "[CV] START .....................................................................\n",
      "[CV] END ................................ score: (test=0.131) total time=   7.0s\n",
      "[Parallel(n_jobs=-1)]: Done 113 tasks      | elapsed:   39.4s\n",
      "[CV] START .....................................................................\n",
      "[CV] END ............................... score: (test=-0.092) total time=   7.1s\n",
      "[Parallel(n_jobs=-1)]: Done 114 tasks      | elapsed:   40.0s\n",
      "[CV] START .....................................................................\n",
      "[CV] END ............................... score: (test=-0.150) total time=   7.2s\n",
      "[Parallel(n_jobs=-1)]: Done 115 tasks      | elapsed:   41.0s\n",
      "[CV] START .....................................................................\n",
      "[CV] END .............................. score: (test=-22.349) total time=   7.2s\n",
      "[Parallel(n_jobs=-1)]: Done 116 tasks      | elapsed:   41.4s\n",
      "[CV] START .....................................................................\n",
      "[CV] END ............................... score: (test=-4.907) total time=   7.3s\n",
      "[Parallel(n_jobs=-1)]: Done 117 tasks      | elapsed:   42.0s\n",
      "[CV] START .....................................................................\n",
      "[CV] END ............................... score: (test=-1.704) total time=   7.4s\n",
      "[Parallel(n_jobs=-1)]: Done 118 tasks      | elapsed:   43.1s\n",
      "[CV] START .....................................................................\n",
      "[CV] END ............................... score: (test=-3.807) total time=   7.5s\n",
      "[Parallel(n_jobs=-1)]: Done 119 tasks      | elapsed:   43.7s\n",
      "[CV] START .....................................................................\n",
      "[CV] END ................................ score: (test=0.071) total time=   7.6s\n",
      "[Parallel(n_jobs=-1)]: Done 120 tasks      | elapsed:   44.2s\n",
      "[CV] START .....................................................................\n",
      "[CV] END ............................... score: (test=-0.521) total time=   7.6s\n",
      "[Parallel(n_jobs=-1)]: Done 121 tasks      | elapsed:   45.0s\n",
      "[CV] START .....................................................................\n",
      "[CV] END .............................. score: (test=-73.364) total time=   7.5s\n",
      "[Parallel(n_jobs=-1)]: Done 122 tasks      | elapsed:   45.3s\n",
      "[CV] START .....................................................................\n",
      "[CV] END ............................... score: (test=-3.697) total time=   7.6s\n",
      "[Parallel(n_jobs=-1)]: Done 123 tasks      | elapsed:   46.1s\n",
      "[CV] START .....................................................................\n",
      "[CV] END ............................... score: (test=-2.022) total time=   7.7s\n",
      "[Parallel(n_jobs=-1)]: Done 124 tasks      | elapsed:   46.9s\n",
      "[CV] START .....................................................................\n",
      "[CV] END ............................... score: (test=-4.154) total time=   7.8s\n",
      "[Parallel(n_jobs=-1)]: Done 125 tasks      | elapsed:   47.3s\n",
      "[CV] START .....................................................................\n",
      "[CV] END .............................. score: (test=-13.747) total time=   8.0s\n",
      "[Parallel(n_jobs=-1)]: Done 126 tasks      | elapsed:   48.1s\n",
      "[CV] START .....................................................................\n",
      "[CV] END ............................... score: (test=-9.546) total time=   8.2s\n",
      "[Parallel(n_jobs=-1)]: Done 127 tasks      | elapsed:   49.2s\n",
      "[CV] START .....................................................................\n",
      "[CV] END ............................... score: (test=-0.763) total time=   8.2s\n",
      "[Parallel(n_jobs=-1)]: Done 128 tasks      | elapsed:   49.6s\n",
      "[CV] START .....................................................................\n",
      "[CV] END ............................... score: (test=-5.592) total time=   8.3s\n",
      "[Parallel(n_jobs=-1)]: Done 129 tasks      | elapsed:   50.3s\n",
      "[CV] START .....................................................................\n",
      "[CV] END ............................... score: (test=-0.415) total time=   8.3s\n",
      "[Parallel(n_jobs=-1)]: Done 130 tasks      | elapsed:   51.3s\n",
      "[CV] START .....................................................................\n",
      "[CV] END ............................... score: (test=-0.321) total time=   8.6s\n",
      "[Parallel(n_jobs=-1)]: Done 131 tasks      | elapsed:   52.4s\n",
      "[CV] START .....................................................................\n",
      "[CV] END ............................... score: (test=-0.197) total time=   8.7s\n",
      "[Parallel(n_jobs=-1)]: Done 132 tasks      | elapsed:   53.0s\n",
      "[CV] START .....................................................................\n",
      "[CV] END ............................... score: (test=-3.780) total time=   8.7s\n",
      "[Parallel(n_jobs=-1)]: Done 133 tasks      | elapsed:   53.7s\n",
      "[CV] START .....................................................................\n",
      "[CV] END ............................... score: (test=-3.294) total time=   8.8s\n",
      "[Parallel(n_jobs=-1)]: Done 134 tasks      | elapsed:   54.1s\n",
      "[CV] START .....................................................................\n",
      "[CV] END ............................... score: (test=-4.937) total time=   8.8s\n",
      "[Parallel(n_jobs=-1)]: Done 135 tasks      | elapsed:   54.9s\n",
      "[CV] START .....................................................................\n",
      "[CV] END ............................... score: (test=-2.589) total time=   8.9s\n",
      "[Parallel(n_jobs=-1)]: Done 136 tasks      | elapsed:   55.9s\n",
      "[CV] START .....................................................................\n",
      "[CV] END ............................... score: (test=-2.143) total time=   8.9s\n",
      "[Parallel(n_jobs=-1)]: Done 137 tasks      | elapsed:   56.2s\n",
      "[CV] START .....................................................................\n",
      "[CV] END ............................... score: (test=-5.543) total time=   8.9s\n",
      "[Parallel(n_jobs=-1)]: Done 138 tasks      | elapsed:   57.0s\n",
      "[CV] START .....................................................................\n",
      "[CV] END ............................... score: (test=-0.403) total time=   9.2s\n",
      "[Parallel(n_jobs=-1)]: Done 139 tasks      | elapsed:   58.4s\n",
      "[CV] START .....................................................................\n",
      "[CV] END .............................. score: (test=-11.017) total time=   9.0s\n",
      "[Parallel(n_jobs=-1)]: Done 140 tasks      | elapsed:   58.6s\n",
      "[CV] START .....................................................................\n",
      "[CV] END ............................... score: (test=-3.472) total time=   9.0s\n",
      "[Parallel(n_jobs=-1)]: Done 141 tasks      | elapsed:   59.3s\n",
      "[CV] START .....................................................................\n",
      "[CV] END ................................ score: (test=0.020) total time=   8.9s\n",
      "[Parallel(n_jobs=-1)]: Done 142 tasks      | elapsed:  1.0min\n",
      "[CV] START .....................................................................\n",
      "[CV] END ............................... score: (test=-6.127) total time=   9.0s\n",
      "[Parallel(n_jobs=-1)]: Done 143 tasks      | elapsed:  1.0min\n",
      "[CV] START .....................................................................\n",
      "[CV] END ............................... score: (test=-6.052) total time=   9.3s\n",
      "[Parallel(n_jobs=-1)]: Done 144 tasks      | elapsed:  1.0min\n",
      "[CV] START .....................................................................\n",
      "[CV] END .............................. score: (test=-30.537) total time=   9.2s\n",
      "[Parallel(n_jobs=-1)]: Done 145 tasks      | elapsed:  1.0min\n",
      "[CV] START .....................................................................\n",
      "[CV] END ............................... score: (test=-0.395) total time=   9.3s\n",
      "[Parallel(n_jobs=-1)]: Done 146 tasks      | elapsed:  1.1min\n",
      "[CV] START .....................................................................\n",
      "[CV] END ............................... score: (test=-3.558) total time=   9.4s\n",
      "[Parallel(n_jobs=-1)]: Done 147 tasks      | elapsed:  1.1min\n",
      "[CV] START .....................................................................\n",
      "[CV] END ............................... score: (test=-0.875) total time=   9.5s\n",
      "[Parallel(n_jobs=-1)]: Done 148 tasks      | elapsed:  1.1min\n",
      "[CV] START .....................................................................\n",
      "[CV] END ............................... score: (test=-2.762) total time=   9.5s\n",
      "[Parallel(n_jobs=-1)]: Done 149 tasks      | elapsed:  1.1min\n",
      "[CV] START .....................................................................\n",
      "[CV] END ................................ score: (test=0.309) total time=   9.5s\n",
      "[Parallel(n_jobs=-1)]: Done 150 tasks      | elapsed:  1.1min\n",
      "[CV] START .....................................................................\n",
      "[CV] END .............................. score: (test=-13.854) total time=   9.7s\n",
      "[Parallel(n_jobs=-1)]: Done 151 tasks      | elapsed:  1.1min\n",
      "[CV] START .....................................................................\n",
      "[CV] END ............................... score: (test=-8.013) total time=   9.7s\n",
      "[Parallel(n_jobs=-1)]: Done 152 tasks      | elapsed:  1.1min\n",
      "[CV] START .....................................................................\n",
      "[CV] END ............................... score: (test=-1.665) total time=   9.7s\n",
      "[Parallel(n_jobs=-1)]: Done 153 tasks      | elapsed:  1.2min\n",
      "[CV] START .....................................................................\n",
      "[CV] END ............................... score: (test=-7.384) total time=   9.8s\n",
      "[Parallel(n_jobs=-1)]: Done 154 tasks      | elapsed:  1.2min\n",
      "[CV] START .....................................................................\n",
      "[CV] END ............................... score: (test=-9.415) total time=   9.9s\n",
      "[Parallel(n_jobs=-1)]: Done 155 tasks      | elapsed:  1.2min\n",
      "[CV] START .....................................................................\n",
      "[CV] END ............................... score: (test=-2.579) total time=  10.0s\n",
      "[Parallel(n_jobs=-1)]: Done 156 tasks      | elapsed:  1.2min\n",
      "[CV] START .....................................................................\n",
      "[CV] END ................................ score: (test=0.140) total time=  10.0s\n",
      "[Parallel(n_jobs=-1)]: Done 157 tasks      | elapsed:  1.2min\n",
      "[CV] START .....................................................................\n",
      "[CV] END .............................. score: (test=-18.406) total time=   9.9s\n",
      "[Parallel(n_jobs=-1)]: Done 158 tasks      | elapsed:  1.2min\n",
      "[CV] START .....................................................................\n",
      "[CV] END ............................... score: (test=-1.862) total time=  10.2s\n",
      "[Parallel(n_jobs=-1)]: Done 159 tasks      | elapsed:  1.2min\n",
      "[CV] START .....................................................................\n",
      "[CV] END .............................. score: (test=-10.200) total time=  10.2s\n",
      "[Parallel(n_jobs=-1)]: Done 160 tasks      | elapsed:  1.3min\n",
      "[CV] START .....................................................................\n",
      "[CV] END .............................. score: (test=-12.625) total time=  10.4s\n",
      "[Parallel(n_jobs=-1)]: Done 161 tasks      | elapsed:  1.3min\n",
      "[CV] START .....................................................................\n",
      "[CV] END ............................... score: (test=-2.488) total time=  10.3s\n",
      "[Parallel(n_jobs=-1)]: Done 162 tasks      | elapsed:  1.3min\n",
      "[CV] START .....................................................................\n",
      "[CV] END ............................... score: (test=-2.221) total time=  10.6s\n",
      "[Parallel(n_jobs=-1)]: Done 163 tasks      | elapsed:  1.3min\n",
      "[CV] START .....................................................................\n",
      "[CV] END ............................... score: (test=-9.970) total time=  10.5s\n",
      "[Parallel(n_jobs=-1)]: Done 164 tasks      | elapsed:  1.3min\n",
      "[CV] START .....................................................................\n",
      "[CV] END ............................... score: (test=-1.670) total time=  10.6s\n",
      "[Parallel(n_jobs=-1)]: Done 165 tasks      | elapsed:  1.3min\n",
      "[CV] START .....................................................................\n",
      "[CV] END ................................ score: (test=0.473) total time=  10.7s\n",
      "[Parallel(n_jobs=-1)]: Done 166 tasks      | elapsed:  1.3min\n",
      "[CV] START .....................................................................\n",
      "[CV] END ................................ score: (test=0.265) total time=  10.6s\n",
      "[Parallel(n_jobs=-1)]: Done 167 tasks      | elapsed:  1.4min\n",
      "[CV] START .....................................................................\n",
      "[CV] END ............................... score: (test=-0.515) total time=  11.0s\n",
      "[Parallel(n_jobs=-1)]: Done 168 tasks      | elapsed:  1.4min\n",
      "[CV] START .....................................................................\n",
      "[CV] END .............................. score: (test=-31.162) total time=  11.0s\n",
      "[Parallel(n_jobs=-1)]: Done 169 tasks      | elapsed:  1.4min\n",
      "[CV] START .....................................................................\n",
      "[CV] END .............................. score: (test=-11.960) total time=  10.9s\n",
      "[Parallel(n_jobs=-1)]: Done 170 tasks      | elapsed:  1.4min\n",
      "[CV] START .....................................................................\n",
      "[CV] END ............................... score: (test=-7.163) total time=  11.3s\n",
      "[Parallel(n_jobs=-1)]: Done 171 tasks      | elapsed:  1.4min\n",
      "[CV] START .....................................................................\n",
      "[CV] END ............................... score: (test=-4.318) total time=  11.1s\n",
      "[Parallel(n_jobs=-1)]: Done 172 tasks      | elapsed:  1.4min\n",
      "[CV] START .....................................................................\n",
      "[CV] END ............................... score: (test=-0.281) total time=  11.1s\n",
      "[Parallel(n_jobs=-1)]: Done 173 tasks      | elapsed:  1.5min\n",
      "[CV] START .....................................................................\n",
      "[CV] END ............................... score: (test=-9.669) total time=  11.0s\n",
      "[Parallel(n_jobs=-1)]: Done 174 tasks      | elapsed:  1.5min\n",
      "[CV] START .....................................................................\n",
      "[CV] END ............................... score: (test=-1.380) total time=  11.3s\n",
      "[Parallel(n_jobs=-1)]: Done 175 tasks      | elapsed:  1.5min\n",
      "[CV] END ............................... score: (test=-2.940) total time=  11.2s\n",
      "[Parallel(n_jobs=-1)]: Done 176 tasks      | elapsed:  1.5min\n",
      "[CV] START .....................................................................\n",
      "[CV] START .....................................................................\n",
      "[CV] END ............................... score: (test=-0.953) total time=  11.5s\n",
      "[Parallel(n_jobs=-1)]: Done 177 tasks      | elapsed:  1.5min\n",
      "[CV] START .....................................................................\n",
      "[CV] END ............................... score: (test=-0.711) total time=  11.3s\n",
      "[Parallel(n_jobs=-1)]: Done 178 tasks      | elapsed:  1.5min\n",
      "[CV] START .....................................................................\n",
      "[CV] END ............................... score: (test=-3.624) total time=  11.2s\n",
      "[Parallel(n_jobs=-1)]: Done 179 tasks      | elapsed:  1.6min\n",
      "[CV] START .....................................................................\n",
      "[CV] END ............................... score: (test=-0.964) total time=  11.3s\n",
      "[Parallel(n_jobs=-1)]: Done 180 tasks      | elapsed:  1.6min\n",
      "[CV] START .....................................................................\n",
      "[CV] END ............................... score: (test=-0.649) total time=  11.4s\n",
      "[Parallel(n_jobs=-1)]: Done 181 tasks      | elapsed:  1.6min\n",
      "[CV] START .....................................................................\n",
      "[CV] END ............................... score: (test=-0.247) total time=  11.6s\n",
      "[Parallel(n_jobs=-1)]: Done 182 tasks      | elapsed:  1.6min\n",
      "[CV] START .....................................................................\n",
      "[CV] END ............................... score: (test=-9.717) total time=  11.4s\n",
      "[Parallel(n_jobs=-1)]: Done 183 tasks      | elapsed:  1.6min\n",
      "[CV] START .....................................................................\n",
      "[CV] END ................................ score: (test=0.346) total time=  11.5s\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed:  1.6min\n",
      "[CV] START .....................................................................\n",
      "[CV] END ............................... score: (test=-1.172) total time=  11.8s\n",
      "[Parallel(n_jobs=-1)]: Done 185 tasks      | elapsed:  1.7min\n",
      "[CV] START .....................................................................\n",
      "[CV] END ............................... score: (test=-3.094) total time=  11.9s\n",
      "[Parallel(n_jobs=-1)]: Done 186 tasks      | elapsed:  1.7min\n",
      "[CV] START .....................................................................\n",
      "[CV] END ............................. score: (test=-205.397) total time=  11.8s\n",
      "[Parallel(n_jobs=-1)]: Done 187 tasks      | elapsed:  1.7min\n",
      "[CV] START .....................................................................\n",
      "[CV] END ............................... score: (test=-0.568) total time=  12.0s\n",
      "[Parallel(n_jobs=-1)]: Done 188 tasks      | elapsed:  1.7min\n",
      "[CV] START .....................................................................\n",
      "[CV] END ............................... score: (test=-1.313) total time=  12.0s\n",
      "[Parallel(n_jobs=-1)]: Done 189 tasks      | elapsed:  1.7min\n",
      "[CV] START .....................................................................\n",
      "[CV] END ............................... score: (test=-4.078) total time=  12.0s\n",
      "[Parallel(n_jobs=-1)]: Done 190 tasks      | elapsed:  1.7min\n",
      "[CV] START .....................................................................\n",
      "[CV] END ............................... score: (test=-2.373) total time=  12.1s\n",
      "[Parallel(n_jobs=-1)]: Done 191 tasks      | elapsed:  1.8min\n",
      "[CV] START .....................................................................\n",
      "[CV] END ............................... score: (test=-0.398) total time=  12.3s\n",
      "[Parallel(n_jobs=-1)]: Done 192 tasks      | elapsed:  1.8min\n",
      "[CV] START .....................................................................\n",
      "[CV] END ............................... score: (test=-0.665) total time=  12.1s\n",
      "[Parallel(n_jobs=-1)]: Done 193 tasks      | elapsed:  1.8min\n",
      "[CV] START .....................................................................\n",
      "[CV] END ............................... score: (test=-0.590) total time=  12.2s\n",
      "[Parallel(n_jobs=-1)]: Done 194 tasks      | elapsed:  1.8min\n",
      "[CV] START .....................................................................\n",
      "[CV] END ............................... score: (test=-0.358) total time=  12.6s\n",
      "[Parallel(n_jobs=-1)]: Done 195 tasks      | elapsed:  1.8min\n",
      "[CV] START .....................................................................\n",
      "[CV] END ............................... score: (test=-4.609) total time=  12.6s\n",
      "[Parallel(n_jobs=-1)]: Done 196 tasks      | elapsed:  1.8min\n",
      "[CV] START .....................................................................\n",
      "[CV] END ............................... score: (test=-4.854) total time=  12.5s\n",
      "[Parallel(n_jobs=-1)]: Done 197 tasks      | elapsed:  1.9min\n",
      "[CV] START .....................................................................\n",
      "[CV] END ............................... score: (test=-0.304) total time=  12.7s\n",
      "[Parallel(n_jobs=-1)]: Done 198 tasks      | elapsed:  1.9min\n",
      "[CV] START .....................................................................\n",
      "[CV] END ................................ score: (test=0.310) total time=  12.7s\n",
      "[Parallel(n_jobs=-1)]: Done 199 tasks      | elapsed:  1.9min\n",
      "[CV] START .....................................................................\n",
      "[CV] END ............................... score: (test=-2.607) total time=  13.0s\n",
      "[Parallel(n_jobs=-1)]: Done 200 tasks      | elapsed:  1.9min\n",
      "[CV] START .....................................................................\n",
      "[CV] END ............................... score: (test=-0.319) total time=  13.0s\n",
      "[Parallel(n_jobs=-1)]: Done 201 tasks      | elapsed:  1.9min\n",
      "[CV] START .....................................................................\n",
      "[CV] END ............................... score: (test=-6.274) total time=  12.9s\n",
      "[Parallel(n_jobs=-1)]: Done 202 tasks      | elapsed:  1.9min\n",
      "[CV] START .....................................................................\n",
      "[CV] END ............................... score: (test=-2.321) total time=  13.2s\n",
      "[Parallel(n_jobs=-1)]: Done 203 tasks      | elapsed:  2.0min\n",
      "[CV] START .....................................................................\n",
      "[CV] END ............................... score: (test=-0.181) total time=  13.1s\n",
      "[Parallel(n_jobs=-1)]: Done 204 tasks      | elapsed:  2.0min\n",
      "[CV] START .....................................................................\n",
      "[CV] END .............................. score: (test=-14.129) total time=  13.0s\n",
      "[Parallel(n_jobs=-1)]: Done 205 tasks      | elapsed:  2.0min\n",
      "[CV] START .....................................................................\n",
      "[CV] END ............................... score: (test=-2.278) total time=  13.3s\n",
      "[Parallel(n_jobs=-1)]: Done 206 tasks      | elapsed:  2.0min\n",
      "[CV] START .....................................................................\n",
      "[CV] END ............................... score: (test=-4.219) total time=  13.1s\n",
      "[Parallel(n_jobs=-1)]: Done 207 tasks      | elapsed:  2.0min\n",
      "[CV] START .....................................................................\n",
      "[CV] END .............................. score: (test=-10.853) total time=  13.2s\n",
      "[Parallel(n_jobs=-1)]: Done 208 tasks      | elapsed:  2.1min\n",
      "[CV] START .....................................................................\n",
      "[CV] END ............................... score: (test=-0.363) total time=  13.4s\n",
      "[Parallel(n_jobs=-1)]: Done 209 tasks      | elapsed:  2.1min\n",
      "[CV] START .....................................................................\n",
      "[CV] END .............................. score: (test=-17.407) total time=  13.7s\n",
      "[Parallel(n_jobs=-1)]: Done 210 tasks      | elapsed:  2.1min\n",
      "[CV] START .....................................................................\n",
      "[CV] END ............................... score: (test=-1.425) total time=  13.4s\n",
      "[Parallel(n_jobs=-1)]: Done 211 tasks      | elapsed:  2.1min\n",
      "[CV] START .....................................................................\n",
      "[CV] END ................................ score: (test=0.507) total time=  13.4s\n",
      "[Parallel(n_jobs=-1)]: Done 212 tasks      | elapsed:  2.1min\n",
      "[CV] START .....................................................................\n",
      "[CV] END .............................. score: (test=-13.954) total time=  13.6s\n",
      "[Parallel(n_jobs=-1)]: Done 213 tasks      | elapsed:  2.2min\n",
      "[CV] START .....................................................................\n",
      "[CV] END ............................... score: (test=-5.806) total time=  13.5s\n",
      "[Parallel(n_jobs=-1)]: Done 214 tasks      | elapsed:  2.2min\n",
      "[CV] START .....................................................................\n",
      "[CV] END ............................... score: (test=-6.229) total time=  13.6s\n",
      "[Parallel(n_jobs=-1)]: Done 215 tasks      | elapsed:  2.2min\n",
      "[CV] START .....................................................................\n",
      "[CV] END .............................. score: (test=-19.895) total time=  13.6s\n",
      "[Parallel(n_jobs=-1)]: Done 216 tasks      | elapsed:  2.2min\n",
      "[CV] START .....................................................................\n",
      "[CV] END ............................... score: (test=-0.489) total time=  13.9s\n",
      "[Parallel(n_jobs=-1)]: Done 217 tasks      | elapsed:  2.2min\n",
      "[CV] START .....................................................................\n",
      "[CV] END ............................... score: (test=-3.140) total time=  13.8s\n",
      "[Parallel(n_jobs=-1)]: Done 218 tasks      | elapsed:  2.3min\n",
      "[CV] START .....................................................................\n",
      "[CV] END ............................... score: (test=-0.963) total time=  14.0s\n",
      "[Parallel(n_jobs=-1)]: Done 219 tasks      | elapsed:  2.3min\n",
      "[CV] START .....................................................................\n",
      "[CV] END ............................... score: (test=-8.408) total time=  13.7s\n",
      "[Parallel(n_jobs=-1)]: Done 220 tasks      | elapsed:  2.3min\n",
      "[CV] START .....................................................................\n",
      "[CV] END ............................... score: (test=-9.422) total time=  14.1s\n",
      "[Parallel(n_jobs=-1)]: Done 221 tasks      | elapsed:  2.3min\n",
      "[CV] START .....................................................................\n",
      "[CV] END ............................... score: (test=-4.241) total time=  14.3s\n",
      "[Parallel(n_jobs=-1)]: Done 222 tasks      | elapsed:  2.3min\n",
      "[CV] START .....................................................................\n",
      "[CV] END ............................... score: (test=-1.513) total time=  14.1s\n",
      "[Parallel(n_jobs=-1)]: Done 223 tasks      | elapsed:  2.4min\n",
      "[CV] START .....................................................................\n",
      "[CV] END ............................... score: (test=-0.608) total time=  14.4s\n",
      "[Parallel(n_jobs=-1)]: Done 224 tasks      | elapsed:  2.4min\n",
      "[CV] START .....................................................................\n",
      "[CV] END ............................... score: (test=-8.375) total time=  14.5s\n",
      "[Parallel(n_jobs=-1)]: Done 225 tasks      | elapsed:  2.4min\n",
      "[CV] START .....................................................................\n",
      "[CV] END ............................... score: (test=-3.693) total time=  14.7s\n",
      "[Parallel(n_jobs=-1)]: Done 226 tasks      | elapsed:  2.4min\n",
      "[CV] START .....................................................................\n",
      "[CV] END ............................... score: (test=-7.737) total time=  14.7s\n",
      "[Parallel(n_jobs=-1)]: Done 227 tasks      | elapsed:  2.4min\n",
      "[CV] START .....................................................................\n",
      "[CV] END ............................... score: (test=-1.866) total time=  14.6s\n",
      "[Parallel(n_jobs=-1)]: Done 228 tasks      | elapsed:  2.5min\n",
      "[CV] START .....................................................................\n",
      "[CV] END ............................... score: (test=-6.285) total time=  15.1s\n",
      "[Parallel(n_jobs=-1)]: Done 229 tasks      | elapsed:  2.5min\n",
      "[CV] START .....................................................................\n",
      "[CV] END .............................. score: (test=-14.283) total time=  15.0s\n",
      "[Parallel(n_jobs=-1)]: Done 230 tasks      | elapsed:  2.5min\n",
      "[CV] START .....................................................................\n",
      "[CV] END ............................... score: (test=-1.889) total time=  15.1s\n",
      "[Parallel(n_jobs=-1)]: Done 231 tasks      | elapsed:  2.5min\n",
      "[CV] START .....................................................................\n",
      "[CV] END ............................... score: (test=-0.866) total time=  15.0s\n",
      "[Parallel(n_jobs=-1)]: Done 232 tasks      | elapsed:  2.5min\n",
      "[CV] START .....................................................................\n",
      "[CV] END ............................... score: (test=-2.586) total time=  15.2s\n",
      "[Parallel(n_jobs=-1)]: Done 233 tasks      | elapsed:  2.6min\n",
      "[CV] START .....................................................................\n",
      "[CV] END ............................... score: (test=-7.987) total time=  15.0s\n",
      "[Parallel(n_jobs=-1)]: Done 234 tasks      | elapsed:  2.6min\n",
      "[CV] START .....................................................................\n",
      "[CV] END ................................ score: (test=0.211) total time=  15.1s\n",
      "[Parallel(n_jobs=-1)]: Done 235 tasks      | elapsed:  2.6min\n",
      "[CV] START .....................................................................\n",
      "[CV] END ................................ score: (test=0.341) total time=  15.0s\n",
      "[Parallel(n_jobs=-1)]: Done 236 tasks      | elapsed:  2.6min\n",
      "[CV] START .....................................................................\n",
      "[CV] END ............................... score: (test=-1.589) total time=  15.3s\n",
      "[Parallel(n_jobs=-1)]: Done 237 tasks      | elapsed:  2.7min\n",
      "[CV] START .....................................................................\n",
      "[CV] END ............................... score: (test=-7.501) total time=  15.3s\n",
      "[Parallel(n_jobs=-1)]: Done 238 tasks      | elapsed:  2.7min\n",
      "[CV] START .....................................................................\n",
      "[CV] END .............................. score: (test=-29.718) total time=  15.4s\n",
      "[Parallel(n_jobs=-1)]: Done 239 tasks      | elapsed:  2.7min\n",
      "[CV] START .....................................................................\n",
      "[CV] END .............................. score: (test=-10.971) total time=  15.3s\n",
      "[Parallel(n_jobs=-1)]: Done 240 tasks      | elapsed:  2.7min\n",
      "[CV] START .....................................................................\n",
      "[CV] END ............................... score: (test=-2.333) total time=  15.4s\n",
      "[Parallel(n_jobs=-1)]: Done 241 tasks      | elapsed:  2.7min\n",
      "[CV] START .....................................................................\n",
      "[CV] END ............................... score: (test=-5.388) total time=  15.7s\n",
      "[Parallel(n_jobs=-1)]: Done 242 tasks      | elapsed:  2.8min\n",
      "[CV] START .....................................................................\n",
      "[CV] END .............................. score: (test=-52.509) total time=  15.3s\n",
      "[Parallel(n_jobs=-1)]: Done 243 tasks      | elapsed:  2.8min\n",
      "[CV] START .....................................................................\n",
      "[CV] END ............................... score: (test=-3.574) total time=  15.4s\n",
      "[Parallel(n_jobs=-1)]: Done 244 tasks      | elapsed:  2.8min\n",
      "[CV] START .....................................................................\n",
      "[CV] END ................................ score: (test=0.415) total time=  15.8s\n",
      "[Parallel(n_jobs=-1)]: Done 245 tasks      | elapsed:  2.8min\n",
      "[CV] START .....................................................................\n",
      "[CV] END .............................. score: (test=-16.710) total time=  15.7s\n",
      "[Parallel(n_jobs=-1)]: Done 246 tasks      | elapsed:  2.9min\n",
      "[CV] START .....................................................................\n",
      "[CV] END ............................... score: (test=-0.943) total time=  16.0s\n",
      "[Parallel(n_jobs=-1)]: Done 247 tasks      | elapsed:  2.9min\n",
      "[CV] START .....................................................................\n",
      "[CV] END .............................. score: (test=-16.241) total time=  15.8s\n",
      "[Parallel(n_jobs=-1)]: Done 248 tasks      | elapsed:  2.9min\n",
      "[CV] START .....................................................................\n",
      "[CV] END ................................ score: (test=0.124) total time=  15.9s\n",
      "[Parallel(n_jobs=-1)]: Done 249 tasks      | elapsed:  2.9min\n",
      "[CV] START .....................................................................\n",
      "[CV] END ............................... score: (test=-0.376) total time=  16.0s\n",
      "[Parallel(n_jobs=-1)]: Done 250 tasks      | elapsed:  2.9min\n",
      "[CV] START .....................................................................\n",
      "[CV] END .............................. score: (test=-25.523) total time=  16.2s\n",
      "[Parallel(n_jobs=-1)]: Done 251 tasks      | elapsed:  3.0min\n",
      "[CV] START .....................................................................\n",
      "[CV] END ............................... score: (test=-7.724) total time=  16.1s\n",
      "[Parallel(n_jobs=-1)]: Done 252 tasks      | elapsed:  3.0min\n",
      "[CV] START .....................................................................\n",
      "[CV] END ............................... score: (test=-1.059) total time=  16.0s\n",
      "[Parallel(n_jobs=-1)]: Done 253 tasks      | elapsed:  3.0min\n",
      "[CV] START .....................................................................\n",
      "[CV] END .............................. score: (test=-14.091) total time=  16.4s\n",
      "[Parallel(n_jobs=-1)]: Done 254 tasks      | elapsed:  3.0min\n",
      "[CV] START .....................................................................\n",
      "[CV] END ............................... score: (test=-4.450) total time=  16.6s\n",
      "[Parallel(n_jobs=-1)]: Done 255 tasks      | elapsed:  3.1min\n",
      "[CV] START .....................................................................\n",
      "[CV] END ............................... score: (test=-5.947) total time=  16.1s\n",
      "[Parallel(n_jobs=-1)]: Done 256 tasks      | elapsed:  3.1min\n",
      "[CV] START .....................................................................\n",
      "[CV] END .............................. score: (test=-23.197) total time=  16.4s\n",
      "[Parallel(n_jobs=-1)]: Done 257 tasks      | elapsed:  3.1min\n",
      "[CV] START .....................................................................\n",
      "[CV] END ............................... score: (test=-1.638) total time=  16.7s\n",
      "[Parallel(n_jobs=-1)]: Done 258 tasks      | elapsed:  3.1min\n",
      "[CV] START .....................................................................\n",
      "[CV] END ............................... score: (test=-0.401) total time=  16.6s\n",
      "[Parallel(n_jobs=-1)]: Done 259 tasks      | elapsed:  3.2min\n",
      "[CV] START .....................................................................\n",
      "[CV] END .............................. score: (test=-33.686) total time=  16.4s\n",
      "[Parallel(n_jobs=-1)]: Done 260 tasks      | elapsed:  3.2min\n",
      "[CV] START .....................................................................\n",
      "[CV] END ............................... score: (test=-1.548) total time=  16.8s\n",
      "[Parallel(n_jobs=-1)]: Done 261 tasks      | elapsed:  3.2min\n",
      "[CV] START .....................................................................\n",
      "[CV] END ............................... score: (test=-0.464) total time=  16.9s\n",
      "[Parallel(n_jobs=-1)]: Done 262 tasks      | elapsed:  3.2min\n",
      "[CV] START .....................................................................\n",
      "[CV] END ............................... score: (test=-8.916) total time=  17.1s\n",
      "[Parallel(n_jobs=-1)]: Done 263 tasks      | elapsed:  3.3min\n",
      "[CV] START .....................................................................\n",
      "[CV] END ............................. score: (test=-131.565) total time=  17.3s\n",
      "[Parallel(n_jobs=-1)]: Done 264 tasks      | elapsed:  3.3min\n",
      "[CV] START .....................................................................\n",
      "[CV] END ............................... score: (test=-0.003) total time=  17.2s\n",
      "[Parallel(n_jobs=-1)]: Done 265 tasks      | elapsed:  3.3min\n",
      "[CV] START .....................................................................\n",
      "[CV] END .............................. score: (test=-29.353) total time=  17.5s\n",
      "[Parallel(n_jobs=-1)]: Done 266 tasks      | elapsed:  3.3min\n",
      "[CV] START .....................................................................\n",
      "[CV] END ................................ score: (test=0.166) total time=  17.7s\n",
      "[Parallel(n_jobs=-1)]: Done 267 tasks      | elapsed:  3.4min\n",
      "[CV] START .....................................................................\n",
      "[CV] END ............................... score: (test=-4.087) total time=  17.7s\n",
      "[Parallel(n_jobs=-1)]: Done 268 tasks      | elapsed:  3.4min\n",
      "[CV] START .....................................................................\n",
      "[CV] END ............................... score: (test=-2.847) total time=  18.1s\n",
      "[Parallel(n_jobs=-1)]: Done 269 tasks      | elapsed:  3.4min\n",
      "[CV] START .....................................................................\n",
      "[CV] END ............................... score: (test=-0.777) total time=  17.9s\n",
      "[Parallel(n_jobs=-1)]: Done 270 tasks      | elapsed:  3.4min\n",
      "[CV] START .....................................................................\n",
      "[CV] END ................................ score: (test=0.186) total time=  18.3s\n",
      "[Parallel(n_jobs=-1)]: Done 271 tasks      | elapsed:  3.5min\n",
      "[CV] START .....................................................................\n",
      "[CV] END ............................... score: (test=-2.862) total time=  18.2s\n",
      "[Parallel(n_jobs=-1)]: Done 272 tasks      | elapsed:  3.5min\n",
      "[CV] START .....................................................................\n",
      "[CV] END ............................... score: (test=-6.700) total time=  18.6s\n",
      "[Parallel(n_jobs=-1)]: Done 273 tasks      | elapsed:  3.5min\n",
      "[CV] START .....................................................................\n",
      "[CV] END ............................... score: (test=-3.326) total time=  18.7s\n",
      "[Parallel(n_jobs=-1)]: Done 274 tasks      | elapsed:  3.5min\n",
      "[CV] START .....................................................................\n",
      "[CV] END ................................ score: (test=0.247) total time=  19.0s\n",
      "[Parallel(n_jobs=-1)]: Done 275 tasks      | elapsed:  3.6min\n",
      "[CV] START .....................................................................\n",
      "[CV] END ............................... score: (test=-0.601) total time=  19.2s\n",
      "[Parallel(n_jobs=-1)]: Done 276 tasks      | elapsed:  3.6min\n",
      "[CV] START .....................................................................\n",
      "[CV] END ............................... score: (test=-2.270) total time=  19.3s\n",
      "[Parallel(n_jobs=-1)]: Done 277 tasks      | elapsed:  3.6min\n",
      "[CV] START .....................................................................\n",
      "[CV] END ............................... score: (test=-9.799) total time=  19.3s\n",
      "[Parallel(n_jobs=-1)]: Done 278 tasks      | elapsed:  3.7min\n",
      "[CV] START .....................................................................\n",
      "[CV] END ............................... score: (test=-1.288) total time=  19.3s\n",
      "[Parallel(n_jobs=-1)]: Done 279 tasks      | elapsed:  3.7min\n",
      "[CV] START .....................................................................\n",
      "[CV] END ............................... score: (test=-0.248) total time=  19.3s\n",
      "[Parallel(n_jobs=-1)]: Done 280 tasks      | elapsed:  3.7min\n",
      "[CV] START .....................................................................\n",
      "[CV] END ............................... score: (test=-8.856) total time=  19.4s\n",
      "[Parallel(n_jobs=-1)]: Done 281 tasks      | elapsed:  3.7min\n",
      "[CV] START .....................................................................\n",
      "[CV] END ............................... score: (test=-3.736) total time=  19.6s\n",
      "[Parallel(n_jobs=-1)]: Done 282 tasks      | elapsed:  3.8min\n",
      "[CV] START .....................................................................\n",
      "[CV] END ............................... score: (test=-2.772) total time=  19.4s\n",
      "[Parallel(n_jobs=-1)]: Done 283 tasks      | elapsed:  3.8min\n",
      "[CV] START .....................................................................\n",
      "[CV] END ............................... score: (test=-2.839) total time=  20.0s\n",
      "[Parallel(n_jobs=-1)]: Done 284 tasks      | elapsed:  3.8min\n",
      "[CV] START .....................................................................\n",
      "[CV] END .............................. score: (test=-21.276) total time=  19.7s\n",
      "[Parallel(n_jobs=-1)]: Done 285 tasks      | elapsed:  3.8min\n",
      "[CV] START .....................................................................\n",
      "[CV] END ............................... score: (test=-6.622) total time=  19.7s\n",
      "[Parallel(n_jobs=-1)]: Done 286 tasks      | elapsed:  3.9min\n",
      "[CV] START .....................................................................\n",
      "[CV] END ............................... score: (test=-1.137) total time=  19.7s\n",
      "[Parallel(n_jobs=-1)]: Done 287 tasks      | elapsed:  3.9min\n",
      "[CV] START .....................................................................\n",
      "[CV] END ............................... score: (test=-0.005) total time=  19.9s\n",
      "[Parallel(n_jobs=-1)]: Done 288 tasks      | elapsed:  3.9min\n",
      "[CV] START .....................................................................\n",
      "[CV] END .............................. score: (test=-35.983) total time=  19.6s\n",
      "[Parallel(n_jobs=-1)]: Done 289 tasks      | elapsed:  4.0min\n",
      "[CV] START .....................................................................\n",
      "[CV] END .............................. score: (test=-34.229) total time=  20.1s\n",
      "[Parallel(n_jobs=-1)]: Done 290 tasks      | elapsed:  4.0min\n",
      "[CV] START .....................................................................\n",
      "[CV] END ................................ score: (test=0.332) total time=  20.3s\n",
      "[Parallel(n_jobs=-1)]: Done 291 tasks      | elapsed:  4.0min\n",
      "[CV] START .....................................................................\n",
      "[CV] END ............................... score: (test=-0.663) total time=  20.2s\n",
      "[Parallel(n_jobs=-1)]: Done 292 tasks      | elapsed:  4.0min\n",
      "[CV] START .....................................................................\n",
      "[CV] END .............................. score: (test=-23.453) total time=  20.3s\n",
      "[Parallel(n_jobs=-1)]: Done 293 tasks      | elapsed:  4.1min\n",
      "[CV] START .....................................................................\n",
      "[CV] END .............................. score: (test=-14.088) total time=  20.2s\n",
      "[Parallel(n_jobs=-1)]: Done 294 tasks      | elapsed:  4.1min\n",
      "[CV] START .....................................................................\n",
      "[CV] END .............................. score: (test=-17.191) total time=  20.1s\n",
      "[Parallel(n_jobs=-1)]: Done 295 tasks      | elapsed:  4.1min\n",
      "[CV] START .....................................................................\n",
      "[CV] END ............................... score: (test=-0.399) total time=  20.4s\n",
      "[Parallel(n_jobs=-1)]: Done 296 tasks      | elapsed:  4.1min\n",
      "[CV] START .....................................................................\n",
      "[CV] END ............................... score: (test=-1.131) total time=  20.4s\n",
      "[Parallel(n_jobs=-1)]: Done 297 tasks      | elapsed:  4.2min\n",
      "[CV] START .....................................................................\n",
      "[CV] END ............................... score: (test=-7.945) total time=  20.6s\n",
      "[Parallel(n_jobs=-1)]: Done 298 tasks      | elapsed:  4.2min\n",
      "[CV] START .....................................................................\n",
      "[CV] END ............................... score: (test=-4.841) total time=  20.4s\n",
      "[Parallel(n_jobs=-1)]: Done 299 tasks      | elapsed:  4.2min\n",
      "[CV] START .....................................................................\n",
      "[CV] END ............................... score: (test=-4.682) total time=  20.6s\n",
      "[Parallel(n_jobs=-1)]: Done 300 tasks      | elapsed:  4.3min\n",
      "[CV] START .....................................................................\n",
      "[CV] END ............................... score: (test=-3.334) total time=  20.4s\n",
      "[Parallel(n_jobs=-1)]: Done 301 tasks      | elapsed:  4.3min\n",
      "[CV] START .....................................................................\n",
      "[CV] END ............................... score: (test=-7.900) total time=  20.8s\n",
      "[Parallel(n_jobs=-1)]: Done 302 tasks      | elapsed:  4.3min\n",
      "[CV] START .....................................................................\n",
      "[CV] END ............................... score: (test=-9.490) total time=  20.4s\n",
      "[Parallel(n_jobs=-1)]: Done 303 tasks      | elapsed:  4.4min\n",
      "[CV] START .....................................................................\n",
      "[CV] END ............................... score: (test=-6.113) total time=  20.8s\n",
      "[Parallel(n_jobs=-1)]: Done 304 tasks      | elapsed:  4.4min\n",
      "[CV] START .....................................................................\n",
      "[CV] END ............................... score: (test=-1.534) total time=  20.9s\n",
      "[Parallel(n_jobs=-1)]: Done 305 tasks      | elapsed:  4.4min\n",
      "[CV] START .....................................................................\n",
      "[CV] END ............................... score: (test=-3.205) total time=  21.5s\n",
      "[Parallel(n_jobs=-1)]: Done 306 tasks      | elapsed:  4.4min\n",
      "[CV] START .....................................................................\n",
      "[CV] END ............................... score: (test=-3.150) total time=  21.0s\n",
      "[Parallel(n_jobs=-1)]: Done 307 tasks      | elapsed:  4.5min\n",
      "[CV] START .....................................................................\n",
      "[CV] END ............................... score: (test=-3.215) total time=  21.2s\n",
      "[Parallel(n_jobs=-1)]: Done 308 tasks      | elapsed:  4.5min\n",
      "[CV] START .....................................................................\n",
      "[CV] END ............................... score: (test=-6.106) total time=  21.0s\n",
      "[Parallel(n_jobs=-1)]: Done 309 tasks      | elapsed:  4.5min\n",
      "[CV] START .....................................................................\n",
      "[CV] END ............................... score: (test=-4.366) total time=  21.6s\n",
      "[Parallel(n_jobs=-1)]: Done 310 tasks      | elapsed:  4.6min\n",
      "[CV] START .....................................................................\n",
      "[CV] END ............................... score: (test=-3.000) total time=  21.7s\n",
      "[Parallel(n_jobs=-1)]: Done 311 tasks      | elapsed:  4.6min\n",
      "[CV] START .....................................................................\n",
      "[CV] END ............................... score: (test=-1.948) total time=  21.7s\n",
      "[Parallel(n_jobs=-1)]: Done 312 tasks      | elapsed:  4.6min\n",
      "[CV] START .....................................................................\n",
      "[CV] END ............................... score: (test=-7.182) total time=  21.3s\n",
      "[Parallel(n_jobs=-1)]: Done 313 tasks      | elapsed:  4.6min\n",
      "[CV] START .....................................................................\n",
      "[CV] END ............................... score: (test=-2.255) total time=  21.6s\n",
      "[Parallel(n_jobs=-1)]: Done 314 tasks      | elapsed:  4.7min\n",
      "[CV] START .....................................................................\n",
      "[CV] END .............................. score: (test=-13.571) total time=  21.4s\n",
      "[Parallel(n_jobs=-1)]: Done 315 tasks      | elapsed:  4.7min\n",
      "[CV] END ............................... score: (test=-7.654) total time=  21.8s\n",
      "[Parallel(n_jobs=-1)]: Done 316 tasks      | elapsed:  4.7min\n",
      "[CV] START .....................................................................\n",
      "[CV] START .....................................................................\n",
      "[CV] END ............................... score: (test=-4.427) total time=  21.8s\n",
      "[Parallel(n_jobs=-1)]: Done 317 tasks      | elapsed:  4.8min\n",
      "[CV] START .....................................................................\n",
      "[CV] END ............................... score: (test=-2.121) total time=  22.1s\n",
      "[Parallel(n_jobs=-1)]: Done 318 tasks      | elapsed:  4.8min\n",
      "[CV] START .....................................................................\n",
      "[CV] END ............................... score: (test=-4.747) total time=  22.3s\n",
      "[Parallel(n_jobs=-1)]: Done 319 tasks      | elapsed:  4.9min\n",
      "[CV] START .....................................................................\n",
      "[CV] END ............................... score: (test=-3.071) total time=  22.6s\n",
      "[Parallel(n_jobs=-1)]: Done 320 tasks      | elapsed:  4.9min\n",
      "[CV] START .....................................................................\n",
      "[CV] END ............................... score: (test=-6.408) total time=  22.3s\n",
      "[Parallel(n_jobs=-1)]: Done 321 tasks      | elapsed:  4.9min\n",
      "[CV] START .....................................................................\n",
      "[CV] END .............................. score: (test=-12.668) total time=  22.2s\n",
      "[Parallel(n_jobs=-1)]: Done 322 tasks      | elapsed:  4.9min\n",
      "[CV] START .....................................................................\n",
      "[CV] END .............................. score: (test=-12.052) total time=  22.5s\n",
      "[Parallel(n_jobs=-1)]: Done 323 tasks      | elapsed:  5.0min\n",
      "[CV] START .....................................................................\n",
      "[CV] END ............................... score: (test=-4.633) total time=  22.6s\n",
      "[Parallel(n_jobs=-1)]: Done 324 tasks      | elapsed:  5.0min\n",
      "[CV] START .....................................................................\n",
      "[CV] END .............................. score: (test=-40.674) total time=  22.4s\n",
      "[Parallel(n_jobs=-1)]: Done 325 tasks      | elapsed:  5.0min\n",
      "[CV] START .....................................................................\n",
      "[CV] END ............................... score: (test=-2.941) total time=  23.0s\n",
      "[Parallel(n_jobs=-1)]: Done 326 tasks      | elapsed:  5.1min\n",
      "[CV] START .....................................................................\n",
      "[CV] END ................................ score: (test=0.073) total time=  22.7s\n",
      "[Parallel(n_jobs=-1)]: Done 327 tasks      | elapsed:  5.1min\n",
      "[CV] START .....................................................................\n",
      "[CV] END ............................... score: (test=-9.508) total time=  22.7s\n",
      "[Parallel(n_jobs=-1)]: Done 328 tasks      | elapsed:  5.1min\n",
      "[CV] START .....................................................................\n",
      "[CV] END ............................... score: (test=-2.327) total time=  23.3s\n",
      "[Parallel(n_jobs=-1)]: Done 329 tasks      | elapsed:  5.2min\n",
      "[CV] START .....................................................................\n",
      "[CV] END .............................. score: (test=-60.549) total time=  22.8s\n",
      "[Parallel(n_jobs=-1)]: Done 330 tasks      | elapsed:  5.2min\n",
      "[CV] START .....................................................................\n",
      "[CV] END ............................... score: (test=-0.888) total time=  23.2s\n",
      "[Parallel(n_jobs=-1)]: Done 331 tasks      | elapsed:  5.2min\n",
      "[CV] START .....................................................................\n",
      "[CV] END ............................... score: (test=-4.486) total time=  22.8s\n",
      "[Parallel(n_jobs=-1)]: Done 332 tasks      | elapsed:  5.3min\n",
      "[CV] START .....................................................................\n",
      "[CV] END ............................... score: (test=-1.997) total time=  22.9s\n",
      "[Parallel(n_jobs=-1)]: Done 333 tasks      | elapsed:  5.3min\n",
      "[CV] START .....................................................................\n",
      "[CV] END ............................... score: (test=-2.615) total time=  22.8s\n",
      "[Parallel(n_jobs=-1)]: Done 334 tasks      | elapsed:  5.3min\n",
      "[CV] START .....................................................................\n",
      "[CV] END ............................... score: (test=-2.713) total time=  23.5s\n",
      "[Parallel(n_jobs=-1)]: Done 335 tasks      | elapsed:  5.4min\n",
      "[CV] START .....................................................................\n",
      "[CV] END ............................... score: (test=-1.552) total time=  23.5s\n",
      "[Parallel(n_jobs=-1)]: Done 336 tasks      | elapsed:  5.4min\n",
      "[CV] START .....................................................................\n",
      "[CV] END ............................... score: (test=-8.822) total time=  23.7s\n",
      "[Parallel(n_jobs=-1)]: Done 337 tasks      | elapsed:  5.4min\n",
      "[CV] START .....................................................................\n",
      "[CV] END ............................... score: (test=-3.150) total time=  23.8s\n",
      "[Parallel(n_jobs=-1)]: Done 338 tasks      | elapsed:  5.5min\n",
      "[CV] START .....................................................................\n",
      "[CV] END ............................... score: (test=-3.493) total time=  23.7s\n",
      "[Parallel(n_jobs=-1)]: Done 339 tasks      | elapsed:  5.5min\n",
      "[CV] START .....................................................................\n",
      "[CV] END ............................... score: (test=-0.025) total time=  23.5s\n",
      "[Parallel(n_jobs=-1)]: Done 340 tasks      | elapsed:  5.5min\n",
      "[CV] START .....................................................................\n",
      "[CV] END ............................... score: (test=-1.343) total time=  23.1s\n",
      "[Parallel(n_jobs=-1)]: Done 341 tasks      | elapsed:  5.6min\n",
      "[CV] START .....................................................................\n",
      "[CV] END ............................... score: (test=-1.068) total time=  23.0s\n",
      "[Parallel(n_jobs=-1)]: Done 342 tasks      | elapsed:  5.6min\n",
      "[CV] START .....................................................................\n",
      "[CV] END ............................... score: (test=-9.123) total time=  23.5s\n",
      "[Parallel(n_jobs=-1)]: Done 343 tasks      | elapsed:  5.7min\n",
      "[CV] START .....................................................................\n",
      "[CV] END ................................ score: (test=0.141) total time=  23.6s\n",
      "[Parallel(n_jobs=-1)]: Done 344 tasks      | elapsed:  5.7min\n",
      "[CV] START .....................................................................\n",
      "[CV] END ................................ score: (test=0.354) total time=  23.2s\n",
      "[Parallel(n_jobs=-1)]: Done 345 tasks      | elapsed:  5.7min\n",
      "[CV] START .....................................................................\n",
      "[CV] END ............................... score: (test=-2.339) total time=  23.7s\n",
      "[Parallel(n_jobs=-1)]: Done 346 tasks      | elapsed:  5.7min\n",
      "[CV] START .....................................................................\n",
      "[CV] END .............................. score: (test=-31.527) total time=  23.8s\n",
      "[Parallel(n_jobs=-1)]: Done 347 tasks      | elapsed:  5.8min\n",
      "[CV] START .....................................................................\n",
      "[CV] END ............................... score: (test=-6.913) total time=  23.6s\n",
      "[Parallel(n_jobs=-1)]: Done 348 tasks      | elapsed:  5.8min\n",
      "[CV] START .....................................................................\n",
      "[CV] END ............................... score: (test=-3.046) total time=  24.0s\n",
      "[Parallel(n_jobs=-1)]: Done 349 tasks      | elapsed:  5.8min\n",
      "[CV] START .....................................................................\n",
      "[CV] END ............................... score: (test=-2.790) total time=  23.7s\n",
      "[Parallel(n_jobs=-1)]: Done 350 tasks      | elapsed:  5.9min\n",
      "[CV] START .....................................................................\n",
      "[CV] END ............................... score: (test=-4.281) total time=  24.0s\n",
      "[Parallel(n_jobs=-1)]: Done 351 tasks      | elapsed:  5.9min\n",
      "[CV] START .....................................................................\n",
      "[CV] END .............................. score: (test=-20.820) total time=  24.1s\n",
      "[Parallel(n_jobs=-1)]: Done 352 tasks      | elapsed:  5.9min\n",
      "[CV] START .....................................................................\n",
      "[CV] END .............................. score: (test=-65.725) total time=  23.9s\n",
      "[Parallel(n_jobs=-1)]: Done 353 tasks      | elapsed:  6.0min\n",
      "[CV] START .....................................................................\n",
      "[CV] END .............................. score: (test=-11.843) total time=  23.4s\n",
      "[Parallel(n_jobs=-1)]: Done 354 tasks      | elapsed:  6.0min\n",
      "[CV] START .....................................................................\n",
      "[CV] END .............................. score: (test=-30.694) total time=  24.1s\n",
      "[Parallel(n_jobs=-1)]: Done 355 tasks      | elapsed:  6.1min\n",
      "[CV] START .....................................................................\n",
      "[CV] END .............................. score: (test=-48.688) total time=  24.6s\n",
      "[Parallel(n_jobs=-1)]: Done 356 tasks      | elapsed:  6.1min\n",
      "[CV] START .....................................................................\n",
      "[CV] END ............................... score: (test=-4.478) total time=  24.6s\n",
      "[Parallel(n_jobs=-1)]: Done 357 tasks      | elapsed:  6.1min\n",
      "[CV] START .....................................................................\n",
      "[CV] END ................................ score: (test=0.265) total time=  24.7s\n",
      "[Parallel(n_jobs=-1)]: Done 358 tasks      | elapsed:  6.2min\n",
      "[CV] START .....................................................................\n",
      "[CV] END ................................ score: (test=0.131) total time=  25.0s\n",
      "[Parallel(n_jobs=-1)]: Done 359 tasks      | elapsed:  6.2min\n",
      "[CV] START .....................................................................\n",
      "[CV] END ............................... score: (test=-1.929) total time=  24.3s\n",
      "[Parallel(n_jobs=-1)]: Done 360 tasks      | elapsed:  6.2min\n",
      "[CV] START .....................................................................\n",
      "[CV] END .............................. score: (test=-11.223) total time=  24.6s\n",
      "[Parallel(n_jobs=-1)]: Done 361 tasks      | elapsed:  6.3min\n",
      "[CV] START .....................................................................\n",
      "[CV] END ............................... score: (test=-6.503) total time=  24.6s\n",
      "[Parallel(n_jobs=-1)]: Done 362 tasks      | elapsed:  6.3min\n",
      "[CV] START .....................................................................\n",
      "[CV] END .............................. score: (test=-22.540) total time=  25.3s\n",
      "[Parallel(n_jobs=-1)]: Done 363 tasks      | elapsed:  6.3min\n",
      "[CV] START .....................................................................\n",
      "[CV] END .............................. score: (test=-20.727) total time=  24.7s\n",
      "[Parallel(n_jobs=-1)]: Done 364 tasks      | elapsed:  6.3min\n",
      "[CV] START .....................................................................\n",
      "[CV] END ............................... score: (test=-3.514) total time=  25.3s\n",
      "[Parallel(n_jobs=-1)]: Done 365 tasks      | elapsed:  6.4min\n",
      "[CV] START .....................................................................\n",
      "[CV] END ............................... score: (test=-5.822) total time=  25.0s\n",
      "[Parallel(n_jobs=-1)]: Done 366 tasks      | elapsed:  6.4min\n",
      "[CV] START .....................................................................\n",
      "[CV] END .............................. score: (test=-16.900) total time=  25.4s\n",
      "[Parallel(n_jobs=-1)]: Done 367 tasks      | elapsed:  6.5min\n",
      "[CV] START .....................................................................\n",
      "[CV] END ............................... score: (test=-2.437) total time=  25.3s\n",
      "[Parallel(n_jobs=-1)]: Done 368 tasks      | elapsed:  6.5min\n",
      "[CV] START .....................................................................\n",
      "[CV] END ............................... score: (test=-5.718) total time=  25.4s\n",
      "[Parallel(n_jobs=-1)]: Done 369 tasks      | elapsed:  6.5min\n",
      "[CV] START .....................................................................\n",
      "[CV] END .............................. score: (test=-10.510) total time=  25.1s\n",
      "[Parallel(n_jobs=-1)]: Done 370 tasks      | elapsed:  6.6min\n",
      "[CV] START .....................................................................\n",
      "[CV] END ............................... score: (test=-3.727) total time=  24.9s\n",
      "[Parallel(n_jobs=-1)]: Done 371 tasks      | elapsed:  6.6min\n",
      "[CV] START .....................................................................\n",
      "[CV] END ............................... score: (test=-0.438) total time=  25.5s\n",
      "[Parallel(n_jobs=-1)]: Done 372 tasks      | elapsed:  6.7min\n",
      "[CV] START .....................................................................\n",
      "[CV] END .............................. score: (test=-11.912) total time=  25.4s\n",
      "[Parallel(n_jobs=-1)]: Done 373 tasks      | elapsed:  6.7min\n",
      "[CV] START .....................................................................\n",
      "[CV] END .............................. score: (test=-11.705) total time=  25.8s\n",
      "[Parallel(n_jobs=-1)]: Done 374 tasks      | elapsed:  6.7min\n",
      "[CV] START .....................................................................\n",
      "[CV] END ............................... score: (test=-3.417) total time=  25.2s\n",
      "[Parallel(n_jobs=-1)]: Done 375 tasks      | elapsed:  6.8min\n",
      "[CV] START .....................................................................\n",
      "[CV] END ............................... score: (test=-7.056) total time=  25.6s\n",
      "[Parallel(n_jobs=-1)]: Done 376 tasks      | elapsed:  6.8min\n",
      "[CV] START .....................................................................\n",
      "[CV] END ............................... score: (test=-4.404) total time=  25.6s\n",
      "[Parallel(n_jobs=-1)]: Done 377 tasks      | elapsed:  6.8min\n",
      "[CV] START .....................................................................\n",
      "[CV] END ............................... score: (test=-4.716) total time=  25.8s\n",
      "[Parallel(n_jobs=-1)]: Done 378 tasks      | elapsed:  6.8min\n",
      "[CV] START .....................................................................\n",
      "[CV] END ............................... score: (test=-0.111) total time=  25.6s\n",
      "[Parallel(n_jobs=-1)]: Done 379 tasks      | elapsed:  6.9min\n",
      "[CV] START .....................................................................\n",
      "[CV] END ............................... score: (test=-0.256) total time=  25.8s\n",
      "[Parallel(n_jobs=-1)]: Done 380 tasks      | elapsed:  6.9min\n",
      "[CV] START .....................................................................\n",
      "[CV] END ............................... score: (test=-2.510) total time=  25.2s\n",
      "[Parallel(n_jobs=-1)]: Done 381 tasks      | elapsed:  7.0min\n",
      "[CV] START .....................................................................\n",
      "[CV] END ............................... score: (test=-0.346) total time=  25.9s\n",
      "[Parallel(n_jobs=-1)]: Done 382 tasks      | elapsed:  7.0min\n",
      "[CV] START .....................................................................\n",
      "[CV] END ............................... score: (test=-6.022) total time=  26.1s\n",
      "[Parallel(n_jobs=-1)]: Done 383 tasks      | elapsed:  7.1min\n",
      "[CV] START .....................................................................\n",
      "[CV] END ............................... score: (test=-0.652) total time=  26.1s\n",
      "[Parallel(n_jobs=-1)]: Done 384 tasks      | elapsed:  7.1min\n",
      "[CV] START .....................................................................\n",
      "[CV] END ............................... score: (test=-1.678) total time=  26.3s\n",
      "[Parallel(n_jobs=-1)]: Done 385 tasks      | elapsed:  7.1min\n",
      "[CV] START .....................................................................\n",
      "[CV] END ............................... score: (test=-0.516) total time=  26.7s\n",
      "[Parallel(n_jobs=-1)]: Done 386 tasks      | elapsed:  7.2min\n",
      "[CV] START .....................................................................\n",
      "[CV] END ............................. score: (test=-221.163) total time=  26.4s\n",
      "[Parallel(n_jobs=-1)]: Done 387 tasks      | elapsed:  7.2min\n",
      "[CV] START .....................................................................\n",
      "[CV] END .............................. score: (test=-12.314) total time=  26.6s\n",
      "[Parallel(n_jobs=-1)]: Done 388 tasks      | elapsed:  7.2min\n",
      "[CV] START .....................................................................\n",
      "[CV] END ............................... score: (test=-9.693) total time=  26.4s\n",
      "[Parallel(n_jobs=-1)]: Done 389 tasks      | elapsed:  7.3min\n",
      "[CV] START .....................................................................\n",
      "[CV] END ............................... score: (test=-3.676) total time=  26.5s\n",
      "[Parallel(n_jobs=-1)]: Done 390 tasks      | elapsed:  7.3min\n",
      "[CV] START .....................................................................\n",
      "[CV] END ............................... score: (test=-1.066) total time=  27.5s\n",
      "[Parallel(n_jobs=-1)]: Done 391 tasks      | elapsed:  7.4min\n",
      "[CV] START .....................................................................\n",
      "[CV] END ................................ score: (test=0.583) total time=  27.4s\n",
      "[Parallel(n_jobs=-1)]: Done 392 tasks      | elapsed:  7.4min\n",
      "[CV] START .....................................................................\n",
      "[CV] END ............................... score: (test=-0.749) total time=  27.0s\n",
      "[Parallel(n_jobs=-1)]: Done 393 tasks      | elapsed:  7.4min\n",
      "[CV] START .....................................................................\n",
      "[CV] END ............................... score: (test=-1.052) total time=  27.0s\n",
      "[Parallel(n_jobs=-1)]: Done 394 tasks      | elapsed:  7.5min\n",
      "[CV] START .....................................................................\n",
      "[CV] END .............................. score: (test=-10.905) total time=  27.2s\n",
      "[Parallel(n_jobs=-1)]: Done 395 tasks      | elapsed:  7.5min\n",
      "[CV] START .....................................................................\n",
      "[CV] END ............................... score: (test=-4.565) total time=  27.1s\n",
      "[Parallel(n_jobs=-1)]: Done 396 tasks      | elapsed:  7.5min\n",
      "[CV] START .....................................................................\n",
      "[CV] END ............................... score: (test=-0.690) total time=  27.3s\n",
      "[Parallel(n_jobs=-1)]: Done 397 tasks      | elapsed:  7.6min\n",
      "[CV] START .....................................................................\n",
      "[CV] END ............................... score: (test=-1.286) total time=  27.7s\n",
      "[Parallel(n_jobs=-1)]: Done 398 tasks      | elapsed:  7.6min\n",
      "[CV] START .....................................................................\n",
      "[CV] END ............................... score: (test=-0.112) total time=  27.5s\n",
      "[Parallel(n_jobs=-1)]: Done 399 tasks      | elapsed:  7.7min\n",
      "[CV] START .....................................................................\n",
      "[CV] END ............................... score: (test=-1.021) total time=  28.0s\n",
      "[Parallel(n_jobs=-1)]: Done 400 tasks      | elapsed:  7.7min\n",
      "[CV] START .....................................................................\n",
      "[CV] END ............................... score: (test=-3.939) total time=  27.6s\n",
      "[Parallel(n_jobs=-1)]: Done 401 tasks      | elapsed:  7.7min\n",
      "[CV] START .....................................................................\n",
      "[CV] END ............................... score: (test=-0.417) total time=  28.3s\n",
      "[Parallel(n_jobs=-1)]: Done 402 tasks      | elapsed:  7.8min\n",
      "[CV] START .....................................................................\n",
      "[CV] END .............................. score: (test=-67.862) total time=  27.6s\n",
      "[Parallel(n_jobs=-1)]: Done 403 tasks      | elapsed:  7.8min\n",
      "[CV] START .....................................................................\n",
      "[CV] END ................................ score: (test=0.621) total time=  28.1s\n",
      "[Parallel(n_jobs=-1)]: Done 404 tasks      | elapsed:  7.9min\n",
      "[CV] END ............................... score: (test=-1.144) total time=  27.5s\n",
      "[Parallel(n_jobs=-1)]: Done 405 tasks      | elapsed:  7.9min\n",
      "[CV] START .....................................................................\n",
      "[CV] START .....................................................................\n",
      "[CV] END ............................... score: (test=-1.456) total time=  27.7s\n",
      "[Parallel(n_jobs=-1)]: Done 406 tasks      | elapsed:  7.9min\n",
      "[CV] START .....................................................................\n",
      "[CV] END ................................ score: (test=0.415) total time=  28.1s\n",
      "[Parallel(n_jobs=-1)]: Done 407 tasks      | elapsed:  8.0min\n",
      "[CV] START .....................................................................\n",
      "[CV] END ............................... score: (test=-4.233) total time=  28.4s\n",
      "[Parallel(n_jobs=-1)]: Done 408 tasks      | elapsed:  8.0min\n",
      "[CV] START .....................................................................\n",
      "[CV] END ............................... score: (test=-4.692) total time=  28.2s\n",
      "[Parallel(n_jobs=-1)]: Done 409 tasks      | elapsed:  8.1min\n",
      "[CV] START .....................................................................\n",
      "[CV] END .............................. score: (test=-34.637) total time=  28.5s\n",
      "[Parallel(n_jobs=-1)]: Done 410 tasks      | elapsed:  8.1min\n",
      "[CV] START .....................................................................\n",
      "[CV] END ............................... score: (test=-8.472) total time=  29.0s\n",
      "[Parallel(n_jobs=-1)]: Done 411 tasks      | elapsed:  8.2min\n",
      "[CV] START .....................................................................\n",
      "[CV] END ............................... score: (test=-1.732) total time=  28.6s\n",
      "[Parallel(n_jobs=-1)]: Done 412 tasks      | elapsed:  8.2min\n",
      "[CV] START .....................................................................\n",
      "[CV] END ............................... score: (test=-0.140) total time=  28.7s\n",
      "[Parallel(n_jobs=-1)]: Done 413 tasks      | elapsed:  8.2min\n",
      "[CV] START .....................................................................\n",
      "[CV] END ................................ score: (test=0.190) total time=  28.9s\n",
      "[Parallel(n_jobs=-1)]: Done 414 tasks      | elapsed:  8.3min\n",
      "[CV] START .....................................................................\n",
      "[CV] END ............................... score: (test=-1.836) total time=  28.7s\n",
      "[Parallel(n_jobs=-1)]: Done 415 tasks      | elapsed:  8.3min\n",
      "[CV] START .....................................................................\n",
      "[CV] END ............................... score: (test=-0.709) total time=  29.1s\n",
      "[Parallel(n_jobs=-1)]: Done 416 tasks      | elapsed:  8.4min\n",
      "[CV] START .....................................................................\n",
      "[CV] END ................................ score: (test=0.129) total time=  29.1s\n",
      "[Parallel(n_jobs=-1)]: Done 417 tasks      | elapsed:  8.4min\n",
      "[CV] START .....................................................................\n",
      "[CV] END ............................... score: (test=-0.563) total time=  28.7s\n",
      "[Parallel(n_jobs=-1)]: Done 418 tasks      | elapsed:  8.4min\n",
      "[CV] START .....................................................................\n",
      "[CV] END ............................... score: (test=-5.707) total time=  27.1s\n",
      "[Parallel(n_jobs=-1)]: Done 419 tasks      | elapsed:  8.5min\n",
      "[CV] START .....................................................................\n",
      "[CV] END ................................ score: (test=0.442) total time=  26.4s\n",
      "[Parallel(n_jobs=-1)]: Done 420 tasks      | elapsed:  8.5min\n",
      "[CV] START .....................................................................\n",
      "[CV] END .............................. score: (test=-17.626) total time=  29.0s\n",
      "[Parallel(n_jobs=-1)]: Done 421 tasks      | elapsed:  8.5min\n",
      "[CV] START .....................................................................\n",
      "[CV] END ............................... score: (test=-1.774) total time=  25.8s\n",
      "[Parallel(n_jobs=-1)]: Done 422 tasks      | elapsed:  8.6min\n",
      "[CV] START .....................................................................\n",
      "[CV] END .............................. score: (test=-65.589) total time=  29.6s\n",
      "[Parallel(n_jobs=-1)]: Done 423 tasks      | elapsed:  8.7min\n",
      "[CV] START .....................................................................\n",
      "[CV] END ............................... score: (test=-2.941) total time=  30.0s\n",
      "[Parallel(n_jobs=-1)]: Done 424 tasks      | elapsed:  8.7min\n",
      "[CV] START .....................................................................\n",
      "[CV] END .............................. score: (test=-12.393) total time=  22.8s\n",
      "[Parallel(n_jobs=-1)]: Done 425 tasks      | elapsed:  8.7min\n",
      "[CV] START .....................................................................\n",
      "[CV] END .............................. score: (test=-13.449) total time=  30.4s\n",
      "[Parallel(n_jobs=-1)]: Done 426 tasks      | elapsed:  8.7min\n",
      "[CV] START .....................................................................\n",
      "[CV] END .............................. score: (test=-49.025) total time=  29.7s\n",
      "[Parallel(n_jobs=-1)]: Done 427 tasks      | elapsed:  8.8min\n",
      "[CV] START .....................................................................\n",
      "[CV] END ............................... score: (test=-5.470) total time=  22.9s\n",
      "[Parallel(n_jobs=-1)]: Done 428 tasks      | elapsed:  8.8min\n",
      "[CV] START .....................................................................\n",
      "[CV] END .............................. score: (test=-19.158) total time=  29.9s\n",
      "[Parallel(n_jobs=-1)]: Done 429 tasks      | elapsed:  8.9min\n",
      "[CV] START .....................................................................\n",
      "[CV] END .............................. score: (test=-14.034) total time=  30.2s\n",
      "[Parallel(n_jobs=-1)]: Done 430 tasks      | elapsed:  8.9min\n",
      "[CV] START .....................................................................\n",
      "[CV] END ............................... score: (test=-3.383) total time=  22.6s\n",
      "[Parallel(n_jobs=-1)]: Done 431 tasks      | elapsed:  8.9min\n",
      "[CV] START .....................................................................\n",
      "[CV] END ............................... score: (test=-5.159) total time=  29.9s\n",
      "[Parallel(n_jobs=-1)]: Done 432 tasks      | elapsed:  8.9min\n",
      "[CV] START .....................................................................\n",
      "[CV] END .............................. score: (test=-40.184) total time=  23.1s\n",
      "[Parallel(n_jobs=-1)]: Done 433 tasks      | elapsed:  9.0min\n",
      "[CV] START .....................................................................\n",
      "[CV] END .............................. score: (test=-16.477) total time=  29.9s\n",
      "[Parallel(n_jobs=-1)]: Done 434 tasks      | elapsed:  9.0min\n",
      "[CV] START .....................................................................\n",
      "[CV] END .............................. score: (test=-17.215) total time=  23.1s\n",
      "[Parallel(n_jobs=-1)]: Done 435 tasks      | elapsed:  9.1min\n",
      "[CV] START .....................................................................\n",
      "[CV] END ................................ score: (test=0.036) total time=  28.9s\n",
      "[Parallel(n_jobs=-1)]: Done 436 tasks      | elapsed:  9.1min\n",
      "[CV] START .....................................................................\n",
      "[CV] END ............................... score: (test=-9.775) total time=  30.0s\n",
      "[Parallel(n_jobs=-1)]: Done 437 tasks      | elapsed:  9.2min\n",
      "[CV] START .....................................................................\n",
      "[CV] END ............................... score: (test=-6.452) total time=  23.0s\n",
      "[Parallel(n_jobs=-1)]: Done 438 tasks      | elapsed:  9.2min\n",
      "[CV] START .....................................................................\n",
      "[CV] END .............................. score: (test=-11.040) total time=  29.4s\n",
      "[Parallel(n_jobs=-1)]: Done 439 tasks      | elapsed:  9.2min\n",
      "[CV] START .....................................................................\n",
      "[CV] END ............................... score: (test=-5.106) total time=  29.6s\n",
      "[Parallel(n_jobs=-1)]: Done 440 tasks      | elapsed:  9.3min\n",
      "[CV] START .....................................................................\n",
      "[CV] END ............................... score: (test=-6.397) total time=  28.3s\n",
      "[Parallel(n_jobs=-1)]: Done 441 tasks      | elapsed:  9.3min\n",
      "[CV] START .....................................................................\n",
      "[CV] END ................................ score: (test=0.031) total time=  23.6s\n",
      "[Parallel(n_jobs=-1)]: Done 442 tasks      | elapsed:  9.3min\n",
      "[CV] START .....................................................................\n",
      "[CV] END ............................... score: (test=-0.342) total time=  28.7s\n",
      "[Parallel(n_jobs=-1)]: Done 443 tasks      | elapsed:  9.3min\n",
      "[CV] START .....................................................................\n",
      "[CV] END ............................... score: (test=-1.048) total time=  29.0s\n",
      "[Parallel(n_jobs=-1)]: Done 444 tasks      | elapsed:  9.4min\n",
      "[CV] START .....................................................................\n",
      "[CV] END ............................... score: (test=-9.540) total time=  28.9s\n",
      "[Parallel(n_jobs=-1)]: Done 445 tasks      | elapsed:  9.4min\n",
      "[CV] START .....................................................................\n",
      "[CV] END ............................... score: (test=-7.300) total time=  28.6s\n",
      "[Parallel(n_jobs=-1)]: Done 446 tasks      | elapsed:  9.5min\n",
      "[CV] START .....................................................................\n",
      "[CV] END .............................. score: (test=-10.994) total time=  28.2s\n",
      "[Parallel(n_jobs=-1)]: Done 447 tasks      | elapsed:  9.6min\n",
      "[CV] START .....................................................................\n",
      "[CV] END ............................... score: (test=-8.937) total time=  29.1s\n",
      "[Parallel(n_jobs=-1)]: Done 448 tasks      | elapsed:  9.6min\n",
      "[CV] START .....................................................................\n",
      "[CV] END .............................. score: (test=-14.183) total time=  29.5s\n",
      "[Parallel(n_jobs=-1)]: Done 449 tasks      | elapsed:  9.7min\n",
      "[CV] START .....................................................................\n",
      "[CV] END ............................... score: (test=-2.712) total time=  29.2s\n",
      "[Parallel(n_jobs=-1)]: Done 450 tasks      | elapsed:  9.7min\n",
      "[CV] START .....................................................................\n",
      "[CV] END ............................... score: (test=-4.596) total time=  28.9s\n",
      "[Parallel(n_jobs=-1)]: Done 451 tasks      | elapsed:  9.7min\n",
      "[CV] START .....................................................................\n",
      "[CV] END ............................... score: (test=-7.661) total time=  29.2s\n",
      "[Parallel(n_jobs=-1)]: Done 452 tasks      | elapsed:  9.7min\n",
      "[CV] START .....................................................................\n",
      "[CV] END ............................... score: (test=-2.702) total time=  24.9s\n",
      "[Parallel(n_jobs=-1)]: Done 453 tasks      | elapsed:  9.8min\n",
      "[CV] START .....................................................................\n",
      "[CV] END ............................... score: (test=-0.941) total time=  30.1s\n",
      "[Parallel(n_jobs=-1)]: Done 454 tasks      | elapsed:  9.8min\n",
      "[CV] START .....................................................................\n",
      "[CV] END ............................... score: (test=-4.427) total time=  30.4s\n",
      "[Parallel(n_jobs=-1)]: Done 455 tasks      | elapsed:  9.9min\n",
      "[CV] START .....................................................................\n",
      "[CV] END ............................... score: (test=-1.979) total time=  30.3s\n",
      "[Parallel(n_jobs=-1)]: Done 456 tasks      | elapsed:  9.9min\n",
      "[CV] START .....................................................................\n",
      "[CV] END .............................. score: (test=-16.028) total time=  30.4s\n",
      "[Parallel(n_jobs=-1)]: Done 457 tasks      | elapsed:  9.9min\n",
      "[CV] START .....................................................................\n",
      "[CV] END .............................. score: (test=-15.849) total time=  31.6s\n",
      "[Parallel(n_jobs=-1)]: Done 458 tasks      | elapsed: 10.0min\n",
      "[CV] START .....................................................................\n",
      "[CV] END ............................... score: (test=-4.946) total time=  32.1s\n",
      "[Parallel(n_jobs=-1)]: Done 459 tasks      | elapsed: 10.1min\n",
      "[CV] START .....................................................................\n",
      "[CV] END ............................... score: (test=-1.621) total time=  31.8s\n",
      "[Parallel(n_jobs=-1)]: Done 460 tasks      | elapsed: 10.2min\n",
      "[CV] START .....................................................................\n",
      "[CV] END .............................. score: (test=-17.870) total time=  32.0s\n",
      "[Parallel(n_jobs=-1)]: Done 461 tasks      | elapsed: 10.2min\n",
      "[CV] START .....................................................................\n",
      "[CV] END .............................. score: (test=-14.157) total time=  31.8s\n",
      "[Parallel(n_jobs=-1)]: Done 462 tasks      | elapsed: 10.2min\n",
      "[CV] END .............................. score: (test=-14.145) total time=  32.8s\n",
      "[Parallel(n_jobs=-1)]: Done 463 tasks      | elapsed: 10.3min\n",
      "[CV] START .....................................................................\n",
      "[CV] START .....................................................................\n",
      "[CV] END ............................... score: (test=-6.783) total time=  32.4s\n",
      "[Parallel(n_jobs=-1)]: Done 464 tasks      | elapsed: 10.3min\n",
      "[CV] START .....................................................................\n",
      "[CV] END ............................... score: (test=-0.357) total time=  32.5s\n",
      "[Parallel(n_jobs=-1)]: Done 465 tasks      | elapsed: 10.3min\n",
      "[CV] START .....................................................................\n",
      "[CV] END ............................... score: (test=-6.478) total time=  32.3s\n",
      "[Parallel(n_jobs=-1)]: Done 466 tasks      | elapsed: 10.4min\n",
      "[CV] START .....................................................................\n",
      "[CV] END ............................... score: (test=-4.767) total time=  32.4s\n",
      "[Parallel(n_jobs=-1)]: Done 467 tasks      | elapsed: 10.4min\n",
      "[CV] END .............................. score: (test=-10.133) total time=  32.8s\n",
      "[Parallel(n_jobs=-1)]: Done 468 tasks      | elapsed: 10.4min\n",
      "[CV] START .....................................................................\n",
      "[CV] START .....................................................................\n",
      "[CV] END ............................... score: (test=-5.399) total time=  32.9s\n",
      "[Parallel(n_jobs=-1)]: Done 469 tasks      | elapsed: 10.5min\n",
      "[CV] START .....................................................................\n",
      "[CV] END ............................... score: (test=-0.303) total time=  31.6s\n",
      "[Parallel(n_jobs=-1)]: Done 470 tasks      | elapsed: 10.6min\n",
      "[CV] START .....................................................................\n",
      "[CV] END ............................... score: (test=-9.027) total time=  28.2s\n",
      "[Parallel(n_jobs=-1)]: Done 471 tasks      | elapsed: 10.6min\n",
      "[CV] END ................................ score: (test=0.561) total time=  31.7s\n",
      "[CV] START .....................................................................\n",
      "[Parallel(n_jobs=-1)]: Done 472 tasks      | elapsed: 10.6min\n",
      "[CV] START .....................................................................\n",
      "[CV] END .............................. score: (test=-13.912) total time=  27.4s\n",
      "[Parallel(n_jobs=-1)]: Done 473 tasks      | elapsed: 10.7min\n",
      "[CV] START .....................................................................\n",
      "[CV] END ............................... score: (test=-0.802) total time=  31.9s\n",
      "[Parallel(n_jobs=-1)]: Done 474 tasks      | elapsed: 10.8min\n",
      "[CV] END .............................. score: (test=-13.908) total time=  32.1s\n",
      "[Parallel(n_jobs=-1)]: Done 475 tasks      | elapsed: 10.8min\n",
      "[CV] START .....................................................................\n",
      "[CV] END ............................... score: (test=-2.027) total time=  32.3s\n",
      "[Parallel(n_jobs=-1)]: Done 476 tasks      | elapsed: 10.8min\n",
      "[CV] START .....................................................................\n",
      "[CV] START .....................................................................\n",
      "[CV] END ............................... score: (test=-4.864) total time=  32.4s\n",
      "[Parallel(n_jobs=-1)]: Done 477 tasks      | elapsed: 10.8min\n",
      "[CV] START .....................................................................\n",
      "[CV] END ............................... score: (test=-0.947) total time=  32.7s\n",
      "[Parallel(n_jobs=-1)]: Done 478 tasks      | elapsed: 10.9min\n",
      "[CV] START .....................................................................\n",
      "[CV] END ............................... score: (test=-5.442) total time=  32.9s\n",
      "[Parallel(n_jobs=-1)]: Done 479 tasks      | elapsed: 11.0min\n",
      "[CV] START .....................................................................\n",
      "[CV] END ............................... score: (test=-2.861) total time=  32.8s\n",
      "[Parallel(n_jobs=-1)]: Done 480 tasks      | elapsed: 11.0min\n",
      "[CV] START .....................................................................\n",
      "[CV] END ............................... score: (test=-1.468) total time=  33.0s\n",
      "[Parallel(n_jobs=-1)]: Done 481 tasks      | elapsed: 11.0min\n",
      "[CV] START .....................................................................\n",
      "[CV] END ............................... score: (test=-5.977) total time=  32.6s\n",
      "[Parallel(n_jobs=-1)]: Done 482 tasks      | elapsed: 11.1min\n",
      "[CV] START .....................................................................\n",
      "[CV] END ............................... score: (test=-4.195) total time=  33.3s\n",
      "[Parallel(n_jobs=-1)]: Done 483 tasks      | elapsed: 11.2min\n",
      "[CV] END ............................... score: (test=-0.876) total time=  32.3s\n",
      "[CV] START .....................................................................\n",
      "[Parallel(n_jobs=-1)]: Done 484 tasks      | elapsed: 11.2min\n",
      "[CV] START .....................................................................\n",
      "[CV] END ............................... score: (test=-1.451) total time=  33.0s\n",
      "[Parallel(n_jobs=-1)]: Done 485 tasks      | elapsed: 11.2min\n",
      "[CV] START .....................................................................\n",
      "[CV] END ............................... score: (test=-1.913) total time=  32.6s\n",
      "[Parallel(n_jobs=-1)]: Done 486 tasks      | elapsed: 11.3min\n",
      "[CV] START .....................................................................\n",
      "[CV] END ............................... score: (test=-5.210) total time=  33.0s\n",
      "[Parallel(n_jobs=-1)]: Done 487 tasks      | elapsed: 11.4min\n",
      "[CV] START .....................................................................\n",
      "[CV] END ............................... score: (test=-3.764) total time=  32.7s\n",
      "[Parallel(n_jobs=-1)]: Done 488 tasks      | elapsed: 11.4min\n",
      "[CV] START .....................................................................\n",
      "[CV] END ............................... score: (test=-9.728) total time=  32.6s\n",
      "[Parallel(n_jobs=-1)]: Done 489 tasks      | elapsed: 11.4min\n",
      "[CV] END ............................... score: (test=-3.662) total time=  26.9s\n",
      "[Parallel(n_jobs=-1)]: Done 490 tasks      | elapsed: 11.4min\n",
      "[CV] START .....................................................................\n",
      "[CV] START .....................................................................\n",
      "[CV] END ............................... score: (test=-0.099) total time=  28.2s\n",
      "[Parallel(n_jobs=-1)]: Done 491 tasks      | elapsed: 11.4min\n",
      "[CV] START .....................................................................\n",
      "[CV] END ............................... score: (test=-5.681) total time=  34.8s\n",
      "[Parallel(n_jobs=-1)]: Done 492 tasks      | elapsed: 11.6min\n",
      "[CV] START .....................................................................\n",
      "[CV] END .............................. score: (test=-16.291) total time=  34.5s\n",
      "[CV] START .....................................................................\n",
      "[CV] END ............................... score: (test=-0.229) total time=  30.7s\n",
      "[CV] START .....................................................................\n",
      "[CV] END ............................... score: (test=-0.896) total time=  29.8s\n",
      "[CV] START .....................................................................\n",
      "[CV] END ............................... score: (test=-3.827) total time=  29.2s\n",
      "[CV] START .....................................................................\n",
      "[CV] END ............................... score: (test=-0.952) total time=  35.1s\n",
      "[CV] START .....................................................................\n",
      "[CV] END ............................... score: (test=-0.377) total time=  27.5s\n",
      "[Parallel(n_jobs=-1)]: Done 498 out of 515 | elapsed: 11.9min remaining:   24.3s\n",
      "[CV] START .....................................................................\n",
      "[CV] END ............................... score: (test=-7.222) total time=  27.5s\n",
      "[CV] START .....................................................................\n",
      "[CV] END ............................... score: (test=-5.601) total time=  34.8s\n",
      "[CV] START .....................................................................\n",
      "[CV] END .............................. score: (test=-18.657) total time=  35.5s\n",
      "[CV] START .....................................................................\n",
      "[CV] END ............................... score: (test=-9.314) total time=  35.4s\n",
      "[CV] START .....................................................................\n",
      "[CV] END ............................... score: (test=-0.047) total time=  35.2s\n",
      "[CV] START .....................................................................\n",
      "[CV] END .............................. score: (test=-42.742) total time=  35.0s\n",
      "[Parallel(n_jobs=-1)]: Done 504 out of 515 | elapsed: 12.1min remaining:   15.9s\n",
      "[CV] END .............................. score: (test=-14.087) total time=  26.6s\n",
      "[CV] END ............................... score: (test=-5.623) total time=  34.8s\n",
      "[CV] END ............................... score: (test=-1.153) total time=  34.9s\n",
      "[CV] END .............................. score: (test=-93.581) total time=  33.8s\n",
      "[CV] END ............................... score: (test=-0.086) total time=  25.3s\n",
      "[CV] END ............................... score: (test=-4.535) total time=  32.2s\n",
      "[Parallel(n_jobs=-1)]: Done 510 out of 515 | elapsed: 12.3min remaining:    7.3s\n",
      "[CV] END ............................... score: (test=-0.647) total time=  29.6s\n",
      "[CV] END .............................. score: (test=-58.551) total time=  28.7s\n",
      "[CV] END ............................... score: (test=-6.683) total time=  26.7s\n",
      "[CV] END .............................. score: (test=-13.395) total time=  27.7s\n",
      "[CV] END ............................... score: (test=-0.296) total time=  26.1s\n",
      "[Parallel(n_jobs=-1)]: Done 515 out of 515 | elapsed: 12.4min finished\n",
      "Average cross-validation score: -8.225223613653357\n"
     ]
    }
   ],
   "source": [
    "# Use your pipeline to compress features and fit the model for predictions\n",
    "print(f'Pipeline Steps :{pipeline.steps}')\n",
    "pipeline.fit(X, y)  # Fit the pipeline on the entire dataset    \n",
    "print(f'Pipeline Score :{pipeline.score(X, y)}')  # Score the pipeline on the entire dataset of training data\n",
    "scores = cross_val_score(pipeline, X, y, cv=cv, scoring=\"r2\", n_jobs=-1, verbose=100) # how well the model generalizes to unseen data\n",
    "average_score = np.mean(scores)\n",
    "print(f'Average cross-validation score: {average_score}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "id": "c471f680",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split 0 R-squared: -13.075453272194059\n",
      "Split 1 R-squared: -0.9331288889240046\n",
      "Split 2 R-squared: -15.27279327781482\n",
      "Split 3 R-squared: -16.46915872140368\n",
      "Split 4 R-squared: -15.314556027995888\n",
      "Split 5 R-squared: 0.7929575025097846\n",
      "Split 6 R-squared: -0.9048806455916754\n",
      "Split 7 R-squared: -7.81944671135046\n",
      "Split 8 R-squared: -0.35521582563253595\n",
      "Split 9 R-squared: -4.275794224193854\n",
      "Split 10 R-squared: -6.988431903410659\n",
      "Split 11 R-squared: -17.199705089049992\n",
      "Split 12 R-squared: 0.500429715695187\n",
      "Split 13 R-squared: -0.35879860212520787\n",
      "Split 14 R-squared: -1.6451412937961525\n",
      "Split 15 R-squared: -0.4883515119283752\n",
      "Split 16 R-squared: -23.770729200047352\n",
      "Split 17 R-squared: -8.018442692611554\n",
      "Split 18 R-squared: -0.3785693696296437\n",
      "Split 19 R-squared: -4.264073684610318\n",
      "Split 20 R-squared: -2.6547025292521345\n",
      "Split 21 R-squared: -0.6522082935420874\n",
      "Split 22 R-squared: -4.613768339497009\n",
      "Split 23 R-squared: -4.092388963987142\n",
      "Split 24 R-squared: -0.2341727829989928\n",
      "Split 25 R-squared: -9.955376392418565\n",
      "Split 26 R-squared: -3.860841505436432\n",
      "Split 27 R-squared: -8.992712942814212\n",
      "Split 28 R-squared: -8.95586585442041\n",
      "Split 29 R-squared: -1.4185874337410516\n",
      "Split 30 R-squared: -0.16430724319772616\n",
      "Split 31 R-squared: -3.11980104062542\n",
      "Split 32 R-squared: -1.9233887101515328\n",
      "Split 33 R-squared: -0.14774700344490777\n",
      "Split 34 R-squared: -48.179887123602605\n",
      "Split 35 R-squared: -2.2924026777691626\n",
      "Split 36 R-squared: -0.8966640246926902\n",
      "Split 37 R-squared: -3.897192931867119\n",
      "Split 38 R-squared: 0.3794514199870954\n",
      "Split 39 R-squared: -9.961062491286578\n",
      "Split 40 R-squared: -0.37727939690284384\n",
      "Split 41 R-squared: -10.792104056513317\n",
      "Split 42 R-squared: -6.787433812802114\n",
      "Split 43 R-squared: -8.881841174333642\n",
      "Split 44 R-squared: -3.129836512903002\n",
      "Split 45 R-squared: -11.348373225624206\n",
      "Split 46 R-squared: -2.0199487691912967\n",
      "Split 47 R-squared: -0.014628259524342324\n",
      "Split 48 R-squared: -25.82244981872104\n",
      "Split 49 R-squared: -4.835496658020621\n",
      "Split 50 R-squared: -9.41247985495536\n",
      "Split 51 R-squared: -1.2366236166725226\n",
      "Split 52 R-squared: -1.6878031044970747\n",
      "Split 53 R-squared: -5.7965783717308845\n",
      "Split 54 R-squared: -5.17629205443662\n",
      "Split 55 R-squared: -6.952237188958049\n",
      "Split 56 R-squared: -6.978082607965456\n",
      "Split 57 R-squared: -1.5429978936633648\n",
      "Split 58 R-squared: -19.81377162242204\n",
      "Split 59 R-squared: -4.608447185974891\n",
      "Split 60 R-squared: -3.907368588448838\n",
      "Split 61 R-squared: -14.632868344464477\n",
      "Split 62 R-squared: -1.8378199140483504\n",
      "Split 63 R-squared: -34.24513274965166\n",
      "Split 64 R-squared: -12.694419189567055\n",
      "Split 65 R-squared: -1.2181494883539323\n",
      "Split 66 R-squared: -1.3953410178173593\n",
      "Split 67 R-squared: -0.47462644903803186\n",
      "Split 68 R-squared: -14.213416492363255\n",
      "Split 69 R-squared: -20.00885439777133\n",
      "Split 70 R-squared: -9.552729193660763\n",
      "Split 71 R-squared: -1.0799704653073485\n",
      "Split 72 R-squared: -9.25022382904153\n",
      "Split 73 R-squared: -0.8098291651485039\n",
      "Split 74 R-squared: -0.848502254723233\n",
      "Split 75 R-squared: -4.106597533485107\n",
      "Split 76 R-squared: -0.6672391527416424\n",
      "Split 77 R-squared: -6.974926051638019\n",
      "Split 78 R-squared: -1.1639303925802729\n",
      "Split 79 R-squared: -1.3131814026025017\n",
      "Split 80 R-squared: -9.145241319485175\n",
      "Split 81 R-squared: 0.6531348771262646\n",
      "Split 82 R-squared: -2.238978840955709\n",
      "Split 83 R-squared: -6.044488212652456\n",
      "Split 84 R-squared: -0.5989842572783985\n",
      "Split 85 R-squared: -0.9395742253816199\n",
      "Split 86 R-squared: -0.5169383183118033\n",
      "Split 87 R-squared: -12.979007579842495\n",
      "Split 88 R-squared: -0.5203476973942334\n",
      "Split 89 R-squared: -0.38124622434335054\n",
      "Split 90 R-squared: -2.543720492085466\n",
      "Split 91 R-squared: -0.6042062498461369\n",
      "Split 92 R-squared: -1.2250571822482073\n",
      "Split 93 R-squared: -0.5871470979996372\n",
      "Split 94 R-squared: -1.1425638405302254\n",
      "Split 95 R-squared: 0.3155260047335505\n",
      "Split 96 R-squared: -3.945199107671705\n",
      "Split 97 R-squared: -1.3542918375678399\n",
      "Split 98 R-squared: -8.164525747099535\n",
      "Split 99 R-squared: -30.45498816093188\n",
      "Split 100 R-squared: -13.0118603296535\n",
      "Split 101 R-squared: -1.85344783736879\n",
      "Split 102 R-squared: -11.87355719591196\n",
      "Split 103 R-squared: -13.785633359090545\n",
      "Split 104 R-squared: -4.789871964579197\n",
      "Split 105 R-squared: -8.784653518570206\n",
      "Split 106 R-squared: -1.8865012033112976\n",
      "Split 107 R-squared: -2.366335763463761\n",
      "Split 108 R-squared: -3.4051644542226427\n",
      "Split 109 R-squared: -41.810228133511316\n",
      "Split 110 R-squared: -0.021173606244174747\n",
      "Split 111 R-squared: -0.03551279938219176\n",
      "Split 112 R-squared: 0.13122214455204284\n",
      "Split 113 R-squared: -0.09169860465718105\n",
      "Split 114 R-squared: -0.14951513478768352\n",
      "Split 115 R-squared: -22.348563717413235\n",
      "Split 116 R-squared: -4.90678830849226\n",
      "Split 117 R-squared: -1.7037842443539462\n",
      "Split 118 R-squared: -3.8071934391857916\n",
      "Split 119 R-squared: 0.07050694178139028\n",
      "Split 120 R-squared: -0.5206556245588876\n",
      "Split 121 R-squared: -73.36367201882565\n",
      "Split 122 R-squared: -3.6965295232034956\n",
      "Split 123 R-squared: -2.0222086352765247\n",
      "Split 124 R-squared: -4.154011494189162\n",
      "Split 125 R-squared: -13.74719227651053\n",
      "Split 126 R-squared: -9.545706748938718\n",
      "Split 127 R-squared: -0.7630688419247307\n",
      "Split 128 R-squared: -5.592236013647454\n",
      "Split 129 R-squared: -0.41485932153360117\n",
      "Split 130 R-squared: -0.32090478184021176\n",
      "Split 131 R-squared: -0.19697989070759991\n",
      "Split 132 R-squared: -3.780269784098903\n",
      "Split 133 R-squared: -3.2943731294104053\n",
      "Split 134 R-squared: -4.9367735067470315\n",
      "Split 135 R-squared: -2.588665673043648\n",
      "Split 136 R-squared: -2.142763676186134\n",
      "Split 137 R-squared: -5.542946349751346\n",
      "Split 138 R-squared: -0.4027337369968347\n",
      "Split 139 R-squared: -11.016816652407083\n",
      "Split 140 R-squared: -3.472039638687722\n",
      "Split 141 R-squared: 0.020025468014828296\n",
      "Split 142 R-squared: -6.127393388424185\n",
      "Split 143 R-squared: -6.051926699303696\n",
      "Split 144 R-squared: -30.53746671262004\n",
      "Split 145 R-squared: -0.39450260850543906\n",
      "Split 146 R-squared: -3.558174957637804\n",
      "Split 147 R-squared: -0.8752509716583077\n",
      "Split 148 R-squared: -2.761620388432524\n",
      "Split 149 R-squared: 0.3089076065967782\n",
      "Split 150 R-squared: -13.85377241344951\n",
      "Split 151 R-squared: -8.012535527260244\n",
      "Split 152 R-squared: -1.6651624107290712\n",
      "Split 153 R-squared: -7.3839140029217365\n",
      "Split 154 R-squared: -9.414572754946711\n",
      "Split 155 R-squared: -2.5786007202368717\n",
      "Split 156 R-squared: 0.13981474040320896\n",
      "Split 157 R-squared: -18.406124447408434\n",
      "Split 158 R-squared: -1.8621856206332357\n",
      "Split 159 R-squared: -10.199936095053559\n",
      "Split 160 R-squared: -12.624653159172357\n",
      "Split 161 R-squared: -2.48792305071244\n",
      "Split 162 R-squared: -2.2206703026241765\n",
      "Split 163 R-squared: -9.969969414613036\n",
      "Split 164 R-squared: -1.6702521252133922\n",
      "Split 165 R-squared: 0.4730456129641408\n",
      "Split 166 R-squared: 0.2654374717294681\n",
      "Split 167 R-squared: -0.5148929567996874\n",
      "Split 168 R-squared: -31.162314710713282\n",
      "Split 169 R-squared: -11.95992869886462\n",
      "Split 170 R-squared: -7.162931615735911\n",
      "Split 171 R-squared: -4.318290097895739\n",
      "Split 172 R-squared: -0.28135104330024663\n",
      "Split 173 R-squared: -9.669467880624932\n",
      "Split 174 R-squared: -1.380116003925698\n",
      "Split 175 R-squared: -2.939994921733249\n",
      "Split 176 R-squared: -0.9532475780148697\n",
      "Split 177 R-squared: -0.7106527828931941\n",
      "Split 178 R-squared: -3.6240778339040345\n",
      "Split 179 R-squared: -0.9639879487699801\n",
      "Split 180 R-squared: -0.648513444352335\n",
      "Split 181 R-squared: -0.2474132212860527\n",
      "Split 182 R-squared: -9.716683850470515\n",
      "Split 183 R-squared: 0.34633246189220257\n",
      "Split 184 R-squared: -1.172473570119299\n",
      "Split 185 R-squared: -3.0938233072245858\n",
      "Split 186 R-squared: -205.39661277963643\n",
      "Split 187 R-squared: -0.5676284370820788\n",
      "Split 188 R-squared: -1.3126350344917768\n",
      "Split 189 R-squared: -4.078446559971558\n",
      "Split 190 R-squared: -2.3725182772685063\n",
      "Split 191 R-squared: -0.3981330301508772\n",
      "Split 192 R-squared: -0.6649272853040955\n",
      "Split 193 R-squared: -0.5898611741337658\n",
      "Split 194 R-squared: -0.35817033998494097\n",
      "Split 195 R-squared: -4.609131998437073\n",
      "Split 196 R-squared: -4.854002448652706\n",
      "Split 197 R-squared: -0.3043868523239224\n",
      "Split 198 R-squared: 0.3098230672794612\n",
      "Split 199 R-squared: -2.6073014990716374\n",
      "Split 200 R-squared: -0.31894093231643605\n",
      "Split 201 R-squared: -6.273885385376975\n",
      "Split 202 R-squared: -2.3209423616518947\n",
      "Split 203 R-squared: -0.18149866741548037\n",
      "Split 204 R-squared: -14.12882185862474\n",
      "Split 205 R-squared: -2.2775516235739475\n",
      "Split 206 R-squared: -4.218590545480366\n",
      "Split 207 R-squared: -10.853214383717464\n",
      "Split 208 R-squared: -0.3629990044675242\n",
      "Split 209 R-squared: -17.406812048130828\n",
      "Split 210 R-squared: -1.4251924047925737\n",
      "Split 211 R-squared: 0.5069715255444569\n",
      "Split 212 R-squared: -13.95356440608827\n",
      "Split 213 R-squared: -5.8058932944612005\n",
      "Split 214 R-squared: -6.229192527638684\n",
      "Split 215 R-squared: -19.89536319602244\n",
      "Split 216 R-squared: -0.4889084021363028\n",
      "Split 217 R-squared: -3.1396745513233952\n",
      "Split 218 R-squared: -0.9631561229115542\n",
      "Split 219 R-squared: -8.407793152731267\n",
      "Split 220 R-squared: -9.421717152212338\n",
      "Split 221 R-squared: -4.240787794278331\n",
      "Split 222 R-squared: -1.5133481469387577\n",
      "Split 223 R-squared: -0.6078618423627109\n",
      "Split 224 R-squared: -8.375381590883768\n",
      "Split 225 R-squared: -3.6933993646414285\n",
      "Split 226 R-squared: -7.737160610590351\n",
      "Split 227 R-squared: -1.8664700170352528\n",
      "Split 228 R-squared: -6.28536819133445\n",
      "Split 229 R-squared: -14.282823117952127\n",
      "Split 230 R-squared: -1.889321243427911\n",
      "Split 231 R-squared: -0.8662591700979974\n",
      "Split 232 R-squared: -2.585771402683803\n",
      "Split 233 R-squared: -7.986581325837955\n",
      "Split 234 R-squared: 0.21129795821481345\n",
      "Split 235 R-squared: 0.3409255240170771\n",
      "Split 236 R-squared: -1.5889279427231613\n",
      "Split 237 R-squared: -7.50128628709899\n",
      "Split 238 R-squared: -29.717572645326484\n",
      "Split 239 R-squared: -10.971489181519393\n",
      "Split 240 R-squared: -2.3329948309729946\n",
      "Split 241 R-squared: -5.387582411977852\n",
      "Split 242 R-squared: -52.50927904857804\n",
      "Split 243 R-squared: -3.574449026195577\n",
      "Split 244 R-squared: 0.4152923074906071\n",
      "Split 245 R-squared: -16.71047089431424\n",
      "Split 246 R-squared: -0.9432867741254805\n",
      "Split 247 R-squared: -16.240657640857307\n",
      "Split 248 R-squared: 0.12382640813605506\n",
      "Split 249 R-squared: -0.37636393691452974\n",
      "Split 250 R-squared: -25.523461962217066\n",
      "Split 251 R-squared: -7.723885302057161\n",
      "Split 252 R-squared: -1.059159583939905\n",
      "Split 253 R-squared: -14.09120696662105\n",
      "Split 254 R-squared: -4.449935906837261\n",
      "Split 255 R-squared: -5.946798429094541\n",
      "Split 256 R-squared: -23.197086324292055\n",
      "Split 257 R-squared: -1.6383265301641892\n",
      "Split 258 R-squared: -0.4012518305699506\n",
      "Split 259 R-squared: -33.686381900057505\n",
      "Split 260 R-squared: -1.5475538255103718\n",
      "Split 261 R-squared: -0.4641691713978293\n",
      "Split 262 R-squared: -8.916308960539983\n",
      "Split 263 R-squared: -131.56546412749802\n",
      "Split 264 R-squared: -0.002768969246984776\n",
      "Split 265 R-squared: -29.353489981612253\n",
      "Split 266 R-squared: 0.16620476877982449\n",
      "Split 267 R-squared: -4.0873372802341885\n",
      "Split 268 R-squared: -2.8472703353183504\n",
      "Split 269 R-squared: -0.7770619993898318\n",
      "Split 270 R-squared: 0.18570653226422895\n",
      "Split 271 R-squared: -2.8623053576655533\n",
      "Split 272 R-squared: -6.7002404492522265\n",
      "Split 273 R-squared: -3.3255528156046212\n",
      "Split 274 R-squared: 0.24710800705992797\n",
      "Split 275 R-squared: -0.6007179449895206\n",
      "Split 276 R-squared: -2.269934213135273\n",
      "Split 277 R-squared: -9.798565355777882\n",
      "Split 278 R-squared: -1.2880069718314262\n",
      "Split 279 R-squared: -0.2479188661468612\n",
      "Split 280 R-squared: -8.855719380209983\n",
      "Split 281 R-squared: -3.7361751845313576\n",
      "Split 282 R-squared: -2.839270560582531\n",
      "Split 283 R-squared: -2.7716450287846444\n",
      "Split 284 R-squared: -21.27574168151254\n",
      "Split 285 R-squared: -6.622425885155194\n",
      "Split 286 R-squared: -1.1368166824505792\n",
      "Split 287 R-squared: -0.005493897260760328\n",
      "Split 288 R-squared: -35.98316720447178\n",
      "Split 289 R-squared: -34.228767656609556\n",
      "Split 290 R-squared: 0.331746502204712\n",
      "Split 291 R-squared: -0.6628631850823448\n",
      "Split 292 R-squared: -23.45254833857884\n",
      "Split 293 R-squared: -14.088019535651801\n",
      "Split 294 R-squared: -17.19085534571012\n",
      "Split 295 R-squared: -0.3986741811620229\n",
      "Split 296 R-squared: -1.1308700404926433\n",
      "Split 297 R-squared: -7.944552873640612\n",
      "Split 298 R-squared: -4.840898544500556\n",
      "Split 299 R-squared: -4.681687036915942\n",
      "Split 300 R-squared: -3.333969856365152\n",
      "Split 301 R-squared: -7.900217516791429\n",
      "Split 302 R-squared: -9.490179831446929\n",
      "Split 303 R-squared: -6.112700833479483\n",
      "Split 304 R-squared: -1.533939255874727\n",
      "Split 305 R-squared: -3.2050465431910444\n",
      "Split 306 R-squared: -3.150398849627913\n",
      "Split 307 R-squared: -3.2153329412856575\n",
      "Split 308 R-squared: -6.105549750570768\n",
      "Split 309 R-squared: -4.3657785847238015\n",
      "Split 310 R-squared: -2.9995010624445584\n",
      "Split 311 R-squared: -1.94842231389522\n",
      "Split 312 R-squared: -7.182212646622952\n",
      "Split 313 R-squared: -2.255140420105095\n",
      "Split 314 R-squared: -13.571232000936087\n",
      "Split 315 R-squared: -7.653786724590727\n",
      "Split 316 R-squared: -4.426922207389352\n",
      "Split 317 R-squared: -2.120934072485594\n",
      "Split 318 R-squared: -4.746865820961371\n",
      "Split 319 R-squared: -3.070983304414071\n",
      "Split 320 R-squared: -6.408048513392279\n",
      "Split 321 R-squared: -12.667738934567273\n",
      "Split 322 R-squared: -12.052486849018324\n",
      "Split 323 R-squared: -4.632761177239387\n",
      "Split 324 R-squared: -40.674350303047845\n",
      "Split 325 R-squared: -2.94109653928214\n",
      "Split 326 R-squared: 0.0730165157298478\n",
      "Split 327 R-squared: -9.50822723314262\n",
      "Split 328 R-squared: -2.326568441624823\n",
      "Split 329 R-squared: -60.5491446251613\n",
      "Split 330 R-squared: -0.888205757191062\n",
      "Split 331 R-squared: -4.4856337565601185\n",
      "Split 332 R-squared: -1.9973673151591353\n",
      "Split 333 R-squared: -2.614553416254324\n",
      "Split 334 R-squared: -2.7132775503601803\n",
      "Split 335 R-squared: -1.552279803401643\n",
      "Split 336 R-squared: -8.822485587979681\n",
      "Split 337 R-squared: -3.1502279144261323\n",
      "Split 338 R-squared: -3.4926935466313607\n",
      "Split 339 R-squared: -0.025459510594116885\n",
      "Split 340 R-squared: -1.3433999663206575\n",
      "Split 341 R-squared: -1.0677571723968908\n",
      "Split 342 R-squared: -9.12318550529185\n",
      "Split 343 R-squared: 0.1414460116741122\n",
      "Split 344 R-squared: 0.3539812383905354\n",
      "Split 345 R-squared: -2.3387062191261707\n",
      "Split 346 R-squared: -31.52655703445668\n",
      "Split 347 R-squared: -6.912743621748275\n",
      "Split 348 R-squared: -3.0461097823298378\n",
      "Split 349 R-squared: -2.790248977015465\n",
      "Split 350 R-squared: -4.280505212042187\n",
      "Split 351 R-squared: -20.820205253251164\n",
      "Split 352 R-squared: -65.72549919050088\n",
      "Split 353 R-squared: -11.843151615475906\n",
      "Split 354 R-squared: -30.694413723554135\n",
      "Split 355 R-squared: -48.687791027340374\n",
      "Split 356 R-squared: -4.478035497946081\n",
      "Split 357 R-squared: 0.2651032084954439\n",
      "Split 358 R-squared: 0.13115106891019968\n",
      "Split 359 R-squared: -1.928783389189225\n",
      "Split 360 R-squared: -11.222781432404675\n",
      "Split 361 R-squared: -6.503211562431051\n",
      "Split 362 R-squared: -22.5399016167271\n",
      "Split 363 R-squared: -20.727062896689574\n",
      "Split 364 R-squared: -3.5140953316714754\n",
      "Split 365 R-squared: -5.821570458092323\n",
      "Split 366 R-squared: -16.90036710559784\n",
      "Split 367 R-squared: -2.4371854109052014\n",
      "Split 368 R-squared: -5.718296911056918\n",
      "Split 369 R-squared: -10.509674278232335\n",
      "Split 370 R-squared: -3.726745380691324\n",
      "Split 371 R-squared: -0.4383135771601596\n",
      "Split 372 R-squared: -11.911599640061354\n",
      "Split 373 R-squared: -11.705289448118409\n",
      "Split 374 R-squared: -3.41681154290304\n",
      "Split 375 R-squared: -7.056053533772584\n",
      "Split 376 R-squared: -4.4035756520511224\n",
      "Split 377 R-squared: -4.715576059801883\n",
      "Split 378 R-squared: -0.11085923423548083\n",
      "Split 379 R-squared: -0.255524763160206\n",
      "Split 380 R-squared: -2.5100891537481447\n",
      "Split 381 R-squared: -0.3459494893145241\n",
      "Split 382 R-squared: -6.022208318565362\n",
      "Split 383 R-squared: -0.6516864189453433\n",
      "Split 384 R-squared: -1.6781956360722603\n",
      "Split 385 R-squared: -0.5162262415439038\n",
      "Split 386 R-squared: -221.16341307221234\n",
      "Split 387 R-squared: -12.314377973455041\n",
      "Split 388 R-squared: -9.693021225950677\n",
      "Split 389 R-squared: -3.675583057297695\n",
      "Split 390 R-squared: -1.065792886851571\n",
      "Split 391 R-squared: 0.5829028073547973\n",
      "Split 392 R-squared: -0.7494212307345955\n",
      "Split 393 R-squared: -1.0518685386609996\n",
      "Split 394 R-squared: -10.904750621037854\n",
      "Split 395 R-squared: -4.564777289050209\n",
      "Split 396 R-squared: -0.6904268751415987\n",
      "Split 397 R-squared: -1.2863834173534796\n",
      "Split 398 R-squared: -0.11183709454485702\n",
      "Split 399 R-squared: -1.020532420648999\n",
      "Split 400 R-squared: -3.9386875992733126\n",
      "Split 401 R-squared: -0.41747014016443806\n",
      "Split 402 R-squared: -67.86151440543829\n",
      "Split 403 R-squared: 0.6205070437112941\n",
      "Split 404 R-squared: -1.1436417529213543\n",
      "Split 405 R-squared: -1.455903314585885\n",
      "Split 406 R-squared: 0.41504769444042644\n",
      "Split 407 R-squared: -4.233346200092311\n",
      "Split 408 R-squared: -4.692030958126291\n",
      "Split 409 R-squared: -34.637171402913566\n",
      "Split 410 R-squared: -8.471965337788449\n",
      "Split 411 R-squared: -1.7324510489069223\n",
      "Split 412 R-squared: -0.13975436586370393\n",
      "Split 413 R-squared: 0.19038000760063334\n",
      "Split 414 R-squared: -1.8356552819528633\n",
      "Split 415 R-squared: 0.12911683173320088\n",
      "Split 416 R-squared: -0.7087181951675978\n",
      "Split 417 R-squared: -0.563422289708456\n",
      "Split 418 R-squared: -5.706597081618579\n",
      "Split 419 R-squared: -17.62648965414367\n",
      "Split 420 R-squared: 0.44231437138232876\n",
      "Split 421 R-squared: -1.7736733003894791\n",
      "Split 422 R-squared: -65.5891626068716\n",
      "Split 423 R-squared: -2.940795998118342\n",
      "Split 424 R-squared: -13.449444836068537\n",
      "Split 425 R-squared: -49.02454255004374\n",
      "Split 426 R-squared: -12.39261257046071\n",
      "Split 427 R-squared: -14.034492928767344\n",
      "Split 428 R-squared: -19.15751948000814\n",
      "Split 429 R-squared: -5.158863392891088\n",
      "Split 430 R-squared: -5.47047027669282\n",
      "Split 431 R-squared: -3.3833734691412625\n",
      "Split 432 R-squared: -16.47747444763524\n",
      "Split 433 R-squared: -40.184436521600595\n",
      "Split 434 R-squared: 0.03616782734570767\n",
      "Split 435 R-squared: -9.775494259191717\n",
      "Split 436 R-squared: -17.215214087398625\n",
      "Split 437 R-squared: -11.039742657464323\n",
      "Split 438 R-squared: -5.105765049967976\n",
      "Split 439 R-squared: -6.452046984831557\n",
      "Split 440 R-squared: -6.397160399696002\n",
      "Split 441 R-squared: -0.3420723738103233\n",
      "Split 442 R-squared: -1.0478126570793664\n",
      "Split 443 R-squared: -9.540018207329023\n",
      "Split 444 R-squared: 0.030511803412374583\n",
      "Split 445 R-squared: -7.299568243438015\n",
      "Split 446 R-squared: -10.994378225611815\n",
      "Split 447 R-squared: -8.937355052753905\n",
      "Split 448 R-squared: -14.183276933284438\n",
      "Split 449 R-squared: -2.7122948404228824\n",
      "Split 450 R-squared: -4.595910907186279\n",
      "Split 451 R-squared: -7.66096225136579\n",
      "Split 452 R-squared: -0.9411211027450495\n",
      "Split 453 R-squared: -2.701742858746352\n",
      "Split 454 R-squared: -4.4266428182380535\n",
      "Split 455 R-squared: -1.9791818847596745\n",
      "Split 456 R-squared: -16.0275028301421\n",
      "Split 457 R-squared: -15.849040061087248\n",
      "Split 458 R-squared: -4.946497228418523\n",
      "Split 459 R-squared: -1.620679452833338\n",
      "Split 460 R-squared: -17.870392688504605\n",
      "Split 461 R-squared: -14.157300778024835\n",
      "Split 462 R-squared: -14.144576058258403\n",
      "Split 463 R-squared: -6.78291696928089\n",
      "Split 464 R-squared: -0.35676846453033106\n",
      "Split 465 R-squared: -6.478225311051665\n",
      "Split 466 R-squared: -4.7673394570906815\n",
      "Split 467 R-squared: -10.133270377219155\n",
      "Split 468 R-squared: -5.399156442138565\n",
      "Split 469 R-squared: -0.303164133480333\n",
      "Split 470 R-squared: 0.5606185588406724\n",
      "Split 471 R-squared: -9.026574798371124\n",
      "Split 472 R-squared: -13.911786518694308\n",
      "Split 473 R-squared: -0.8024580586950538\n",
      "Split 474 R-squared: -13.907619073876967\n",
      "Split 475 R-squared: -2.0267500405074035\n",
      "Split 476 R-squared: -4.863889467084389\n",
      "Split 477 R-squared: -0.9465534500286121\n",
      "Split 478 R-squared: -5.441937934336802\n",
      "Split 479 R-squared: -2.8610461368871034\n",
      "Split 480 R-squared: -1.467786794023687\n",
      "Split 481 R-squared: -5.977075002961946\n",
      "Split 482 R-squared: -4.195092594068811\n",
      "Split 483 R-squared: -0.8758132606150462\n",
      "Split 484 R-squared: -1.4506472054046808\n",
      "Split 485 R-squared: -1.9131802020243982\n",
      "Split 486 R-squared: -5.209623080324901\n",
      "Split 487 R-squared: -3.7638084640878606\n",
      "Split 488 R-squared: -9.728314018164244\n",
      "Split 489 R-squared: -3.6615438585052313\n",
      "Split 490 R-squared: -0.09900879587638256\n",
      "Split 491 R-squared: -5.681285141943771\n",
      "Split 492 R-squared: -16.29125804633534\n",
      "Split 493 R-squared: -0.22894097978777328\n",
      "Split 494 R-squared: -0.8955479933330908\n",
      "Split 495 R-squared: -0.9524828378923837\n",
      "Split 496 R-squared: -3.8269453407046123\n",
      "Split 497 R-squared: -5.601489829437788\n",
      "Split 498 R-squared: -18.657159221475705\n",
      "Split 499 R-squared: -9.313754707717807\n",
      "Split 500 R-squared: -0.04744471923801319\n",
      "Split 501 R-squared: -0.3770099501307749\n",
      "Split 502 R-squared: -7.222224203549107\n",
      "Split 503 R-squared: -42.742478735802976\n",
      "Split 504 R-squared: -5.623091451610537\n",
      "Split 505 R-squared: -1.1527764189214258\n",
      "Split 506 R-squared: -93.58056072403237\n",
      "Split 507 R-squared: -14.087449233509908\n",
      "Split 508 R-squared: -4.535130451907732\n",
      "Split 509 R-squared: -0.08591451424289365\n",
      "Split 510 R-squared: -0.6474134167295607\n",
      "Split 511 R-squared: -58.55119216121199\n",
      "Split 512 R-squared: -13.395189946452497\n",
      "Split 513 R-squared: -6.682519934884821\n",
      "Split 514 R-squared: -0.29576429385891645\n",
      "Mean Squared Error (MSE): 0.001152325535740645\n",
      "Root Mean Squared Error (RMSE): 0.033945920752583\n",
      "Mean Absolute Error (MAE): 0.025881564889844232\n",
      "R-squared: -0.09755978554209754\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Predictions\n",
    "X_slices = cv_splitter.take(X)\n",
    "y_slices = cv_splitter.take(y)\n",
    "\n",
    "test_labels = []\n",
    "test_preds = []\n",
    "for split in X_slices.index.unique(level=\"split\"):  \n",
    "    X_train_slice = X_slices[(split, \"train\")]  \n",
    "    y_train_slice = y_slices[(split, \"train\")]\n",
    "    X_test_slice = X_slices[(split, \"test\")]\n",
    "    y_test_slice = y_slices[(split, \"test\")]\n",
    "    slice_pipeline = pipeline.fit(X_train_slice, y_train_slice)  \n",
    "    test_pred = slice_pipeline.predict(X_test_slice)  \n",
    "    test_pred = pd.Series(test_pred, index=y_test_slice.index)\n",
    "    test_labels.append(y_test_slice)\n",
    "    test_preds.append(test_pred)\n",
    "    print(f\"Split {split} R-squared: {r2_score(y_test_slice, test_pred)}\")\n",
    "\n",
    "test_labels = pd.concat(test_labels).rename(\"labels\")  \n",
    "test_preds = pd.concat(test_preds).rename(\"preds\")\n",
    "\n",
    "# Show the accuracy of the predictions\n",
    "# Assuming test_labels and test_preds are your true and predicted values\n",
    "mse = mean_squared_error(test_labels, test_preds)\n",
    "rmse = np.sqrt(mse)  # or use mean_squared_error with squared=False\n",
    "mae = mean_absolute_error(test_labels, test_preds)\n",
    "r2 = r2_score(test_labels, test_preds)\n",
    "\n",
    "print(f\"Mean Squared Error (MSE): {mse}\")\n",
    "print(f\"Root Mean Squared Error (RMSE): {rmse}\")\n",
    "print(f\"Mean Absolute Error (MAE): {mae}\")\n",
    "print(f\"R-squared: {r2}\")\n",
    "\n",
    "# Visualize the predictions as a heatmap plotted against the price\n",
    "# data.close.vbt.overlay_with_heatmap(test_preds).show_svg()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "514e99fe",
   "metadata": {},
   "source": [
    "### Save the model\n",
    "this just saves the last cross validation model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "id": "84262055",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['model_upto_2023.joblib']"
      ]
     },
     "execution_count": 252,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from joblib import dump, load\n",
    "filename = 'model_upto_2023.joblib'\n",
    "dump(slice_pipeline, filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "id": "7f4262dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R-squared on the entire dataset: 0.7439928062964846\n"
     ]
    }
   ],
   "source": [
    "filename = 'model_upto_2023.joblib'\n",
    "# Load the model from the .joblib file\n",
    "final_pipeline = load(filename) \n",
    "\n",
    "# Make predictions on the entire dataset\n",
    "predictions = final_pipeline.predict(X)\n",
    "\n",
    "# Calculate the R-squared score on the entire dataset\n",
    "r2 = r2_score(y, predictions)\n",
    "\n",
    "print(f\"R-squared on the entire dataset: {r2}\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "916f6d12",
   "metadata": {},
   "source": [
    "# Test it on out of sample data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "id": "3124064b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "year\n",
      "2023    19012\n",
      "Name: count, dtype: int64 (19012, 17) (19012,)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "n = 150 # number of periods in the future to predict\n",
    "\n",
    "# Generate the features (X) using TA-Lib indicators\n",
    "# X = data.run(\"talib\", periods=vbt.run_func_dict(mavp=n))\n",
    "Xoos = outofsample_data.get()\n",
    "psar_vbt = outofsample_data.run(\"pandas_ta:PSAR\", append=True, acceleration=0.02, maximum=0.2)\n",
    "# add trend label as a feature\n",
    "Xoos['trend'] = outofsample_data.run(\"trendlb\", .2, 0.05, mode=\"binary\").labels # add trend label as a feature\n",
    "# X['psar_cross'] = psar_vbt.psarr\n",
    "# Drop the time columns\n",
    "# Drop Open time and close time\n",
    "Xoos = Xoos.drop(['Open Time','Close Time'], axis=1)\n",
    "# Add time features\n",
    "Xoos['dayofmonth']  = Xoos.index.day\n",
    "Xoos['month']       = Xoos.index.month\n",
    "Xoos['year']        = Xoos.index.year\n",
    "Xoos['hour']        = Xoos.index.hour\n",
    "Xoos['minute']      = Xoos.index.minute\n",
    "Xoos['dayofweek']   = Xoos.index.dayofweek\n",
    "Xoos['dayofyear']   = Xoos.index.dayofyear\n",
    "\n",
    "# Now we are trying to generate future price predictions so we will set the y labels to the price change n periods in the future\n",
    "yoos = (outofsample_data.close.shift(-n) / outofsample_data.close - 1).rolling(n).mean() # future price change we use rolling mean to smooth the data\n",
    "print(Xoos['year'].value_counts(), Xoos.shape, yoos.shape)\n",
    "# Preprocessing steps to handle NaNs\n",
    "Xoos = Xoos.replace([-np.inf, np.inf], np.nan) # replace inf with nan\n",
    "invalid_column_mask = Xoos.isnull().all(axis=0) #| (Xoos.nunique() == 1) # drop columns that are all nan or have only one unique value\n",
    "Xoos = Xoos.loc[:, ~invalid_column_mask] # drop invalid columns\n",
    "invalid_row_mask = Xoos.isnull().any(axis=1) | yoos.isnull() # drop rows that have nan in any column or in y\n",
    "\n",
    "# Drop invalid rows in X and y\n",
    "Xoos = Xoos.loc[~invalid_row_mask]\n",
    "yoos = yoos.loc[~invalid_row_mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "id": "04e7bbd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16809,)\n",
      "(16809, 17)\n"
     ]
    }
   ],
   "source": [
    "print(yoos.shape)\n",
    "print(Xoos.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "cb2e6bff",
   "metadata": {},
   "source": [
    "### Test the model on data it has never seen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "id": "76e7ee74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R-squared on the entire dataset: -0.5081144832850475\n"
     ]
    }
   ],
   "source": [
    "# Make predictions on the entire dataset\n",
    "predictions = final_pipeline.predict(Xoos)\n",
    "\n",
    "# Calculate the R-squared score on the entire dataset\n",
    "r2 = r2_score(yoos, predictions)\n",
    "\n",
    "print(f\"R-squared on the entire dataset: {r2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "id": "68199994",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Open Time\n",
       "2023-01-05 00:12:00+00:00    0.036279\n",
       "2023-01-05 00:55:00+00:00    0.028800\n",
       "2023-01-05 01:32:00+00:00    0.042632\n",
       "2023-01-05 03:34:00+00:00    0.035124\n",
       "2023-01-05 05:34:00+00:00    0.021477\n",
       "                               ...   \n",
       "2023-05-12 18:52:00+00:00   -0.016851\n",
       "2023-05-12 19:05:00+00:00   -0.035510\n",
       "2023-05-12 19:06:00+00:00   -0.021985\n",
       "2023-05-12 19:14:00+00:00   -0.011926\n",
       "2023-05-12 19:25:00+00:00   -0.034376\n",
       "Name: predictions, Length: 16809, dtype: float32"
      ]
     },
     "execution_count": 280,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a pandas dataframe or series with the predictions and the index from the out of sample data\n",
    "predictions = pd.Series(predictions, index=yoos.index)\n",
    "predictions = predictions.rename(\"predictions\")\n",
    "predictions"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f165b4a6",
   "metadata": {},
   "source": [
    "#### Run a hypothetical portfolio sim on out-of-sample data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "id": "f829bdae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start                         2023-01-05 00:12:00+00:00\n",
      "End                           2023-05-12 19:25:00+00:00\n",
      "Period                                            16809\n",
      "Start Value                                       100.0\n",
      "Min Value                                     99.410886\n",
      "Max Value                                    159.722864\n",
      "End Value                                    150.327808\n",
      "Total Return [%]                              50.327808\n",
      "Benchmark Return [%]                          53.705321\n",
      "Total Time Exposure [%]                       35.962877\n",
      "Max Gross Exposure [%]                       105.326711\n",
      "Max Drawdown [%]                               7.475423\n",
      "Max Drawdown Duration                            6567.0\n",
      "Total Orders                                        170\n",
      "Total Fees Paid                                     0.0\n",
      "Total Trades                                         85\n",
      "Win Rate [%]                                  49.411765\n",
      "Best Trade [%]                                13.489384\n",
      "Worst Trade [%]                               -2.548543\n",
      "Avg Winning Trade [%]                          1.827473\n",
      "Avg Losing Trade [%]                          -0.789402\n",
      "Avg Winning Trade Duration                    86.809524\n",
      "Avg Losing Trade Duration                     55.790698\n",
      "Profit Factor                                  2.079852\n",
      "Expectancy                                     0.592092\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "pf = vbt.Portfolio.from_signals(\n",
    "    outofsample_data.close[predictions.index], # use only the test set\n",
    "    entries         = predictions > 0.05, # long when probability of price increase is greater than 2%\n",
    "    exits           = predictions < 0.00, # long when probability of price increase is greater than 2%\n",
    "    short_entries   = predictions < -0.04, # long when probability of price increase is greater than 2%\n",
    "    short_exits     = predictions > 0.0, # short when probability prediction is less than -5%\n",
    "    # direction=\"both\" # long and short\n",
    ")\n",
    "print(pf.stats())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "id": "f3d45606",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dc82816cf09b4064a524e73106b3b53b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FigureWidget({\n",
       "    'data': [{'showlegend': False,\n",
       "              'type': 'scatter',\n",
       "              'uid': '61ce1684-ccf9-4634-9c43-531a035debf9',\n",
       "              'x': array([datetime.datetime(2023, 1, 5, 0, 12, tzinfo=datetime.timezone.utc),\n",
       "                          datetime.datetime(2023, 1, 5, 0, 55, tzinfo=datetime.timezone.utc),\n",
       "                          datetime.datetime(2023, 1, 5, 1, 32, tzinfo=datetime.timezone.utc), ...,\n",
       "                          datetime.datetime(2023, 5, 12, 19, 6, tzinfo=datetime.timezone.utc),\n",
       "                          datetime.datetime(2023, 5, 12, 19, 14, tzinfo=datetime.timezone.utc),\n",
       "                          datetime.datetime(2023, 5, 12, 19, 25, tzinfo=datetime.timezone.utc)],\n",
       "                         dtype=object),\n",
       "              'y': array([1.        , 1.        , 1.        , ..., 1.50327808, 1.50327808,\n",
       "                          1.50327808])}],\n",
       "    'layout': {'height': 200,\n",
       "               'legend': {'orientation': 'h',\n",
       "                          'traceorder': 'normal',\n",
       "                          'x': 1,\n",
       "                          'xanchor': 'right',\n",
       "                          'y': 1.02,\n",
       "                          'yanchor': 'bottom'},\n",
       "               'margin': {'b': 30, 'l': 30, 'r': 30, 't': 30},\n",
       "               'template': '...',\n",
       "               'title': {'text': 'Cumulative Returns'},\n",
       "               'width': 800}\n",
       "})"
      ]
     },
     "execution_count": 298,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Plot the equity curve\n",
    "pf.cumulative_returns.vbt.plot(title=\"Cumulative Returns\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "id": "3051d7b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start                         2021-01-05 00:43:00+00:00\n",
      "End                           2022-11-20 22:07:00+00:00\n",
      "Period                                           103000\n",
      "Start Value                                       100.0\n",
      "Min Value                                     94.806732\n",
      "Max Value                                  36715.737951\n",
      "End Value                                   34442.71571\n",
      "Total Return [%]                            34342.71571\n",
      "Benchmark Return [%]                         -49.859093\n",
      "Total Time Exposure [%]                       46.091262\n",
      "Max Gross Exposure [%]                       119.010255\n",
      "Max Drawdown [%]                              28.172648\n",
      "Max Drawdown Duration                            6255.0\n",
      "Total Orders                                       3643\n",
      "Total Fees Paid                                     0.0\n",
      "Total Trades                                       1843\n",
      "Win Rate [%]                                   53.20304\n",
      "Best Trade [%]                                18.821047\n",
      "Worst Trade [%]                               -7.773382\n",
      "Avg Winning Trade [%]                          1.313584\n",
      "Avg Losing Trade [%]                          -0.772467\n",
      "Avg Winning Trade Duration                    34.926531\n",
      "Avg Losing Trade Duration                     15.339141\n",
      "Profit Factor                                  1.647842\n",
      "Expectancy                                    18.329047\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "pf = vbt.Portfolio.from_signals(\n",
    "    data.close[test_preds.index], # use only the test set\n",
    "    entries         = test_preds > 0.05, # long when probability of price increase is greater than 2%\n",
    "    exits           = test_preds < 0.00, # long when probability of price increase is greater than 2%\n",
    "    short_entries   = test_preds < -0.02, # long when probability of price increase is greater than 2%\n",
    "    short_exits     = test_preds > 0.0, # short when probability prediction is less than -5%\n",
    "    # direction=\"both\" # long and short\n",
    ")\n",
    "print(pf.stats())\n",
    "# pf.plot().show_svg()\n",
    "# Show first period\n",
    "# pf['2018':'2021'].plot().show_svg()\n",
    "# Show second period\n",
    "# pf['2021':'2023'].plot().show_svg()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "id": "a82c4832",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: xlabel='Open Time'>"
      ]
     },
     "execution_count": 274,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pf.cumulative_returns.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "id": "950a94b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "trades = pf.trades.records_readable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "id": "9c43d6f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Exit Trade Id', 'Column', 'Size', 'Entry Order Id', 'Entry Index',\n",
       "       'Avg Entry Price', 'Entry Fees', 'Exit Order Id', 'Exit Index',\n",
       "       'Avg Exit Price', 'Exit Fees', 'PnL', 'Return', 'Direction', 'Status',\n",
       "       'Position Id'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 237,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trades.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "id": "ea6b46f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "id": "0467be22",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     -0.093568\n",
       "1      0.069835\n",
       "2      0.079223\n",
       "3      0.119176\n",
       "4      0.292235\n",
       "5      0.479242\n",
       "6      0.681068\n",
       "7      0.664205\n",
       "8      0.648885\n",
       "9      0.664747\n",
       "10     0.618195\n",
       "11     0.727713\n",
       "12     0.739285\n",
       "13     0.682467\n",
       "14     0.684473\n",
       "15     0.665843\n",
       "16     0.659420\n",
       "17     0.621389\n",
       "18     0.596163\n",
       "19     0.605308\n",
       "20     0.661325\n",
       "21     0.789655\n",
       "22     0.725321\n",
       "23     0.738717\n",
       "24     0.743559\n",
       "25     0.942702\n",
       "26     1.006950\n",
       "27     1.121159\n",
       "28     1.123540\n",
       "29     1.126232\n",
       "30     1.126321\n",
       "31     1.122834\n",
       "32     1.118541\n",
       "33     1.241230\n",
       "34     1.436890\n",
       "35     1.557385\n",
       "36     1.486426\n",
       "37     1.558936\n",
       "38     1.492381\n",
       "39     1.470659\n",
       "40     1.485587\n",
       "41     1.474581\n",
       "42     1.549354\n",
       "43     1.615579\n",
       "44     1.608512\n",
       "45     1.631505\n",
       "46     1.650737\n",
       "47     1.631495\n",
       "48     1.699710\n",
       "49     1.702695\n",
       "50     1.802934\n",
       "51     1.991144\n",
       "52     2.339177\n",
       "53     2.245478\n",
       "54     2.208691\n",
       "55     2.353065\n",
       "56     2.457167\n",
       "57     2.479185\n",
       "58     2.484244\n",
       "59     2.466179\n",
       "60     2.462894\n",
       "61     2.504543\n",
       "62     2.524944\n",
       "63     2.537285\n",
       "64     2.690134\n",
       "65     2.841220\n",
       "66     2.809654\n",
       "67     2.875338\n",
       "68     2.966926\n",
       "69     2.964151\n",
       "70     3.138222\n",
       "71     3.290108\n",
       "72     3.396464\n",
       "73     3.557103\n",
       "74     3.545147\n",
       "75     3.527061\n",
       "76     3.614555\n",
       "77     3.863395\n",
       "78     3.934440\n",
       "79     3.936140\n",
       "80     3.900418\n",
       "81     3.936731\n",
       "82     3.939704\n",
       "83     3.918382\n",
       "84     3.645045\n",
       "85     3.663333\n",
       "86     3.669523\n",
       "87     3.720883\n",
       "88     3.891291\n",
       "89     4.004993\n",
       "90     3.930451\n",
       "91     4.024212\n",
       "92     4.122962\n",
       "93     4.128781\n",
       "94     4.150765\n",
       "95     4.106870\n",
       "96     4.310147\n",
       "97     4.305521\n",
       "98     4.357581\n",
       "99     4.574034\n",
       "100    4.705735\n",
       "101    4.685693\n",
       "102    4.586739\n",
       "103    4.659596\n",
       "104    4.798772\n",
       "105    4.822314\n",
       "106    4.763449\n",
       "107    4.774808\n",
       "108    4.634383\n",
       "109    4.629413\n",
       "110    4.973842\n",
       "111    4.983743\n",
       "112    5.335380\n",
       "113    5.325479\n",
       "114    5.349786\n",
       "115    5.327821\n",
       "116    5.211656\n",
       "117    5.161036\n",
       "118    4.994793\n",
       "119    4.970605\n",
       "120    5.058119\n",
       "121    5.000635\n",
       "122    4.977681\n",
       "123    4.967393\n",
       "124    5.188810\n",
       "125    5.248250\n",
       "126    5.245411\n",
       "127    5.598609\n",
       "128    5.713723\n",
       "129    6.005196\n",
       "130    5.954223\n",
       "131    5.986220\n",
       "132    6.032431\n",
       "Name: Return, dtype: float64"
      ]
     },
     "execution_count": 239,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trades['Return'].cumsum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "id": "678a8e4b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Size</th>\n",
       "      <th>Entry Index</th>\n",
       "      <th>Avg Entry Price</th>\n",
       "      <th>Exit Index</th>\n",
       "      <th>Direction</th>\n",
       "      <th>Status</th>\n",
       "      <th>Avg Exit Price</th>\n",
       "      <th>PnL</th>\n",
       "      <th>Return</th>\n",
       "      <th>Position Id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.003234</td>\n",
       "      <td>2021-01-05 04:15:00+00:00</td>\n",
       "      <td>30921.37</td>\n",
       "      <td>2021-01-06 02:51:00+00:00</td>\n",
       "      <td>Short</td>\n",
       "      <td>Closed</td>\n",
       "      <td>33814.61</td>\n",
       "      <td>-9.356765</td>\n",
       "      <td>-0.093568</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.002681</td>\n",
       "      <td>2021-01-06 02:51:00+00:00</td>\n",
       "      <td>33814.61</td>\n",
       "      <td>2021-01-07 18:19:00+00:00</td>\n",
       "      <td>Long</td>\n",
       "      <td>Closed</td>\n",
       "      <td>39340.00</td>\n",
       "      <td>14.811326</td>\n",
       "      <td>0.163402</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.002681</td>\n",
       "      <td>2021-01-07 18:19:00+00:00</td>\n",
       "      <td>39340.00</td>\n",
       "      <td>2021-01-07 18:22:00+00:00</td>\n",
       "      <td>Short</td>\n",
       "      <td>Closed</td>\n",
       "      <td>38970.68</td>\n",
       "      <td>0.989997</td>\n",
       "      <td>0.009388</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.002731</td>\n",
       "      <td>2021-01-07 18:22:00+00:00</td>\n",
       "      <td>38970.68</td>\n",
       "      <td>2021-01-10 03:21:00+00:00</td>\n",
       "      <td>Long</td>\n",
       "      <td>Closed</td>\n",
       "      <td>40527.68</td>\n",
       "      <td>4.252792</td>\n",
       "      <td>0.039953</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.002731</td>\n",
       "      <td>2021-01-10 03:21:00+00:00</td>\n",
       "      <td>40527.68</td>\n",
       "      <td>2021-01-11 21:02:00+00:00</td>\n",
       "      <td>Short</td>\n",
       "      <td>Closed</td>\n",
       "      <td>33513.98</td>\n",
       "      <td>19.157228</td>\n",
       "      <td>0.173059</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.003875</td>\n",
       "      <td>2021-01-11 21:02:00+00:00</td>\n",
       "      <td>33513.98</td>\n",
       "      <td>2021-01-14 15:36:00+00:00</td>\n",
       "      <td>Long</td>\n",
       "      <td>Closed</td>\n",
       "      <td>39781.31</td>\n",
       "      <td>24.283642</td>\n",
       "      <td>0.187006</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.003875</td>\n",
       "      <td>2021-01-14 15:36:00+00:00</td>\n",
       "      <td>39781.31</td>\n",
       "      <td>2021-01-22 05:29:00+00:00</td>\n",
       "      <td>Short</td>\n",
       "      <td>Closed</td>\n",
       "      <td>31752.39</td>\n",
       "      <td>31.109167</td>\n",
       "      <td>0.201826</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.005834</td>\n",
       "      <td>2021-01-22 05:29:00+00:00</td>\n",
       "      <td>31752.39</td>\n",
       "      <td>2021-01-22 07:22:00+00:00</td>\n",
       "      <td>Long</td>\n",
       "      <td>Closed</td>\n",
       "      <td>31216.94</td>\n",
       "      <td>-3.123882</td>\n",
       "      <td>-0.016863</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.005834</td>\n",
       "      <td>2021-01-22 07:22:00+00:00</td>\n",
       "      <td>31216.94</td>\n",
       "      <td>2021-01-23 23:43:00+00:00</td>\n",
       "      <td>Short</td>\n",
       "      <td>Closed</td>\n",
       "      <td>31695.18</td>\n",
       "      <td>-2.790112</td>\n",
       "      <td>-0.015320</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.005658</td>\n",
       "      <td>2021-01-23 23:43:00+00:00</td>\n",
       "      <td>31695.18</td>\n",
       "      <td>2021-01-26 10:31:00+00:00</td>\n",
       "      <td>Long</td>\n",
       "      <td>Closed</td>\n",
       "      <td>32197.92</td>\n",
       "      <td>2.844536</td>\n",
       "      <td>0.015862</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.005658</td>\n",
       "      <td>2021-01-26 10:31:00+00:00</td>\n",
       "      <td>32197.92</td>\n",
       "      <td>2021-01-29 08:44:00+00:00</td>\n",
       "      <td>Short</td>\n",
       "      <td>Closed</td>\n",
       "      <td>33696.78</td>\n",
       "      <td>-8.480648</td>\n",
       "      <td>-0.046551</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.005155</td>\n",
       "      <td>2021-01-29 08:44:00+00:00</td>\n",
       "      <td>33696.78</td>\n",
       "      <td>2021-01-29 08:59:00+00:00</td>\n",
       "      <td>Long</td>\n",
       "      <td>Closed</td>\n",
       "      <td>37387.18</td>\n",
       "      <td>19.022958</td>\n",
       "      <td>0.109518</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.005155</td>\n",
       "      <td>2021-01-29 08:59:00+00:00</td>\n",
       "      <td>37387.18</td>\n",
       "      <td>2021-01-29 09:49:00+00:00</td>\n",
       "      <td>Short</td>\n",
       "      <td>Closed</td>\n",
       "      <td>36954.54</td>\n",
       "      <td>2.230136</td>\n",
       "      <td>0.011572</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.005275</td>\n",
       "      <td>2021-01-29 09:49:00+00:00</td>\n",
       "      <td>36954.54</td>\n",
       "      <td>2021-01-29 18:43:00+00:00</td>\n",
       "      <td>Long</td>\n",
       "      <td>Closed</td>\n",
       "      <td>34854.86</td>\n",
       "      <td>-11.076674</td>\n",
       "      <td>-0.056818</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.005275</td>\n",
       "      <td>2021-01-29 18:43:00+00:00</td>\n",
       "      <td>34854.86</td>\n",
       "      <td>2021-01-29 18:45:00+00:00</td>\n",
       "      <td>Short</td>\n",
       "      <td>Closed</td>\n",
       "      <td>34784.96</td>\n",
       "      <td>0.368751</td>\n",
       "      <td>0.002005</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.005297</td>\n",
       "      <td>2021-01-29 18:45:00+00:00</td>\n",
       "      <td>34784.96</td>\n",
       "      <td>2021-01-29 19:42:00+00:00</td>\n",
       "      <td>Long</td>\n",
       "      <td>Closed</td>\n",
       "      <td>34136.93</td>\n",
       "      <td>-3.432364</td>\n",
       "      <td>-0.018630</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.005297</td>\n",
       "      <td>2021-01-29 19:42:00+00:00</td>\n",
       "      <td>34136.93</td>\n",
       "      <td>2021-01-29 19:53:00+00:00</td>\n",
       "      <td>Short</td>\n",
       "      <td>Closed</td>\n",
       "      <td>34356.19</td>\n",
       "      <td>-1.161335</td>\n",
       "      <td>-0.006423</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.005229</td>\n",
       "      <td>2021-01-29 19:53:00+00:00</td>\n",
       "      <td>34356.19</td>\n",
       "      <td>2021-01-30 03:34:00+00:00</td>\n",
       "      <td>Long</td>\n",
       "      <td>Closed</td>\n",
       "      <td>33049.58</td>\n",
       "      <td>-6.832273</td>\n",
       "      <td>-0.038031</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.005229</td>\n",
       "      <td>2021-01-30 03:34:00+00:00</td>\n",
       "      <td>33049.58</td>\n",
       "      <td>2021-01-30 05:38:00+00:00</td>\n",
       "      <td>Short</td>\n",
       "      <td>Closed</td>\n",
       "      <td>33883.29</td>\n",
       "      <td>-4.359475</td>\n",
       "      <td>-0.025226</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.004972</td>\n",
       "      <td>2021-01-30 05:38:00+00:00</td>\n",
       "      <td>33883.29</td>\n",
       "      <td>2021-01-30 14:08:00+00:00</td>\n",
       "      <td>Long</td>\n",
       "      <td>Closed</td>\n",
       "      <td>34193.18</td>\n",
       "      <td>1.540675</td>\n",
       "      <td>0.009146</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.004972</td>\n",
       "      <td>2021-01-30 14:08:00+00:00</td>\n",
       "      <td>34193.18</td>\n",
       "      <td>2021-01-31 17:56:00+00:00</td>\n",
       "      <td>Short</td>\n",
       "      <td>Closed</td>\n",
       "      <td>32277.80</td>\n",
       "      <td>9.522664</td>\n",
       "      <td>0.056016</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.005562</td>\n",
       "      <td>2021-01-31 17:56:00+00:00</td>\n",
       "      <td>32277.80</td>\n",
       "      <td>2021-02-03 07:17:00+00:00</td>\n",
       "      <td>Long</td>\n",
       "      <td>Closed</td>\n",
       "      <td>36420.01</td>\n",
       "      <td>23.037845</td>\n",
       "      <td>0.128330</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.005562</td>\n",
       "      <td>2021-02-03 07:17:00+00:00</td>\n",
       "      <td>36420.01</td>\n",
       "      <td>2021-02-04 08:24:00+00:00</td>\n",
       "      <td>Short</td>\n",
       "      <td>Closed</td>\n",
       "      <td>38763.05</td>\n",
       "      <td>-13.031351</td>\n",
       "      <td>-0.064334</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.004889</td>\n",
       "      <td>2021-02-04 08:24:00+00:00</td>\n",
       "      <td>38763.05</td>\n",
       "      <td>2021-02-06 04:18:00+00:00</td>\n",
       "      <td>Long</td>\n",
       "      <td>Closed</td>\n",
       "      <td>39282.31</td>\n",
       "      <td>2.538854</td>\n",
       "      <td>0.013396</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.004889</td>\n",
       "      <td>2021-02-06 04:18:00+00:00</td>\n",
       "      <td>39282.31</td>\n",
       "      <td>2021-02-07 00:00:00+00:00</td>\n",
       "      <td>Short</td>\n",
       "      <td>Closed</td>\n",
       "      <td>39092.10</td>\n",
       "      <td>0.930007</td>\n",
       "      <td>0.004842</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.004937</td>\n",
       "      <td>2021-02-07 00:00:00+00:00</td>\n",
       "      <td>39092.10</td>\n",
       "      <td>2021-02-10 10:28:00+00:00</td>\n",
       "      <td>Long</td>\n",
       "      <td>Closed</td>\n",
       "      <td>46877.01</td>\n",
       "      <td>38.433703</td>\n",
       "      <td>0.199143</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.004937</td>\n",
       "      <td>2021-02-10 10:28:00+00:00</td>\n",
       "      <td>46877.01</td>\n",
       "      <td>2021-02-10 15:45:00+00:00</td>\n",
       "      <td>Short</td>\n",
       "      <td>Closed</td>\n",
       "      <td>43865.26</td>\n",
       "      <td>14.868856</td>\n",
       "      <td>0.064248</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.005615</td>\n",
       "      <td>2021-02-10 15:45:00+00:00</td>\n",
       "      <td>43865.26</td>\n",
       "      <td>2021-02-14 13:52:00+00:00</td>\n",
       "      <td>Long</td>\n",
       "      <td>Closed</td>\n",
       "      <td>48875.10</td>\n",
       "      <td>28.129660</td>\n",
       "      <td>0.114210</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.005615</td>\n",
       "      <td>2021-02-14 13:52:00+00:00</td>\n",
       "      <td>48875.10</td>\n",
       "      <td>2021-02-15 00:07:00+00:00</td>\n",
       "      <td>Short</td>\n",
       "      <td>Closed</td>\n",
       "      <td>48758.75</td>\n",
       "      <td>0.653292</td>\n",
       "      <td>0.002381</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.005642</td>\n",
       "      <td>2021-02-15 00:07:00+00:00</td>\n",
       "      <td>48758.75</td>\n",
       "      <td>2021-02-16 06:19:00+00:00</td>\n",
       "      <td>Long</td>\n",
       "      <td>Closed</td>\n",
       "      <td>48889.99</td>\n",
       "      <td>0.740414</td>\n",
       "      <td>0.002692</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0.005642</td>\n",
       "      <td>2021-02-16 06:19:00+00:00</td>\n",
       "      <td>48889.99</td>\n",
       "      <td>2021-02-16 06:25:00+00:00</td>\n",
       "      <td>Short</td>\n",
       "      <td>Closed</td>\n",
       "      <td>48885.62</td>\n",
       "      <td>0.024654</td>\n",
       "      <td>0.000089</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>0.005643</td>\n",
       "      <td>2021-02-16 06:25:00+00:00</td>\n",
       "      <td>48885.62</td>\n",
       "      <td>2021-02-16 11:45:00+00:00</td>\n",
       "      <td>Long</td>\n",
       "      <td>Closed</td>\n",
       "      <td>48715.17</td>\n",
       "      <td>-0.961796</td>\n",
       "      <td>-0.003487</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0.005643</td>\n",
       "      <td>2021-02-16 11:45:00+00:00</td>\n",
       "      <td>48715.17</td>\n",
       "      <td>2021-02-16 12:01:00+00:00</td>\n",
       "      <td>Short</td>\n",
       "      <td>Closed</td>\n",
       "      <td>48924.33</td>\n",
       "      <td>-1.180225</td>\n",
       "      <td>-0.004294</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>0.005594</td>\n",
       "      <td>2021-02-16 12:01:00+00:00</td>\n",
       "      <td>48924.33</td>\n",
       "      <td>2021-02-22 10:48:00+00:00</td>\n",
       "      <td>Long</td>\n",
       "      <td>Closed</td>\n",
       "      <td>54926.84</td>\n",
       "      <td>33.580685</td>\n",
       "      <td>0.122690</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>0.005594</td>\n",
       "      <td>2021-02-22 10:48:00+00:00</td>\n",
       "      <td>54926.84</td>\n",
       "      <td>2021-02-28 19:38:00+00:00</td>\n",
       "      <td>Short</td>\n",
       "      <td>Closed</td>\n",
       "      <td>44179.85</td>\n",
       "      <td>60.123397</td>\n",
       "      <td>0.195660</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>0.008316</td>\n",
       "      <td>2021-02-28 19:38:00+00:00</td>\n",
       "      <td>44179.85</td>\n",
       "      <td>2021-03-04 04:15:00+00:00</td>\n",
       "      <td>Long</td>\n",
       "      <td>Closed</td>\n",
       "      <td>49503.28</td>\n",
       "      <td>44.270693</td>\n",
       "      <td>0.120495</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>0.008316</td>\n",
       "      <td>2021-03-04 04:15:00+00:00</td>\n",
       "      <td>49503.28</td>\n",
       "      <td>2021-03-09 01:25:00+00:00</td>\n",
       "      <td>Short</td>\n",
       "      <td>Closed</td>\n",
       "      <td>53016.00</td>\n",
       "      <td>-29.212472</td>\n",
       "      <td>-0.070959</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>0.007214</td>\n",
       "      <td>2021-03-09 01:25:00+00:00</td>\n",
       "      <td>53016.00</td>\n",
       "      <td>2021-03-12 11:12:00+00:00</td>\n",
       "      <td>Long</td>\n",
       "      <td>Closed</td>\n",
       "      <td>56860.20</td>\n",
       "      <td>27.732721</td>\n",
       "      <td>0.072510</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>0.007214</td>\n",
       "      <td>2021-03-12 11:12:00+00:00</td>\n",
       "      <td>56860.20</td>\n",
       "      <td>2021-03-13 19:32:00+00:00</td>\n",
       "      <td>Short</td>\n",
       "      <td>Closed</td>\n",
       "      <td>60644.51</td>\n",
       "      <td>-27.300664</td>\n",
       "      <td>-0.066555</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>0.006314</td>\n",
       "      <td>2021-03-13 19:32:00+00:00</td>\n",
       "      <td>60644.51</td>\n",
       "      <td>2021-03-15 00:03:00+00:00</td>\n",
       "      <td>Long</td>\n",
       "      <td>Closed</td>\n",
       "      <td>59327.16</td>\n",
       "      <td>-8.317513</td>\n",
       "      <td>-0.021722</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>0.006314</td>\n",
       "      <td>2021-03-15 00:03:00+00:00</td>\n",
       "      <td>59327.16</td>\n",
       "      <td>2021-03-18 09:38:00+00:00</td>\n",
       "      <td>Short</td>\n",
       "      <td>Closed</td>\n",
       "      <td>58441.50</td>\n",
       "      <td>5.591899</td>\n",
       "      <td>0.014928</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>0.006505</td>\n",
       "      <td>2021-03-18 09:38:00+00:00</td>\n",
       "      <td>58441.50</td>\n",
       "      <td>2021-03-19 07:55:00+00:00</td>\n",
       "      <td>Long</td>\n",
       "      <td>Closed</td>\n",
       "      <td>57798.28</td>\n",
       "      <td>-4.184268</td>\n",
       "      <td>-0.011006</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>0.006505</td>\n",
       "      <td>2021-03-19 07:55:00+00:00</td>\n",
       "      <td>57798.28</td>\n",
       "      <td>2021-03-24 22:00:00+00:00</td>\n",
       "      <td>Short</td>\n",
       "      <td>Closed</td>\n",
       "      <td>53476.53</td>\n",
       "      <td>28.113801</td>\n",
       "      <td>0.074773</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>0.007557</td>\n",
       "      <td>2021-03-24 22:00:00+00:00</td>\n",
       "      <td>53476.53</td>\n",
       "      <td>2021-03-29 08:51:00+00:00</td>\n",
       "      <td>Long</td>\n",
       "      <td>Closed</td>\n",
       "      <td>57018.00</td>\n",
       "      <td>26.761591</td>\n",
       "      <td>0.066225</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>0.007557</td>\n",
       "      <td>2021-03-29 08:51:00+00:00</td>\n",
       "      <td>57018.00</td>\n",
       "      <td>2021-03-31 08:06:00+00:00</td>\n",
       "      <td>Short</td>\n",
       "      <td>Closed</td>\n",
       "      <td>57420.93</td>\n",
       "      <td>-3.044794</td>\n",
       "      <td>-0.007067</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>0.007451</td>\n",
       "      <td>2021-03-31 08:06:00+00:00</td>\n",
       "      <td>57420.93</td>\n",
       "      <td>2021-04-03 16:01:00+00:00</td>\n",
       "      <td>Long</td>\n",
       "      <td>Closed</td>\n",
       "      <td>58741.20</td>\n",
       "      <td>9.836780</td>\n",
       "      <td>0.022993</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>0.007451</td>\n",
       "      <td>2021-04-03 16:01:00+00:00</td>\n",
       "      <td>58741.20</td>\n",
       "      <td>2021-04-05 03:59:00+00:00</td>\n",
       "      <td>Short</td>\n",
       "      <td>Closed</td>\n",
       "      <td>57611.50</td>\n",
       "      <td>8.416922</td>\n",
       "      <td>0.019232</td>\n",
       "      <td>46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>0.007743</td>\n",
       "      <td>2021-04-05 03:59:00+00:00</td>\n",
       "      <td>57611.50</td>\n",
       "      <td>2021-04-08 00:39:00+00:00</td>\n",
       "      <td>Long</td>\n",
       "      <td>Closed</td>\n",
       "      <td>56502.99</td>\n",
       "      <td>-8.582946</td>\n",
       "      <td>-0.019241</td>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>0.007743</td>\n",
       "      <td>2021-04-08 00:39:00+00:00</td>\n",
       "      <td>56502.99</td>\n",
       "      <td>2021-04-18 03:35:00+00:00</td>\n",
       "      <td>Short</td>\n",
       "      <td>Closed</td>\n",
       "      <td>52648.69</td>\n",
       "      <td>29.842988</td>\n",
       "      <td>0.068214</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>0.008876</td>\n",
       "      <td>2021-04-18 03:35:00+00:00</td>\n",
       "      <td>52648.69</td>\n",
       "      <td>2021-04-18 03:37:00+00:00</td>\n",
       "      <td>Long</td>\n",
       "      <td>Closed</td>\n",
       "      <td>52805.87</td>\n",
       "      <td>1.395199</td>\n",
       "      <td>0.002985</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>0.008876</td>\n",
       "      <td>2021-04-18 03:37:00+00:00</td>\n",
       "      <td>52805.87</td>\n",
       "      <td>2021-04-25 21:46:00+00:00</td>\n",
       "      <td>Short</td>\n",
       "      <td>Closed</td>\n",
       "      <td>47512.66</td>\n",
       "      <td>46.984875</td>\n",
       "      <td>0.100239</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>0.010854</td>\n",
       "      <td>2021-04-25 21:46:00+00:00</td>\n",
       "      <td>47512.66</td>\n",
       "      <td>2021-04-28 20:05:00+00:00</td>\n",
       "      <td>Long</td>\n",
       "      <td>Closed</td>\n",
       "      <td>56455.04</td>\n",
       "      <td>97.062614</td>\n",
       "      <td>0.188210</td>\n",
       "      <td>51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>0.010854</td>\n",
       "      <td>2021-04-28 20:05:00+00:00</td>\n",
       "      <td>56455.04</td>\n",
       "      <td>2021-05-23 05:11:00+00:00</td>\n",
       "      <td>Short</td>\n",
       "      <td>Closed</td>\n",
       "      <td>36806.85</td>\n",
       "      <td>213.265895</td>\n",
       "      <td>0.348033</td>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>0.022443</td>\n",
       "      <td>2021-05-23 05:11:00+00:00</td>\n",
       "      <td>36806.85</td>\n",
       "      <td>2021-05-23 14:11:00+00:00</td>\n",
       "      <td>Long</td>\n",
       "      <td>Closed</td>\n",
       "      <td>33358.08</td>\n",
       "      <td>-77.399389</td>\n",
       "      <td>-0.093699</td>\n",
       "      <td>53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>0.022443</td>\n",
       "      <td>2021-05-23 14:11:00+00:00</td>\n",
       "      <td>33358.08</td>\n",
       "      <td>2021-05-24 04:42:00+00:00</td>\n",
       "      <td>Short</td>\n",
       "      <td>Closed</td>\n",
       "      <td>34585.21</td>\n",
       "      <td>-27.539996</td>\n",
       "      <td>-0.036787</td>\n",
       "      <td>54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>0.020850</td>\n",
       "      <td>2021-05-24 04:42:00+00:00</td>\n",
       "      <td>34585.21</td>\n",
       "      <td>2021-05-24 20:00:00+00:00</td>\n",
       "      <td>Long</td>\n",
       "      <td>Closed</td>\n",
       "      <td>39578.41</td>\n",
       "      <td>104.108313</td>\n",
       "      <td>0.144374</td>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>0.020850</td>\n",
       "      <td>2021-05-24 20:00:00+00:00</td>\n",
       "      <td>39578.41</td>\n",
       "      <td>2021-05-30 06:08:00+00:00</td>\n",
       "      <td>Short</td>\n",
       "      <td>Closed</td>\n",
       "      <td>35458.24</td>\n",
       "      <td>85.905621</td>\n",
       "      <td>0.104101</td>\n",
       "      <td>56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>0.025695</td>\n",
       "      <td>2021-05-30 06:08:00+00:00</td>\n",
       "      <td>35458.24</td>\n",
       "      <td>2021-05-30 11:51:00+00:00</td>\n",
       "      <td>Long</td>\n",
       "      <td>Closed</td>\n",
       "      <td>36238.97</td>\n",
       "      <td>20.061226</td>\n",
       "      <td>0.022018</td>\n",
       "      <td>57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>0.025695</td>\n",
       "      <td>2021-05-30 11:51:00+00:00</td>\n",
       "      <td>36238.97</td>\n",
       "      <td>2021-05-30 12:06:00+00:00</td>\n",
       "      <td>Short</td>\n",
       "      <td>Closed</td>\n",
       "      <td>36055.64</td>\n",
       "      <td>4.710751</td>\n",
       "      <td>0.005059</td>\n",
       "      <td>58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>0.025957</td>\n",
       "      <td>2021-05-30 12:06:00+00:00</td>\n",
       "      <td>36055.64</td>\n",
       "      <td>2021-05-30 12:49:00+00:00</td>\n",
       "      <td>Long</td>\n",
       "      <td>Closed</td>\n",
       "      <td>35404.31</td>\n",
       "      <td>-16.906427</td>\n",
       "      <td>-0.018065</td>\n",
       "      <td>59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>0.025957</td>\n",
       "      <td>2021-05-30 12:49:00+00:00</td>\n",
       "      <td>35404.31</td>\n",
       "      <td>2021-05-30 13:02:00+00:00</td>\n",
       "      <td>Short</td>\n",
       "      <td>Closed</td>\n",
       "      <td>35520.62</td>\n",
       "      <td>-3.019033</td>\n",
       "      <td>-0.003285</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>0.025787</td>\n",
       "      <td>2021-05-30 13:02:00+00:00</td>\n",
       "      <td>35520.62</td>\n",
       "      <td>2021-06-04 05:14:00+00:00</td>\n",
       "      <td>Long</td>\n",
       "      <td>Closed</td>\n",
       "      <td>37000.00</td>\n",
       "      <td>38.148460</td>\n",
       "      <td>0.041648</td>\n",
       "      <td>61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>0.025787</td>\n",
       "      <td>2021-06-04 05:14:00+00:00</td>\n",
       "      <td>37000.00</td>\n",
       "      <td>2021-06-06 15:03:00+00:00</td>\n",
       "      <td>Short</td>\n",
       "      <td>Closed</td>\n",
       "      <td>36245.14</td>\n",
       "      <td>19.465415</td>\n",
       "      <td>0.020402</td>\n",
       "      <td>62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>0.026861</td>\n",
       "      <td>2021-06-06 15:03:00+00:00</td>\n",
       "      <td>36245.14</td>\n",
       "      <td>2021-06-07 01:48:00+00:00</td>\n",
       "      <td>Long</td>\n",
       "      <td>Closed</td>\n",
       "      <td>36692.43</td>\n",
       "      <td>12.014606</td>\n",
       "      <td>0.012341</td>\n",
       "      <td>63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>0.026861</td>\n",
       "      <td>2021-06-07 01:48:00+00:00</td>\n",
       "      <td>36692.43</td>\n",
       "      <td>2021-06-08 15:23:00+00:00</td>\n",
       "      <td>Short</td>\n",
       "      <td>Closed</td>\n",
       "      <td>31084.04</td>\n",
       "      <td>150.646328</td>\n",
       "      <td>0.152849</td>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>0.036554</td>\n",
       "      <td>2021-06-08 15:23:00+00:00</td>\n",
       "      <td>31084.04</td>\n",
       "      <td>2021-06-12 02:22:00+00:00</td>\n",
       "      <td>Long</td>\n",
       "      <td>Closed</td>\n",
       "      <td>35780.43</td>\n",
       "      <td>171.670561</td>\n",
       "      <td>0.151087</td>\n",
       "      <td>65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>0.036554</td>\n",
       "      <td>2021-06-12 02:22:00+00:00</td>\n",
       "      <td>35780.43</td>\n",
       "      <td>2021-06-13 16:54:00+00:00</td>\n",
       "      <td>Short</td>\n",
       "      <td>Closed</td>\n",
       "      <td>36909.89</td>\n",
       "      <td>-41.285973</td>\n",
       "      <td>-0.031566</td>\n",
       "      <td>66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>0.034317</td>\n",
       "      <td>2021-06-13 16:54:00+00:00</td>\n",
       "      <td>36909.89</td>\n",
       "      <td>2021-06-14 01:42:00+00:00</td>\n",
       "      <td>Long</td>\n",
       "      <td>Closed</td>\n",
       "      <td>39334.28</td>\n",
       "      <td>83.196834</td>\n",
       "      <td>0.065684</td>\n",
       "      <td>67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>0.034317</td>\n",
       "      <td>2021-06-14 01:42:00+00:00</td>\n",
       "      <td>39334.28</td>\n",
       "      <td>2021-06-19 00:50:00+00:00</td>\n",
       "      <td>Short</td>\n",
       "      <td>Closed</td>\n",
       "      <td>35731.74</td>\n",
       "      <td>123.626943</td>\n",
       "      <td>0.091588</td>\n",
       "      <td>68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>0.041236</td>\n",
       "      <td>2021-06-19 00:50:00+00:00</td>\n",
       "      <td>35731.74</td>\n",
       "      <td>2021-06-19 22:23:00+00:00</td>\n",
       "      <td>Long</td>\n",
       "      <td>Closed</td>\n",
       "      <td>35632.59</td>\n",
       "      <td>-4.088582</td>\n",
       "      <td>-0.002775</td>\n",
       "      <td>69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>0.041236</td>\n",
       "      <td>2021-06-19 22:23:00+00:00</td>\n",
       "      <td>35632.59</td>\n",
       "      <td>2021-06-22 14:00:00+00:00</td>\n",
       "      <td>Short</td>\n",
       "      <td>Closed</td>\n",
       "      <td>29429.98</td>\n",
       "      <td>255.772886</td>\n",
       "      <td>0.174071</td>\n",
       "      <td>70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>0.058618</td>\n",
       "      <td>2021-06-22 14:00:00+00:00</td>\n",
       "      <td>29429.98</td>\n",
       "      <td>2021-06-23 14:01:00+00:00</td>\n",
       "      <td>Long</td>\n",
       "      <td>Closed</td>\n",
       "      <td>33899.99</td>\n",
       "      <td>262.023598</td>\n",
       "      <td>0.151886</td>\n",
       "      <td>71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>0.058618</td>\n",
       "      <td>2021-06-23 14:01:00+00:00</td>\n",
       "      <td>33899.99</td>\n",
       "      <td>2021-06-26 09:09:00+00:00</td>\n",
       "      <td>Short</td>\n",
       "      <td>Closed</td>\n",
       "      <td>30294.55</td>\n",
       "      <td>211.344127</td>\n",
       "      <td>0.106355</td>\n",
       "      <td>72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>0.072571</td>\n",
       "      <td>2021-06-26 09:09:00+00:00</td>\n",
       "      <td>30294.55</td>\n",
       "      <td>2021-06-30 07:54:00+00:00</td>\n",
       "      <td>Long</td>\n",
       "      <td>Closed</td>\n",
       "      <td>35161.04</td>\n",
       "      <td>353.164783</td>\n",
       "      <td>0.160639</td>\n",
       "      <td>73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>0.072571</td>\n",
       "      <td>2021-06-30 07:54:00+00:00</td>\n",
       "      <td>35161.04</td>\n",
       "      <td>2021-07-04 07:51:00+00:00</td>\n",
       "      <td>Short</td>\n",
       "      <td>Closed</td>\n",
       "      <td>35581.43</td>\n",
       "      <td>-30.508014</td>\n",
       "      <td>-0.011956</td>\n",
       "      <td>74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>0.070856</td>\n",
       "      <td>2021-07-04 07:51:00+00:00</td>\n",
       "      <td>35581.43</td>\n",
       "      <td>2021-07-05 00:02:00+00:00</td>\n",
       "      <td>Long</td>\n",
       "      <td>Closed</td>\n",
       "      <td>34937.91</td>\n",
       "      <td>-45.597197</td>\n",
       "      <td>-0.018086</td>\n",
       "      <td>75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>0.070856</td>\n",
       "      <td>2021-07-05 00:02:00+00:00</td>\n",
       "      <td>34937.91</td>\n",
       "      <td>2021-07-21 18:59:00+00:00</td>\n",
       "      <td>Short</td>\n",
       "      <td>Closed</td>\n",
       "      <td>31881.06</td>\n",
       "      <td>216.595897</td>\n",
       "      <td>0.087494</td>\n",
       "      <td>76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>0.084444</td>\n",
       "      <td>2021-07-21 18:59:00+00:00</td>\n",
       "      <td>31881.06</td>\n",
       "      <td>2021-07-26 01:00:00+00:00</td>\n",
       "      <td>Long</td>\n",
       "      <td>Closed</td>\n",
       "      <td>39814.35</td>\n",
       "      <td>669.916045</td>\n",
       "      <td>0.248840</td>\n",
       "      <td>77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>0.084444</td>\n",
       "      <td>2021-07-26 01:00:00+00:00</td>\n",
       "      <td>39814.35</td>\n",
       "      <td>2021-07-27 00:12:00+00:00</td>\n",
       "      <td>Short</td>\n",
       "      <td>Closed</td>\n",
       "      <td>36985.72</td>\n",
       "      <td>238.859871</td>\n",
       "      <td>0.071045</td>\n",
       "      <td>78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>0.097360</td>\n",
       "      <td>2021-07-27 00:12:00+00:00</td>\n",
       "      <td>36985.72</td>\n",
       "      <td>2021-07-27 02:01:00+00:00</td>\n",
       "      <td>Long</td>\n",
       "      <td>Closed</td>\n",
       "      <td>37048.58</td>\n",
       "      <td>6.120049</td>\n",
       "      <td>0.001700</td>\n",
       "      <td>79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>0.097360</td>\n",
       "      <td>2021-07-27 02:01:00+00:00</td>\n",
       "      <td>37048.58</td>\n",
       "      <td>2021-07-27 12:48:00+00:00</td>\n",
       "      <td>Short</td>\n",
       "      <td>Closed</td>\n",
       "      <td>38372.02</td>\n",
       "      <td>-128.850105</td>\n",
       "      <td>-0.035722</td>\n",
       "      <td>80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>0.090644</td>\n",
       "      <td>2021-07-27 12:48:00+00:00</td>\n",
       "      <td>38372.02</td>\n",
       "      <td>2021-08-01 23:29:00+00:00</td>\n",
       "      <td>Long</td>\n",
       "      <td>Closed</td>\n",
       "      <td>39765.43</td>\n",
       "      <td>126.304469</td>\n",
       "      <td>0.036313</td>\n",
       "      <td>81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>0.090644</td>\n",
       "      <td>2021-08-01 23:29:00+00:00</td>\n",
       "      <td>39765.43</td>\n",
       "      <td>2021-08-02 01:03:00+00:00</td>\n",
       "      <td>Short</td>\n",
       "      <td>Closed</td>\n",
       "      <td>39647.22</td>\n",
       "      <td>10.715045</td>\n",
       "      <td>0.002973</td>\n",
       "      <td>82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>0.091185</td>\n",
       "      <td>2021-08-02 01:03:00+00:00</td>\n",
       "      <td>39647.22</td>\n",
       "      <td>2021-08-03 03:18:00+00:00</td>\n",
       "      <td>Long</td>\n",
       "      <td>Closed</td>\n",
       "      <td>38801.88</td>\n",
       "      <td>-77.082051</td>\n",
       "      <td>-0.021322</td>\n",
       "      <td>83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>0.091185</td>\n",
       "      <td>2021-08-03 03:18:00+00:00</td>\n",
       "      <td>38801.88</td>\n",
       "      <td>2021-08-23 00:52:00+00:00</td>\n",
       "      <td>Short</td>\n",
       "      <td>Closed</td>\n",
       "      <td>49407.90</td>\n",
       "      <td>-967.106461</td>\n",
       "      <td>-0.273338</td>\n",
       "      <td>84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>0.052037</td>\n",
       "      <td>2021-08-23 00:52:00+00:00</td>\n",
       "      <td>49407.90</td>\n",
       "      <td>2021-08-23 10:53:00+00:00</td>\n",
       "      <td>Long</td>\n",
       "      <td>Closed</td>\n",
       "      <td>50311.47</td>\n",
       "      <td>47.018914</td>\n",
       "      <td>0.018288</td>\n",
       "      <td>85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>0.052037</td>\n",
       "      <td>2021-08-23 10:53:00+00:00</td>\n",
       "      <td>50311.47</td>\n",
       "      <td>2021-09-02 10:50:00+00:00</td>\n",
       "      <td>Short</td>\n",
       "      <td>Closed</td>\n",
       "      <td>50000.01</td>\n",
       "      <td>16.207390</td>\n",
       "      <td>0.006191</td>\n",
       "      <td>86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>0.052685</td>\n",
       "      <td>2021-09-02 10:50:00+00:00</td>\n",
       "      <td>50000.01</td>\n",
       "      <td>2021-09-07 06:33:00+00:00</td>\n",
       "      <td>Long</td>\n",
       "      <td>Closed</td>\n",
       "      <td>52567.98</td>\n",
       "      <td>135.293810</td>\n",
       "      <td>0.051359</td>\n",
       "      <td>87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>0.052685</td>\n",
       "      <td>2021-09-07 06:33:00+00:00</td>\n",
       "      <td>52567.98</td>\n",
       "      <td>2021-09-30 23:01:00+00:00</td>\n",
       "      <td>Short</td>\n",
       "      <td>Closed</td>\n",
       "      <td>43609.96</td>\n",
       "      <td>471.954365</td>\n",
       "      <td>0.170408</td>\n",
       "      <td>88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>0.074329</td>\n",
       "      <td>2021-09-30 23:01:00+00:00</td>\n",
       "      <td>43609.96</td>\n",
       "      <td>2021-10-04 21:26:00+00:00</td>\n",
       "      <td>Long</td>\n",
       "      <td>Closed</td>\n",
       "      <td>48568.51</td>\n",
       "      <td>368.566340</td>\n",
       "      <td>0.113702</td>\n",
       "      <td>89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>0.074329</td>\n",
       "      <td>2021-10-04 21:26:00+00:00</td>\n",
       "      <td>48568.51</td>\n",
       "      <td>2021-10-06 12:21:00+00:00</td>\n",
       "      <td>Short</td>\n",
       "      <td>Closed</td>\n",
       "      <td>52188.90</td>\n",
       "      <td>-269.101631</td>\n",
       "      <td>-0.074542</td>\n",
       "      <td>90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>0.064017</td>\n",
       "      <td>2021-10-06 12:21:00+00:00</td>\n",
       "      <td>52188.90</td>\n",
       "      <td>2021-10-12 11:59:00+00:00</td>\n",
       "      <td>Long</td>\n",
       "      <td>Closed</td>\n",
       "      <td>57082.15</td>\n",
       "      <td>313.250495</td>\n",
       "      <td>0.093760</td>\n",
       "      <td>91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>0.064017</td>\n",
       "      <td>2021-10-12 11:59:00+00:00</td>\n",
       "      <td>57082.15</td>\n",
       "      <td>2021-12-07 14:47:00+00:00</td>\n",
       "      <td>Short</td>\n",
       "      <td>Closed</td>\n",
       "      <td>51445.25</td>\n",
       "      <td>360.856632</td>\n",
       "      <td>0.098751</td>\n",
       "      <td>92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>0.078046</td>\n",
       "      <td>2021-12-07 14:47:00+00:00</td>\n",
       "      <td>51445.25</td>\n",
       "      <td>2021-12-07 15:44:00+00:00</td>\n",
       "      <td>Long</td>\n",
       "      <td>Closed</td>\n",
       "      <td>51744.62</td>\n",
       "      <td>23.364518</td>\n",
       "      <td>0.005819</td>\n",
       "      <td>93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>0.078046</td>\n",
       "      <td>2021-12-07 15:44:00+00:00</td>\n",
       "      <td>51744.62</td>\n",
       "      <td>2021-12-27 01:14:00+00:00</td>\n",
       "      <td>Short</td>\n",
       "      <td>Closed</td>\n",
       "      <td>50607.07</td>\n",
       "      <td>88.780798</td>\n",
       "      <td>0.021984</td>\n",
       "      <td>94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>0.081554</td>\n",
       "      <td>2021-12-27 01:14:00+00:00</td>\n",
       "      <td>50607.07</td>\n",
       "      <td>2021-12-28 17:05:00+00:00</td>\n",
       "      <td>Long</td>\n",
       "      <td>Closed</td>\n",
       "      <td>48385.67</td>\n",
       "      <td>-181.164622</td>\n",
       "      <td>-0.043895</td>\n",
       "      <td>95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.081554</td>\n",
       "      <td>2021-12-28 17:05:00+00:00</td>\n",
       "      <td>48385.67</td>\n",
       "      <td>2022-01-29 20:35:00+00:00</td>\n",
       "      <td>Short</td>\n",
       "      <td>Closed</td>\n",
       "      <td>38550.00</td>\n",
       "      <td>802.140739</td>\n",
       "      <td>0.203277</td>\n",
       "      <td>96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>0.123170</td>\n",
       "      <td>2022-01-29 20:35:00+00:00</td>\n",
       "      <td>38550.00</td>\n",
       "      <td>2022-02-01 00:43:00+00:00</td>\n",
       "      <td>Long</td>\n",
       "      <td>Closed</td>\n",
       "      <td>38371.67</td>\n",
       "      <td>-21.964881</td>\n",
       "      <td>-0.004626</td>\n",
       "      <td>97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>0.123170</td>\n",
       "      <td>2022-02-01 00:43:00+00:00</td>\n",
       "      <td>38371.67</td>\n",
       "      <td>2022-02-03 10:02:00+00:00</td>\n",
       "      <td>Short</td>\n",
       "      <td>Closed</td>\n",
       "      <td>36374.02</td>\n",
       "      <td>246.050266</td>\n",
       "      <td>0.052061</td>\n",
       "      <td>98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>0.136699</td>\n",
       "      <td>2022-02-03 10:02:00+00:00</td>\n",
       "      <td>36374.02</td>\n",
       "      <td>2022-02-09 00:42:00+00:00</td>\n",
       "      <td>Long</td>\n",
       "      <td>Closed</td>\n",
       "      <td>44247.28</td>\n",
       "      <td>1076.264871</td>\n",
       "      <td>0.216453</td>\n",
       "      <td>99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>0.136699</td>\n",
       "      <td>2022-02-09 00:42:00+00:00</td>\n",
       "      <td>44247.28</td>\n",
       "      <td>2022-02-24 21:02:00+00:00</td>\n",
       "      <td>Short</td>\n",
       "      <td>Closed</td>\n",
       "      <td>38419.90</td>\n",
       "      <td>796.595614</td>\n",
       "      <td>0.131700</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>0.178167</td>\n",
       "      <td>2022-02-24 21:02:00+00:00</td>\n",
       "      <td>38419.90</td>\n",
       "      <td>2022-02-27 23:36:00+00:00</td>\n",
       "      <td>Long</td>\n",
       "      <td>Closed</td>\n",
       "      <td>37649.90</td>\n",
       "      <td>-137.188301</td>\n",
       "      <td>-0.020042</td>\n",
       "      <td>101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>0.178167</td>\n",
       "      <td>2022-02-27 23:36:00+00:00</td>\n",
       "      <td>37649.90</td>\n",
       "      <td>2022-02-28 17:58:00+00:00</td>\n",
       "      <td>Short</td>\n",
       "      <td>Closed</td>\n",
       "      <td>41375.50</td>\n",
       "      <td>-663.777575</td>\n",
       "      <td>-0.098954</td>\n",
       "      <td>102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>0.146081</td>\n",
       "      <td>2022-02-28 17:58:00+00:00</td>\n",
       "      <td>41375.50</td>\n",
       "      <td>2022-03-02 15:06:00+00:00</td>\n",
       "      <td>Long</td>\n",
       "      <td>Closed</td>\n",
       "      <td>44390.00</td>\n",
       "      <td>440.361436</td>\n",
       "      <td>0.072857</td>\n",
       "      <td>103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>0.146081</td>\n",
       "      <td>2022-03-02 15:06:00+00:00</td>\n",
       "      <td>44390.00</td>\n",
       "      <td>2022-03-07 21:15:00+00:00</td>\n",
       "      <td>Short</td>\n",
       "      <td>Closed</td>\n",
       "      <td>38212.00</td>\n",
       "      <td>902.488954</td>\n",
       "      <td>0.139175</td>\n",
       "      <td>104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>0.193317</td>\n",
       "      <td>2022-03-07 21:15:00+00:00</td>\n",
       "      <td>38212.00</td>\n",
       "      <td>2022-03-16 00:54:00+00:00</td>\n",
       "      <td>Long</td>\n",
       "      <td>Closed</td>\n",
       "      <td>39111.60</td>\n",
       "      <td>173.907954</td>\n",
       "      <td>0.023542</td>\n",
       "      <td>105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>0.193317</td>\n",
       "      <td>2022-03-16 00:54:00+00:00</td>\n",
       "      <td>39111.60</td>\n",
       "      <td>2022-03-22 02:03:00+00:00</td>\n",
       "      <td>Short</td>\n",
       "      <td>Closed</td>\n",
       "      <td>41413.90</td>\n",
       "      <td>-445.073680</td>\n",
       "      <td>-0.058865</td>\n",
       "      <td>106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>0.171823</td>\n",
       "      <td>2022-03-22 02:03:00+00:00</td>\n",
       "      <td>41413.90</td>\n",
       "      <td>2022-03-23 04:17:00+00:00</td>\n",
       "      <td>Long</td>\n",
       "      <td>Closed</td>\n",
       "      <td>41884.30</td>\n",
       "      <td>80.825563</td>\n",
       "      <td>0.011359</td>\n",
       "      <td>107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>0.171823</td>\n",
       "      <td>2022-03-23 04:17:00+00:00</td>\n",
       "      <td>41884.30</td>\n",
       "      <td>2022-03-28 15:10:00+00:00</td>\n",
       "      <td>Short</td>\n",
       "      <td>Closed</td>\n",
       "      <td>47765.90</td>\n",
       "      <td>-1010.594459</td>\n",
       "      <td>-0.140425</td>\n",
       "      <td>108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>0.129509</td>\n",
       "      <td>2022-03-28 15:10:00+00:00</td>\n",
       "      <td>47765.90</td>\n",
       "      <td>2022-03-28 22:49:00+00:00</td>\n",
       "      <td>Long</td>\n",
       "      <td>Closed</td>\n",
       "      <td>47528.50</td>\n",
       "      <td>-30.745336</td>\n",
       "      <td>-0.004970</td>\n",
       "      <td>109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>0.129509</td>\n",
       "      <td>2022-03-28 22:49:00+00:00</td>\n",
       "      <td>47528.50</td>\n",
       "      <td>2022-05-30 20:24:00+00:00</td>\n",
       "      <td>Short</td>\n",
       "      <td>Closed</td>\n",
       "      <td>31158.30</td>\n",
       "      <td>2120.081319</td>\n",
       "      <td>0.344429</td>\n",
       "      <td>110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>0.265593</td>\n",
       "      <td>2022-05-30 20:24:00+00:00</td>\n",
       "      <td>31158.30</td>\n",
       "      <td>2022-06-01 11:33:00+00:00</td>\n",
       "      <td>Long</td>\n",
       "      <td>Closed</td>\n",
       "      <td>31466.80</td>\n",
       "      <td>81.935474</td>\n",
       "      <td>0.009901</td>\n",
       "      <td>111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>0.265593</td>\n",
       "      <td>2022-06-01 11:33:00+00:00</td>\n",
       "      <td>31466.80</td>\n",
       "      <td>2022-06-19 21:08:00+00:00</td>\n",
       "      <td>Short</td>\n",
       "      <td>Closed</td>\n",
       "      <td>20401.90</td>\n",
       "      <td>2938.761187</td>\n",
       "      <td>0.351637</td>\n",
       "      <td>112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>0.553680</td>\n",
       "      <td>2022-06-19 21:08:00+00:00</td>\n",
       "      <td>20401.90</td>\n",
       "      <td>2022-06-20 00:33:00+00:00</td>\n",
       "      <td>Long</td>\n",
       "      <td>Closed</td>\n",
       "      <td>20199.90</td>\n",
       "      <td>-111.843384</td>\n",
       "      <td>-0.009901</td>\n",
       "      <td>113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>0.553680</td>\n",
       "      <td>2022-06-20 00:33:00+00:00</td>\n",
       "      <td>20199.90</td>\n",
       "      <td>2022-07-01 00:01:00+00:00</td>\n",
       "      <td>Short</td>\n",
       "      <td>Closed</td>\n",
       "      <td>19708.90</td>\n",
       "      <td>271.856938</td>\n",
       "      <td>0.024307</td>\n",
       "      <td>114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>0.581267</td>\n",
       "      <td>2022-07-01 00:01:00+00:00</td>\n",
       "      <td>19708.90</td>\n",
       "      <td>2022-07-02 23:39:00+00:00</td>\n",
       "      <td>Long</td>\n",
       "      <td>Closed</td>\n",
       "      <td>19276.00</td>\n",
       "      <td>-251.630634</td>\n",
       "      <td>-0.021965</td>\n",
       "      <td>115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>0.581267</td>\n",
       "      <td>2022-07-02 23:39:00+00:00</td>\n",
       "      <td>19276.00</td>\n",
       "      <td>2022-07-08 14:27:00+00:00</td>\n",
       "      <td>Short</td>\n",
       "      <td>Closed</td>\n",
       "      <td>21515.20</td>\n",
       "      <td>-1301.573838</td>\n",
       "      <td>-0.116165</td>\n",
       "      <td>116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>0.460276</td>\n",
       "      <td>2022-07-08 14:27:00+00:00</td>\n",
       "      <td>21515.20</td>\n",
       "      <td>2022-07-11 06:17:00+00:00</td>\n",
       "      <td>Long</td>\n",
       "      <td>Closed</td>\n",
       "      <td>20426.10</td>\n",
       "      <td>-501.286860</td>\n",
       "      <td>-0.050620</td>\n",
       "      <td>117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>0.460276</td>\n",
       "      <td>2022-07-11 06:17:00+00:00</td>\n",
       "      <td>20426.10</td>\n",
       "      <td>2022-07-29 01:02:00+00:00</td>\n",
       "      <td>Short</td>\n",
       "      <td>Closed</td>\n",
       "      <td>23821.80</td>\n",
       "      <td>-1562.960050</td>\n",
       "      <td>-0.166243</td>\n",
       "      <td>118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>0.329055</td>\n",
       "      <td>2022-07-29 01:02:00+00:00</td>\n",
       "      <td>23821.80</td>\n",
       "      <td>2022-08-06 00:54:00+00:00</td>\n",
       "      <td>Long</td>\n",
       "      <td>Closed</td>\n",
       "      <td>23245.60</td>\n",
       "      <td>-189.601641</td>\n",
       "      <td>-0.024188</td>\n",
       "      <td>119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>0.329055</td>\n",
       "      <td>2022-08-06 00:54:00+00:00</td>\n",
       "      <td>23245.60</td>\n",
       "      <td>2022-09-10 00:13:00+00:00</td>\n",
       "      <td>Short</td>\n",
       "      <td>Closed</td>\n",
       "      <td>21211.30</td>\n",
       "      <td>669.397115</td>\n",
       "      <td>0.087513</td>\n",
       "      <td>120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>0.392172</td>\n",
       "      <td>2022-09-10 00:13:00+00:00</td>\n",
       "      <td>21211.30</td>\n",
       "      <td>2022-09-13 21:42:00+00:00</td>\n",
       "      <td>Long</td>\n",
       "      <td>Closed</td>\n",
       "      <td>19992.00</td>\n",
       "      <td>-478.175671</td>\n",
       "      <td>-0.057484</td>\n",
       "      <td>121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>0.392172</td>\n",
       "      <td>2022-09-13 21:42:00+00:00</td>\n",
       "      <td>19992.00</td>\n",
       "      <td>2022-10-31 01:49:00+00:00</td>\n",
       "      <td>Short</td>\n",
       "      <td>Closed</td>\n",
       "      <td>20450.90</td>\n",
       "      <td>-179.967863</td>\n",
       "      <td>-0.022954</td>\n",
       "      <td>122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>0.374572</td>\n",
       "      <td>2022-10-31 01:49:00+00:00</td>\n",
       "      <td>20450.90</td>\n",
       "      <td>2022-11-03 16:54:00+00:00</td>\n",
       "      <td>Long</td>\n",
       "      <td>Closed</td>\n",
       "      <td>20240.50</td>\n",
       "      <td>-78.810011</td>\n",
       "      <td>-0.010288</td>\n",
       "      <td>123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>0.374572</td>\n",
       "      <td>2022-11-03 16:54:00+00:00</td>\n",
       "      <td>20240.50</td>\n",
       "      <td>2022-11-22 10:38:00+00:00</td>\n",
       "      <td>Short</td>\n",
       "      <td>Closed</td>\n",
       "      <td>15758.90</td>\n",
       "      <td>1678.683193</td>\n",
       "      <td>0.221417</td>\n",
       "      <td>124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>0.587618</td>\n",
       "      <td>2022-11-22 10:38:00+00:00</td>\n",
       "      <td>15758.90</td>\n",
       "      <td>2022-12-18 12:45:00+00:00</td>\n",
       "      <td>Long</td>\n",
       "      <td>Closed</td>\n",
       "      <td>16695.60</td>\n",
       "      <td>550.421805</td>\n",
       "      <td>0.059439</td>\n",
       "      <td>125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>0.587618</td>\n",
       "      <td>2022-12-18 12:45:00+00:00</td>\n",
       "      <td>16695.60</td>\n",
       "      <td>2023-01-06 10:59:00+00:00</td>\n",
       "      <td>Short</td>\n",
       "      <td>Closed</td>\n",
       "      <td>16743.00</td>\n",
       "      <td>-27.853094</td>\n",
       "      <td>-0.002839</td>\n",
       "      <td>126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>0.584291</td>\n",
       "      <td>2023-01-06 10:59:00+00:00</td>\n",
       "      <td>16743.00</td>\n",
       "      <td>2023-01-27 01:36:00+00:00</td>\n",
       "      <td>Long</td>\n",
       "      <td>Closed</td>\n",
       "      <td>22656.60</td>\n",
       "      <td>3455.262625</td>\n",
       "      <td>0.353198</td>\n",
       "      <td>127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>0.584291</td>\n",
       "      <td>2023-01-27 01:36:00+00:00</td>\n",
       "      <td>22656.60</td>\n",
       "      <td>2023-03-10 13:30:00+00:00</td>\n",
       "      <td>Short</td>\n",
       "      <td>Closed</td>\n",
       "      <td>20048.50</td>\n",
       "      <td>1523.889078</td>\n",
       "      <td>0.115114</td>\n",
       "      <td>128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129</th>\n",
       "      <td>0.736311</td>\n",
       "      <td>2023-03-10 13:30:00+00:00</td>\n",
       "      <td>20048.50</td>\n",
       "      <td>2023-03-14 13:19:00+00:00</td>\n",
       "      <td>Long</td>\n",
       "      <td>Closed</td>\n",
       "      <td>25892.10</td>\n",
       "      <td>4302.707846</td>\n",
       "      <td>0.291473</td>\n",
       "      <td>129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130</th>\n",
       "      <td>0.736311</td>\n",
       "      <td>2023-03-14 13:19:00+00:00</td>\n",
       "      <td>25892.10</td>\n",
       "      <td>2023-03-17 21:42:00+00:00</td>\n",
       "      <td>Short</td>\n",
       "      <td>Closed</td>\n",
       "      <td>27211.90</td>\n",
       "      <td>-971.783458</td>\n",
       "      <td>-0.050973</td>\n",
       "      <td>130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>0.664888</td>\n",
       "      <td>2023-03-17 21:42:00+00:00</td>\n",
       "      <td>27211.90</td>\n",
       "      <td>2023-03-22 18:33:00+00:00</td>\n",
       "      <td>Long</td>\n",
       "      <td>Closed</td>\n",
       "      <td>28082.60</td>\n",
       "      <td>578.917750</td>\n",
       "      <td>0.031997</td>\n",
       "      <td>131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>0.664888</td>\n",
       "      <td>2023-03-22 18:33:00+00:00</td>\n",
       "      <td>28082.60</td>\n",
       "      <td>2023-05-11 17:44:00+00:00</td>\n",
       "      <td>Short</td>\n",
       "      <td>Open</td>\n",
       "      <td>26784.90</td>\n",
       "      <td>862.824812</td>\n",
       "      <td>0.046210</td>\n",
       "      <td>132</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Size               Entry Index  Avg Entry Price  \\\n",
       "0    0.003234 2021-01-05 04:15:00+00:00         30921.37   \n",
       "1    0.002681 2021-01-06 02:51:00+00:00         33814.61   \n",
       "2    0.002681 2021-01-07 18:19:00+00:00         39340.00   \n",
       "3    0.002731 2021-01-07 18:22:00+00:00         38970.68   \n",
       "4    0.002731 2021-01-10 03:21:00+00:00         40527.68   \n",
       "5    0.003875 2021-01-11 21:02:00+00:00         33513.98   \n",
       "6    0.003875 2021-01-14 15:36:00+00:00         39781.31   \n",
       "7    0.005834 2021-01-22 05:29:00+00:00         31752.39   \n",
       "8    0.005834 2021-01-22 07:22:00+00:00         31216.94   \n",
       "9    0.005658 2021-01-23 23:43:00+00:00         31695.18   \n",
       "10   0.005658 2021-01-26 10:31:00+00:00         32197.92   \n",
       "11   0.005155 2021-01-29 08:44:00+00:00         33696.78   \n",
       "12   0.005155 2021-01-29 08:59:00+00:00         37387.18   \n",
       "13   0.005275 2021-01-29 09:49:00+00:00         36954.54   \n",
       "14   0.005275 2021-01-29 18:43:00+00:00         34854.86   \n",
       "15   0.005297 2021-01-29 18:45:00+00:00         34784.96   \n",
       "16   0.005297 2021-01-29 19:42:00+00:00         34136.93   \n",
       "17   0.005229 2021-01-29 19:53:00+00:00         34356.19   \n",
       "18   0.005229 2021-01-30 03:34:00+00:00         33049.58   \n",
       "19   0.004972 2021-01-30 05:38:00+00:00         33883.29   \n",
       "20   0.004972 2021-01-30 14:08:00+00:00         34193.18   \n",
       "21   0.005562 2021-01-31 17:56:00+00:00         32277.80   \n",
       "22   0.005562 2021-02-03 07:17:00+00:00         36420.01   \n",
       "23   0.004889 2021-02-04 08:24:00+00:00         38763.05   \n",
       "24   0.004889 2021-02-06 04:18:00+00:00         39282.31   \n",
       "25   0.004937 2021-02-07 00:00:00+00:00         39092.10   \n",
       "26   0.004937 2021-02-10 10:28:00+00:00         46877.01   \n",
       "27   0.005615 2021-02-10 15:45:00+00:00         43865.26   \n",
       "28   0.005615 2021-02-14 13:52:00+00:00         48875.10   \n",
       "29   0.005642 2021-02-15 00:07:00+00:00         48758.75   \n",
       "30   0.005642 2021-02-16 06:19:00+00:00         48889.99   \n",
       "31   0.005643 2021-02-16 06:25:00+00:00         48885.62   \n",
       "32   0.005643 2021-02-16 11:45:00+00:00         48715.17   \n",
       "33   0.005594 2021-02-16 12:01:00+00:00         48924.33   \n",
       "34   0.005594 2021-02-22 10:48:00+00:00         54926.84   \n",
       "35   0.008316 2021-02-28 19:38:00+00:00         44179.85   \n",
       "36   0.008316 2021-03-04 04:15:00+00:00         49503.28   \n",
       "37   0.007214 2021-03-09 01:25:00+00:00         53016.00   \n",
       "38   0.007214 2021-03-12 11:12:00+00:00         56860.20   \n",
       "39   0.006314 2021-03-13 19:32:00+00:00         60644.51   \n",
       "40   0.006314 2021-03-15 00:03:00+00:00         59327.16   \n",
       "41   0.006505 2021-03-18 09:38:00+00:00         58441.50   \n",
       "42   0.006505 2021-03-19 07:55:00+00:00         57798.28   \n",
       "43   0.007557 2021-03-24 22:00:00+00:00         53476.53   \n",
       "44   0.007557 2021-03-29 08:51:00+00:00         57018.00   \n",
       "45   0.007451 2021-03-31 08:06:00+00:00         57420.93   \n",
       "46   0.007451 2021-04-03 16:01:00+00:00         58741.20   \n",
       "47   0.007743 2021-04-05 03:59:00+00:00         57611.50   \n",
       "48   0.007743 2021-04-08 00:39:00+00:00         56502.99   \n",
       "49   0.008876 2021-04-18 03:35:00+00:00         52648.69   \n",
       "50   0.008876 2021-04-18 03:37:00+00:00         52805.87   \n",
       "51   0.010854 2021-04-25 21:46:00+00:00         47512.66   \n",
       "52   0.010854 2021-04-28 20:05:00+00:00         56455.04   \n",
       "53   0.022443 2021-05-23 05:11:00+00:00         36806.85   \n",
       "54   0.022443 2021-05-23 14:11:00+00:00         33358.08   \n",
       "55   0.020850 2021-05-24 04:42:00+00:00         34585.21   \n",
       "56   0.020850 2021-05-24 20:00:00+00:00         39578.41   \n",
       "57   0.025695 2021-05-30 06:08:00+00:00         35458.24   \n",
       "58   0.025695 2021-05-30 11:51:00+00:00         36238.97   \n",
       "59   0.025957 2021-05-30 12:06:00+00:00         36055.64   \n",
       "60   0.025957 2021-05-30 12:49:00+00:00         35404.31   \n",
       "61   0.025787 2021-05-30 13:02:00+00:00         35520.62   \n",
       "62   0.025787 2021-06-04 05:14:00+00:00         37000.00   \n",
       "63   0.026861 2021-06-06 15:03:00+00:00         36245.14   \n",
       "64   0.026861 2021-06-07 01:48:00+00:00         36692.43   \n",
       "65   0.036554 2021-06-08 15:23:00+00:00         31084.04   \n",
       "66   0.036554 2021-06-12 02:22:00+00:00         35780.43   \n",
       "67   0.034317 2021-06-13 16:54:00+00:00         36909.89   \n",
       "68   0.034317 2021-06-14 01:42:00+00:00         39334.28   \n",
       "69   0.041236 2021-06-19 00:50:00+00:00         35731.74   \n",
       "70   0.041236 2021-06-19 22:23:00+00:00         35632.59   \n",
       "71   0.058618 2021-06-22 14:00:00+00:00         29429.98   \n",
       "72   0.058618 2021-06-23 14:01:00+00:00         33899.99   \n",
       "73   0.072571 2021-06-26 09:09:00+00:00         30294.55   \n",
       "74   0.072571 2021-06-30 07:54:00+00:00         35161.04   \n",
       "75   0.070856 2021-07-04 07:51:00+00:00         35581.43   \n",
       "76   0.070856 2021-07-05 00:02:00+00:00         34937.91   \n",
       "77   0.084444 2021-07-21 18:59:00+00:00         31881.06   \n",
       "78   0.084444 2021-07-26 01:00:00+00:00         39814.35   \n",
       "79   0.097360 2021-07-27 00:12:00+00:00         36985.72   \n",
       "80   0.097360 2021-07-27 02:01:00+00:00         37048.58   \n",
       "81   0.090644 2021-07-27 12:48:00+00:00         38372.02   \n",
       "82   0.090644 2021-08-01 23:29:00+00:00         39765.43   \n",
       "83   0.091185 2021-08-02 01:03:00+00:00         39647.22   \n",
       "84   0.091185 2021-08-03 03:18:00+00:00         38801.88   \n",
       "85   0.052037 2021-08-23 00:52:00+00:00         49407.90   \n",
       "86   0.052037 2021-08-23 10:53:00+00:00         50311.47   \n",
       "87   0.052685 2021-09-02 10:50:00+00:00         50000.01   \n",
       "88   0.052685 2021-09-07 06:33:00+00:00         52567.98   \n",
       "89   0.074329 2021-09-30 23:01:00+00:00         43609.96   \n",
       "90   0.074329 2021-10-04 21:26:00+00:00         48568.51   \n",
       "91   0.064017 2021-10-06 12:21:00+00:00         52188.90   \n",
       "92   0.064017 2021-10-12 11:59:00+00:00         57082.15   \n",
       "93   0.078046 2021-12-07 14:47:00+00:00         51445.25   \n",
       "94   0.078046 2021-12-07 15:44:00+00:00         51744.62   \n",
       "95   0.081554 2021-12-27 01:14:00+00:00         50607.07   \n",
       "96   0.081554 2021-12-28 17:05:00+00:00         48385.67   \n",
       "97   0.123170 2022-01-29 20:35:00+00:00         38550.00   \n",
       "98   0.123170 2022-02-01 00:43:00+00:00         38371.67   \n",
       "99   0.136699 2022-02-03 10:02:00+00:00         36374.02   \n",
       "100  0.136699 2022-02-09 00:42:00+00:00         44247.28   \n",
       "101  0.178167 2022-02-24 21:02:00+00:00         38419.90   \n",
       "102  0.178167 2022-02-27 23:36:00+00:00         37649.90   \n",
       "103  0.146081 2022-02-28 17:58:00+00:00         41375.50   \n",
       "104  0.146081 2022-03-02 15:06:00+00:00         44390.00   \n",
       "105  0.193317 2022-03-07 21:15:00+00:00         38212.00   \n",
       "106  0.193317 2022-03-16 00:54:00+00:00         39111.60   \n",
       "107  0.171823 2022-03-22 02:03:00+00:00         41413.90   \n",
       "108  0.171823 2022-03-23 04:17:00+00:00         41884.30   \n",
       "109  0.129509 2022-03-28 15:10:00+00:00         47765.90   \n",
       "110  0.129509 2022-03-28 22:49:00+00:00         47528.50   \n",
       "111  0.265593 2022-05-30 20:24:00+00:00         31158.30   \n",
       "112  0.265593 2022-06-01 11:33:00+00:00         31466.80   \n",
       "113  0.553680 2022-06-19 21:08:00+00:00         20401.90   \n",
       "114  0.553680 2022-06-20 00:33:00+00:00         20199.90   \n",
       "115  0.581267 2022-07-01 00:01:00+00:00         19708.90   \n",
       "116  0.581267 2022-07-02 23:39:00+00:00         19276.00   \n",
       "117  0.460276 2022-07-08 14:27:00+00:00         21515.20   \n",
       "118  0.460276 2022-07-11 06:17:00+00:00         20426.10   \n",
       "119  0.329055 2022-07-29 01:02:00+00:00         23821.80   \n",
       "120  0.329055 2022-08-06 00:54:00+00:00         23245.60   \n",
       "121  0.392172 2022-09-10 00:13:00+00:00         21211.30   \n",
       "122  0.392172 2022-09-13 21:42:00+00:00         19992.00   \n",
       "123  0.374572 2022-10-31 01:49:00+00:00         20450.90   \n",
       "124  0.374572 2022-11-03 16:54:00+00:00         20240.50   \n",
       "125  0.587618 2022-11-22 10:38:00+00:00         15758.90   \n",
       "126  0.587618 2022-12-18 12:45:00+00:00         16695.60   \n",
       "127  0.584291 2023-01-06 10:59:00+00:00         16743.00   \n",
       "128  0.584291 2023-01-27 01:36:00+00:00         22656.60   \n",
       "129  0.736311 2023-03-10 13:30:00+00:00         20048.50   \n",
       "130  0.736311 2023-03-14 13:19:00+00:00         25892.10   \n",
       "131  0.664888 2023-03-17 21:42:00+00:00         27211.90   \n",
       "132  0.664888 2023-03-22 18:33:00+00:00         28082.60   \n",
       "\n",
       "                   Exit Index Direction  Status  Avg Exit Price          PnL  \\\n",
       "0   2021-01-06 02:51:00+00:00     Short  Closed        33814.61    -9.356765   \n",
       "1   2021-01-07 18:19:00+00:00      Long  Closed        39340.00    14.811326   \n",
       "2   2021-01-07 18:22:00+00:00     Short  Closed        38970.68     0.989997   \n",
       "3   2021-01-10 03:21:00+00:00      Long  Closed        40527.68     4.252792   \n",
       "4   2021-01-11 21:02:00+00:00     Short  Closed        33513.98    19.157228   \n",
       "5   2021-01-14 15:36:00+00:00      Long  Closed        39781.31    24.283642   \n",
       "6   2021-01-22 05:29:00+00:00     Short  Closed        31752.39    31.109167   \n",
       "7   2021-01-22 07:22:00+00:00      Long  Closed        31216.94    -3.123882   \n",
       "8   2021-01-23 23:43:00+00:00     Short  Closed        31695.18    -2.790112   \n",
       "9   2021-01-26 10:31:00+00:00      Long  Closed        32197.92     2.844536   \n",
       "10  2021-01-29 08:44:00+00:00     Short  Closed        33696.78    -8.480648   \n",
       "11  2021-01-29 08:59:00+00:00      Long  Closed        37387.18    19.022958   \n",
       "12  2021-01-29 09:49:00+00:00     Short  Closed        36954.54     2.230136   \n",
       "13  2021-01-29 18:43:00+00:00      Long  Closed        34854.86   -11.076674   \n",
       "14  2021-01-29 18:45:00+00:00     Short  Closed        34784.96     0.368751   \n",
       "15  2021-01-29 19:42:00+00:00      Long  Closed        34136.93    -3.432364   \n",
       "16  2021-01-29 19:53:00+00:00     Short  Closed        34356.19    -1.161335   \n",
       "17  2021-01-30 03:34:00+00:00      Long  Closed        33049.58    -6.832273   \n",
       "18  2021-01-30 05:38:00+00:00     Short  Closed        33883.29    -4.359475   \n",
       "19  2021-01-30 14:08:00+00:00      Long  Closed        34193.18     1.540675   \n",
       "20  2021-01-31 17:56:00+00:00     Short  Closed        32277.80     9.522664   \n",
       "21  2021-02-03 07:17:00+00:00      Long  Closed        36420.01    23.037845   \n",
       "22  2021-02-04 08:24:00+00:00     Short  Closed        38763.05   -13.031351   \n",
       "23  2021-02-06 04:18:00+00:00      Long  Closed        39282.31     2.538854   \n",
       "24  2021-02-07 00:00:00+00:00     Short  Closed        39092.10     0.930007   \n",
       "25  2021-02-10 10:28:00+00:00      Long  Closed        46877.01    38.433703   \n",
       "26  2021-02-10 15:45:00+00:00     Short  Closed        43865.26    14.868856   \n",
       "27  2021-02-14 13:52:00+00:00      Long  Closed        48875.10    28.129660   \n",
       "28  2021-02-15 00:07:00+00:00     Short  Closed        48758.75     0.653292   \n",
       "29  2021-02-16 06:19:00+00:00      Long  Closed        48889.99     0.740414   \n",
       "30  2021-02-16 06:25:00+00:00     Short  Closed        48885.62     0.024654   \n",
       "31  2021-02-16 11:45:00+00:00      Long  Closed        48715.17    -0.961796   \n",
       "32  2021-02-16 12:01:00+00:00     Short  Closed        48924.33    -1.180225   \n",
       "33  2021-02-22 10:48:00+00:00      Long  Closed        54926.84    33.580685   \n",
       "34  2021-02-28 19:38:00+00:00     Short  Closed        44179.85    60.123397   \n",
       "35  2021-03-04 04:15:00+00:00      Long  Closed        49503.28    44.270693   \n",
       "36  2021-03-09 01:25:00+00:00     Short  Closed        53016.00   -29.212472   \n",
       "37  2021-03-12 11:12:00+00:00      Long  Closed        56860.20    27.732721   \n",
       "38  2021-03-13 19:32:00+00:00     Short  Closed        60644.51   -27.300664   \n",
       "39  2021-03-15 00:03:00+00:00      Long  Closed        59327.16    -8.317513   \n",
       "40  2021-03-18 09:38:00+00:00     Short  Closed        58441.50     5.591899   \n",
       "41  2021-03-19 07:55:00+00:00      Long  Closed        57798.28    -4.184268   \n",
       "42  2021-03-24 22:00:00+00:00     Short  Closed        53476.53    28.113801   \n",
       "43  2021-03-29 08:51:00+00:00      Long  Closed        57018.00    26.761591   \n",
       "44  2021-03-31 08:06:00+00:00     Short  Closed        57420.93    -3.044794   \n",
       "45  2021-04-03 16:01:00+00:00      Long  Closed        58741.20     9.836780   \n",
       "46  2021-04-05 03:59:00+00:00     Short  Closed        57611.50     8.416922   \n",
       "47  2021-04-08 00:39:00+00:00      Long  Closed        56502.99    -8.582946   \n",
       "48  2021-04-18 03:35:00+00:00     Short  Closed        52648.69    29.842988   \n",
       "49  2021-04-18 03:37:00+00:00      Long  Closed        52805.87     1.395199   \n",
       "50  2021-04-25 21:46:00+00:00     Short  Closed        47512.66    46.984875   \n",
       "51  2021-04-28 20:05:00+00:00      Long  Closed        56455.04    97.062614   \n",
       "52  2021-05-23 05:11:00+00:00     Short  Closed        36806.85   213.265895   \n",
       "53  2021-05-23 14:11:00+00:00      Long  Closed        33358.08   -77.399389   \n",
       "54  2021-05-24 04:42:00+00:00     Short  Closed        34585.21   -27.539996   \n",
       "55  2021-05-24 20:00:00+00:00      Long  Closed        39578.41   104.108313   \n",
       "56  2021-05-30 06:08:00+00:00     Short  Closed        35458.24    85.905621   \n",
       "57  2021-05-30 11:51:00+00:00      Long  Closed        36238.97    20.061226   \n",
       "58  2021-05-30 12:06:00+00:00     Short  Closed        36055.64     4.710751   \n",
       "59  2021-05-30 12:49:00+00:00      Long  Closed        35404.31   -16.906427   \n",
       "60  2021-05-30 13:02:00+00:00     Short  Closed        35520.62    -3.019033   \n",
       "61  2021-06-04 05:14:00+00:00      Long  Closed        37000.00    38.148460   \n",
       "62  2021-06-06 15:03:00+00:00     Short  Closed        36245.14    19.465415   \n",
       "63  2021-06-07 01:48:00+00:00      Long  Closed        36692.43    12.014606   \n",
       "64  2021-06-08 15:23:00+00:00     Short  Closed        31084.04   150.646328   \n",
       "65  2021-06-12 02:22:00+00:00      Long  Closed        35780.43   171.670561   \n",
       "66  2021-06-13 16:54:00+00:00     Short  Closed        36909.89   -41.285973   \n",
       "67  2021-06-14 01:42:00+00:00      Long  Closed        39334.28    83.196834   \n",
       "68  2021-06-19 00:50:00+00:00     Short  Closed        35731.74   123.626943   \n",
       "69  2021-06-19 22:23:00+00:00      Long  Closed        35632.59    -4.088582   \n",
       "70  2021-06-22 14:00:00+00:00     Short  Closed        29429.98   255.772886   \n",
       "71  2021-06-23 14:01:00+00:00      Long  Closed        33899.99   262.023598   \n",
       "72  2021-06-26 09:09:00+00:00     Short  Closed        30294.55   211.344127   \n",
       "73  2021-06-30 07:54:00+00:00      Long  Closed        35161.04   353.164783   \n",
       "74  2021-07-04 07:51:00+00:00     Short  Closed        35581.43   -30.508014   \n",
       "75  2021-07-05 00:02:00+00:00      Long  Closed        34937.91   -45.597197   \n",
       "76  2021-07-21 18:59:00+00:00     Short  Closed        31881.06   216.595897   \n",
       "77  2021-07-26 01:00:00+00:00      Long  Closed        39814.35   669.916045   \n",
       "78  2021-07-27 00:12:00+00:00     Short  Closed        36985.72   238.859871   \n",
       "79  2021-07-27 02:01:00+00:00      Long  Closed        37048.58     6.120049   \n",
       "80  2021-07-27 12:48:00+00:00     Short  Closed        38372.02  -128.850105   \n",
       "81  2021-08-01 23:29:00+00:00      Long  Closed        39765.43   126.304469   \n",
       "82  2021-08-02 01:03:00+00:00     Short  Closed        39647.22    10.715045   \n",
       "83  2021-08-03 03:18:00+00:00      Long  Closed        38801.88   -77.082051   \n",
       "84  2021-08-23 00:52:00+00:00     Short  Closed        49407.90  -967.106461   \n",
       "85  2021-08-23 10:53:00+00:00      Long  Closed        50311.47    47.018914   \n",
       "86  2021-09-02 10:50:00+00:00     Short  Closed        50000.01    16.207390   \n",
       "87  2021-09-07 06:33:00+00:00      Long  Closed        52567.98   135.293810   \n",
       "88  2021-09-30 23:01:00+00:00     Short  Closed        43609.96   471.954365   \n",
       "89  2021-10-04 21:26:00+00:00      Long  Closed        48568.51   368.566340   \n",
       "90  2021-10-06 12:21:00+00:00     Short  Closed        52188.90  -269.101631   \n",
       "91  2021-10-12 11:59:00+00:00      Long  Closed        57082.15   313.250495   \n",
       "92  2021-12-07 14:47:00+00:00     Short  Closed        51445.25   360.856632   \n",
       "93  2021-12-07 15:44:00+00:00      Long  Closed        51744.62    23.364518   \n",
       "94  2021-12-27 01:14:00+00:00     Short  Closed        50607.07    88.780798   \n",
       "95  2021-12-28 17:05:00+00:00      Long  Closed        48385.67  -181.164622   \n",
       "96  2022-01-29 20:35:00+00:00     Short  Closed        38550.00   802.140739   \n",
       "97  2022-02-01 00:43:00+00:00      Long  Closed        38371.67   -21.964881   \n",
       "98  2022-02-03 10:02:00+00:00     Short  Closed        36374.02   246.050266   \n",
       "99  2022-02-09 00:42:00+00:00      Long  Closed        44247.28  1076.264871   \n",
       "100 2022-02-24 21:02:00+00:00     Short  Closed        38419.90   796.595614   \n",
       "101 2022-02-27 23:36:00+00:00      Long  Closed        37649.90  -137.188301   \n",
       "102 2022-02-28 17:58:00+00:00     Short  Closed        41375.50  -663.777575   \n",
       "103 2022-03-02 15:06:00+00:00      Long  Closed        44390.00   440.361436   \n",
       "104 2022-03-07 21:15:00+00:00     Short  Closed        38212.00   902.488954   \n",
       "105 2022-03-16 00:54:00+00:00      Long  Closed        39111.60   173.907954   \n",
       "106 2022-03-22 02:03:00+00:00     Short  Closed        41413.90  -445.073680   \n",
       "107 2022-03-23 04:17:00+00:00      Long  Closed        41884.30    80.825563   \n",
       "108 2022-03-28 15:10:00+00:00     Short  Closed        47765.90 -1010.594459   \n",
       "109 2022-03-28 22:49:00+00:00      Long  Closed        47528.50   -30.745336   \n",
       "110 2022-05-30 20:24:00+00:00     Short  Closed        31158.30  2120.081319   \n",
       "111 2022-06-01 11:33:00+00:00      Long  Closed        31466.80    81.935474   \n",
       "112 2022-06-19 21:08:00+00:00     Short  Closed        20401.90  2938.761187   \n",
       "113 2022-06-20 00:33:00+00:00      Long  Closed        20199.90  -111.843384   \n",
       "114 2022-07-01 00:01:00+00:00     Short  Closed        19708.90   271.856938   \n",
       "115 2022-07-02 23:39:00+00:00      Long  Closed        19276.00  -251.630634   \n",
       "116 2022-07-08 14:27:00+00:00     Short  Closed        21515.20 -1301.573838   \n",
       "117 2022-07-11 06:17:00+00:00      Long  Closed        20426.10  -501.286860   \n",
       "118 2022-07-29 01:02:00+00:00     Short  Closed        23821.80 -1562.960050   \n",
       "119 2022-08-06 00:54:00+00:00      Long  Closed        23245.60  -189.601641   \n",
       "120 2022-09-10 00:13:00+00:00     Short  Closed        21211.30   669.397115   \n",
       "121 2022-09-13 21:42:00+00:00      Long  Closed        19992.00  -478.175671   \n",
       "122 2022-10-31 01:49:00+00:00     Short  Closed        20450.90  -179.967863   \n",
       "123 2022-11-03 16:54:00+00:00      Long  Closed        20240.50   -78.810011   \n",
       "124 2022-11-22 10:38:00+00:00     Short  Closed        15758.90  1678.683193   \n",
       "125 2022-12-18 12:45:00+00:00      Long  Closed        16695.60   550.421805   \n",
       "126 2023-01-06 10:59:00+00:00     Short  Closed        16743.00   -27.853094   \n",
       "127 2023-01-27 01:36:00+00:00      Long  Closed        22656.60  3455.262625   \n",
       "128 2023-03-10 13:30:00+00:00     Short  Closed        20048.50  1523.889078   \n",
       "129 2023-03-14 13:19:00+00:00      Long  Closed        25892.10  4302.707846   \n",
       "130 2023-03-17 21:42:00+00:00     Short  Closed        27211.90  -971.783458   \n",
       "131 2023-03-22 18:33:00+00:00      Long  Closed        28082.60   578.917750   \n",
       "132 2023-05-11 17:44:00+00:00     Short    Open        26784.90   862.824812   \n",
       "\n",
       "       Return  Position Id  \n",
       "0   -0.093568            0  \n",
       "1    0.163402            1  \n",
       "2    0.009388            2  \n",
       "3    0.039953            3  \n",
       "4    0.173059            4  \n",
       "5    0.187006            5  \n",
       "6    0.201826            6  \n",
       "7   -0.016863            7  \n",
       "8   -0.015320            8  \n",
       "9    0.015862            9  \n",
       "10  -0.046551           10  \n",
       "11   0.109518           11  \n",
       "12   0.011572           12  \n",
       "13  -0.056818           13  \n",
       "14   0.002005           14  \n",
       "15  -0.018630           15  \n",
       "16  -0.006423           16  \n",
       "17  -0.038031           17  \n",
       "18  -0.025226           18  \n",
       "19   0.009146           19  \n",
       "20   0.056016           20  \n",
       "21   0.128330           21  \n",
       "22  -0.064334           22  \n",
       "23   0.013396           23  \n",
       "24   0.004842           24  \n",
       "25   0.199143           25  \n",
       "26   0.064248           26  \n",
       "27   0.114210           27  \n",
       "28   0.002381           28  \n",
       "29   0.002692           29  \n",
       "30   0.000089           30  \n",
       "31  -0.003487           31  \n",
       "32  -0.004294           32  \n",
       "33   0.122690           33  \n",
       "34   0.195660           34  \n",
       "35   0.120495           35  \n",
       "36  -0.070959           36  \n",
       "37   0.072510           37  \n",
       "38  -0.066555           38  \n",
       "39  -0.021722           39  \n",
       "40   0.014928           40  \n",
       "41  -0.011006           41  \n",
       "42   0.074773           42  \n",
       "43   0.066225           43  \n",
       "44  -0.007067           44  \n",
       "45   0.022993           45  \n",
       "46   0.019232           46  \n",
       "47  -0.019241           47  \n",
       "48   0.068214           48  \n",
       "49   0.002985           49  \n",
       "50   0.100239           50  \n",
       "51   0.188210           51  \n",
       "52   0.348033           52  \n",
       "53  -0.093699           53  \n",
       "54  -0.036787           54  \n",
       "55   0.144374           55  \n",
       "56   0.104101           56  \n",
       "57   0.022018           57  \n",
       "58   0.005059           58  \n",
       "59  -0.018065           59  \n",
       "60  -0.003285           60  \n",
       "61   0.041648           61  \n",
       "62   0.020402           62  \n",
       "63   0.012341           63  \n",
       "64   0.152849           64  \n",
       "65   0.151087           65  \n",
       "66  -0.031566           66  \n",
       "67   0.065684           67  \n",
       "68   0.091588           68  \n",
       "69  -0.002775           69  \n",
       "70   0.174071           70  \n",
       "71   0.151886           71  \n",
       "72   0.106355           72  \n",
       "73   0.160639           73  \n",
       "74  -0.011956           74  \n",
       "75  -0.018086           75  \n",
       "76   0.087494           76  \n",
       "77   0.248840           77  \n",
       "78   0.071045           78  \n",
       "79   0.001700           79  \n",
       "80  -0.035722           80  \n",
       "81   0.036313           81  \n",
       "82   0.002973           82  \n",
       "83  -0.021322           83  \n",
       "84  -0.273338           84  \n",
       "85   0.018288           85  \n",
       "86   0.006191           86  \n",
       "87   0.051359           87  \n",
       "88   0.170408           88  \n",
       "89   0.113702           89  \n",
       "90  -0.074542           90  \n",
       "91   0.093760           91  \n",
       "92   0.098751           92  \n",
       "93   0.005819           93  \n",
       "94   0.021984           94  \n",
       "95  -0.043895           95  \n",
       "96   0.203277           96  \n",
       "97  -0.004626           97  \n",
       "98   0.052061           98  \n",
       "99   0.216453           99  \n",
       "100  0.131700          100  \n",
       "101 -0.020042          101  \n",
       "102 -0.098954          102  \n",
       "103  0.072857          103  \n",
       "104  0.139175          104  \n",
       "105  0.023542          105  \n",
       "106 -0.058865          106  \n",
       "107  0.011359          107  \n",
       "108 -0.140425          108  \n",
       "109 -0.004970          109  \n",
       "110  0.344429          110  \n",
       "111  0.009901          111  \n",
       "112  0.351637          112  \n",
       "113 -0.009901          113  \n",
       "114  0.024307          114  \n",
       "115 -0.021965          115  \n",
       "116 -0.116165          116  \n",
       "117 -0.050620          117  \n",
       "118 -0.166243          118  \n",
       "119 -0.024188          119  \n",
       "120  0.087513          120  \n",
       "121 -0.057484          121  \n",
       "122 -0.022954          122  \n",
       "123 -0.010288          123  \n",
       "124  0.221417          124  \n",
       "125  0.059439          125  \n",
       "126 -0.002839          126  \n",
       "127  0.353198          127  \n",
       "128  0.115114          128  \n",
       "129  0.291473          129  \n",
       "130 -0.050973          130  \n",
       "131  0.031997          131  \n",
       "132  0.046210          132  "
      ]
     },
     "execution_count": 240,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trades[[ 'Size', 'Entry Index',\n",
    "       'Avg Entry Price',  'Exit Index',\n",
    "         'Direction', 'Status','Avg Exit Price','PnL','Return', \n",
    "       'Position Id']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "id": "ae20e807",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: xlabel='Open Time'>"
      ]
     },
     "execution_count": 233,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pf.cumulative_returns.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "8106222f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('portfolio.pkl')"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pf.save('portfolio.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "f0afc35f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pf.stats().to_csv('stats-full.csv')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "9f1a93d2",
   "metadata": {},
   "source": [
    "# Hyperparameter Tuning"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "6fd079e2",
   "metadata": {},
   "source": [
    "### Grid Search Method\n",
    "#### DONT RUN WITHOUT GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80c7709d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Specify hyperparameters to tune and their respective ranges\n",
    "param_grid = {\n",
    "    'model__learning_rate': [0.01, 0.1, 0.2],\n",
    "    'model__n_estimators': [100, 500, 1000],\n",
    "    'model__max_depth': [3, 5, 7],\n",
    "    'model__min_child_weight': [1, 5, 10],\n",
    "    'model__subsample': [0.5, 0.7, 1.0],\n",
    "    'model__colsample_bytree': [0.5, 0.7, 1.0]\n",
    "    # add other parameters here\n",
    "}\n",
    "\n",
    "# Perform grid search\n",
    "grid_search = GridSearchCV(pipeline, param_grid, cv=cv, scoring=\"r2\", n_jobs=-1, verbose=10)\n",
    "grid_search.fit(X, y)\n",
    "\n",
    "# Best parameters and score from grid search\n",
    "print(f\"Best parameters: {grid_search.best_params_}\")\n",
    "print(f\"Best score: {grid_search.best_score_}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f429f2b",
   "metadata": {},
   "source": [
    "### Randomized Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "0bb34aef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 37 folds for each of 30 candidates, totalling 1110 fits\n",
      "[CV 2/37; 1/30] START model__colsample_bytree=0.6872700594236812, model__learning_rate=0.20014286128198325, model__max_depth=5, model__min_child_weight=8, model__n_estimators=800, model__subsample=0.7984250789732434\n",
      "[CV 1/37; 1/30] START model__colsample_bytree=0.6872700594236812, model__learning_rate=0.20014286128198325, model__max_depth=5, model__min_child_weight=8, model__n_estimators=800, model__subsample=0.7984250789732434\n",
      "[CV 4/37; 1/30] START model__colsample_bytree=0.6872700594236812, model__learning_rate=0.20014286128198325, model__max_depth=5, model__min_child_weight=8, model__n_estimators=800, model__subsample=0.7984250789732434\n",
      "[CV 3/37; 1/30] START model__colsample_bytree=0.6872700594236812, model__learning_rate=0.20014286128198325, model__max_depth=5, model__min_child_weight=8, model__n_estimators=800, model__subsample=0.7984250789732434\n",
      "[CV 5/37; 1/30] START model__colsample_bytree=0.6872700594236812, model__learning_rate=0.20014286128198325, model__max_depth=5, model__min_child_weight=8, model__n_estimators=800, model__subsample=0.7984250789732434\n",
      "[CV 7/37; 1/30] START model__colsample_bytree=0.6872700594236812, model__learning_rate=0.20014286128198325, model__max_depth=5, model__min_child_weight=8, model__n_estimators=800, model__subsample=0.7984250789732434\n",
      "[CV 6/37; 1/30] START model__colsample_bytree=0.6872700594236812, model__learning_rate=0.20014286128198325, model__max_depth=5, model__min_child_weight=8, model__n_estimators=800, model__subsample=0.7984250789732434\n",
      "[CV 8/37; 1/30] START model__colsample_bytree=0.6872700594236812, model__learning_rate=0.20014286128198325, model__max_depth=5, model__min_child_weight=8, model__n_estimators=800, model__subsample=0.7984250789732434\n",
      "[CV 10/37; 1/30] START model__colsample_bytree=0.6872700594236812, model__learning_rate=0.20014286128198325, model__max_depth=5, model__min_child_weight=8, model__n_estimators=800, model__subsample=0.7984250789732434\n",
      "[CV 9/37; 1/30] START model__colsample_bytree=0.6872700594236812, model__learning_rate=0.20014286128198325, model__max_depth=5, model__min_child_weight=8, model__n_estimators=800, model__subsample=0.7984250789732434\n",
      "[CV 11/37; 1/30] START model__colsample_bytree=0.6872700594236812, model__learning_rate=0.20014286128198325, model__max_depth=5, model__min_child_weight=8, model__n_estimators=800, model__subsample=0.7984250789732434\n",
      "[CV 12/37; 1/30] START model__colsample_bytree=0.6872700594236812, model__learning_rate=0.20014286128198325, model__max_depth=5, model__min_child_weight=8, model__n_estimators=800, model__subsample=0.7984250789732434\n",
      "[CV 1/37; 1/30] END model__colsample_bytree=0.6872700594236812, model__learning_rate=0.20014286128198325, model__max_depth=5, model__min_child_weight=8, model__n_estimators=800, model__subsample=0.7984250789732434;, score=-43.212 total time=   0.3s\n",
      "[CV 13/37; 1/30] START model__colsample_bytree=0.6872700594236812, model__learning_rate=0.20014286128198325, model__max_depth=5, model__min_child_weight=8, model__n_estimators=800, model__subsample=0.7984250789732434\n",
      "[CV 2/37; 1/30] END model__colsample_bytree=0.6872700594236812, model__learning_rate=0.20014286128198325, model__max_depth=5, model__min_child_weight=8, model__n_estimators=800, model__subsample=0.7984250789732434;, score=-0.198 total time=   0.4s\n",
      "[CV 14/37; 1/30] START model__colsample_bytree=0.6872700594236812, model__learning_rate=0.20014286128198325, model__max_depth=5, model__min_child_weight=8, model__n_estimators=800, model__subsample=0.7984250789732434\n",
      "[CV 3/37; 1/30] END model__colsample_bytree=0.6872700594236812, model__learning_rate=0.20014286128198325, model__max_depth=5, model__min_child_weight=8, model__n_estimators=800, model__subsample=0.7984250789732434;, score=-15.113 total time=   0.6s\n",
      "[CV 15/37; 1/30] START model__colsample_bytree=0.6872700594236812, model__learning_rate=0.20014286128198325, model__max_depth=5, model__min_child_weight=8, model__n_estimators=800, model__subsample=0.7984250789732434\n",
      "[CV 4/37; 1/30] END model__colsample_bytree=0.6872700594236812, model__learning_rate=0.20014286128198325, model__max_depth=5, model__min_child_weight=8, model__n_estimators=800, model__subsample=0.7984250789732434;, score=-7.133 total time=   0.8s\n",
      "[CV 16/37; 1/30] START model__colsample_bytree=0.6872700594236812, model__learning_rate=0.20014286128198325, model__max_depth=5, model__min_child_weight=8, model__n_estimators=800, model__subsample=0.7984250789732434\n",
      "[CV 5/37; 1/30] END model__colsample_bytree=0.6872700594236812, model__learning_rate=0.20014286128198325, model__max_depth=5, model__min_child_weight=8, model__n_estimators=800, model__subsample=0.7984250789732434;, score=-37.777 total time=   1.0s\n",
      "[CV 17/37; 1/30] START model__colsample_bytree=0.6872700594236812, model__learning_rate=0.20014286128198325, model__max_depth=5, model__min_child_weight=8, model__n_estimators=800, model__subsample=0.7984250789732434\n",
      "[CV 6/37; 1/30] END model__colsample_bytree=0.6872700594236812, model__learning_rate=0.20014286128198325, model__max_depth=5, model__min_child_weight=8, model__n_estimators=800, model__subsample=0.7984250789732434;, score=-1.440 total time=   1.3s\n",
      "[CV 18/37; 1/30] START model__colsample_bytree=0.6872700594236812, model__learning_rate=0.20014286128198325, model__max_depth=5, model__min_child_weight=8, model__n_estimators=800, model__subsample=0.7984250789732434\n",
      "[CV 7/37; 1/30] END model__colsample_bytree=0.6872700594236812, model__learning_rate=0.20014286128198325, model__max_depth=5, model__min_child_weight=8, model__n_estimators=800, model__subsample=0.7984250789732434;, score=-6.064 total time=   1.6s\n",
      "[CV 19/37; 1/30] START model__colsample_bytree=0.6872700594236812, model__learning_rate=0.20014286128198325, model__max_depth=5, model__min_child_weight=8, model__n_estimators=800, model__subsample=0.7984250789732434\n",
      "[CV 8/37; 1/30] END model__colsample_bytree=0.6872700594236812, model__learning_rate=0.20014286128198325, model__max_depth=5, model__min_child_weight=8, model__n_estimators=800, model__subsample=0.7984250789732434;, score=-9.380 total time=   1.8s\n",
      "[CV 20/37; 1/30] START model__colsample_bytree=0.6872700594236812, model__learning_rate=0.20014286128198325, model__max_depth=5, model__min_child_weight=8, model__n_estimators=800, model__subsample=0.7984250789732434\n",
      "[CV 9/37; 1/30] END model__colsample_bytree=0.6872700594236812, model__learning_rate=0.20014286128198325, model__max_depth=5, model__min_child_weight=8, model__n_estimators=800, model__subsample=0.7984250789732434;, score=-0.587 total time=   2.2s\n",
      "[CV 21/37; 1/30] START model__colsample_bytree=0.6872700594236812, model__learning_rate=0.20014286128198325, model__max_depth=5, model__min_child_weight=8, model__n_estimators=800, model__subsample=0.7984250789732434\n",
      "[CV 10/37; 1/30] END model__colsample_bytree=0.6872700594236812, model__learning_rate=0.20014286128198325, model__max_depth=5, model__min_child_weight=8, model__n_estimators=800, model__subsample=0.7984250789732434;, score=-34.504 total time=   2.6s\n",
      "[CV 22/37; 1/30] START model__colsample_bytree=0.6872700594236812, model__learning_rate=0.20014286128198325, model__max_depth=5, model__min_child_weight=8, model__n_estimators=800, model__subsample=0.7984250789732434\n",
      "[CV 11/37; 1/30] END model__colsample_bytree=0.6872700594236812, model__learning_rate=0.20014286128198325, model__max_depth=5, model__min_child_weight=8, model__n_estimators=800, model__subsample=0.7984250789732434;, score=-4.325 total time=   2.8s\n",
      "[CV 23/37; 1/30] START model__colsample_bytree=0.6872700594236812, model__learning_rate=0.20014286128198325, model__max_depth=5, model__min_child_weight=8, model__n_estimators=800, model__subsample=0.7984250789732434\n",
      "[CV 12/37; 1/30] END model__colsample_bytree=0.6872700594236812, model__learning_rate=0.20014286128198325, model__max_depth=5, model__min_child_weight=8, model__n_estimators=800, model__subsample=0.7984250789732434;, score=-19.105 total time=   3.1s\n",
      "[CV 24/37; 1/30] START model__colsample_bytree=0.6872700594236812, model__learning_rate=0.20014286128198325, model__max_depth=5, model__min_child_weight=8, model__n_estimators=800, model__subsample=0.7984250789732434\n",
      "[CV 13/37; 1/30] END model__colsample_bytree=0.6872700594236812, model__learning_rate=0.20014286128198325, model__max_depth=5, model__min_child_weight=8, model__n_estimators=800, model__subsample=0.7984250789732434;, score=0.171 total time=   3.5s\n",
      "[CV 25/37; 1/30] START model__colsample_bytree=0.6872700594236812, model__learning_rate=0.20014286128198325, model__max_depth=5, model__min_child_weight=8, model__n_estimators=800, model__subsample=0.7984250789732434\n",
      "[CV 14/37; 1/30] END model__colsample_bytree=0.6872700594236812, model__learning_rate=0.20014286128198325, model__max_depth=5, model__min_child_weight=8, model__n_estimators=800, model__subsample=0.7984250789732434;, score=-25.146 total time=   3.9s\n",
      "[CV 26/37; 1/30] START model__colsample_bytree=0.6872700594236812, model__learning_rate=0.20014286128198325, model__max_depth=5, model__min_child_weight=8, model__n_estimators=800, model__subsample=0.7984250789732434\n",
      "[CV 15/37; 1/30] END model__colsample_bytree=0.6872700594236812, model__learning_rate=0.20014286128198325, model__max_depth=5, model__min_child_weight=8, model__n_estimators=800, model__subsample=0.7984250789732434;, score=-0.080 total time=   4.2s\n",
      "[CV 27/37; 1/30] START model__colsample_bytree=0.6872700594236812, model__learning_rate=0.20014286128198325, model__max_depth=5, model__min_child_weight=8, model__n_estimators=800, model__subsample=0.7984250789732434\n",
      "[CV 16/37; 1/30] END model__colsample_bytree=0.6872700594236812, model__learning_rate=0.20014286128198325, model__max_depth=5, model__min_child_weight=8, model__n_estimators=800, model__subsample=0.7984250789732434;, score=-1.139 total time=   4.3s\n",
      "[CV 28/37; 1/30] START model__colsample_bytree=0.6872700594236812, model__learning_rate=0.20014286128198325, model__max_depth=5, model__min_child_weight=8, model__n_estimators=800, model__subsample=0.7984250789732434\n",
      "[CV 17/37; 1/30] END model__colsample_bytree=0.6872700594236812, model__learning_rate=0.20014286128198325, model__max_depth=5, model__min_child_weight=8, model__n_estimators=800, model__subsample=0.7984250789732434;, score=-18.606 total time=   4.6s\n",
      "[CV 29/37; 1/30] START model__colsample_bytree=0.6872700594236812, model__learning_rate=0.20014286128198325, model__max_depth=5, model__min_child_weight=8, model__n_estimators=800, model__subsample=0.7984250789732434\n",
      "[CV 18/37; 1/30] END model__colsample_bytree=0.6872700594236812, model__learning_rate=0.20014286128198325, model__max_depth=5, model__min_child_weight=8, model__n_estimators=800, model__subsample=0.7984250789732434;, score=-1.150 total time=   4.9s\n",
      "[CV 30/37; 1/30] START model__colsample_bytree=0.6872700594236812, model__learning_rate=0.20014286128198325, model__max_depth=5, model__min_child_weight=8, model__n_estimators=800, model__subsample=0.7984250789732434\n",
      "[CV 19/37; 1/30] END model__colsample_bytree=0.6872700594236812, model__learning_rate=0.20014286128198325, model__max_depth=5, model__min_child_weight=8, model__n_estimators=800, model__subsample=0.7984250789732434;, score=-1.741 total time=   5.1s\n",
      "[CV 31/37; 1/30] START model__colsample_bytree=0.6872700594236812, model__learning_rate=0.20014286128198325, model__max_depth=5, model__min_child_weight=8, model__n_estimators=800, model__subsample=0.7984250789732434\n",
      "[CV 20/37; 1/30] END model__colsample_bytree=0.6872700594236812, model__learning_rate=0.20014286128198325, model__max_depth=5, model__min_child_weight=8, model__n_estimators=800, model__subsample=0.7984250789732434;, score=-4.766 total time=   5.4s\n",
      "[CV 32/37; 1/30] START model__colsample_bytree=0.6872700594236812, model__learning_rate=0.20014286128198325, model__max_depth=5, model__min_child_weight=8, model__n_estimators=800, model__subsample=0.7984250789732434\n",
      "[CV 21/37; 1/30] END model__colsample_bytree=0.6872700594236812, model__learning_rate=0.20014286128198325, model__max_depth=5, model__min_child_weight=8, model__n_estimators=800, model__subsample=0.7984250789732434;, score=-1.462 total time=   5.6s\n",
      "[CV 33/37; 1/30] START model__colsample_bytree=0.6872700594236812, model__learning_rate=0.20014286128198325, model__max_depth=5, model__min_child_weight=8, model__n_estimators=800, model__subsample=0.7984250789732434\n",
      "[CV 22/37; 1/30] END model__colsample_bytree=0.6872700594236812, model__learning_rate=0.20014286128198325, model__max_depth=5, model__min_child_weight=8, model__n_estimators=800, model__subsample=0.7984250789732434;, score=-0.794 total time=   5.9s\n",
      "[CV 34/37; 1/30] START model__colsample_bytree=0.6872700594236812, model__learning_rate=0.20014286128198325, model__max_depth=5, model__min_child_weight=8, model__n_estimators=800, model__subsample=0.7984250789732434\n",
      "[CV 23/37; 1/30] END model__colsample_bytree=0.6872700594236812, model__learning_rate=0.20014286128198325, model__max_depth=5, model__min_child_weight=8, model__n_estimators=800, model__subsample=0.7984250789732434;, score=-10.030 total time=   6.1s\n",
      "[CV 35/37; 1/30] START model__colsample_bytree=0.6872700594236812, model__learning_rate=0.20014286128198325, model__max_depth=5, model__min_child_weight=8, model__n_estimators=800, model__subsample=0.7984250789732434\n",
      "[CV 24/37; 1/30] END model__colsample_bytree=0.6872700594236812, model__learning_rate=0.20014286128198325, model__max_depth=5, model__min_child_weight=8, model__n_estimators=800, model__subsample=0.7984250789732434;, score=-6.088 total time=   6.3s\n",
      "[CV 36/37; 1/30] START model__colsample_bytree=0.6872700594236812, model__learning_rate=0.20014286128198325, model__max_depth=5, model__min_child_weight=8, model__n_estimators=800, model__subsample=0.7984250789732434\n",
      "[CV 25/37; 1/30] END model__colsample_bytree=0.6872700594236812, model__learning_rate=0.20014286128198325, model__max_depth=5, model__min_child_weight=8, model__n_estimators=800, model__subsample=0.7984250789732434;, score=-1.354 total time=   6.5s\n",
      "[CV 37/37; 1/30] START model__colsample_bytree=0.6872700594236812, model__learning_rate=0.20014286128198325, model__max_depth=5, model__min_child_weight=8, model__n_estimators=800, model__subsample=0.7984250789732434\n",
      "[CV 26/37; 1/30] END model__colsample_bytree=0.6872700594236812, model__learning_rate=0.20014286128198325, model__max_depth=5, model__min_child_weight=8, model__n_estimators=800, model__subsample=0.7984250789732434;, score=-2.664 total time=   6.8s\n",
      "[CV 1/37; 2/30] START model__colsample_bytree=0.7229163764267956, model__learning_rate=0.02999498316360058, model__max_depth=5, model__min_child_weight=8, model__n_estimators=472, model__subsample=0.8005575058716043\n",
      "[CV 1/37; 2/30] END model__colsample_bytree=0.7229163764267956, model__learning_rate=0.02999498316360058, model__max_depth=5, model__min_child_weight=8, model__n_estimators=472, model__subsample=0.8005575058716043;, score=-40.434 total time=   0.3s\n",
      "[CV 2/37; 2/30] START model__colsample_bytree=0.7229163764267956, model__learning_rate=0.02999498316360058, model__max_depth=5, model__min_child_weight=8, model__n_estimators=472, model__subsample=0.8005575058716043\n",
      "[CV 27/37; 1/30] END model__colsample_bytree=0.6872700594236812, model__learning_rate=0.20014286128198325, model__max_depth=5, model__min_child_weight=8, model__n_estimators=800, model__subsample=0.7984250789732434;, score=-4.337 total time=   7.1s\n",
      "[CV 2/37; 2/30] END model__colsample_bytree=0.7229163764267956, model__learning_rate=0.02999498316360058, model__max_depth=5, model__min_child_weight=8, model__n_estimators=472, model__subsample=0.8005575058716043;, score=-0.330 total time=   0.5s\n",
      "[CV 4/37; 2/30] START model__colsample_bytree=0.7229163764267956, model__learning_rate=0.02999498316360058, model__max_depth=5, model__min_child_weight=8, model__n_estimators=472, model__subsample=0.8005575058716043\n",
      "[CV 3/37; 2/30] START model__colsample_bytree=0.7229163764267956, model__learning_rate=0.02999498316360058, model__max_depth=5, model__min_child_weight=8, model__n_estimators=472, model__subsample=0.8005575058716043\n",
      "[CV 28/37; 1/30] END model__colsample_bytree=0.6872700594236812, model__learning_rate=0.20014286128198325, model__max_depth=5, model__min_child_weight=8, model__n_estimators=800, model__subsample=0.7984250789732434;, score=-2.119 total time=   7.4s\n",
      "[CV 5/37; 2/30] START model__colsample_bytree=0.7229163764267956, model__learning_rate=0.02999498316360058, model__max_depth=5, model__min_child_weight=8, model__n_estimators=472, model__subsample=0.8005575058716043\n",
      "[CV 3/37; 2/30] END model__colsample_bytree=0.7229163764267956, model__learning_rate=0.02999498316360058, model__max_depth=5, model__min_child_weight=8, model__n_estimators=472, model__subsample=0.8005575058716043;, score=-18.008 total time=   0.6s\n",
      "[CV 6/37; 2/30] START model__colsample_bytree=0.7229163764267956, model__learning_rate=0.02999498316360058, model__max_depth=5, model__min_child_weight=8, model__n_estimators=472, model__subsample=0.8005575058716043\n",
      "[CV 4/37; 2/30] END model__colsample_bytree=0.7229163764267956, model__learning_rate=0.02999498316360058, model__max_depth=5, model__min_child_weight=8, model__n_estimators=472, model__subsample=0.8005575058716043;, score=-7.588 total time=   0.7s\n",
      "[CV 7/37; 2/30] START model__colsample_bytree=0.7229163764267956, model__learning_rate=0.02999498316360058, model__max_depth=5, model__min_child_weight=8, model__n_estimators=472, model__subsample=0.8005575058716043\n",
      "[CV 29/37; 1/30] END model__colsample_bytree=0.6872700594236812, model__learning_rate=0.20014286128198325, model__max_depth=5, model__min_child_weight=8, model__n_estimators=800, model__subsample=0.7984250789732434;, score=-14.127 total time=   7.7s\n",
      "[CV 8/37; 2/30] START model__colsample_bytree=0.7229163764267956, model__learning_rate=0.02999498316360058, model__max_depth=5, model__min_child_weight=8, model__n_estimators=472, model__subsample=0.8005575058716043\n",
      "[CV 5/37; 2/30] END model__colsample_bytree=0.7229163764267956, model__learning_rate=0.02999498316360058, model__max_depth=5, model__min_child_weight=8, model__n_estimators=472, model__subsample=0.8005575058716043;, score=-37.814 total time=   0.9s\n",
      "[CV 9/37; 2/30] START model__colsample_bytree=0.7229163764267956, model__learning_rate=0.02999498316360058, model__max_depth=5, model__min_child_weight=8, model__n_estimators=472, model__subsample=0.8005575058716043\n",
      "[CV 6/37; 2/30] END model__colsample_bytree=0.7229163764267956, model__learning_rate=0.02999498316360058, model__max_depth=5, model__min_child_weight=8, model__n_estimators=472, model__subsample=0.8005575058716043;, score=-1.479 total time=   1.1s\n",
      "[CV 10/37; 2/30] START model__colsample_bytree=0.7229163764267956, model__learning_rate=0.02999498316360058, model__max_depth=5, model__min_child_weight=8, model__n_estimators=472, model__subsample=0.8005575058716043\n",
      "[CV 7/37; 2/30] END model__colsample_bytree=0.7229163764267956, model__learning_rate=0.02999498316360058, model__max_depth=5, model__min_child_weight=8, model__n_estimators=472, model__subsample=0.8005575058716043;, score=-6.135 total time=   1.2s\n",
      "[CV 11/37; 2/30] START model__colsample_bytree=0.7229163764267956, model__learning_rate=0.02999498316360058, model__max_depth=5, model__min_child_weight=8, model__n_estimators=472, model__subsample=0.8005575058716043\n",
      "[CV 30/37; 1/30] END model__colsample_bytree=0.6872700594236812, model__learning_rate=0.20014286128198325, model__max_depth=5, model__min_child_weight=8, model__n_estimators=800, model__subsample=0.7984250789732434;, score=-0.478 total time=   7.9s\n",
      "[CV 12/37; 2/30] START model__colsample_bytree=0.7229163764267956, model__learning_rate=0.02999498316360058, model__max_depth=5, model__min_child_weight=8, model__n_estimators=472, model__subsample=0.8005575058716043\n",
      "[CV 8/37; 2/30] END model__colsample_bytree=0.7229163764267956, model__learning_rate=0.02999498316360058, model__max_depth=5, model__min_child_weight=8, model__n_estimators=472, model__subsample=0.8005575058716043;, score=-8.486 total time=   1.4s\n",
      "[CV 13/37; 2/30] START model__colsample_bytree=0.7229163764267956, model__learning_rate=0.02999498316360058, model__max_depth=5, model__min_child_weight=8, model__n_estimators=472, model__subsample=0.8005575058716043\n",
      "[CV 31/37; 1/30] END model__colsample_bytree=0.6872700594236812, model__learning_rate=0.20014286128198325, model__max_depth=5, model__min_child_weight=8, model__n_estimators=800, model__subsample=0.7984250789732434;, score=-0.450 total time=   8.1s\n",
      "[CV 14/37; 2/30] START model__colsample_bytree=0.7229163764267956, model__learning_rate=0.02999498316360058, model__max_depth=5, model__min_child_weight=8, model__n_estimators=472, model__subsample=0.8005575058716043\n",
      "[CV 9/37; 2/30] END model__colsample_bytree=0.7229163764267956, model__learning_rate=0.02999498316360058, model__max_depth=5, model__min_child_weight=8, model__n_estimators=472, model__subsample=0.8005575058716043;, score=-0.845 total time=   1.5s\n",
      "[CV 15/37; 2/30] START model__colsample_bytree=0.7229163764267956, model__learning_rate=0.02999498316360058, model__max_depth=5, model__min_child_weight=8, model__n_estimators=472, model__subsample=0.8005575058716043\n",
      "[CV 10/37; 2/30] END model__colsample_bytree=0.7229163764267956, model__learning_rate=0.02999498316360058, model__max_depth=5, model__min_child_weight=8, model__n_estimators=472, model__subsample=0.8005575058716043;, score=-24.860 total time=   1.6s\n",
      "[CV 16/37; 2/30] START model__colsample_bytree=0.7229163764267956, model__learning_rate=0.02999498316360058, model__max_depth=5, model__min_child_weight=8, model__n_estimators=472, model__subsample=0.8005575058716043\n",
      "[CV 32/37; 1/30] END model__colsample_bytree=0.6872700594236812, model__learning_rate=0.20014286128198325, model__max_depth=5, model__min_child_weight=8, model__n_estimators=800, model__subsample=0.7984250789732434;, score=-3.431 total time=   8.4s\n",
      "[CV 17/37; 2/30] START model__colsample_bytree=0.7229163764267956, model__learning_rate=0.02999498316360058, model__max_depth=5, model__min_child_weight=8, model__n_estimators=472, model__subsample=0.8005575058716043\n",
      "[CV 11/37; 2/30] END model__colsample_bytree=0.7229163764267956, model__learning_rate=0.02999498316360058, model__max_depth=5, model__min_child_weight=8, model__n_estimators=472, model__subsample=0.8005575058716043;, score=-3.469 total time=   1.8s\n",
      "[CV 18/37; 2/30] START model__colsample_bytree=0.7229163764267956, model__learning_rate=0.02999498316360058, model__max_depth=5, model__min_child_weight=8, model__n_estimators=472, model__subsample=0.8005575058716043\n",
      "[CV 12/37; 2/30] END model__colsample_bytree=0.7229163764267956, model__learning_rate=0.02999498316360058, model__max_depth=5, model__min_child_weight=8, model__n_estimators=472, model__subsample=0.8005575058716043;, score=-16.584 total time=   1.9s\n",
      "[CV 19/37; 2/30] START model__colsample_bytree=0.7229163764267956, model__learning_rate=0.02999498316360058, model__max_depth=5, model__min_child_weight=8, model__n_estimators=472, model__subsample=0.8005575058716043\n",
      "[CV 33/37; 1/30] END model__colsample_bytree=0.6872700594236812, model__learning_rate=0.20014286128198325, model__max_depth=5, model__min_child_weight=8, model__n_estimators=800, model__subsample=0.7984250789732434;, score=-17.986 total time=   8.8s\n",
      "[CV 20/37; 2/30] START model__colsample_bytree=0.7229163764267956, model__learning_rate=0.02999498316360058, model__max_depth=5, model__min_child_weight=8, model__n_estimators=472, model__subsample=0.8005575058716043\n",
      "[CV 13/37; 2/30] END model__colsample_bytree=0.7229163764267956, model__learning_rate=0.02999498316360058, model__max_depth=5, model__min_child_weight=8, model__n_estimators=472, model__subsample=0.8005575058716043;, score=0.136 total time=   2.1s\n",
      "[CV 21/37; 2/30] START model__colsample_bytree=0.7229163764267956, model__learning_rate=0.02999498316360058, model__max_depth=5, model__min_child_weight=8, model__n_estimators=472, model__subsample=0.8005575058716043\n",
      "[CV 14/37; 2/30] END model__colsample_bytree=0.7229163764267956, model__learning_rate=0.02999498316360058, model__max_depth=5, model__min_child_weight=8, model__n_estimators=472, model__subsample=0.8005575058716043;, score=-20.954 total time=   2.2s\n",
      "[CV 22/37; 2/30] START model__colsample_bytree=0.7229163764267956, model__learning_rate=0.02999498316360058, model__max_depth=5, model__min_child_weight=8, model__n_estimators=472, model__subsample=0.8005575058716043\n",
      "[CV 15/37; 2/30] END model__colsample_bytree=0.7229163764267956, model__learning_rate=0.02999498316360058, model__max_depth=5, model__min_child_weight=8, model__n_estimators=472, model__subsample=0.8005575058716043;, score=0.039 total time=   2.3s\n",
      "[CV 23/37; 2/30] START model__colsample_bytree=0.7229163764267956, model__learning_rate=0.02999498316360058, model__max_depth=5, model__min_child_weight=8, model__n_estimators=472, model__subsample=0.8005575058716043\n",
      "[CV 34/37; 1/30] END model__colsample_bytree=0.6872700594236812, model__learning_rate=0.20014286128198325, model__max_depth=5, model__min_child_weight=8, model__n_estimators=800, model__subsample=0.7984250789732434;, score=0.099 total time=   9.0s\n",
      "[CV 24/37; 2/30] START model__colsample_bytree=0.7229163764267956, model__learning_rate=0.02999498316360058, model__max_depth=5, model__min_child_weight=8, model__n_estimators=472, model__subsample=0.8005575058716043\n",
      "[CV 16/37; 2/30] END model__colsample_bytree=0.7229163764267956, model__learning_rate=0.02999498316360058, model__max_depth=5, model__min_child_weight=8, model__n_estimators=472, model__subsample=0.8005575058716043;, score=-0.609 total time=   2.5s\n",
      "[CV 25/37; 2/30] START model__colsample_bytree=0.7229163764267956, model__learning_rate=0.02999498316360058, model__max_depth=5, model__min_child_weight=8, model__n_estimators=472, model__subsample=0.8005575058716043\n",
      "[CV 17/37; 2/30] END model__colsample_bytree=0.7229163764267956, model__learning_rate=0.02999498316360058, model__max_depth=5, model__min_child_weight=8, model__n_estimators=472, model__subsample=0.8005575058716043;, score=-17.953 total time=   2.5s\n",
      "[CV 26/37; 2/30] START model__colsample_bytree=0.7229163764267956, model__learning_rate=0.02999498316360058, model__max_depth=5, model__min_child_weight=8, model__n_estimators=472, model__subsample=0.8005575058716043\n",
      "[CV 35/37; 1/30] END model__colsample_bytree=0.6872700594236812, model__learning_rate=0.20014286128198325, model__max_depth=5, model__min_child_weight=8, model__n_estimators=800, model__subsample=0.7984250789732434;, score=-20.413 total time=   9.2s\n",
      "[CV 27/37; 2/30] START model__colsample_bytree=0.7229163764267956, model__learning_rate=0.02999498316360058, model__max_depth=5, model__min_child_weight=8, model__n_estimators=472, model__subsample=0.8005575058716043\n",
      "[CV 18/37; 2/30] END model__colsample_bytree=0.7229163764267956, model__learning_rate=0.02999498316360058, model__max_depth=5, model__min_child_weight=8, model__n_estimators=472, model__subsample=0.8005575058716043;, score=-0.189 total time=   2.8s\n",
      "[CV 28/37; 2/30] START model__colsample_bytree=0.7229163764267956, model__learning_rate=0.02999498316360058, model__max_depth=5, model__min_child_weight=8, model__n_estimators=472, model__subsample=0.8005575058716043\n",
      "[CV 19/37; 2/30] END model__colsample_bytree=0.7229163764267956, model__learning_rate=0.02999498316360058, model__max_depth=5, model__min_child_weight=8, model__n_estimators=472, model__subsample=0.8005575058716043;, score=-0.630 total time=   3.0s\n",
      "[CV 29/37; 2/30] START model__colsample_bytree=0.7229163764267956, model__learning_rate=0.02999498316360058, model__max_depth=5, model__min_child_weight=8, model__n_estimators=472, model__subsample=0.8005575058716043\n",
      "[CV 36/37; 1/30] END model__colsample_bytree=0.6872700594236812, model__learning_rate=0.20014286128198325, model__max_depth=5, model__min_child_weight=8, model__n_estimators=800, model__subsample=0.7984250789732434;, score=-1.575 total time=   9.5s\n",
      "[CV 30/37; 2/30] START model__colsample_bytree=0.7229163764267956, model__learning_rate=0.02999498316360058, model__max_depth=5, model__min_child_weight=8, model__n_estimators=472, model__subsample=0.8005575058716043\n",
      "[CV 20/37; 2/30] END model__colsample_bytree=0.7229163764267956, model__learning_rate=0.02999498316360058, model__max_depth=5, model__min_child_weight=8, model__n_estimators=472, model__subsample=0.8005575058716043;, score=-4.487 total time=   3.0s\n",
      "[CV 31/37; 2/30] START model__colsample_bytree=0.7229163764267956, model__learning_rate=0.02999498316360058, model__max_depth=5, model__min_child_weight=8, model__n_estimators=472, model__subsample=0.8005575058716043\n",
      "[CV 21/37; 2/30] END model__colsample_bytree=0.7229163764267956, model__learning_rate=0.02999498316360058, model__max_depth=5, model__min_child_weight=8, model__n_estimators=472, model__subsample=0.8005575058716043;, score=-0.962 total time=   3.1s\n",
      "[CV 32/37; 2/30] START model__colsample_bytree=0.7229163764267956, model__learning_rate=0.02999498316360058, model__max_depth=5, model__min_child_weight=8, model__n_estimators=472, model__subsample=0.8005575058716043\n",
      "[CV 37/37; 1/30] END model__colsample_bytree=0.6872700594236812, model__learning_rate=0.20014286128198325, model__max_depth=5, model__min_child_weight=8, model__n_estimators=800, model__subsample=0.7984250789732434;, score=-0.611 total time=   9.6s\n",
      "[CV 33/37; 2/30] START model__colsample_bytree=0.7229163764267956, model__learning_rate=0.02999498316360058, model__max_depth=5, model__min_child_weight=8, model__n_estimators=472, model__subsample=0.8005575058716043\n",
      "[CV 22/37; 2/30] END model__colsample_bytree=0.7229163764267956, model__learning_rate=0.02999498316360058, model__max_depth=5, model__min_child_weight=8, model__n_estimators=472, model__subsample=0.8005575058716043;, score=-0.397 total time=   3.2s\n",
      "[CV 34/37; 2/30] START model__colsample_bytree=0.7229163764267956, model__learning_rate=0.02999498316360058, model__max_depth=5, model__min_child_weight=8, model__n_estimators=472, model__subsample=0.8005575058716043\n",
      "[CV 23/37; 2/30] END model__colsample_bytree=0.7229163764267956, model__learning_rate=0.02999498316360058, model__max_depth=5, model__min_child_weight=8, model__n_estimators=472, model__subsample=0.8005575058716043;, score=-12.119 total time=   3.5s\n",
      "[CV 35/37; 2/30] START model__colsample_bytree=0.7229163764267956, model__learning_rate=0.02999498316360058, model__max_depth=5, model__min_child_weight=8, model__n_estimators=472, model__subsample=0.8005575058716043\n",
      "[CV 24/37; 2/30] END model__colsample_bytree=0.7229163764267956, model__learning_rate=0.02999498316360058, model__max_depth=5, model__min_child_weight=8, model__n_estimators=472, model__subsample=0.8005575058716043;, score=-5.793 total time=   3.4s\n",
      "[CV 36/37; 2/30] START model__colsample_bytree=0.7229163764267956, model__learning_rate=0.02999498316360058, model__max_depth=5, model__min_child_weight=8, model__n_estimators=472, model__subsample=0.8005575058716043\n",
      "[CV 25/37; 2/30] END model__colsample_bytree=0.7229163764267956, model__learning_rate=0.02999498316360058, model__max_depth=5, model__min_child_weight=8, model__n_estimators=472, model__subsample=0.8005575058716043;, score=-0.970 total time=   3.6s\n",
      "[CV 37/37; 2/30] START model__colsample_bytree=0.7229163764267956, model__learning_rate=0.02999498316360058, model__max_depth=5, model__min_child_weight=8, model__n_estimators=472, model__subsample=0.8005575058716043\n",
      "[CV 26/37; 2/30] END model__colsample_bytree=0.7229163764267956, model__learning_rate=0.02999498316360058, model__max_depth=5, model__min_child_weight=8, model__n_estimators=472, model__subsample=0.8005575058716043;, score=-1.149 total time=   3.8s\n",
      "[CV 1/37; 3/30] START model__colsample_bytree=0.8540362888980227, model__learning_rate=0.014116898859160489, model__max_depth=4, model__min_child_weight=8, model__n_estimators=591, model__subsample=0.9692763545078751\n",
      "[CV 27/37; 2/30] END model__colsample_bytree=0.7229163764267956, model__learning_rate=0.02999498316360058, model__max_depth=5, model__min_child_weight=8, model__n_estimators=472, model__subsample=0.8005575058716043;, score=-2.289 total time=   3.8s\n",
      "[CV 2/37; 3/30] START model__colsample_bytree=0.8540362888980227, model__learning_rate=0.014116898859160489, model__max_depth=4, model__min_child_weight=8, model__n_estimators=591, model__subsample=0.9692763545078751\n",
      "[CV 1/37; 3/30] END model__colsample_bytree=0.8540362888980227, model__learning_rate=0.014116898859160489, model__max_depth=4, model__min_child_weight=8, model__n_estimators=591, model__subsample=0.9692763545078751;, score=-41.051 total time=   0.4s\n",
      "[CV 3/37; 3/30] START model__colsample_bytree=0.8540362888980227, model__learning_rate=0.014116898859160489, model__max_depth=4, model__min_child_weight=8, model__n_estimators=591, model__subsample=0.9692763545078751\n",
      "[CV 2/37; 3/30] END model__colsample_bytree=0.8540362888980227, model__learning_rate=0.014116898859160489, model__max_depth=4, model__min_child_weight=8, model__n_estimators=591, model__subsample=0.9692763545078751;, score=-0.238 total time=   0.5s\n",
      "[CV 4/37; 3/30] START model__colsample_bytree=0.8540362888980227, model__learning_rate=0.014116898859160489, model__max_depth=4, model__min_child_weight=8, model__n_estimators=591, model__subsample=0.9692763545078751\n",
      "[CV 28/37; 2/30] END model__colsample_bytree=0.7229163764267956, model__learning_rate=0.02999498316360058, model__max_depth=5, model__min_child_weight=8, model__n_estimators=472, model__subsample=0.8005575058716043;, score=-0.977 total time=   4.1s\n",
      "[CV 5/37; 3/30] START model__colsample_bytree=0.8540362888980227, model__learning_rate=0.014116898859160489, model__max_depth=4, model__min_child_weight=8, model__n_estimators=591, model__subsample=0.9692763545078751\n",
      "[CV 3/37; 3/30] END model__colsample_bytree=0.8540362888980227, model__learning_rate=0.014116898859160489, model__max_depth=4, model__min_child_weight=8, model__n_estimators=591, model__subsample=0.9692763545078751;, score=-20.872 total time=   0.7s\n",
      "[CV 6/37; 3/30] START model__colsample_bytree=0.8540362888980227, model__learning_rate=0.014116898859160489, model__max_depth=4, model__min_child_weight=8, model__n_estimators=591, model__subsample=0.9692763545078751\n",
      "[CV 29/37; 2/30] END model__colsample_bytree=0.7229163764267956, model__learning_rate=0.02999498316360058, model__max_depth=5, model__min_child_weight=8, model__n_estimators=472, model__subsample=0.8005575058716043;, score=-8.821 total time=   4.2s\n",
      "[CV 7/37; 3/30] START model__colsample_bytree=0.8540362888980227, model__learning_rate=0.014116898859160489, model__max_depth=4, model__min_child_weight=8, model__n_estimators=591, model__subsample=0.9692763545078751\n",
      "[CV 30/37; 2/30] END model__colsample_bytree=0.7229163764267956, model__learning_rate=0.02999498316360058, model__max_depth=5, model__min_child_weight=8, model__n_estimators=472, model__subsample=0.8005575058716043;, score=-0.184 total time=   4.3s\n",
      "[CV 8/37; 3/30] START model__colsample_bytree=0.8540362888980227, model__learning_rate=0.014116898859160489, model__max_depth=4, model__min_child_weight=8, model__n_estimators=591, model__subsample=0.9692763545078751\n",
      "[CV 4/37; 3/30] END model__colsample_bytree=0.8540362888980227, model__learning_rate=0.014116898859160489, model__max_depth=4, model__min_child_weight=8, model__n_estimators=591, model__subsample=0.9692763545078751;, score=-8.183 total time=   0.8s\n",
      "[CV 9/37; 3/30] START model__colsample_bytree=0.8540362888980227, model__learning_rate=0.014116898859160489, model__max_depth=4, model__min_child_weight=8, model__n_estimators=591, model__subsample=0.9692763545078751\n",
      "[CV 5/37; 3/30] END model__colsample_bytree=0.8540362888980227, model__learning_rate=0.014116898859160489, model__max_depth=4, model__min_child_weight=8, model__n_estimators=591, model__subsample=0.9692763545078751;, score=-38.504 total time=   1.0s\n",
      "[CV 10/37; 3/30] START model__colsample_bytree=0.8540362888980227, model__learning_rate=0.014116898859160489, model__max_depth=4, model__min_child_weight=8, model__n_estimators=591, model__subsample=0.9692763545078751\n",
      "[CV 31/37; 2/30] END model__colsample_bytree=0.7229163764267956, model__learning_rate=0.02999498316360058, model__max_depth=5, model__min_child_weight=8, model__n_estimators=472, model__subsample=0.8005575058716043;, score=0.221 total time=   4.4s\n",
      "[CV 11/37; 3/30] START model__colsample_bytree=0.8540362888980227, model__learning_rate=0.014116898859160489, model__max_depth=4, model__min_child_weight=8, model__n_estimators=591, model__subsample=0.9692763545078751\n",
      "[CV 6/37; 3/30] END model__colsample_bytree=0.8540362888980227, model__learning_rate=0.014116898859160489, model__max_depth=4, model__min_child_weight=8, model__n_estimators=591, model__subsample=0.9692763545078751;, score=-1.606 total time=   1.2s\n",
      "[CV 12/37; 3/30] START model__colsample_bytree=0.8540362888980227, model__learning_rate=0.014116898859160489, model__max_depth=4, model__min_child_weight=8, model__n_estimators=591, model__subsample=0.9692763545078751\n",
      "[CV 7/37; 3/30] END model__colsample_bytree=0.8540362888980227, model__learning_rate=0.014116898859160489, model__max_depth=4, model__min_child_weight=8, model__n_estimators=591, model__subsample=0.9692763545078751;, score=-5.165 total time=   1.3s\n",
      "[CV 13/37; 3/30] START model__colsample_bytree=0.8540362888980227, model__learning_rate=0.014116898859160489, model__max_depth=4, model__min_child_weight=8, model__n_estimators=591, model__subsample=0.9692763545078751\n",
      "[CV 32/37; 2/30] END model__colsample_bytree=0.7229163764267956, model__learning_rate=0.02999498316360058, model__max_depth=5, model__min_child_weight=8, model__n_estimators=472, model__subsample=0.8005575058716043;, score=-3.241 total time=   4.5s\n",
      "[CV 14/37; 3/30] START model__colsample_bytree=0.8540362888980227, model__learning_rate=0.014116898859160489, model__max_depth=4, model__min_child_weight=8, model__n_estimators=591, model__subsample=0.9692763545078751\n",
      "[CV 33/37; 2/30] END model__colsample_bytree=0.7229163764267956, model__learning_rate=0.02999498316360058, model__max_depth=5, model__min_child_weight=8, model__n_estimators=472, model__subsample=0.8005575058716043;, score=-17.500 total time=   4.6s\n",
      "[CV 15/37; 3/30] START model__colsample_bytree=0.8540362888980227, model__learning_rate=0.014116898859160489, model__max_depth=4, model__min_child_weight=8, model__n_estimators=591, model__subsample=0.9692763545078751\n",
      "[CV 8/37; 3/30] END model__colsample_bytree=0.8540362888980227, model__learning_rate=0.014116898859160489, model__max_depth=4, model__min_child_weight=8, model__n_estimators=591, model__subsample=0.9692763545078751;, score=-7.267 total time=   1.5s\n",
      "[CV 16/37; 3/30] START model__colsample_bytree=0.8540362888980227, model__learning_rate=0.014116898859160489, model__max_depth=4, model__min_child_weight=8, model__n_estimators=591, model__subsample=0.9692763545078751\n",
      "[CV 9/37; 3/30] END model__colsample_bytree=0.8540362888980227, model__learning_rate=0.014116898859160489, model__max_depth=4, model__min_child_weight=8, model__n_estimators=591, model__subsample=0.9692763545078751;, score=-0.845 total time=   1.7s\n",
      "[CV 17/37; 3/30] START model__colsample_bytree=0.8540362888980227, model__learning_rate=0.014116898859160489, model__max_depth=4, model__min_child_weight=8, model__n_estimators=591, model__subsample=0.9692763545078751\n",
      "[CV 34/37; 2/30] END model__colsample_bytree=0.7229163764267956, model__learning_rate=0.02999498316360058, model__max_depth=5, model__min_child_weight=8, model__n_estimators=472, model__subsample=0.8005575058716043;, score=0.160 total time=   4.9s\n",
      "[CV 18/37; 3/30] START model__colsample_bytree=0.8540362888980227, model__learning_rate=0.014116898859160489, model__max_depth=4, model__min_child_weight=8, model__n_estimators=591, model__subsample=0.9692763545078751\n",
      "[CV 10/37; 3/30] END model__colsample_bytree=0.8540362888980227, model__learning_rate=0.014116898859160489, model__max_depth=4, model__min_child_weight=8, model__n_estimators=591, model__subsample=0.9692763545078751;, score=-21.652 total time=   1.8s\n",
      "[CV 19/37; 3/30] START model__colsample_bytree=0.8540362888980227, model__learning_rate=0.014116898859160489, model__max_depth=4, model__min_child_weight=8, model__n_estimators=591, model__subsample=0.9692763545078751\n",
      "[CV 35/37; 2/30] END model__colsample_bytree=0.7229163764267956, model__learning_rate=0.02999498316360058, model__max_depth=5, model__min_child_weight=8, model__n_estimators=472, model__subsample=0.8005575058716043;, score=-18.844 total time=   4.9s\n",
      "[CV 20/37; 3/30] START model__colsample_bytree=0.8540362888980227, model__learning_rate=0.014116898859160489, model__max_depth=4, model__min_child_weight=8, model__n_estimators=591, model__subsample=0.9692763545078751\n",
      "[CV 36/37; 2/30] END model__colsample_bytree=0.7229163764267956, model__learning_rate=0.02999498316360058, model__max_depth=5, model__min_child_weight=8, model__n_estimators=472, model__subsample=0.8005575058716043;, score=-0.946 total time=   5.1s\n",
      "[CV 21/37; 3/30] START model__colsample_bytree=0.8540362888980227, model__learning_rate=0.014116898859160489, model__max_depth=4, model__min_child_weight=8, model__n_estimators=591, model__subsample=0.9692763545078751\n",
      "[CV 11/37; 3/30] END model__colsample_bytree=0.8540362888980227, model__learning_rate=0.014116898859160489, model__max_depth=4, model__min_child_weight=8, model__n_estimators=591, model__subsample=0.9692763545078751;, score=-3.173 total time=   2.0s\n",
      "[CV 22/37; 3/30] START model__colsample_bytree=0.8540362888980227, model__learning_rate=0.014116898859160489, model__max_depth=4, model__min_child_weight=8, model__n_estimators=591, model__subsample=0.9692763545078751\n",
      "[CV 12/37; 3/30] END model__colsample_bytree=0.8540362888980227, model__learning_rate=0.014116898859160489, model__max_depth=4, model__min_child_weight=8, model__n_estimators=591, model__subsample=0.9692763545078751;, score=-14.933 total time=   2.1s\n",
      "[CV 23/37; 3/30] START model__colsample_bytree=0.8540362888980227, model__learning_rate=0.014116898859160489, model__max_depth=4, model__min_child_weight=8, model__n_estimators=591, model__subsample=0.9692763545078751\n",
      "[CV 37/37; 2/30] END model__colsample_bytree=0.7229163764267956, model__learning_rate=0.02999498316360058, model__max_depth=5, model__min_child_weight=8, model__n_estimators=472, model__subsample=0.8005575058716043;, score=0.162 total time=   5.2s\n",
      "[CV 24/37; 3/30] START model__colsample_bytree=0.8540362888980227, model__learning_rate=0.014116898859160489, model__max_depth=4, model__min_child_weight=8, model__n_estimators=591, model__subsample=0.9692763545078751\n",
      "[CV 13/37; 3/30] END model__colsample_bytree=0.8540362888980227, model__learning_rate=0.014116898859160489, model__max_depth=4, model__min_child_weight=8, model__n_estimators=591, model__subsample=0.9692763545078751;, score=0.239 total time=   2.3s\n",
      "[CV 25/37; 3/30] START model__colsample_bytree=0.8540362888980227, model__learning_rate=0.014116898859160489, model__max_depth=4, model__min_child_weight=8, model__n_estimators=591, model__subsample=0.9692763545078751\n",
      "[CV 14/37; 3/30] END model__colsample_bytree=0.8540362888980227, model__learning_rate=0.014116898859160489, model__max_depth=4, model__min_child_weight=8, model__n_estimators=591, model__subsample=0.9692763545078751;, score=-20.305 total time=   2.4s\n",
      "[CV 26/37; 3/30] START model__colsample_bytree=0.8540362888980227, model__learning_rate=0.014116898859160489, model__max_depth=4, model__min_child_weight=8, model__n_estimators=591, model__subsample=0.9692763545078751\n",
      "[CV 15/37; 3/30] END model__colsample_bytree=0.8540362888980227, model__learning_rate=0.014116898859160489, model__max_depth=4, model__min_child_weight=8, model__n_estimators=591, model__subsample=0.9692763545078751;, score=0.095 total time=   2.6s\n",
      "[CV 27/37; 3/30] START model__colsample_bytree=0.8540362888980227, model__learning_rate=0.014116898859160489, model__max_depth=4, model__min_child_weight=8, model__n_estimators=591, model__subsample=0.9692763545078751\n",
      "[CV 16/37; 3/30] END model__colsample_bytree=0.8540362888980227, model__learning_rate=0.014116898859160489, model__max_depth=4, model__min_child_weight=8, model__n_estimators=591, model__subsample=0.9692763545078751;, score=-0.459 total time=   2.8s\n",
      "[CV 28/37; 3/30] START model__colsample_bytree=0.8540362888980227, model__learning_rate=0.014116898859160489, model__max_depth=4, model__min_child_weight=8, model__n_estimators=591, model__subsample=0.9692763545078751\n",
      "[CV 17/37; 3/30] END model__colsample_bytree=0.8540362888980227, model__learning_rate=0.014116898859160489, model__max_depth=4, model__min_child_weight=8, model__n_estimators=591, model__subsample=0.9692763545078751;, score=-18.011 total time=   2.9s\n",
      "[CV 29/37; 3/30] START model__colsample_bytree=0.8540362888980227, model__learning_rate=0.014116898859160489, model__max_depth=4, model__min_child_weight=8, model__n_estimators=591, model__subsample=0.9692763545078751\n",
      "[CV 18/37; 3/30] END model__colsample_bytree=0.8540362888980227, model__learning_rate=0.014116898859160489, model__max_depth=4, model__min_child_weight=8, model__n_estimators=591, model__subsample=0.9692763545078751;, score=-0.129 total time=   3.0s\n",
      "[CV 30/37; 3/30] START model__colsample_bytree=0.8540362888980227, model__learning_rate=0.014116898859160489, model__max_depth=4, model__min_child_weight=8, model__n_estimators=591, model__subsample=0.9692763545078751\n",
      "[CV 19/37; 3/30] END model__colsample_bytree=0.8540362888980227, model__learning_rate=0.014116898859160489, model__max_depth=4, model__min_child_weight=8, model__n_estimators=591, model__subsample=0.9692763545078751;, score=-0.435 total time=   3.3s\n",
      "[CV 31/37; 3/30] START model__colsample_bytree=0.8540362888980227, model__learning_rate=0.014116898859160489, model__max_depth=4, model__min_child_weight=8, model__n_estimators=591, model__subsample=0.9692763545078751\n",
      "[CV 20/37; 3/30] END model__colsample_bytree=0.8540362888980227, model__learning_rate=0.014116898859160489, model__max_depth=4, model__min_child_weight=8, model__n_estimators=591, model__subsample=0.9692763545078751;, score=-6.184 total time=   3.4s\n",
      "[CV 32/37; 3/30] START model__colsample_bytree=0.8540362888980227, model__learning_rate=0.014116898859160489, model__max_depth=4, model__min_child_weight=8, model__n_estimators=591, model__subsample=0.9692763545078751\n",
      "[CV 21/37; 3/30] END model__colsample_bytree=0.8540362888980227, model__learning_rate=0.014116898859160489, model__max_depth=4, model__min_child_weight=8, model__n_estimators=591, model__subsample=0.9692763545078751;, score=-0.961 total time=   3.6s\n",
      "[CV 33/37; 3/30] START model__colsample_bytree=0.8540362888980227, model__learning_rate=0.014116898859160489, model__max_depth=4, model__min_child_weight=8, model__n_estimators=591, model__subsample=0.9692763545078751\n",
      "[CV 22/37; 3/30] END model__colsample_bytree=0.8540362888980227, model__learning_rate=0.014116898859160489, model__max_depth=4, model__min_child_weight=8, model__n_estimators=591, model__subsample=0.9692763545078751;, score=-0.343 total time=   3.7s\n",
      "[CV 34/37; 3/30] START model__colsample_bytree=0.8540362888980227, model__learning_rate=0.014116898859160489, model__max_depth=4, model__min_child_weight=8, model__n_estimators=591, model__subsample=0.9692763545078751\n",
      "[CV 23/37; 3/30] END model__colsample_bytree=0.8540362888980227, model__learning_rate=0.014116898859160489, model__max_depth=4, model__min_child_weight=8, model__n_estimators=591, model__subsample=0.9692763545078751;, score=-12.484 total time=   3.9s\n",
      "[CV 35/37; 3/30] START model__colsample_bytree=0.8540362888980227, model__learning_rate=0.014116898859160489, model__max_depth=4, model__min_child_weight=8, model__n_estimators=591, model__subsample=0.9692763545078751\n",
      "[CV 24/37; 3/30] END model__colsample_bytree=0.8540362888980227, model__learning_rate=0.014116898859160489, model__max_depth=4, model__min_child_weight=8, model__n_estimators=591, model__subsample=0.9692763545078751;, score=-6.553 total time=   4.1s\n",
      "[CV 36/37; 3/30] START model__colsample_bytree=0.8540362888980227, model__learning_rate=0.014116898859160489, model__max_depth=4, model__min_child_weight=8, model__n_estimators=591, model__subsample=0.9692763545078751\n",
      "[CV 25/37; 3/30] END model__colsample_bytree=0.8540362888980227, model__learning_rate=0.014116898859160489, model__max_depth=4, model__min_child_weight=8, model__n_estimators=591, model__subsample=0.9692763545078751;, score=-0.767 total time=   4.3s\n",
      "[CV 37/37; 3/30] START model__colsample_bytree=0.8540362888980227, model__learning_rate=0.014116898859160489, model__max_depth=4, model__min_child_weight=8, model__n_estimators=591, model__subsample=0.9692763545078751\n",
      "[CV 26/37; 3/30] END model__colsample_bytree=0.8540362888980227, model__learning_rate=0.014116898859160489, model__max_depth=4, model__min_child_weight=8, model__n_estimators=591, model__subsample=0.9692763545078751;, score=-0.739 total time=   4.5s\n",
      "[CV 1/37; 4/30] START model__colsample_bytree=0.5003893829205072, model__learning_rate=0.20844231185824352, model__max_depth=3, model__min_child_weight=6, model__n_estimators=352, model__subsample=0.7159725093210578\n",
      "[CV 1/37; 4/30] END model__colsample_bytree=0.5003893829205072, model__learning_rate=0.20844231185824352, model__max_depth=3, model__min_child_weight=6, model__n_estimators=352, model__subsample=0.7159725093210578;, score=-46.751 total time=   0.2s\n",
      "[CV 2/37; 4/30] START model__colsample_bytree=0.5003893829205072, model__learning_rate=0.20844231185824352, model__max_depth=3, model__min_child_weight=6, model__n_estimators=352, model__subsample=0.7159725093210578\n",
      "[CV 2/37; 4/30] END model__colsample_bytree=0.5003893829205072, model__learning_rate=0.20844231185824352, model__max_depth=3, model__min_child_weight=6, model__n_estimators=352, model__subsample=0.7159725093210578;, score=-1.159 total time=   0.2s\n",
      "[CV 3/37; 4/30] START model__colsample_bytree=0.5003893829205072, model__learning_rate=0.20844231185824352, model__max_depth=3, model__min_child_weight=6, model__n_estimators=352, model__subsample=0.7159725093210578\n",
      "[CV 27/37; 3/30] END model__colsample_bytree=0.8540362888980227, model__learning_rate=0.014116898859160489, model__max_depth=4, model__min_child_weight=8, model__n_estimators=591, model__subsample=0.9692763545078751;, score=-1.810 total time=   4.6s\n",
      "[CV 4/37; 4/30] START model__colsample_bytree=0.5003893829205072, model__learning_rate=0.20844231185824352, model__max_depth=3, model__min_child_weight=6, model__n_estimators=352, model__subsample=0.7159725093210578\n",
      "[CV 3/37; 4/30] END model__colsample_bytree=0.5003893829205072, model__learning_rate=0.20844231185824352, model__max_depth=3, model__min_child_weight=6, model__n_estimators=352, model__subsample=0.7159725093210578;, score=-25.896 total time=   0.2s\n",
      "[CV 5/37; 4/30] START model__colsample_bytree=0.5003893829205072, model__learning_rate=0.20844231185824352, model__max_depth=3, model__min_child_weight=6, model__n_estimators=352, model__subsample=0.7159725093210578\n",
      "[CV 4/37; 4/30] END model__colsample_bytree=0.5003893829205072, model__learning_rate=0.20844231185824352, model__max_depth=3, model__min_child_weight=6, model__n_estimators=352, model__subsample=0.7159725093210578;, score=-6.958 total time=   0.3s\n",
      "[CV 6/37; 4/30] START model__colsample_bytree=0.5003893829205072, model__learning_rate=0.20844231185824352, model__max_depth=3, model__min_child_weight=6, model__n_estimators=352, model__subsample=0.7159725093210578\n",
      "[CV 5/37; 4/30] END model__colsample_bytree=0.5003893829205072, model__learning_rate=0.20844231185824352, model__max_depth=3, model__min_child_weight=6, model__n_estimators=352, model__subsample=0.7159725093210578;, score=-34.621 total time=   0.3s\n",
      "[CV 7/37; 4/30] START model__colsample_bytree=0.5003893829205072, model__learning_rate=0.20844231185824352, model__max_depth=3, model__min_child_weight=6, model__n_estimators=352, model__subsample=0.7159725093210578\n",
      "[CV 28/37; 3/30] END model__colsample_bytree=0.8540362888980227, model__learning_rate=0.014116898859160489, model__max_depth=4, model__min_child_weight=8, model__n_estimators=591, model__subsample=0.9692763545078751;, score=-0.813 total time=   4.9s\n",
      "[CV 6/37; 4/30] END model__colsample_bytree=0.5003893829205072, model__learning_rate=0.20844231185824352, model__max_depth=3, model__min_child_weight=6, model__n_estimators=352, model__subsample=0.7159725093210578;, score=-3.160 total time=   0.4s\n",
      "[CV 9/37; 4/30] START model__colsample_bytree=0.5003893829205072, model__learning_rate=0.20844231185824352, model__max_depth=3, model__min_child_weight=6, model__n_estimators=352, model__subsample=0.7159725093210578\n",
      "[CV 8/37; 4/30] START model__colsample_bytree=0.5003893829205072, model__learning_rate=0.20844231185824352, model__max_depth=3, model__min_child_weight=6, model__n_estimators=352, model__subsample=0.7159725093210578\n",
      "[CV 7/37; 4/30] END model__colsample_bytree=0.5003893829205072, model__learning_rate=0.20844231185824352, model__max_depth=3, model__min_child_weight=6, model__n_estimators=352, model__subsample=0.7159725093210578;, score=-6.195 total time=   0.4s\n",
      "[CV 10/37; 4/30] START model__colsample_bytree=0.5003893829205072, model__learning_rate=0.20844231185824352, model__max_depth=3, model__min_child_weight=6, model__n_estimators=352, model__subsample=0.7159725093210578\n",
      "[CV 29/37; 3/30] END model__colsample_bytree=0.8540362888980227, model__learning_rate=0.014116898859160489, model__max_depth=4, model__min_child_weight=8, model__n_estimators=591, model__subsample=0.9692763545078751;, score=-7.667 total time=   5.0s\n",
      "[CV 11/37; 4/30] START model__colsample_bytree=0.5003893829205072, model__learning_rate=0.20844231185824352, model__max_depth=3, model__min_child_weight=6, model__n_estimators=352, model__subsample=0.7159725093210578\n",
      "[CV 8/37; 4/30] END model__colsample_bytree=0.5003893829205072, model__learning_rate=0.20844231185824352, model__max_depth=3, model__min_child_weight=6, model__n_estimators=352, model__subsample=0.7159725093210578;, score=-9.337 total time=   0.5s\n",
      "[CV 12/37; 4/30] START model__colsample_bytree=0.5003893829205072, model__learning_rate=0.20844231185824352, model__max_depth=3, model__min_child_weight=6, model__n_estimators=352, model__subsample=0.7159725093210578\n",
      "[CV 9/37; 4/30] END model__colsample_bytree=0.5003893829205072, model__learning_rate=0.20844231185824352, model__max_depth=3, model__min_child_weight=6, model__n_estimators=352, model__subsample=0.7159725093210578;, score=-0.985 total time=   0.5s\n",
      "[CV 13/37; 4/30] START model__colsample_bytree=0.5003893829205072, model__learning_rate=0.20844231185824352, model__max_depth=3, model__min_child_weight=6, model__n_estimators=352, model__subsample=0.7159725093210578\n",
      "[CV 30/37; 3/30] END model__colsample_bytree=0.8540362888980227, model__learning_rate=0.014116898859160489, model__max_depth=4, model__min_child_weight=8, model__n_estimators=591, model__subsample=0.9692763545078751;, score=-0.258 total time=   5.0s\n",
      "[CV 14/37; 4/30] START model__colsample_bytree=0.5003893829205072, model__learning_rate=0.20844231185824352, model__max_depth=3, model__min_child_weight=6, model__n_estimators=352, model__subsample=0.7159725093210578\n",
      "[CV 10/37; 4/30] END model__colsample_bytree=0.5003893829205072, model__learning_rate=0.20844231185824352, model__max_depth=3, model__min_child_weight=6, model__n_estimators=352, model__subsample=0.7159725093210578;, score=-33.435 total time=   0.6s\n",
      "[CV 15/37; 4/30] START model__colsample_bytree=0.5003893829205072, model__learning_rate=0.20844231185824352, model__max_depth=3, model__min_child_weight=6, model__n_estimators=352, model__subsample=0.7159725093210578\n",
      "[CV 11/37; 4/30] END model__colsample_bytree=0.5003893829205072, model__learning_rate=0.20844231185824352, model__max_depth=3, model__min_child_weight=6, model__n_estimators=352, model__subsample=0.7159725093210578;, score=-4.097 total time=   0.6s\n",
      "[CV 16/37; 4/30] START model__colsample_bytree=0.5003893829205072, model__learning_rate=0.20844231185824352, model__max_depth=3, model__min_child_weight=6, model__n_estimators=352, model__subsample=0.7159725093210578\n",
      "[CV 12/37; 4/30] END model__colsample_bytree=0.5003893829205072, model__learning_rate=0.20844231185824352, model__max_depth=3, model__min_child_weight=6, model__n_estimators=352, model__subsample=0.7159725093210578;, score=-16.405 total time=   0.7s\n",
      "[CV 17/37; 4/30] START model__colsample_bytree=0.5003893829205072, model__learning_rate=0.20844231185824352, model__max_depth=3, model__min_child_weight=6, model__n_estimators=352, model__subsample=0.7159725093210578\n",
      "[CV 13/37; 4/30] END model__colsample_bytree=0.5003893829205072, model__learning_rate=0.20844231185824352, model__max_depth=3, model__min_child_weight=6, model__n_estimators=352, model__subsample=0.7159725093210578;, score=0.116 total time=   0.7s\n",
      "[CV 18/37; 4/30] START model__colsample_bytree=0.5003893829205072, model__learning_rate=0.20844231185824352, model__max_depth=3, model__min_child_weight=6, model__n_estimators=352, model__subsample=0.7159725093210578\n",
      "[CV 14/37; 4/30] END model__colsample_bytree=0.5003893829205072, model__learning_rate=0.20844231185824352, model__max_depth=3, model__min_child_weight=6, model__n_estimators=352, model__subsample=0.7159725093210578;, score=-20.631 total time=   0.7s\n",
      "[CV 19/37; 4/30] START model__colsample_bytree=0.5003893829205072, model__learning_rate=0.20844231185824352, model__max_depth=3, model__min_child_weight=6, model__n_estimators=352, model__subsample=0.7159725093210578\n",
      "[CV 31/37; 3/30] END model__colsample_bytree=0.8540362888980227, model__learning_rate=0.014116898859160489, model__max_depth=4, model__min_child_weight=8, model__n_estimators=591, model__subsample=0.9692763545078751;, score=0.399 total time=   5.2s\n",
      "[CV 20/37; 4/30] START model__colsample_bytree=0.5003893829205072, model__learning_rate=0.20844231185824352, model__max_depth=3, model__min_child_weight=6, model__n_estimators=352, model__subsample=0.7159725093210578\n",
      "[CV 15/37; 4/30] END model__colsample_bytree=0.5003893829205072, model__learning_rate=0.20844231185824352, model__max_depth=3, model__min_child_weight=6, model__n_estimators=352, model__subsample=0.7159725093210578;, score=-0.176 total time=   0.8s\n",
      "[CV 21/37; 4/30] START model__colsample_bytree=0.5003893829205072, model__learning_rate=0.20844231185824352, model__max_depth=3, model__min_child_weight=6, model__n_estimators=352, model__subsample=0.7159725093210578\n",
      "[CV 32/37; 3/30] END model__colsample_bytree=0.8540362888980227, model__learning_rate=0.014116898859160489, model__max_depth=4, model__min_child_weight=8, model__n_estimators=591, model__subsample=0.9692763545078751;, score=-3.189 total time=   5.4s\n",
      "[CV 22/37; 4/30] START model__colsample_bytree=0.5003893829205072, model__learning_rate=0.20844231185824352, model__max_depth=3, model__min_child_weight=6, model__n_estimators=352, model__subsample=0.7159725093210578\n",
      "[CV 16/37; 4/30] END model__colsample_bytree=0.5003893829205072, model__learning_rate=0.20844231185824352, model__max_depth=3, model__min_child_weight=6, model__n_estimators=352, model__subsample=0.7159725093210578;, score=-0.864 total time=   0.9s\n",
      "[CV 23/37; 4/30] START model__colsample_bytree=0.5003893829205072, model__learning_rate=0.20844231185824352, model__max_depth=3, model__min_child_weight=6, model__n_estimators=352, model__subsample=0.7159725093210578\n",
      "[CV 17/37; 4/30] END model__colsample_bytree=0.5003893829205072, model__learning_rate=0.20844231185824352, model__max_depth=3, model__min_child_weight=6, model__n_estimators=352, model__subsample=0.7159725093210578;, score=-18.941 total time=   0.9s\n",
      "[CV 24/37; 4/30] START model__colsample_bytree=0.5003893829205072, model__learning_rate=0.20844231185824352, model__max_depth=3, model__min_child_weight=6, model__n_estimators=352, model__subsample=0.7159725093210578\n",
      "[CV 18/37; 4/30] END model__colsample_bytree=0.5003893829205072, model__learning_rate=0.20844231185824352, model__max_depth=3, model__min_child_weight=6, model__n_estimators=352, model__subsample=0.7159725093210578;, score=-0.498 total time=   1.0s\n",
      "[CV 25/37; 4/30] START model__colsample_bytree=0.5003893829205072, model__learning_rate=0.20844231185824352, model__max_depth=3, model__min_child_weight=6, model__n_estimators=352, model__subsample=0.7159725093210578\n",
      "[CV 19/37; 4/30] END model__colsample_bytree=0.5003893829205072, model__learning_rate=0.20844231185824352, model__max_depth=3, model__min_child_weight=6, model__n_estimators=352, model__subsample=0.7159725093210578;, score=-0.920 total time=   1.0s\n",
      "[CV 26/37; 4/30] START model__colsample_bytree=0.5003893829205072, model__learning_rate=0.20844231185824352, model__max_depth=3, model__min_child_weight=6, model__n_estimators=352, model__subsample=0.7159725093210578\n",
      "[CV 20/37; 4/30] END model__colsample_bytree=0.5003893829205072, model__learning_rate=0.20844231185824352, model__max_depth=3, model__min_child_weight=6, model__n_estimators=352, model__subsample=0.7159725093210578;, score=-3.793 total time=   1.1s\n",
      "[CV 33/37; 3/30] END model__colsample_bytree=0.8540362888980227, model__learning_rate=0.014116898859160489, model__max_depth=4, model__min_child_weight=8, model__n_estimators=591, model__subsample=0.9692763545078751;, score=-14.819 total time=   5.5s\n",
      "[CV 27/37; 4/30] START model__colsample_bytree=0.5003893829205072, model__learning_rate=0.20844231185824352, model__max_depth=3, model__min_child_weight=6, model__n_estimators=352, model__subsample=0.7159725093210578\n",
      "[CV 28/37; 4/30] START model__colsample_bytree=0.5003893829205072, model__learning_rate=0.20844231185824352, model__max_depth=3, model__min_child_weight=6, model__n_estimators=352, model__subsample=0.7159725093210578\n",
      "[CV 21/37; 4/30] END model__colsample_bytree=0.5003893829205072, model__learning_rate=0.20844231185824352, model__max_depth=3, model__min_child_weight=6, model__n_estimators=352, model__subsample=0.7159725093210578;, score=-2.453 total time=   1.2s\n",
      "[CV 29/37; 4/30] START model__colsample_bytree=0.5003893829205072, model__learning_rate=0.20844231185824352, model__max_depth=3, model__min_child_weight=6, model__n_estimators=352, model__subsample=0.7159725093210578\n",
      "[CV 34/37; 3/30] END model__colsample_bytree=0.8540362888980227, model__learning_rate=0.014116898859160489, model__max_depth=4, model__min_child_weight=8, model__n_estimators=591, model__subsample=0.9692763545078751;, score=-0.142 total time=   5.7s\n",
      "[CV 30/37; 4/30] START model__colsample_bytree=0.5003893829205072, model__learning_rate=0.20844231185824352, model__max_depth=3, model__min_child_weight=6, model__n_estimators=352, model__subsample=0.7159725093210578\n",
      "[CV 22/37; 4/30] END model__colsample_bytree=0.5003893829205072, model__learning_rate=0.20844231185824352, model__max_depth=3, model__min_child_weight=6, model__n_estimators=352, model__subsample=0.7159725093210578;, score=-0.484 total time=   1.1s\n",
      "[CV 31/37; 4/30] START model__colsample_bytree=0.5003893829205072, model__learning_rate=0.20844231185824352, model__max_depth=3, model__min_child_weight=6, model__n_estimators=352, model__subsample=0.7159725093210578\n",
      "[CV 23/37; 4/30] END model__colsample_bytree=0.5003893829205072, model__learning_rate=0.20844231185824352, model__max_depth=3, model__min_child_weight=6, model__n_estimators=352, model__subsample=0.7159725093210578;, score=-12.714 total time=   1.2s\n",
      "[CV 32/37; 4/30] START model__colsample_bytree=0.5003893829205072, model__learning_rate=0.20844231185824352, model__max_depth=3, model__min_child_weight=6, model__n_estimators=352, model__subsample=0.7159725093210578\n",
      "[CV 24/37; 4/30] END model__colsample_bytree=0.5003893829205072, model__learning_rate=0.20844231185824352, model__max_depth=3, model__min_child_weight=6, model__n_estimators=352, model__subsample=0.7159725093210578;, score=-6.655 total time=   1.2s\n",
      "[CV 33/37; 4/30] START model__colsample_bytree=0.5003893829205072, model__learning_rate=0.20844231185824352, model__max_depth=3, model__min_child_weight=6, model__n_estimators=352, model__subsample=0.7159725093210578\n",
      "[CV 25/37; 4/30] END model__colsample_bytree=0.5003893829205072, model__learning_rate=0.20844231185824352, model__max_depth=3, model__min_child_weight=6, model__n_estimators=352, model__subsample=0.7159725093210578;, score=-1.545 total time=   1.3s\n",
      "[CV 34/37; 4/30] START model__colsample_bytree=0.5003893829205072, model__learning_rate=0.20844231185824352, model__max_depth=3, model__min_child_weight=6, model__n_estimators=352, model__subsample=0.7159725093210578\n",
      "[CV 35/37; 3/30] END model__colsample_bytree=0.8540362888980227, model__learning_rate=0.014116898859160489, model__max_depth=4, model__min_child_weight=8, model__n_estimators=591, model__subsample=0.9692763545078751;, score=-15.771 total time=   6.0s\n",
      "[CV 26/37; 4/30] END model__colsample_bytree=0.5003893829205072, model__learning_rate=0.20844231185824352, model__max_depth=3, model__min_child_weight=6, model__n_estimators=352, model__subsample=0.7159725093210578;, score=-2.668 total time=   1.3s\n",
      "[CV 35/37; 4/30] START model__colsample_bytree=0.5003893829205072, model__learning_rate=0.20844231185824352, model__max_depth=3, model__min_child_weight=6, model__n_estimators=352, model__subsample=0.7159725093210578\n",
      "[CV 36/37; 4/30] START model__colsample_bytree=0.5003893829205072, model__learning_rate=0.20844231185824352, model__max_depth=3, model__min_child_weight=6, model__n_estimators=352, model__subsample=0.7159725093210578\n",
      "[CV 27/37; 4/30] END model__colsample_bytree=0.5003893829205072, model__learning_rate=0.20844231185824352, model__max_depth=3, model__min_child_weight=6, model__n_estimators=352, model__subsample=0.7159725093210578;, score=-3.801 total time=   1.4s\n",
      "[CV 37/37; 4/30] START model__colsample_bytree=0.5003893829205072, model__learning_rate=0.20844231185824352, model__max_depth=3, model__min_child_weight=6, model__n_estimators=352, model__subsample=0.7159725093210578\n",
      "[CV 28/37; 4/30] END model__colsample_bytree=0.5003893829205072, model__learning_rate=0.20844231185824352, model__max_depth=3, model__min_child_weight=6, model__n_estimators=352, model__subsample=0.7159725093210578;, score=-1.898 total time=   1.4s\n",
      "[CV 1/37; 5/30] START model__colsample_bytree=0.645614570099021, model__learning_rate=0.1323705789444759, model__max_depth=4, model__min_child_weight=3, model__n_estimators=975, model__subsample=0.7571172192068059\n",
      "[CV 36/37; 3/30] END model__colsample_bytree=0.8540362888980227, model__learning_rate=0.014116898859160489, model__max_depth=4, model__min_child_weight=8, model__n_estimators=591, model__subsample=0.9692763545078751;, score=-1.104 total time=   6.0s\n",
      "[CV 2/37; 5/30] START model__colsample_bytree=0.645614570099021, model__learning_rate=0.1323705789444759, model__max_depth=4, model__min_child_weight=3, model__n_estimators=975, model__subsample=0.7571172192068059\n",
      "[CV 29/37; 4/30] END model__colsample_bytree=0.5003893829205072, model__learning_rate=0.20844231185824352, model__max_depth=3, model__min_child_weight=6, model__n_estimators=352, model__subsample=0.7159725093210578;, score=-12.917 total time=   1.5s\n",
      "[CV 3/37; 5/30] START model__colsample_bytree=0.645614570099021, model__learning_rate=0.1323705789444759, model__max_depth=4, model__min_child_weight=3, model__n_estimators=975, model__subsample=0.7571172192068059\n",
      "[CV 1/37; 5/30] END model__colsample_bytree=0.645614570099021, model__learning_rate=0.1323705789444759, model__max_depth=4, model__min_child_weight=3, model__n_estimators=975, model__subsample=0.7571172192068059;, score=-39.828 total time=   0.3s\n",
      "[CV 4/37; 5/30] START model__colsample_bytree=0.645614570099021, model__learning_rate=0.1323705789444759, model__max_depth=4, model__min_child_weight=3, model__n_estimators=975, model__subsample=0.7571172192068059\n",
      "[CV 30/37; 4/30] END model__colsample_bytree=0.5003893829205072, model__learning_rate=0.20844231185824352, model__max_depth=3, model__min_child_weight=6, model__n_estimators=352, model__subsample=0.7159725093210578;, score=-0.339 total time=   1.5s\n",
      "[CV 5/37; 5/30] START model__colsample_bytree=0.645614570099021, model__learning_rate=0.1323705789444759, model__max_depth=4, model__min_child_weight=3, model__n_estimators=975, model__subsample=0.7571172192068059\n",
      "[CV 37/37; 3/30] END model__colsample_bytree=0.8540362888980227, model__learning_rate=0.014116898859160489, model__max_depth=4, model__min_child_weight=8, model__n_estimators=591, model__subsample=0.9692763545078751;, score=0.263 total time=   6.2s\n",
      "[CV 31/37; 4/30] END model__colsample_bytree=0.5003893829205072, model__learning_rate=0.20844231185824352, model__max_depth=3, model__min_child_weight=6, model__n_estimators=352, model__subsample=0.7159725093210578;, score=0.182 total time=   1.6s\n",
      "[CV 6/37; 5/30] START model__colsample_bytree=0.645614570099021, model__learning_rate=0.1323705789444759, model__max_depth=4, model__min_child_weight=3, model__n_estimators=975, model__subsample=0.7571172192068059\n",
      "[CV 7/37; 5/30] START model__colsample_bytree=0.645614570099021, model__learning_rate=0.1323705789444759, model__max_depth=4, model__min_child_weight=3, model__n_estimators=975, model__subsample=0.7571172192068059\n",
      "[CV 32/37; 4/30] END model__colsample_bytree=0.5003893829205072, model__learning_rate=0.20844231185824352, model__max_depth=3, model__min_child_weight=6, model__n_estimators=352, model__subsample=0.7159725093210578;, score=-3.067 total time=   1.5s\n",
      "[CV 2/37; 5/30] END model__colsample_bytree=0.645614570099021, model__learning_rate=0.1323705789444759, model__max_depth=4, model__min_child_weight=3, model__n_estimators=975, model__subsample=0.7571172192068059;, score=-0.744 total time=   0.4s\n",
      "[CV 9/37; 5/30] START model__colsample_bytree=0.645614570099021, model__learning_rate=0.1323705789444759, model__max_depth=4, model__min_child_weight=3, model__n_estimators=975, model__subsample=0.7571172192068059\n",
      "[CV 8/37; 5/30] START model__colsample_bytree=0.645614570099021, model__learning_rate=0.1323705789444759, model__max_depth=4, model__min_child_weight=3, model__n_estimators=975, model__subsample=0.7571172192068059\n",
      "[CV 33/37; 4/30] END model__colsample_bytree=0.5003893829205072, model__learning_rate=0.20844231185824352, model__max_depth=3, model__min_child_weight=6, model__n_estimators=352, model__subsample=0.7159725093210578;, score=-16.472 total time=   1.6s\n",
      "[CV 10/37; 5/30] START model__colsample_bytree=0.645614570099021, model__learning_rate=0.1323705789444759, model__max_depth=4, model__min_child_weight=3, model__n_estimators=975, model__subsample=0.7571172192068059\n",
      "[CV 3/37; 5/30] END model__colsample_bytree=0.645614570099021, model__learning_rate=0.1323705789444759, model__max_depth=4, model__min_child_weight=3, model__n_estimators=975, model__subsample=0.7571172192068059;, score=-20.788 total time=   0.7s\n",
      "[CV 11/37; 5/30] START model__colsample_bytree=0.645614570099021, model__learning_rate=0.1323705789444759, model__max_depth=4, model__min_child_weight=3, model__n_estimators=975, model__subsample=0.7571172192068059\n",
      "[CV 34/37; 4/30] END model__colsample_bytree=0.5003893829205072, model__learning_rate=0.20844231185824352, model__max_depth=3, model__min_child_weight=6, model__n_estimators=352, model__subsample=0.7159725093210578;, score=0.253 total time=   1.7s\n",
      "[CV 12/37; 5/30] START model__colsample_bytree=0.645614570099021, model__learning_rate=0.1323705789444759, model__max_depth=4, model__min_child_weight=3, model__n_estimators=975, model__subsample=0.7571172192068059\n",
      "[CV 4/37; 5/30] END model__colsample_bytree=0.645614570099021, model__learning_rate=0.1323705789444759, model__max_depth=4, model__min_child_weight=3, model__n_estimators=975, model__subsample=0.7571172192068059;, score=-6.899 total time=   0.9s\n",
      "[CV 13/37; 5/30] START model__colsample_bytree=0.645614570099021, model__learning_rate=0.1323705789444759, model__max_depth=4, model__min_child_weight=3, model__n_estimators=975, model__subsample=0.7571172192068059\n",
      "[CV 35/37; 4/30] END model__colsample_bytree=0.5003893829205072, model__learning_rate=0.20844231185824352, model__max_depth=3, model__min_child_weight=6, model__n_estimators=352, model__subsample=0.7159725093210578;, score=-18.830 total time=   1.7s\n",
      "[CV 14/37; 5/30] START model__colsample_bytree=0.645614570099021, model__learning_rate=0.1323705789444759, model__max_depth=4, model__min_child_weight=3, model__n_estimators=975, model__subsample=0.7571172192068059\n",
      "[CV 36/37; 4/30] END model__colsample_bytree=0.5003893829205072, model__learning_rate=0.20844231185824352, model__max_depth=3, model__min_child_weight=6, model__n_estimators=352, model__subsample=0.7159725093210578;, score=-1.235 total time=   1.7s\n",
      "[CV 15/37; 5/30] START model__colsample_bytree=0.645614570099021, model__learning_rate=0.1323705789444759, model__max_depth=4, model__min_child_weight=3, model__n_estimators=975, model__subsample=0.7571172192068059\n",
      "[CV 5/37; 5/30] END model__colsample_bytree=0.645614570099021, model__learning_rate=0.1323705789444759, model__max_depth=4, model__min_child_weight=3, model__n_estimators=975, model__subsample=0.7571172192068059;, score=-38.440 total time=   1.2s\n",
      "[CV 16/37; 5/30] START model__colsample_bytree=0.645614570099021, model__learning_rate=0.1323705789444759, model__max_depth=4, model__min_child_weight=3, model__n_estimators=975, model__subsample=0.7571172192068059\n",
      "[CV 37/37; 4/30] END model__colsample_bytree=0.5003893829205072, model__learning_rate=0.20844231185824352, model__max_depth=3, model__min_child_weight=6, model__n_estimators=352, model__subsample=0.7159725093210578;, score=0.116 total time=   1.7s\n",
      "[CV 17/37; 5/30] START model__colsample_bytree=0.645614570099021, model__learning_rate=0.1323705789444759, model__max_depth=4, model__min_child_weight=3, model__n_estimators=975, model__subsample=0.7571172192068059\n",
      "[CV 6/37; 5/30] END model__colsample_bytree=0.645614570099021, model__learning_rate=0.1323705789444759, model__max_depth=4, model__min_child_weight=3, model__n_estimators=975, model__subsample=0.7571172192068059;, score=-1.710 total time=   1.6s\n",
      "[CV 18/37; 5/30] START model__colsample_bytree=0.645614570099021, model__learning_rate=0.1323705789444759, model__max_depth=4, model__min_child_weight=3, model__n_estimators=975, model__subsample=0.7571172192068059\n",
      "[CV 7/37; 5/30] END model__colsample_bytree=0.645614570099021, model__learning_rate=0.1323705789444759, model__max_depth=4, model__min_child_weight=3, model__n_estimators=975, model__subsample=0.7571172192068059;, score=-6.525 total time=   1.9s\n",
      "[CV 19/37; 5/30] START model__colsample_bytree=0.645614570099021, model__learning_rate=0.1323705789444759, model__max_depth=4, model__min_child_weight=3, model__n_estimators=975, model__subsample=0.7571172192068059\n",
      "[CV 8/37; 5/30] END model__colsample_bytree=0.645614570099021, model__learning_rate=0.1323705789444759, model__max_depth=4, model__min_child_weight=3, model__n_estimators=975, model__subsample=0.7571172192068059;, score=-9.346 total time=   2.1s\n",
      "[CV 20/37; 5/30] START model__colsample_bytree=0.645614570099021, model__learning_rate=0.1323705789444759, model__max_depth=4, model__min_child_weight=3, model__n_estimators=975, model__subsample=0.7571172192068059\n",
      "[CV 9/37; 5/30] END model__colsample_bytree=0.645614570099021, model__learning_rate=0.1323705789444759, model__max_depth=4, model__min_child_weight=3, model__n_estimators=975, model__subsample=0.7571172192068059;, score=-0.842 total time=   2.3s\n",
      "[CV 21/37; 5/30] START model__colsample_bytree=0.645614570099021, model__learning_rate=0.1323705789444759, model__max_depth=4, model__min_child_weight=3, model__n_estimators=975, model__subsample=0.7571172192068059\n",
      "[CV 10/37; 5/30] END model__colsample_bytree=0.645614570099021, model__learning_rate=0.1323705789444759, model__max_depth=4, model__min_child_weight=3, model__n_estimators=975, model__subsample=0.7571172192068059;, score=-29.455 total time=   2.5s\n",
      "[CV 22/37; 5/30] START model__colsample_bytree=0.645614570099021, model__learning_rate=0.1323705789444759, model__max_depth=4, model__min_child_weight=3, model__n_estimators=975, model__subsample=0.7571172192068059\n",
      "[CV 11/37; 5/30] END model__colsample_bytree=0.645614570099021, model__learning_rate=0.1323705789444759, model__max_depth=4, model__min_child_weight=3, model__n_estimators=975, model__subsample=0.7571172192068059;, score=-4.071 total time=   2.7s\n",
      "[CV 23/37; 5/30] START model__colsample_bytree=0.645614570099021, model__learning_rate=0.1323705789444759, model__max_depth=4, model__min_child_weight=3, model__n_estimators=975, model__subsample=0.7571172192068059\n",
      "[CV 12/37; 5/30] END model__colsample_bytree=0.645614570099021, model__learning_rate=0.1323705789444759, model__max_depth=4, model__min_child_weight=3, model__n_estimators=975, model__subsample=0.7571172192068059;, score=-18.927 total time=   2.9s\n",
      "[CV 24/37; 5/30] START model__colsample_bytree=0.645614570099021, model__learning_rate=0.1323705789444759, model__max_depth=4, model__min_child_weight=3, model__n_estimators=975, model__subsample=0.7571172192068059\n",
      "[CV 13/37; 5/30] END model__colsample_bytree=0.645614570099021, model__learning_rate=0.1323705789444759, model__max_depth=4, model__min_child_weight=3, model__n_estimators=975, model__subsample=0.7571172192068059;, score=0.109 total time=   3.1s\n",
      "[CV 25/37; 5/30] START model__colsample_bytree=0.645614570099021, model__learning_rate=0.1323705789444759, model__max_depth=4, model__min_child_weight=3, model__n_estimators=975, model__subsample=0.7571172192068059\n",
      "[CV 14/37; 5/30] END model__colsample_bytree=0.645614570099021, model__learning_rate=0.1323705789444759, model__max_depth=4, model__min_child_weight=3, model__n_estimators=975, model__subsample=0.7571172192068059;, score=-22.257 total time=   3.4s\n",
      "[CV 26/37; 5/30] START model__colsample_bytree=0.645614570099021, model__learning_rate=0.1323705789444759, model__max_depth=4, model__min_child_weight=3, model__n_estimators=975, model__subsample=0.7571172192068059\n",
      "[CV 15/37; 5/30] END model__colsample_bytree=0.645614570099021, model__learning_rate=0.1323705789444759, model__max_depth=4, model__min_child_weight=3, model__n_estimators=975, model__subsample=0.7571172192068059;, score=-0.285 total time=   3.6s\n",
      "[CV 27/37; 5/30] START model__colsample_bytree=0.645614570099021, model__learning_rate=0.1323705789444759, model__max_depth=4, model__min_child_weight=3, model__n_estimators=975, model__subsample=0.7571172192068059\n",
      "[CV 16/37; 5/30] END model__colsample_bytree=0.645614570099021, model__learning_rate=0.1323705789444759, model__max_depth=4, model__min_child_weight=3, model__n_estimators=975, model__subsample=0.7571172192068059;, score=-0.878 total time=   3.8s\n",
      "[CV 28/37; 5/30] START model__colsample_bytree=0.645614570099021, model__learning_rate=0.1323705789444759, model__max_depth=4, model__min_child_weight=3, model__n_estimators=975, model__subsample=0.7571172192068059\n",
      "[CV 17/37; 5/30] END model__colsample_bytree=0.645614570099021, model__learning_rate=0.1323705789444759, model__max_depth=4, model__min_child_weight=3, model__n_estimators=975, model__subsample=0.7571172192068059;, score=-19.394 total time=   3.9s\n",
      "[CV 29/37; 5/30] START model__colsample_bytree=0.645614570099021, model__learning_rate=0.1323705789444759, model__max_depth=4, model__min_child_weight=3, model__n_estimators=975, model__subsample=0.7571172192068059\n",
      "[CV 18/37; 5/30] END model__colsample_bytree=0.645614570099021, model__learning_rate=0.1323705789444759, model__max_depth=4, model__min_child_weight=3, model__n_estimators=975, model__subsample=0.7571172192068059;, score=-1.965 total time=   4.2s\n",
      "[CV 30/37; 5/30] START model__colsample_bytree=0.645614570099021, model__learning_rate=0.1323705789444759, model__max_depth=4, model__min_child_weight=3, model__n_estimators=975, model__subsample=0.7571172192068059\n",
      "[CV 19/37; 5/30] END model__colsample_bytree=0.645614570099021, model__learning_rate=0.1323705789444759, model__max_depth=4, model__min_child_weight=3, model__n_estimators=975, model__subsample=0.7571172192068059;, score=-1.223 total time=   4.4s\n",
      "[CV 31/37; 5/30] START model__colsample_bytree=0.645614570099021, model__learning_rate=0.1323705789444759, model__max_depth=4, model__min_child_weight=3, model__n_estimators=975, model__subsample=0.7571172192068059\n",
      "[CV 20/37; 5/30] END model__colsample_bytree=0.645614570099021, model__learning_rate=0.1323705789444759, model__max_depth=4, model__min_child_weight=3, model__n_estimators=975, model__subsample=0.7571172192068059;, score=-4.964 total time=   4.5s\n",
      "[CV 32/37; 5/30] START model__colsample_bytree=0.645614570099021, model__learning_rate=0.1323705789444759, model__max_depth=4, model__min_child_weight=3, model__n_estimators=975, model__subsample=0.7571172192068059\n",
      "[CV 21/37; 5/30] END model__colsample_bytree=0.645614570099021, model__learning_rate=0.1323705789444759, model__max_depth=4, model__min_child_weight=3, model__n_estimators=975, model__subsample=0.7571172192068059;, score=-1.654 total time=   4.7s\n",
      "[CV 33/37; 5/30] START model__colsample_bytree=0.645614570099021, model__learning_rate=0.1323705789444759, model__max_depth=4, model__min_child_weight=3, model__n_estimators=975, model__subsample=0.7571172192068059\n",
      "[CV 22/37; 5/30] END model__colsample_bytree=0.645614570099021, model__learning_rate=0.1323705789444759, model__max_depth=4, model__min_child_weight=3, model__n_estimators=975, model__subsample=0.7571172192068059;, score=-0.630 total time=   5.0s\n",
      "[CV 34/37; 5/30] START model__colsample_bytree=0.645614570099021, model__learning_rate=0.1323705789444759, model__max_depth=4, model__min_child_weight=3, model__n_estimators=975, model__subsample=0.7571172192068059\n",
      "[CV 23/37; 5/30] END model__colsample_bytree=0.645614570099021, model__learning_rate=0.1323705789444759, model__max_depth=4, model__min_child_weight=3, model__n_estimators=975, model__subsample=0.7571172192068059;, score=-10.716 total time=   5.2s\n",
      "[CV 35/37; 5/30] START model__colsample_bytree=0.645614570099021, model__learning_rate=0.1323705789444759, model__max_depth=4, model__min_child_weight=3, model__n_estimators=975, model__subsample=0.7571172192068059\n",
      "[CV 24/37; 5/30] END model__colsample_bytree=0.645614570099021, model__learning_rate=0.1323705789444759, model__max_depth=4, model__min_child_weight=3, model__n_estimators=975, model__subsample=0.7571172192068059;, score=-6.012 total time=   5.3s\n",
      "[CV 36/37; 5/30] START model__colsample_bytree=0.645614570099021, model__learning_rate=0.1323705789444759, model__max_depth=4, model__min_child_weight=3, model__n_estimators=975, model__subsample=0.7571172192068059\n",
      "[CV 25/37; 5/30] END model__colsample_bytree=0.645614570099021, model__learning_rate=0.1323705789444759, model__max_depth=4, model__min_child_weight=3, model__n_estimators=975, model__subsample=0.7571172192068059;, score=-1.701 total time=   5.5s\n",
      "[CV 37/37; 5/30] START model__colsample_bytree=0.645614570099021, model__learning_rate=0.1323705789444759, model__max_depth=4, model__min_child_weight=3, model__n_estimators=975, model__subsample=0.7571172192068059\n",
      "[CV 26/37; 5/30] END model__colsample_bytree=0.645614570099021, model__learning_rate=0.1323705789444759, model__max_depth=4, model__min_child_weight=3, model__n_estimators=975, model__subsample=0.7571172192068059;, score=-3.088 total time=   5.6s\n",
      "[CV 1/37; 6/30] START model__colsample_bytree=0.7962072844310213, model__learning_rate=0.019290082543999547, model__max_depth=5, model__min_child_weight=7, model__n_estimators=120, model__subsample=0.7252496259847715\n",
      "[CV 1/37; 6/30] END model__colsample_bytree=0.7962072844310213, model__learning_rate=0.019290082543999547, model__max_depth=5, model__min_child_weight=7, model__n_estimators=120, model__subsample=0.7252496259847715;, score=-8.166 total time=   0.1s\n",
      "[CV 2/37; 6/30] START model__colsample_bytree=0.7962072844310213, model__learning_rate=0.019290082543999547, model__max_depth=5, model__min_child_weight=7, model__n_estimators=120, model__subsample=0.7252496259847715\n",
      "[CV 2/37; 6/30] END model__colsample_bytree=0.7962072844310213, model__learning_rate=0.019290082543999547, model__max_depth=5, model__min_child_weight=7, model__n_estimators=120, model__subsample=0.7252496259847715;, score=-8.349 total time=   0.1s\n",
      "[CV 3/37; 6/30] START model__colsample_bytree=0.7962072844310213, model__learning_rate=0.019290082543999547, model__max_depth=5, model__min_child_weight=7, model__n_estimators=120, model__subsample=0.7252496259847715\n",
      "[CV 3/37; 6/30] END model__colsample_bytree=0.7962072844310213, model__learning_rate=0.019290082543999547, model__max_depth=5, model__min_child_weight=7, model__n_estimators=120, model__subsample=0.7252496259847715;, score=-105.475 total time=   0.1s\n",
      "[CV 4/37; 6/30] START model__colsample_bytree=0.7962072844310213, model__learning_rate=0.019290082543999547, model__max_depth=5, model__min_child_weight=7, model__n_estimators=120, model__subsample=0.7252496259847715\n",
      "[CV 27/37; 5/30] END model__colsample_bytree=0.645614570099021, model__learning_rate=0.1323705789444759, model__max_depth=4, model__min_child_weight=3, model__n_estimators=975, model__subsample=0.7571172192068059;, score=-3.567 total time=   5.8s\n",
      "[CV 5/37; 6/30] START model__colsample_bytree=0.7962072844310213, model__learning_rate=0.019290082543999547, model__max_depth=5, model__min_child_weight=7, model__n_estimators=120, model__subsample=0.7252496259847715\n",
      "[CV 4/37; 6/30] END model__colsample_bytree=0.7962072844310213, model__learning_rate=0.019290082543999547, model__max_depth=5, model__min_child_weight=7, model__n_estimators=120, model__subsample=0.7252496259847715;, score=-48.733 total time=   0.2s\n",
      "[CV 6/37; 6/30] START model__colsample_bytree=0.7962072844310213, model__learning_rate=0.019290082543999547, model__max_depth=5, model__min_child_weight=7, model__n_estimators=120, model__subsample=0.7252496259847715\n",
      "[CV 5/37; 6/30] END model__colsample_bytree=0.7962072844310213, model__learning_rate=0.019290082543999547, model__max_depth=5, model__min_child_weight=7, model__n_estimators=120, model__subsample=0.7252496259847715;, score=-73.705 total time=   0.2s\n",
      "[CV 7/37; 6/30] START model__colsample_bytree=0.7962072844310213, model__learning_rate=0.019290082543999547, model__max_depth=5, model__min_child_weight=7, model__n_estimators=120, model__subsample=0.7252496259847715\n",
      "[CV 6/37; 6/30] END model__colsample_bytree=0.7962072844310213, model__learning_rate=0.019290082543999547, model__max_depth=5, model__min_child_weight=7, model__n_estimators=120, model__subsample=0.7252496259847715;, score=-4.064 total time=   0.3s\n",
      "[CV 8/37; 6/30] START model__colsample_bytree=0.7962072844310213, model__learning_rate=0.019290082543999547, model__max_depth=5, model__min_child_weight=7, model__n_estimators=120, model__subsample=0.7252496259847715\n",
      "[CV 7/37; 6/30] END model__colsample_bytree=0.7962072844310213, model__learning_rate=0.019290082543999547, model__max_depth=5, model__min_child_weight=7, model__n_estimators=120, model__subsample=0.7252496259847715;, score=0.107 total time=   0.3s\n",
      "[CV 9/37; 6/30] START model__colsample_bytree=0.7962072844310213, model__learning_rate=0.019290082543999547, model__max_depth=5, model__min_child_weight=7, model__n_estimators=120, model__subsample=0.7252496259847715\n",
      "[CV 8/37; 6/30] END model__colsample_bytree=0.7962072844310213, model__learning_rate=0.019290082543999547, model__max_depth=5, model__min_child_weight=7, model__n_estimators=120, model__subsample=0.7252496259847715;, score=-0.892 total time=   0.3s\n",
      "[CV 28/37; 5/30] END model__colsample_bytree=0.645614570099021, model__learning_rate=0.1323705789444759, model__max_depth=4, model__min_child_weight=3, model__n_estimators=975, model__subsample=0.7571172192068059;, score=-2.423 total time=   6.2s\n",
      "[CV 11/37; 6/30] START model__colsample_bytree=0.7962072844310213, model__learning_rate=0.019290082543999547, model__max_depth=5, model__min_child_weight=7, model__n_estimators=120, model__subsample=0.7252496259847715\n",
      "[CV 10/37; 6/30] START model__colsample_bytree=0.7962072844310213, model__learning_rate=0.019290082543999547, model__max_depth=5, model__min_child_weight=7, model__n_estimators=120, model__subsample=0.7252496259847715\n",
      "[CV 9/37; 6/30] END model__colsample_bytree=0.7962072844310213, model__learning_rate=0.019290082543999547, model__max_depth=5, model__min_child_weight=7, model__n_estimators=120, model__subsample=0.7252496259847715;, score=-5.343 total time=   0.4s\n",
      "[CV 12/37; 6/30] START model__colsample_bytree=0.7962072844310213, model__learning_rate=0.019290082543999547, model__max_depth=5, model__min_child_weight=7, model__n_estimators=120, model__subsample=0.7252496259847715\n",
      "[CV 29/37; 5/30] END model__colsample_bytree=0.645614570099021, model__learning_rate=0.1323705789444759, model__max_depth=4, model__min_child_weight=3, model__n_estimators=975, model__subsample=0.7571172192068059;, score=-10.206 total time=   6.3s\n",
      "[CV 13/37; 6/30] START model__colsample_bytree=0.7962072844310213, model__learning_rate=0.019290082543999547, model__max_depth=5, model__min_child_weight=7, model__n_estimators=120, model__subsample=0.7252496259847715\n",
      "[CV 10/37; 6/30] END model__colsample_bytree=0.7962072844310213, model__learning_rate=0.019290082543999547, model__max_depth=5, model__min_child_weight=7, model__n_estimators=120, model__subsample=0.7252496259847715;, score=-77.704 total time=   0.4s\n",
      "[CV 14/37; 6/30] START model__colsample_bytree=0.7962072844310213, model__learning_rate=0.019290082543999547, model__max_depth=5, model__min_child_weight=7, model__n_estimators=120, model__subsample=0.7252496259847715\n",
      "[CV 11/37; 6/30] END model__colsample_bytree=0.7962072844310213, model__learning_rate=0.019290082543999547, model__max_depth=5, model__min_child_weight=7, model__n_estimators=120, model__subsample=0.7252496259847715;, score=-11.426 total time=   0.4s\n",
      "[CV 15/37; 6/30] START model__colsample_bytree=0.7962072844310213, model__learning_rate=0.019290082543999547, model__max_depth=5, model__min_child_weight=7, model__n_estimators=120, model__subsample=0.7252496259847715\n",
      "[CV 12/37; 6/30] END model__colsample_bytree=0.7962072844310213, model__learning_rate=0.019290082543999547, model__max_depth=5, model__min_child_weight=7, model__n_estimators=120, model__subsample=0.7252496259847715;, score=-47.164 total time=   0.5s\n",
      "[CV 16/37; 6/30] START model__colsample_bytree=0.7962072844310213, model__learning_rate=0.019290082543999547, model__max_depth=5, model__min_child_weight=7, model__n_estimators=120, model__subsample=0.7252496259847715\n",
      "[CV 13/37; 6/30] END model__colsample_bytree=0.7962072844310213, model__learning_rate=0.019290082543999547, model__max_depth=5, model__min_child_weight=7, model__n_estimators=120, model__subsample=0.7252496259847715;, score=-1.388 total time=   0.5s\n",
      "[CV 17/37; 6/30] START model__colsample_bytree=0.7962072844310213, model__learning_rate=0.019290082543999547, model__max_depth=5, model__min_child_weight=7, model__n_estimators=120, model__subsample=0.7252496259847715\n",
      "[CV 14/37; 6/30] END model__colsample_bytree=0.7962072844310213, model__learning_rate=0.019290082543999547, model__max_depth=5, model__min_child_weight=7, model__n_estimators=120, model__subsample=0.7252496259847715;, score=0.266 total time=   0.5s\n",
      "[CV 18/37; 6/30] START model__colsample_bytree=0.7962072844310213, model__learning_rate=0.019290082543999547, model__max_depth=5, model__min_child_weight=7, model__n_estimators=120, model__subsample=0.7252496259847715\n",
      "[CV 15/37; 6/30] END model__colsample_bytree=0.7962072844310213, model__learning_rate=0.019290082543999547, model__max_depth=5, model__min_child_weight=7, model__n_estimators=120, model__subsample=0.7252496259847715;, score=-4.435 total time=   0.6s\n",
      "[CV 19/37; 6/30] START model__colsample_bytree=0.7962072844310213, model__learning_rate=0.019290082543999547, model__max_depth=5, model__min_child_weight=7, model__n_estimators=120, model__subsample=0.7252496259847715\n",
      "[CV 16/37; 6/30] END model__colsample_bytree=0.7962072844310213, model__learning_rate=0.019290082543999547, model__max_depth=5, model__min_child_weight=7, model__n_estimators=120, model__subsample=0.7252496259847715;, score=-4.605 total time=   0.6s\n",
      "[CV 20/37; 6/30] START model__colsample_bytree=0.7962072844310213, model__learning_rate=0.019290082543999547, model__max_depth=5, model__min_child_weight=7, model__n_estimators=120, model__subsample=0.7252496259847715\n",
      "[CV 17/37; 6/30] END model__colsample_bytree=0.7962072844310213, model__learning_rate=0.019290082543999547, model__max_depth=5, model__min_child_weight=7, model__n_estimators=120, model__subsample=0.7252496259847715;, score=-5.212 total time=   0.7s\n",
      "[CV 21/37; 6/30] START model__colsample_bytree=0.7962072844310213, model__learning_rate=0.019290082543999547, model__max_depth=5, model__min_child_weight=7, model__n_estimators=120, model__subsample=0.7252496259847715\n",
      "[CV 30/37; 5/30] END model__colsample_bytree=0.645614570099021, model__learning_rate=0.1323705789444759, model__max_depth=4, model__min_child_weight=3, model__n_estimators=975, model__subsample=0.7571172192068059;, score=-0.386 total time=   6.8s\n",
      "[CV 22/37; 6/30] START model__colsample_bytree=0.7962072844310213, model__learning_rate=0.019290082543999547, model__max_depth=5, model__min_child_weight=7, model__n_estimators=120, model__subsample=0.7252496259847715\n",
      "[CV 18/37; 6/30] END model__colsample_bytree=0.7962072844310213, model__learning_rate=0.019290082543999547, model__max_depth=5, model__min_child_weight=7, model__n_estimators=120, model__subsample=0.7252496259847715;, score=-3.500 total time=   0.7s\n",
      "[CV 23/37; 6/30] START model__colsample_bytree=0.7962072844310213, model__learning_rate=0.019290082543999547, model__max_depth=5, model__min_child_weight=7, model__n_estimators=120, model__subsample=0.7252496259847715\n",
      "[CV 19/37; 6/30] END model__colsample_bytree=0.7962072844310213, model__learning_rate=0.019290082543999547, model__max_depth=5, model__min_child_weight=7, model__n_estimators=120, model__subsample=0.7252496259847715;, score=-1.922 total time=   0.7s\n",
      "[CV 24/37; 6/30] START model__colsample_bytree=0.7962072844310213, model__learning_rate=0.019290082543999547, model__max_depth=5, model__min_child_weight=7, model__n_estimators=120, model__subsample=0.7252496259847715\n",
      "[CV 20/37; 6/30] END model__colsample_bytree=0.7962072844310213, model__learning_rate=0.019290082543999547, model__max_depth=5, model__min_child_weight=7, model__n_estimators=120, model__subsample=0.7252496259847715;, score=-0.886 total time=   0.8s\n",
      "[CV 25/37; 6/30] START model__colsample_bytree=0.7962072844310213, model__learning_rate=0.019290082543999547, model__max_depth=5, model__min_child_weight=7, model__n_estimators=120, model__subsample=0.7252496259847715\n",
      "[CV 31/37; 5/30] END model__colsample_bytree=0.645614570099021, model__learning_rate=0.1323705789444759, model__max_depth=4, model__min_child_weight=3, model__n_estimators=975, model__subsample=0.7571172192068059;, score=-0.399 total time=   6.9s\n",
      "[CV 26/37; 6/30] START model__colsample_bytree=0.7962072844310213, model__learning_rate=0.019290082543999547, model__max_depth=5, model__min_child_weight=7, model__n_estimators=120, model__subsample=0.7252496259847715\n",
      "[CV 21/37; 6/30] END model__colsample_bytree=0.7962072844310213, model__learning_rate=0.019290082543999547, model__max_depth=5, model__min_child_weight=7, model__n_estimators=120, model__subsample=0.7252496259847715;, score=-4.981 total time=   0.8s\n",
      "[CV 27/37; 6/30] START model__colsample_bytree=0.7962072844310213, model__learning_rate=0.019290082543999547, model__max_depth=5, model__min_child_weight=7, model__n_estimators=120, model__subsample=0.7252496259847715\n",
      "[CV 22/37; 6/30] END model__colsample_bytree=0.7962072844310213, model__learning_rate=0.019290082543999547, model__max_depth=5, model__min_child_weight=7, model__n_estimators=120, model__subsample=0.7252496259847715;, score=-3.131 total time=   0.8s\n",
      "[CV 28/37; 6/30] START model__colsample_bytree=0.7962072844310213, model__learning_rate=0.019290082543999547, model__max_depth=5, model__min_child_weight=7, model__n_estimators=120, model__subsample=0.7252496259847715\n",
      "[CV 23/37; 6/30] END model__colsample_bytree=0.7962072844310213, model__learning_rate=0.019290082543999547, model__max_depth=5, model__min_child_weight=7, model__n_estimators=120, model__subsample=0.7252496259847715;, score=-3.147 total time=   0.9s\n",
      "[CV 29/37; 6/30] START model__colsample_bytree=0.7962072844310213, model__learning_rate=0.019290082543999547, model__max_depth=5, model__min_child_weight=7, model__n_estimators=120, model__subsample=0.7252496259847715\n",
      "[CV 24/37; 6/30] END model__colsample_bytree=0.7962072844310213, model__learning_rate=0.019290082543999547, model__max_depth=5, model__min_child_weight=7, model__n_estimators=120, model__subsample=0.7252496259847715;, score=-18.303 total time=   1.0s\n",
      "[CV 30/37; 6/30] START model__colsample_bytree=0.7962072844310213, model__learning_rate=0.019290082543999547, model__max_depth=5, model__min_child_weight=7, model__n_estimators=120, model__subsample=0.7252496259847715\n",
      "[CV 32/37; 5/30] END model__colsample_bytree=0.645614570099021, model__learning_rate=0.1323705789444759, model__max_depth=4, model__min_child_weight=3, model__n_estimators=975, model__subsample=0.7571172192068059;, score=-3.887 total time=   7.2s\n",
      "[CV 31/37; 6/30] START model__colsample_bytree=0.7962072844310213, model__learning_rate=0.019290082543999547, model__max_depth=5, model__min_child_weight=7, model__n_estimators=120, model__subsample=0.7252496259847715\n",
      "[CV 25/37; 6/30] END model__colsample_bytree=0.7962072844310213, model__learning_rate=0.019290082543999547, model__max_depth=5, model__min_child_weight=7, model__n_estimators=120, model__subsample=0.7252496259847715;, score=-3.221 total time=   1.0s\n",
      "[CV 32/37; 6/30] START model__colsample_bytree=0.7962072844310213, model__learning_rate=0.019290082543999547, model__max_depth=5, model__min_child_weight=7, model__n_estimators=120, model__subsample=0.7252496259847715\n",
      "[CV 26/37; 6/30] END model__colsample_bytree=0.7962072844310213, model__learning_rate=0.019290082543999547, model__max_depth=5, model__min_child_weight=7, model__n_estimators=120, model__subsample=0.7252496259847715;, score=-10.176 total time=   1.0s\n",
      "[CV 33/37; 5/30] END model__colsample_bytree=0.645614570099021, model__learning_rate=0.1323705789444759, model__max_depth=4, model__min_child_weight=3, model__n_estimators=975, model__subsample=0.7571172192068059;, score=-19.151 total time=   7.3s\n",
      "[CV 34/37; 6/30] START model__colsample_bytree=0.7962072844310213, model__learning_rate=0.019290082543999547, model__max_depth=5, model__min_child_weight=7, model__n_estimators=120, model__subsample=0.7252496259847715\n",
      "[CV 33/37; 6/30] START model__colsample_bytree=0.7962072844310213, model__learning_rate=0.019290082543999547, model__max_depth=5, model__min_child_weight=7, model__n_estimators=120, model__subsample=0.7252496259847715\n",
      "[CV 27/37; 6/30] END model__colsample_bytree=0.7962072844310213, model__learning_rate=0.019290082543999547, model__max_depth=5, model__min_child_weight=7, model__n_estimators=120, model__subsample=0.7252496259847715;, score=-16.869 total time=   1.0s\n",
      "[CV 35/37; 6/30] START model__colsample_bytree=0.7962072844310213, model__learning_rate=0.019290082543999547, model__max_depth=5, model__min_child_weight=7, model__n_estimators=120, model__subsample=0.7252496259847715\n",
      "[CV 28/37; 6/30] END model__colsample_bytree=0.7962072844310213, model__learning_rate=0.019290082543999547, model__max_depth=5, model__min_child_weight=7, model__n_estimators=120, model__subsample=0.7252496259847715;, score=-14.501 total time=   1.1s\n",
      "[CV 36/37; 6/30] START model__colsample_bytree=0.7962072844310213, model__learning_rate=0.019290082543999547, model__max_depth=5, model__min_child_weight=7, model__n_estimators=120, model__subsample=0.7252496259847715\n",
      "[CV 29/37; 6/30] END model__colsample_bytree=0.7962072844310213, model__learning_rate=0.019290082543999547, model__max_depth=5, model__min_child_weight=7, model__n_estimators=120, model__subsample=0.7252496259847715;, score=-9.387 total time=   1.1s\n",
      "[CV 37/37; 6/30] START model__colsample_bytree=0.7962072844310213, model__learning_rate=0.019290082543999547, model__max_depth=5, model__min_child_weight=7, model__n_estimators=120, model__subsample=0.7252496259847715\n",
      "[CV 30/37; 6/30] END model__colsample_bytree=0.7962072844310213, model__learning_rate=0.019290082543999547, model__max_depth=5, model__min_child_weight=7, model__n_estimators=120, model__subsample=0.7252496259847715;, score=-2.390 total time=   1.2s\n",
      "[CV 1/37; 7/30] START model__colsample_bytree=0.5066324805799333, model__learning_rate=0.19844035113697056, model__max_depth=8, model__min_child_weight=2, model__n_estimators=876, model__subsample=0.5079831261101071\n",
      "[CV 31/37; 6/30] END model__colsample_bytree=0.7962072844310213, model__learning_rate=0.019290082543999547, model__max_depth=5, model__min_child_weight=7, model__n_estimators=120, model__subsample=0.7252496259847715;, score=-2.691 total time=   1.2s\n",
      "[CV 2/37; 7/30] START model__colsample_bytree=0.5066324805799333, model__learning_rate=0.19844035113697056, model__max_depth=8, model__min_child_weight=2, model__n_estimators=876, model__subsample=0.5079831261101071\n",
      "[CV 1/37; 7/30] END model__colsample_bytree=0.5066324805799333, model__learning_rate=0.19844035113697056, model__max_depth=8, model__min_child_weight=2, model__n_estimators=876, model__subsample=0.5079831261101071;, score=-42.646 total time=   0.3s\n",
      "[CV 3/37; 7/30] START model__colsample_bytree=0.5066324805799333, model__learning_rate=0.19844035113697056, model__max_depth=8, model__min_child_weight=2, model__n_estimators=876, model__subsample=0.5079831261101071\n",
      "[CV 32/37; 6/30] END model__colsample_bytree=0.7962072844310213, model__learning_rate=0.019290082543999547, model__max_depth=5, model__min_child_weight=7, model__n_estimators=120, model__subsample=0.7252496259847715;, score=-11.203 total time=   1.3s\n",
      "[CV 34/37; 5/30] END model__colsample_bytree=0.645614570099021, model__learning_rate=0.1323705789444759, model__max_depth=4, model__min_child_weight=3, model__n_estimators=975, model__subsample=0.7571172192068059;, score=0.219 total time=   7.6s\n",
      "[CV 4/37; 7/30] START model__colsample_bytree=0.5066324805799333, model__learning_rate=0.19844035113697056, model__max_depth=8, model__min_child_weight=2, model__n_estimators=876, model__subsample=0.5079831261101071\n",
      "[CV 5/37; 7/30] START model__colsample_bytree=0.5066324805799333, model__learning_rate=0.19844035113697056, model__max_depth=8, model__min_child_weight=2, model__n_estimators=876, model__subsample=0.5079831261101071\n",
      "[CV 2/37; 7/30] END model__colsample_bytree=0.5066324805799333, model__learning_rate=0.19844035113697056, model__max_depth=8, model__min_child_weight=2, model__n_estimators=876, model__subsample=0.5079831261101071;, score=-1.350 total time=   0.3s\n",
      "[CV 6/37; 7/30] START model__colsample_bytree=0.5066324805799333, model__learning_rate=0.19844035113697056, model__max_depth=8, model__min_child_weight=2, model__n_estimators=876, model__subsample=0.5079831261101071\n",
      "[CV 33/37; 6/30] END model__colsample_bytree=0.7962072844310213, model__learning_rate=0.019290082543999547, model__max_depth=5, model__min_child_weight=7, model__n_estimators=120, model__subsample=0.7252496259847715;, score=-54.702 total time=   1.3s\n",
      "[CV 7/37; 7/30] START model__colsample_bytree=0.5066324805799333, model__learning_rate=0.19844035113697056, model__max_depth=8, model__min_child_weight=2, model__n_estimators=876, model__subsample=0.5079831261101071\n",
      "[CV 34/37; 6/30] END model__colsample_bytree=0.7962072844310213, model__learning_rate=0.019290082543999547, model__max_depth=5, model__min_child_weight=7, model__n_estimators=120, model__subsample=0.7252496259847715;, score=-5.079 total time=   1.3s\n",
      "[CV 8/37; 7/30] START model__colsample_bytree=0.5066324805799333, model__learning_rate=0.19844035113697056, model__max_depth=8, model__min_child_weight=2, model__n_estimators=876, model__subsample=0.5079831261101071\n",
      "[CV 3/37; 7/30] END model__colsample_bytree=0.5066324805799333, model__learning_rate=0.19844035113697056, model__max_depth=8, model__min_child_weight=2, model__n_estimators=876, model__subsample=0.5079831261101071;, score=-8.660 total time=   0.5s\n",
      "[CV 9/37; 7/30] START model__colsample_bytree=0.5066324805799333, model__learning_rate=0.19844035113697056, model__max_depth=8, model__min_child_weight=2, model__n_estimators=876, model__subsample=0.5079831261101071\n",
      "[CV 35/37; 6/30] END model__colsample_bytree=0.7962072844310213, model__learning_rate=0.019290082543999547, model__max_depth=5, model__min_child_weight=7, model__n_estimators=120, model__subsample=0.7252496259847715;, score=-3.080 total time=   1.4s\n",
      "[CV 10/37; 7/30] START model__colsample_bytree=0.5066324805799333, model__learning_rate=0.19844035113697056, model__max_depth=8, model__min_child_weight=2, model__n_estimators=876, model__subsample=0.5079831261101071\n",
      "[CV 35/37; 5/30] END model__colsample_bytree=0.645614570099021, model__learning_rate=0.1323705789444759, model__max_depth=4, model__min_child_weight=3, model__n_estimators=975, model__subsample=0.7571172192068059;, score=-20.822 total time=   7.8s\n",
      "[CV 11/37; 7/30] START model__colsample_bytree=0.5066324805799333, model__learning_rate=0.19844035113697056, model__max_depth=8, model__min_child_weight=2, model__n_estimators=876, model__subsample=0.5079831261101071\n",
      "[CV 37/37; 6/30] END model__colsample_bytree=0.7962072844310213, model__learning_rate=0.019290082543999547, model__max_depth=5, model__min_child_weight=7, model__n_estimators=120, model__subsample=0.7252496259847715;, score=-4.298 total time=   1.4s\n",
      "[CV 36/37; 6/30] END model__colsample_bytree=0.7962072844310213, model__learning_rate=0.019290082543999547, model__max_depth=5, model__min_child_weight=7, model__n_estimators=120, model__subsample=0.7252496259847715;, score=-7.323 total time=   1.4s\n",
      "[CV 4/37; 7/30] END model__colsample_bytree=0.5066324805799333, model__learning_rate=0.19844035113697056, model__max_depth=8, model__min_child_weight=2, model__n_estimators=876, model__subsample=0.5079831261101071;, score=-7.553 total time=   0.6s\n",
      "[CV 12/37; 7/30] START model__colsample_bytree=0.5066324805799333, model__learning_rate=0.19844035113697056, model__max_depth=8, model__min_child_weight=2, model__n_estimators=876, model__subsample=0.5079831261101071\n",
      "[CV 14/37; 7/30] START model__colsample_bytree=0.5066324805799333, model__learning_rate=0.19844035113697056, model__max_depth=8, model__min_child_weight=2, model__n_estimators=876, model__subsample=0.5079831261101071\n",
      "[CV 13/37; 7/30] START model__colsample_bytree=0.5066324805799333, model__learning_rate=0.19844035113697056, model__max_depth=8, model__min_child_weight=2, model__n_estimators=876, model__subsample=0.5079831261101071\n",
      "[CV 5/37; 7/30] END model__colsample_bytree=0.5066324805799333, model__learning_rate=0.19844035113697056, model__max_depth=8, model__min_child_weight=2, model__n_estimators=876, model__subsample=0.5079831261101071;, score=-39.986 total time=   0.7s\n",
      "[CV 15/37; 7/30] START model__colsample_bytree=0.5066324805799333, model__learning_rate=0.19844035113697056, model__max_depth=8, model__min_child_weight=2, model__n_estimators=876, model__subsample=0.5079831261101071\n",
      "[CV 6/37; 7/30] END model__colsample_bytree=0.5066324805799333, model__learning_rate=0.19844035113697056, model__max_depth=8, model__min_child_weight=2, model__n_estimators=876, model__subsample=0.5079831261101071;, score=-1.120 total time=   0.8s\n",
      "[CV 16/37; 7/30] START model__colsample_bytree=0.5066324805799333, model__learning_rate=0.19844035113697056, model__max_depth=8, model__min_child_weight=2, model__n_estimators=876, model__subsample=0.5079831261101071\n",
      "[CV 7/37; 7/30] END model__colsample_bytree=0.5066324805799333, model__learning_rate=0.19844035113697056, model__max_depth=8, model__min_child_weight=2, model__n_estimators=876, model__subsample=0.5079831261101071;, score=-6.084 total time=   1.0s\n",
      "[CV 17/37; 7/30] START model__colsample_bytree=0.5066324805799333, model__learning_rate=0.19844035113697056, model__max_depth=8, model__min_child_weight=2, model__n_estimators=876, model__subsample=0.5079831261101071\n",
      "[CV 36/37; 5/30] END model__colsample_bytree=0.645614570099021, model__learning_rate=0.1323705789444759, model__max_depth=4, model__min_child_weight=3, model__n_estimators=975, model__subsample=0.7571172192068059;, score=-1.363 total time=   7.9s\n",
      "[CV 18/37; 7/30] START model__colsample_bytree=0.5066324805799333, model__learning_rate=0.19844035113697056, model__max_depth=8, model__min_child_weight=2, model__n_estimators=876, model__subsample=0.5079831261101071\n",
      "[CV 8/37; 7/30] END model__colsample_bytree=0.5066324805799333, model__learning_rate=0.19844035113697056, model__max_depth=8, model__min_child_weight=2, model__n_estimators=876, model__subsample=0.5079831261101071;, score=-9.474 total time=   1.1s\n",
      "[CV 19/37; 7/30] START model__colsample_bytree=0.5066324805799333, model__learning_rate=0.19844035113697056, model__max_depth=8, model__min_child_weight=2, model__n_estimators=876, model__subsample=0.5079831261101071\n",
      "[CV 9/37; 7/30] END model__colsample_bytree=0.5066324805799333, model__learning_rate=0.19844035113697056, model__max_depth=8, model__min_child_weight=2, model__n_estimators=876, model__subsample=0.5079831261101071;, score=-0.709 total time=   1.3s\n",
      "[CV 20/37; 7/30] START model__colsample_bytree=0.5066324805799333, model__learning_rate=0.19844035113697056, model__max_depth=8, model__min_child_weight=2, model__n_estimators=876, model__subsample=0.5079831261101071\n",
      "[CV 10/37; 7/30] END model__colsample_bytree=0.5066324805799333, model__learning_rate=0.19844035113697056, model__max_depth=8, model__min_child_weight=2, model__n_estimators=876, model__subsample=0.5079831261101071;, score=-36.667 total time=   1.4s\n",
      "[CV 21/37; 7/30] START model__colsample_bytree=0.5066324805799333, model__learning_rate=0.19844035113697056, model__max_depth=8, model__min_child_weight=2, model__n_estimators=876, model__subsample=0.5079831261101071\n",
      "[CV 37/37; 5/30] END model__colsample_bytree=0.645614570099021, model__learning_rate=0.1323705789444759, model__max_depth=4, model__min_child_weight=3, model__n_estimators=975, model__subsample=0.7571172192068059;, score=-0.487 total time=   8.2s\n",
      "[CV 22/37; 7/30] START model__colsample_bytree=0.5066324805799333, model__learning_rate=0.19844035113697056, model__max_depth=8, model__min_child_weight=2, model__n_estimators=876, model__subsample=0.5079831261101071\n",
      "[CV 11/37; 7/30] END model__colsample_bytree=0.5066324805799333, model__learning_rate=0.19844035113697056, model__max_depth=8, model__min_child_weight=2, model__n_estimators=876, model__subsample=0.5079831261101071;, score=-3.546 total time=   1.7s\n",
      "[CV 23/37; 7/30] START model__colsample_bytree=0.5066324805799333, model__learning_rate=0.19844035113697056, model__max_depth=8, model__min_child_weight=2, model__n_estimators=876, model__subsample=0.5079831261101071\n",
      "[CV 12/37; 7/30] END model__colsample_bytree=0.5066324805799333, model__learning_rate=0.19844035113697056, model__max_depth=8, model__min_child_weight=2, model__n_estimators=876, model__subsample=0.5079831261101071;, score=-17.774 total time=   1.9s\n",
      "[CV 24/37; 7/30] START model__colsample_bytree=0.5066324805799333, model__learning_rate=0.19844035113697056, model__max_depth=8, model__min_child_weight=2, model__n_estimators=876, model__subsample=0.5079831261101071\n",
      "[CV 13/37; 7/30] END model__colsample_bytree=0.5066324805799333, model__learning_rate=0.19844035113697056, model__max_depth=8, model__min_child_weight=2, model__n_estimators=876, model__subsample=0.5079831261101071;, score=0.160 total time=   2.0s\n",
      "[CV 25/37; 7/30] START model__colsample_bytree=0.5066324805799333, model__learning_rate=0.19844035113697056, model__max_depth=8, model__min_child_weight=2, model__n_estimators=876, model__subsample=0.5079831261101071\n",
      "[CV 14/37; 7/30] END model__colsample_bytree=0.5066324805799333, model__learning_rate=0.19844035113697056, model__max_depth=8, model__min_child_weight=2, model__n_estimators=876, model__subsample=0.5079831261101071;, score=-16.641 total time=   2.3s\n",
      "[CV 26/37; 7/30] START model__colsample_bytree=0.5066324805799333, model__learning_rate=0.19844035113697056, model__max_depth=8, model__min_child_weight=2, model__n_estimators=876, model__subsample=0.5079831261101071\n",
      "[CV 15/37; 7/30] END model__colsample_bytree=0.5066324805799333, model__learning_rate=0.19844035113697056, model__max_depth=8, model__min_child_weight=2, model__n_estimators=876, model__subsample=0.5079831261101071;, score=-0.665 total time=   2.4s\n",
      "[CV 27/37; 7/30] START model__colsample_bytree=0.5066324805799333, model__learning_rate=0.19844035113697056, model__max_depth=8, model__min_child_weight=2, model__n_estimators=876, model__subsample=0.5079831261101071\n",
      "[CV 16/37; 7/30] END model__colsample_bytree=0.5066324805799333, model__learning_rate=0.19844035113697056, model__max_depth=8, model__min_child_weight=2, model__n_estimators=876, model__subsample=0.5079831261101071;, score=-1.038 total time=   2.7s\n",
      "[CV 28/37; 7/30] START model__colsample_bytree=0.5066324805799333, model__learning_rate=0.19844035113697056, model__max_depth=8, model__min_child_weight=2, model__n_estimators=876, model__subsample=0.5079831261101071\n",
      "[CV 17/37; 7/30] END model__colsample_bytree=0.5066324805799333, model__learning_rate=0.19844035113697056, model__max_depth=8, model__min_child_weight=2, model__n_estimators=876, model__subsample=0.5079831261101071;, score=-17.008 total time=   3.1s\n",
      "[CV 29/37; 7/30] START model__colsample_bytree=0.5066324805799333, model__learning_rate=0.19844035113697056, model__max_depth=8, model__min_child_weight=2, model__n_estimators=876, model__subsample=0.5079831261101071\n",
      "[CV 18/37; 7/30] END model__colsample_bytree=0.5066324805799333, model__learning_rate=0.19844035113697056, model__max_depth=8, model__min_child_weight=2, model__n_estimators=876, model__subsample=0.5079831261101071;, score=-0.279 total time=   3.3s\n",
      "[CV 30/37; 7/30] START model__colsample_bytree=0.5066324805799333, model__learning_rate=0.19844035113697056, model__max_depth=8, model__min_child_weight=2, model__n_estimators=876, model__subsample=0.5079831261101071\n",
      "[CV 19/37; 7/30] END model__colsample_bytree=0.5066324805799333, model__learning_rate=0.19844035113697056, model__max_depth=8, model__min_child_weight=2, model__n_estimators=876, model__subsample=0.5079831261101071;, score=-1.168 total time=   3.6s\n",
      "[CV 31/37; 7/30] START model__colsample_bytree=0.5066324805799333, model__learning_rate=0.19844035113697056, model__max_depth=8, model__min_child_weight=2, model__n_estimators=876, model__subsample=0.5079831261101071\n",
      "[CV 20/37; 7/30] END model__colsample_bytree=0.5066324805799333, model__learning_rate=0.19844035113697056, model__max_depth=8, model__min_child_weight=2, model__n_estimators=876, model__subsample=0.5079831261101071;, score=-6.919 total time=   3.9s\n",
      "[CV 32/37; 7/30] START model__colsample_bytree=0.5066324805799333, model__learning_rate=0.19844035113697056, model__max_depth=8, model__min_child_weight=2, model__n_estimators=876, model__subsample=0.5079831261101071\n",
      "[CV 21/37; 7/30] END model__colsample_bytree=0.5066324805799333, model__learning_rate=0.19844035113697056, model__max_depth=8, model__min_child_weight=2, model__n_estimators=876, model__subsample=0.5079831261101071;, score=-2.115 total time=   4.2s\n",
      "[CV 33/37; 7/30] START model__colsample_bytree=0.5066324805799333, model__learning_rate=0.19844035113697056, model__max_depth=8, model__min_child_weight=2, model__n_estimators=876, model__subsample=0.5079831261101071\n",
      "[CV 22/37; 7/30] END model__colsample_bytree=0.5066324805799333, model__learning_rate=0.19844035113697056, model__max_depth=8, model__min_child_weight=2, model__n_estimators=876, model__subsample=0.5079831261101071;, score=-0.773 total time=   4.4s\n",
      "[CV 34/37; 7/30] START model__colsample_bytree=0.5066324805799333, model__learning_rate=0.19844035113697056, model__max_depth=8, model__min_child_weight=2, model__n_estimators=876, model__subsample=0.5079831261101071\n",
      "[CV 23/37; 7/30] END model__colsample_bytree=0.5066324805799333, model__learning_rate=0.19844035113697056, model__max_depth=8, model__min_child_weight=2, model__n_estimators=876, model__subsample=0.5079831261101071;, score=-11.722 total time=   4.6s\n",
      "[CV 35/37; 7/30] START model__colsample_bytree=0.5066324805799333, model__learning_rate=0.19844035113697056, model__max_depth=8, model__min_child_weight=2, model__n_estimators=876, model__subsample=0.5079831261101071\n",
      "[CV 24/37; 7/30] END model__colsample_bytree=0.5066324805799333, model__learning_rate=0.19844035113697056, model__max_depth=8, model__min_child_weight=2, model__n_estimators=876, model__subsample=0.5079831261101071;, score=-8.768 total time=   4.9s\n",
      "[CV 36/37; 7/30] START model__colsample_bytree=0.5066324805799333, model__learning_rate=0.19844035113697056, model__max_depth=8, model__min_child_weight=2, model__n_estimators=876, model__subsample=0.5079831261101071\n",
      "[CV 25/37; 7/30] END model__colsample_bytree=0.5066324805799333, model__learning_rate=0.19844035113697056, model__max_depth=8, model__min_child_weight=2, model__n_estimators=876, model__subsample=0.5079831261101071;, score=-0.988 total time=   5.0s\n",
      "[CV 37/37; 7/30] START model__colsample_bytree=0.5066324805799333, model__learning_rate=0.19844035113697056, model__max_depth=8, model__min_child_weight=2, model__n_estimators=876, model__subsample=0.5079831261101071\n",
      "[CV 26/37; 7/30] END model__colsample_bytree=0.5066324805799333, model__learning_rate=0.19844035113697056, model__max_depth=8, model__min_child_weight=2, model__n_estimators=876, model__subsample=0.5079831261101071;, score=-2.022 total time=   5.4s\n",
      "[CV 1/37; 8/30] START model__colsample_bytree=0.6154469128110744, model__learning_rate=0.05820509320520235, model__max_depth=6, model__min_child_weight=7, model__n_estimators=527, model__subsample=0.7475884550556351\n",
      "[CV 1/37; 8/30] END model__colsample_bytree=0.6154469128110744, model__learning_rate=0.05820509320520235, model__max_depth=6, model__min_child_weight=7, model__n_estimators=527, model__subsample=0.7475884550556351;, score=-41.091 total time=   0.3s\n",
      "[CV 2/37; 8/30] START model__colsample_bytree=0.6154469128110744, model__learning_rate=0.05820509320520235, model__max_depth=6, model__min_child_weight=7, model__n_estimators=527, model__subsample=0.7475884550556351\n",
      "[CV 27/37; 7/30] END model__colsample_bytree=0.5066324805799333, model__learning_rate=0.19844035113697056, model__max_depth=8, model__min_child_weight=2, model__n_estimators=876, model__subsample=0.5079831261101071;, score=-3.939 total time=   5.5s\n",
      "[CV 3/37; 8/30] START model__colsample_bytree=0.6154469128110744, model__learning_rate=0.05820509320520235, model__max_depth=6, model__min_child_weight=7, model__n_estimators=527, model__subsample=0.7475884550556351\n",
      "[CV 2/37; 8/30] END model__colsample_bytree=0.6154469128110744, model__learning_rate=0.05820509320520235, model__max_depth=6, model__min_child_weight=7, model__n_estimators=527, model__subsample=0.7475884550556351;, score=-0.351 total time=   0.5s\n",
      "[CV 4/37; 8/30] START model__colsample_bytree=0.6154469128110744, model__learning_rate=0.05820509320520235, model__max_depth=6, model__min_child_weight=7, model__n_estimators=527, model__subsample=0.7475884550556351\n",
      "[CV 3/37; 8/30] END model__colsample_bytree=0.6154469128110744, model__learning_rate=0.05820509320520235, model__max_depth=6, model__min_child_weight=7, model__n_estimators=527, model__subsample=0.7475884550556351;, score=-12.305 total time=   0.8s\n",
      "[CV 5/37; 8/30] START model__colsample_bytree=0.6154469128110744, model__learning_rate=0.05820509320520235, model__max_depth=6, model__min_child_weight=7, model__n_estimators=527, model__subsample=0.7475884550556351\n",
      "[CV 28/37; 7/30] END model__colsample_bytree=0.5066324805799333, model__learning_rate=0.19844035113697056, model__max_depth=8, model__min_child_weight=2, model__n_estimators=876, model__subsample=0.5079831261101071;, score=-2.236 total time=   5.9s\n",
      "[CV 6/37; 8/30] START model__colsample_bytree=0.6154469128110744, model__learning_rate=0.05820509320520235, model__max_depth=6, model__min_child_weight=7, model__n_estimators=527, model__subsample=0.7475884550556351\n",
      "[CV 4/37; 8/30] END model__colsample_bytree=0.6154469128110744, model__learning_rate=0.05820509320520235, model__max_depth=6, model__min_child_weight=7, model__n_estimators=527, model__subsample=0.7475884550556351;, score=-6.983 total time=   1.0s\n",
      "[CV 7/37; 8/30] START model__colsample_bytree=0.6154469128110744, model__learning_rate=0.05820509320520235, model__max_depth=6, model__min_child_weight=7, model__n_estimators=527, model__subsample=0.7475884550556351\n",
      "[CV 29/37; 7/30] END model__colsample_bytree=0.5066324805799333, model__learning_rate=0.19844035113697056, model__max_depth=8, model__min_child_weight=2, model__n_estimators=876, model__subsample=0.5079831261101071;, score=-12.156 total time=   6.1s\n",
      "[CV 8/37; 8/30] START model__colsample_bytree=0.6154469128110744, model__learning_rate=0.05820509320520235, model__max_depth=6, model__min_child_weight=7, model__n_estimators=527, model__subsample=0.7475884550556351\n",
      "[CV 5/37; 8/30] END model__colsample_bytree=0.6154469128110744, model__learning_rate=0.05820509320520235, model__max_depth=6, model__min_child_weight=7, model__n_estimators=527, model__subsample=0.7475884550556351;, score=-37.928 total time=   1.1s\n",
      "[CV 9/37; 8/30] START model__colsample_bytree=0.6154469128110744, model__learning_rate=0.05820509320520235, model__max_depth=6, model__min_child_weight=7, model__n_estimators=527, model__subsample=0.7475884550556351\n",
      "[CV 30/37; 7/30] END model__colsample_bytree=0.5066324805799333, model__learning_rate=0.19844035113697056, model__max_depth=8, model__min_child_weight=2, model__n_estimators=876, model__subsample=0.5079831261101071;, score=-0.393 total time=   6.2s\n",
      "[CV 10/37; 8/30] START model__colsample_bytree=0.6154469128110744, model__learning_rate=0.05820509320520235, model__max_depth=6, model__min_child_weight=7, model__n_estimators=527, model__subsample=0.7475884550556351\n",
      "[CV 6/37; 8/30] END model__colsample_bytree=0.6154469128110744, model__learning_rate=0.05820509320520235, model__max_depth=6, model__min_child_weight=7, model__n_estimators=527, model__subsample=0.7475884550556351;, score=-1.423 total time=   1.3s\n",
      "[CV 11/37; 8/30] START model__colsample_bytree=0.6154469128110744, model__learning_rate=0.05820509320520235, model__max_depth=6, model__min_child_weight=7, model__n_estimators=527, model__subsample=0.7475884550556351\n",
      "[CV 31/37; 7/30] END model__colsample_bytree=0.5066324805799333, model__learning_rate=0.19844035113697056, model__max_depth=8, model__min_child_weight=2, model__n_estimators=876, model__subsample=0.5079831261101071;, score=-0.430 total time=   6.5s\n",
      "[CV 12/37; 8/30] START model__colsample_bytree=0.6154469128110744, model__learning_rate=0.05820509320520235, model__max_depth=6, model__min_child_weight=7, model__n_estimators=527, model__subsample=0.7475884550556351\n",
      "[CV 7/37; 8/30] END model__colsample_bytree=0.6154469128110744, model__learning_rate=0.05820509320520235, model__max_depth=6, model__min_child_weight=7, model__n_estimators=527, model__subsample=0.7475884550556351;, score=-6.198 total time=   1.4s\n",
      "[CV 13/37; 8/30] START model__colsample_bytree=0.6154469128110744, model__learning_rate=0.05820509320520235, model__max_depth=6, model__min_child_weight=7, model__n_estimators=527, model__subsample=0.7475884550556351\n",
      "[CV 8/37; 8/30] END model__colsample_bytree=0.6154469128110744, model__learning_rate=0.05820509320520235, model__max_depth=6, model__min_child_weight=7, model__n_estimators=527, model__subsample=0.7475884550556351;, score=-8.491 total time=   1.7s\n",
      "[CV 14/37; 8/30] START model__colsample_bytree=0.6154469128110744, model__learning_rate=0.05820509320520235, model__max_depth=6, model__min_child_weight=7, model__n_estimators=527, model__subsample=0.7475884550556351\n",
      "[CV 32/37; 7/30] END model__colsample_bytree=0.5066324805799333, model__learning_rate=0.19844035113697056, model__max_depth=8, model__min_child_weight=2, model__n_estimators=876, model__subsample=0.5079831261101071;, score=-3.359 total time=   6.9s\n",
      "[CV 15/37; 8/30] START model__colsample_bytree=0.6154469128110744, model__learning_rate=0.05820509320520235, model__max_depth=6, model__min_child_weight=7, model__n_estimators=527, model__subsample=0.7475884550556351\n",
      "[CV 9/37; 8/30] END model__colsample_bytree=0.6154469128110744, model__learning_rate=0.05820509320520235, model__max_depth=6, model__min_child_weight=7, model__n_estimators=527, model__subsample=0.7475884550556351;, score=-0.620 total time=   1.9s\n",
      "[CV 16/37; 8/30] START model__colsample_bytree=0.6154469128110744, model__learning_rate=0.05820509320520235, model__max_depth=6, model__min_child_weight=7, model__n_estimators=527, model__subsample=0.7475884550556351\n",
      "[CV 10/37; 8/30] END model__colsample_bytree=0.6154469128110744, model__learning_rate=0.05820509320520235, model__max_depth=6, model__min_child_weight=7, model__n_estimators=527, model__subsample=0.7475884550556351;, score=-28.731 total time=   2.0s\n",
      "[CV 17/37; 8/30] START model__colsample_bytree=0.6154469128110744, model__learning_rate=0.05820509320520235, model__max_depth=6, model__min_child_weight=7, model__n_estimators=527, model__subsample=0.7475884550556351\n",
      "[CV 11/37; 8/30] END model__colsample_bytree=0.6154469128110744, model__learning_rate=0.05820509320520235, model__max_depth=6, model__min_child_weight=7, model__n_estimators=527, model__subsample=0.7475884550556351;, score=-3.121 total time=   2.1s\n",
      "[CV 18/37; 8/30] START model__colsample_bytree=0.6154469128110744, model__learning_rate=0.05820509320520235, model__max_depth=6, model__min_child_weight=7, model__n_estimators=527, model__subsample=0.7475884550556351\n",
      "[CV 33/37; 7/30] END model__colsample_bytree=0.5066324805799333, model__learning_rate=0.19844035113697056, model__max_depth=8, model__min_child_weight=2, model__n_estimators=876, model__subsample=0.5079831261101071;, score=-19.681 total time=   7.3s\n",
      "[CV 19/37; 8/30] START model__colsample_bytree=0.6154469128110744, model__learning_rate=0.05820509320520235, model__max_depth=6, model__min_child_weight=7, model__n_estimators=527, model__subsample=0.7475884550556351\n",
      "[CV 34/37; 7/30] END model__colsample_bytree=0.5066324805799333, model__learning_rate=0.19844035113697056, model__max_depth=8, model__min_child_weight=2, model__n_estimators=876, model__subsample=0.5079831261101071;, score=-0.329 total time=   7.4s\n",
      "[CV 20/37; 8/30] START model__colsample_bytree=0.6154469128110744, model__learning_rate=0.05820509320520235, model__max_depth=6, model__min_child_weight=7, model__n_estimators=527, model__subsample=0.7475884550556351\n",
      "[CV 12/37; 8/30] END model__colsample_bytree=0.6154469128110744, model__learning_rate=0.05820509320520235, model__max_depth=6, model__min_child_weight=7, model__n_estimators=527, model__subsample=0.7475884550556351;, score=-17.958 total time=   2.5s\n",
      "[CV 21/37; 8/30] START model__colsample_bytree=0.6154469128110744, model__learning_rate=0.05820509320520235, model__max_depth=6, model__min_child_weight=7, model__n_estimators=527, model__subsample=0.7475884550556351\n",
      "[CV 13/37; 8/30] END model__colsample_bytree=0.6154469128110744, model__learning_rate=0.05820509320520235, model__max_depth=6, model__min_child_weight=7, model__n_estimators=527, model__subsample=0.7475884550556351;, score=0.124 total time=   2.6s\n",
      "[CV 22/37; 8/30] START model__colsample_bytree=0.6154469128110744, model__learning_rate=0.05820509320520235, model__max_depth=6, model__min_child_weight=7, model__n_estimators=527, model__subsample=0.7475884550556351\n",
      "[CV 35/37; 7/30] END model__colsample_bytree=0.5066324805799333, model__learning_rate=0.19844035113697056, model__max_depth=8, model__min_child_weight=2, model__n_estimators=876, model__subsample=0.5079831261101071;, score=-20.571 total time=   8.0s\n",
      "[CV 23/37; 8/30] START model__colsample_bytree=0.6154469128110744, model__learning_rate=0.05820509320520235, model__max_depth=6, model__min_child_weight=7, model__n_estimators=527, model__subsample=0.7475884550556351\n",
      "[CV 14/37; 8/30] END model__colsample_bytree=0.6154469128110744, model__learning_rate=0.05820509320520235, model__max_depth=6, model__min_child_weight=7, model__n_estimators=527, model__subsample=0.7475884550556351;, score=-20.844 total time=   2.9s\n",
      "[CV 24/37; 8/30] START model__colsample_bytree=0.6154469128110744, model__learning_rate=0.05820509320520235, model__max_depth=6, model__min_child_weight=7, model__n_estimators=527, model__subsample=0.7475884550556351\n",
      "[CV 15/37; 8/30] END model__colsample_bytree=0.6154469128110744, model__learning_rate=0.05820509320520235, model__max_depth=6, model__min_child_weight=7, model__n_estimators=527, model__subsample=0.7475884550556351;, score=-0.185 total time=   3.1s\n",
      "[CV 25/37; 8/30] START model__colsample_bytree=0.6154469128110744, model__learning_rate=0.05820509320520235, model__max_depth=6, model__min_child_weight=7, model__n_estimators=527, model__subsample=0.7475884550556351\n",
      "[CV 36/37; 7/30] END model__colsample_bytree=0.5066324805799333, model__learning_rate=0.19844035113697056, model__max_depth=8, model__min_child_weight=2, model__n_estimators=876, model__subsample=0.5079831261101071;, score=-1.875 total time=   8.3s\n",
      "[CV 26/37; 8/30] START model__colsample_bytree=0.6154469128110744, model__learning_rate=0.05820509320520235, model__max_depth=6, model__min_child_weight=7, model__n_estimators=527, model__subsample=0.7475884550556351\n",
      "[CV 16/37; 8/30] END model__colsample_bytree=0.6154469128110744, model__learning_rate=0.05820509320520235, model__max_depth=6, model__min_child_weight=7, model__n_estimators=527, model__subsample=0.7475884550556351;, score=-0.672 total time=   3.3s\n",
      "[CV 27/37; 8/30] START model__colsample_bytree=0.6154469128110744, model__learning_rate=0.05820509320520235, model__max_depth=6, model__min_child_weight=7, model__n_estimators=527, model__subsample=0.7475884550556351\n",
      "[CV 17/37; 8/30] END model__colsample_bytree=0.6154469128110744, model__learning_rate=0.05820509320520235, model__max_depth=6, model__min_child_weight=7, model__n_estimators=527, model__subsample=0.7475884550556351;, score=-17.593 total time=   3.6s\n",
      "[CV 28/37; 8/30] START model__colsample_bytree=0.6154469128110744, model__learning_rate=0.05820509320520235, model__max_depth=6, model__min_child_weight=7, model__n_estimators=527, model__subsample=0.7475884550556351\n",
      "[CV 37/37; 7/30] END model__colsample_bytree=0.5066324805799333, model__learning_rate=0.19844035113697056, model__max_depth=8, model__min_child_weight=2, model__n_estimators=876, model__subsample=0.5079831261101071;, score=-0.534 total time=   9.0s\n",
      "[CV 29/37; 8/30] START model__colsample_bytree=0.6154469128110744, model__learning_rate=0.05820509320520235, model__max_depth=6, model__min_child_weight=7, model__n_estimators=527, model__subsample=0.7475884550556351\n",
      "[CV 18/37; 8/30] END model__colsample_bytree=0.6154469128110744, model__learning_rate=0.05820509320520235, model__max_depth=6, model__min_child_weight=7, model__n_estimators=527, model__subsample=0.7475884550556351;, score=-0.528 total time=   3.6s\n",
      "[CV 30/37; 8/30] START model__colsample_bytree=0.6154469128110744, model__learning_rate=0.05820509320520235, model__max_depth=6, model__min_child_weight=7, model__n_estimators=527, model__subsample=0.7475884550556351\n",
      "[CV 19/37; 8/30] END model__colsample_bytree=0.6154469128110744, model__learning_rate=0.05820509320520235, model__max_depth=6, model__min_child_weight=7, model__n_estimators=527, model__subsample=0.7475884550556351;, score=-0.910 total time=   3.8s\n",
      "[CV 31/37; 8/30] START model__colsample_bytree=0.6154469128110744, model__learning_rate=0.05820509320520235, model__max_depth=6, model__min_child_weight=7, model__n_estimators=527, model__subsample=0.7475884550556351\n",
      "[CV 20/37; 8/30] END model__colsample_bytree=0.6154469128110744, model__learning_rate=0.05820509320520235, model__max_depth=6, model__min_child_weight=7, model__n_estimators=527, model__subsample=0.7475884550556351;, score=-4.113 total time=   3.9s\n",
      "[CV 32/37; 8/30] START model__colsample_bytree=0.6154469128110744, model__learning_rate=0.05820509320520235, model__max_depth=6, model__min_child_weight=7, model__n_estimators=527, model__subsample=0.7475884550556351\n",
      "[CV 21/37; 8/30] END model__colsample_bytree=0.6154469128110744, model__learning_rate=0.05820509320520235, model__max_depth=6, model__min_child_weight=7, model__n_estimators=527, model__subsample=0.7475884550556351;, score=-1.043 total time=   4.1s\n",
      "[CV 33/37; 8/30] START model__colsample_bytree=0.6154469128110744, model__learning_rate=0.05820509320520235, model__max_depth=6, model__min_child_weight=7, model__n_estimators=527, model__subsample=0.7475884550556351\n",
      "[CV 22/37; 8/30] END model__colsample_bytree=0.6154469128110744, model__learning_rate=0.05820509320520235, model__max_depth=6, model__min_child_weight=7, model__n_estimators=527, model__subsample=0.7475884550556351;, score=-0.446 total time=   4.2s\n",
      "[CV 34/37; 8/30] START model__colsample_bytree=0.6154469128110744, model__learning_rate=0.05820509320520235, model__max_depth=6, model__min_child_weight=7, model__n_estimators=527, model__subsample=0.7475884550556351\n",
      "[CV 23/37; 8/30] END model__colsample_bytree=0.6154469128110744, model__learning_rate=0.05820509320520235, model__max_depth=6, model__min_child_weight=7, model__n_estimators=527, model__subsample=0.7475884550556351;, score=-10.809 total time=   4.4s\n",
      "[CV 35/37; 8/30] START model__colsample_bytree=0.6154469128110744, model__learning_rate=0.05820509320520235, model__max_depth=6, model__min_child_weight=7, model__n_estimators=527, model__subsample=0.7475884550556351\n",
      "[CV 24/37; 8/30] END model__colsample_bytree=0.6154469128110744, model__learning_rate=0.05820509320520235, model__max_depth=6, model__min_child_weight=7, model__n_estimators=527, model__subsample=0.7475884550556351;, score=-5.366 total time=   4.7s\n",
      "[CV 36/37; 8/30] START model__colsample_bytree=0.6154469128110744, model__learning_rate=0.05820509320520235, model__max_depth=6, model__min_child_weight=7, model__n_estimators=527, model__subsample=0.7475884550556351\n",
      "[CV 25/37; 8/30] END model__colsample_bytree=0.6154469128110744, model__learning_rate=0.05820509320520235, model__max_depth=6, model__min_child_weight=7, model__n_estimators=527, model__subsample=0.7475884550556351;, score=-0.982 total time=   4.7s\n",
      "[CV 37/37; 8/30] START model__colsample_bytree=0.6154469128110744, model__learning_rate=0.05820509320520235, model__max_depth=6, model__min_child_weight=7, model__n_estimators=527, model__subsample=0.7475884550556351\n",
      "[CV 26/37; 8/30] END model__colsample_bytree=0.6154469128110744, model__learning_rate=0.05820509320520235, model__max_depth=6, model__min_child_weight=7, model__n_estimators=527, model__subsample=0.7475884550556351;, score=-1.733 total time=   4.9s\n",
      "[CV 1/37; 9/30] START model__colsample_bytree=0.5171942605576092, model__learning_rate=0.19186408041575642, model__max_depth=6, model__min_child_weight=2, model__n_estimators=971, model__subsample=0.8776807051588262\n",
      "[CV 1/37; 9/30] END model__colsample_bytree=0.5171942605576092, model__learning_rate=0.19186408041575642, model__max_depth=6, model__min_child_weight=2, model__n_estimators=971, model__subsample=0.8776807051588262;, score=-39.882 total time=   0.3s\n",
      "[CV 2/37; 9/30] START model__colsample_bytree=0.5171942605576092, model__learning_rate=0.19186408041575642, model__max_depth=6, model__min_child_weight=2, model__n_estimators=971, model__subsample=0.8776807051588262\n",
      "[CV 27/37; 8/30] END model__colsample_bytree=0.6154469128110744, model__learning_rate=0.05820509320520235, model__max_depth=6, model__min_child_weight=7, model__n_estimators=527, model__subsample=0.7475884550556351;, score=-2.705 total time=   5.2s\n",
      "[CV 3/37; 9/30] START model__colsample_bytree=0.5171942605576092, model__learning_rate=0.19186408041575642, model__max_depth=6, model__min_child_weight=2, model__n_estimators=971, model__subsample=0.8776807051588262\n",
      "[CV 2/37; 9/30] END model__colsample_bytree=0.5171942605576092, model__learning_rate=0.19186408041575642, model__max_depth=6, model__min_child_weight=2, model__n_estimators=971, model__subsample=0.8776807051588262;, score=-1.019 total time=   0.4s\n",
      "[CV 4/37; 9/30] START model__colsample_bytree=0.5171942605576092, model__learning_rate=0.19186408041575642, model__max_depth=6, model__min_child_weight=2, model__n_estimators=971, model__subsample=0.8776807051588262\n",
      "[CV 3/37; 9/30] END model__colsample_bytree=0.5171942605576092, model__learning_rate=0.19186408041575642, model__max_depth=6, model__min_child_weight=2, model__n_estimators=971, model__subsample=0.8776807051588262;, score=-14.135 total time=   0.5s\n",
      "[CV 5/37; 9/30] START model__colsample_bytree=0.5171942605576092, model__learning_rate=0.19186408041575642, model__max_depth=6, model__min_child_weight=2, model__n_estimators=971, model__subsample=0.8776807051588262\n",
      "[CV 28/37; 8/30] END model__colsample_bytree=0.6154469128110744, model__learning_rate=0.05820509320520235, model__max_depth=6, model__min_child_weight=7, model__n_estimators=527, model__subsample=0.7475884550556351;, score=-1.117 total time=   5.3s\n",
      "[CV 6/37; 9/30] START model__colsample_bytree=0.5171942605576092, model__learning_rate=0.19186408041575642, model__max_depth=6, model__min_child_weight=2, model__n_estimators=971, model__subsample=0.8776807051588262\n",
      "[CV 4/37; 9/30] END model__colsample_bytree=0.5171942605576092, model__learning_rate=0.19186408041575642, model__max_depth=6, model__min_child_weight=2, model__n_estimators=971, model__subsample=0.8776807051588262;, score=-8.032 total time=   0.5s\n",
      "[CV 7/37; 9/30] START model__colsample_bytree=0.5171942605576092, model__learning_rate=0.19186408041575642, model__max_depth=6, model__min_child_weight=2, model__n_estimators=971, model__subsample=0.8776807051588262\n",
      "[CV 29/37; 8/30] END model__colsample_bytree=0.6154469128110744, model__learning_rate=0.05820509320520235, model__max_depth=6, model__min_child_weight=7, model__n_estimators=527, model__subsample=0.7475884550556351;, score=-9.347 total time=   5.4s\n",
      "[CV 8/37; 9/30] START model__colsample_bytree=0.5171942605576092, model__learning_rate=0.19186408041575642, model__max_depth=6, model__min_child_weight=2, model__n_estimators=971, model__subsample=0.8776807051588262\n",
      "[CV 5/37; 9/30] END model__colsample_bytree=0.5171942605576092, model__learning_rate=0.19186408041575642, model__max_depth=6, model__min_child_weight=2, model__n_estimators=971, model__subsample=0.8776807051588262;, score=-37.095 total time=   0.7s\n",
      "[CV 9/37; 9/30] START model__colsample_bytree=0.5171942605576092, model__learning_rate=0.19186408041575642, model__max_depth=6, model__min_child_weight=2, model__n_estimators=971, model__subsample=0.8776807051588262\n",
      "[CV 30/37; 8/30] END model__colsample_bytree=0.6154469128110744, model__learning_rate=0.05820509320520235, model__max_depth=6, model__min_child_weight=7, model__n_estimators=527, model__subsample=0.7475884550556351;, score=-0.203 total time=   5.6s\n",
      "[CV 10/37; 9/30] START model__colsample_bytree=0.5171942605576092, model__learning_rate=0.19186408041575642, model__max_depth=6, model__min_child_weight=2, model__n_estimators=971, model__subsample=0.8776807051588262\n",
      "[CV 6/37; 9/30] END model__colsample_bytree=0.5171942605576092, model__learning_rate=0.19186408041575642, model__max_depth=6, model__min_child_weight=2, model__n_estimators=971, model__subsample=0.8776807051588262;, score=-0.917 total time=   0.8s\n",
      "[CV 11/37; 9/30] START model__colsample_bytree=0.5171942605576092, model__learning_rate=0.19186408041575642, model__max_depth=6, model__min_child_weight=2, model__n_estimators=971, model__subsample=0.8776807051588262\n",
      "[CV 7/37; 9/30] END model__colsample_bytree=0.5171942605576092, model__learning_rate=0.19186408041575642, model__max_depth=6, model__min_child_weight=2, model__n_estimators=971, model__subsample=0.8776807051588262;, score=-6.037 total time=   1.0s\n",
      "[CV 31/37; 8/30] END model__colsample_bytree=0.6154469128110744, model__learning_rate=0.05820509320520235, model__max_depth=6, model__min_child_weight=7, model__n_estimators=527, model__subsample=0.7475884550556351;, score=-0.053 total time=   5.8s\n",
      "[CV 13/37; 9/30] START model__colsample_bytree=0.5171942605576092, model__learning_rate=0.19186408041575642, model__max_depth=6, model__min_child_weight=2, model__n_estimators=971, model__subsample=0.8776807051588262\n",
      "[CV 12/37; 9/30] START model__colsample_bytree=0.5171942605576092, model__learning_rate=0.19186408041575642, model__max_depth=6, model__min_child_weight=2, model__n_estimators=971, model__subsample=0.8776807051588262\n",
      "[CV 8/37; 9/30] END model__colsample_bytree=0.5171942605576092, model__learning_rate=0.19186408041575642, model__max_depth=6, model__min_child_weight=2, model__n_estimators=971, model__subsample=0.8776807051588262;, score=-9.000 total time=   1.3s\n",
      "[CV 14/37; 9/30] START model__colsample_bytree=0.5171942605576092, model__learning_rate=0.19186408041575642, model__max_depth=6, model__min_child_weight=2, model__n_estimators=971, model__subsample=0.8776807051588262\n",
      "[CV 32/37; 8/30] END model__colsample_bytree=0.6154469128110744, model__learning_rate=0.05820509320520235, model__max_depth=6, model__min_child_weight=7, model__n_estimators=527, model__subsample=0.7475884550556351;, score=-3.546 total time=   5.9s\n",
      "[CV 15/37; 9/30] START model__colsample_bytree=0.5171942605576092, model__learning_rate=0.19186408041575642, model__max_depth=6, model__min_child_weight=2, model__n_estimators=971, model__subsample=0.8776807051588262\n",
      "[CV 9/37; 9/30] END model__colsample_bytree=0.5171942605576092, model__learning_rate=0.19186408041575642, model__max_depth=6, model__min_child_weight=2, model__n_estimators=971, model__subsample=0.8776807051588262;, score=-1.099 total time=   1.5s\n",
      "[CV 16/37; 9/30] START model__colsample_bytree=0.5171942605576092, model__learning_rate=0.19186408041575642, model__max_depth=6, model__min_child_weight=2, model__n_estimators=971, model__subsample=0.8776807051588262\n",
      "[CV 10/37; 9/30] END model__colsample_bytree=0.5171942605576092, model__learning_rate=0.19186408041575642, model__max_depth=6, model__min_child_weight=2, model__n_estimators=971, model__subsample=0.8776807051588262;, score=-32.769 total time=   1.7s\n",
      "[CV 17/37; 9/30] START model__colsample_bytree=0.5171942605576092, model__learning_rate=0.19186408041575642, model__max_depth=6, model__min_child_weight=2, model__n_estimators=971, model__subsample=0.8776807051588262\n",
      "[CV 33/37; 8/30] END model__colsample_bytree=0.6154469128110744, model__learning_rate=0.05820509320520235, model__max_depth=6, model__min_child_weight=7, model__n_estimators=527, model__subsample=0.7475884550556351;, score=-18.145 total time=   6.2s\n",
      "[CV 18/37; 9/30] START model__colsample_bytree=0.5171942605576092, model__learning_rate=0.19186408041575642, model__max_depth=6, model__min_child_weight=2, model__n_estimators=971, model__subsample=0.8776807051588262\n",
      "[CV 11/37; 9/30] END model__colsample_bytree=0.5171942605576092, model__learning_rate=0.19186408041575642, model__max_depth=6, model__min_child_weight=2, model__n_estimators=971, model__subsample=0.8776807051588262;, score=-3.480 total time=   1.9s\n",
      "[CV 19/37; 9/30] START model__colsample_bytree=0.5171942605576092, model__learning_rate=0.19186408041575642, model__max_depth=6, model__min_child_weight=2, model__n_estimators=971, model__subsample=0.8776807051588262\n",
      "[CV 34/37; 8/30] END model__colsample_bytree=0.6154469128110744, model__learning_rate=0.05820509320520235, model__max_depth=6, model__min_child_weight=7, model__n_estimators=527, model__subsample=0.7475884550556351;, score=0.304 total time=   6.4s\n",
      "[CV 20/37; 9/30] START model__colsample_bytree=0.5171942605576092, model__learning_rate=0.19186408041575642, model__max_depth=6, model__min_child_weight=2, model__n_estimators=971, model__subsample=0.8776807051588262\n",
      "[CV 12/37; 9/30] END model__colsample_bytree=0.5171942605576092, model__learning_rate=0.19186408041575642, model__max_depth=6, model__min_child_weight=2, model__n_estimators=971, model__subsample=0.8776807051588262;, score=-17.889 total time=   2.1s\n",
      "[CV 21/37; 9/30] START model__colsample_bytree=0.5171942605576092, model__learning_rate=0.19186408041575642, model__max_depth=6, model__min_child_weight=2, model__n_estimators=971, model__subsample=0.8776807051588262\n",
      "[CV 13/37; 9/30] END model__colsample_bytree=0.5171942605576092, model__learning_rate=0.19186408041575642, model__max_depth=6, model__min_child_weight=2, model__n_estimators=971, model__subsample=0.8776807051588262;, score=-0.099 total time=   2.4s\n",
      "[CV 22/37; 9/30] START model__colsample_bytree=0.5171942605576092, model__learning_rate=0.19186408041575642, model__max_depth=6, model__min_child_weight=2, model__n_estimators=971, model__subsample=0.8776807051588262\n",
      "[CV 35/37; 8/30] END model__colsample_bytree=0.6154469128110744, model__learning_rate=0.05820509320520235, model__max_depth=6, model__min_child_weight=7, model__n_estimators=527, model__subsample=0.7475884550556351;, score=-19.400 total time=   6.5s\n",
      "[CV 23/37; 9/30] START model__colsample_bytree=0.5171942605576092, model__learning_rate=0.19186408041575642, model__max_depth=6, model__min_child_weight=2, model__n_estimators=971, model__subsample=0.8776807051588262\n",
      "[CV 14/37; 9/30] END model__colsample_bytree=0.5171942605576092, model__learning_rate=0.19186408041575642, model__max_depth=6, model__min_child_weight=2, model__n_estimators=971, model__subsample=0.8776807051588262;, score=-15.000 total time=   2.6s\n",
      "[CV 24/37; 9/30] START model__colsample_bytree=0.5171942605576092, model__learning_rate=0.19186408041575642, model__max_depth=6, model__min_child_weight=2, model__n_estimators=971, model__subsample=0.8776807051588262\n",
      "[CV 36/37; 8/30] END model__colsample_bytree=0.6154469128110744, model__learning_rate=0.05820509320520235, model__max_depth=6, model__min_child_weight=7, model__n_estimators=527, model__subsample=0.7475884550556351;, score=-1.209 total time=   6.5s\n",
      "[CV 25/37; 9/30] START model__colsample_bytree=0.5171942605576092, model__learning_rate=0.19186408041575642, model__max_depth=6, model__min_child_weight=2, model__n_estimators=971, model__subsample=0.8776807051588262\n",
      "[CV 15/37; 9/30] END model__colsample_bytree=0.5171942605576092, model__learning_rate=0.19186408041575642, model__max_depth=6, model__min_child_weight=2, model__n_estimators=971, model__subsample=0.8776807051588262;, score=-0.388 total time=   2.8s\n",
      "[CV 26/37; 9/30] START model__colsample_bytree=0.5171942605576092, model__learning_rate=0.19186408041575642, model__max_depth=6, model__min_child_weight=2, model__n_estimators=971, model__subsample=0.8776807051588262\n",
      "[CV 16/37; 9/30] END model__colsample_bytree=0.5171942605576092, model__learning_rate=0.19186408041575642, model__max_depth=6, model__min_child_weight=2, model__n_estimators=971, model__subsample=0.8776807051588262;, score=-0.922 total time=   3.2s\n",
      "[CV 27/37; 9/30] START model__colsample_bytree=0.5171942605576092, model__learning_rate=0.19186408041575642, model__max_depth=6, model__min_child_weight=2, model__n_estimators=971, model__subsample=0.8776807051588262\n",
      "[CV 37/37; 8/30] END model__colsample_bytree=0.6154469128110744, model__learning_rate=0.05820509320520235, model__max_depth=6, model__min_child_weight=7, model__n_estimators=527, model__subsample=0.7475884550556351;, score=-0.169 total time=   6.7s\n",
      "[CV 28/37; 9/30] START model__colsample_bytree=0.5171942605576092, model__learning_rate=0.19186408041575642, model__max_depth=6, model__min_child_weight=2, model__n_estimators=971, model__subsample=0.8776807051588262\n",
      "[CV 17/37; 9/30] END model__colsample_bytree=0.5171942605576092, model__learning_rate=0.19186408041575642, model__max_depth=6, model__min_child_weight=2, model__n_estimators=971, model__subsample=0.8776807051588262;, score=-18.334 total time=   3.5s\n",
      "[CV 29/37; 9/30] START model__colsample_bytree=0.5171942605576092, model__learning_rate=0.19186408041575642, model__max_depth=6, model__min_child_weight=2, model__n_estimators=971, model__subsample=0.8776807051588262\n",
      "[CV 18/37; 9/30] END model__colsample_bytree=0.5171942605576092, model__learning_rate=0.19186408041575642, model__max_depth=6, model__min_child_weight=2, model__n_estimators=971, model__subsample=0.8776807051588262;, score=-0.163 total time=   3.8s\n",
      "[CV 30/37; 9/30] START model__colsample_bytree=0.5171942605576092, model__learning_rate=0.19186408041575642, model__max_depth=6, model__min_child_weight=2, model__n_estimators=971, model__subsample=0.8776807051588262\n",
      "[CV 19/37; 9/30] END model__colsample_bytree=0.5171942605576092, model__learning_rate=0.19186408041575642, model__max_depth=6, model__min_child_weight=2, model__n_estimators=971, model__subsample=0.8776807051588262;, score=-1.149 total time=   4.2s\n",
      "[CV 31/37; 9/30] START model__colsample_bytree=0.5171942605576092, model__learning_rate=0.19186408041575642, model__max_depth=6, model__min_child_weight=2, model__n_estimators=971, model__subsample=0.8776807051588262\n",
      "[CV 20/37; 9/30] END model__colsample_bytree=0.5171942605576092, model__learning_rate=0.19186408041575642, model__max_depth=6, model__min_child_weight=2, model__n_estimators=971, model__subsample=0.8776807051588262;, score=-6.421 total time=   4.5s\n",
      "[CV 32/37; 9/30] START model__colsample_bytree=0.5171942605576092, model__learning_rate=0.19186408041575642, model__max_depth=6, model__min_child_weight=2, model__n_estimators=971, model__subsample=0.8776807051588262\n",
      "[CV 21/37; 9/30] END model__colsample_bytree=0.5171942605576092, model__learning_rate=0.19186408041575642, model__max_depth=6, model__min_child_weight=2, model__n_estimators=971, model__subsample=0.8776807051588262;, score=-2.517 total time=   4.7s\n",
      "[CV 33/37; 9/30] START model__colsample_bytree=0.5171942605576092, model__learning_rate=0.19186408041575642, model__max_depth=6, model__min_child_weight=2, model__n_estimators=971, model__subsample=0.8776807051588262\n",
      "[CV 22/37; 9/30] END model__colsample_bytree=0.5171942605576092, model__learning_rate=0.19186408041575642, model__max_depth=6, model__min_child_weight=2, model__n_estimators=971, model__subsample=0.8776807051588262;, score=-0.775 total time=   5.2s\n",
      "[CV 34/37; 9/30] START model__colsample_bytree=0.5171942605576092, model__learning_rate=0.19186408041575642, model__max_depth=6, model__min_child_weight=2, model__n_estimators=971, model__subsample=0.8776807051588262\n",
      "[CV 23/37; 9/30] END model__colsample_bytree=0.5171942605576092, model__learning_rate=0.19186408041575642, model__max_depth=6, model__min_child_weight=2, model__n_estimators=971, model__subsample=0.8776807051588262;, score=-11.323 total time=   5.5s\n",
      "[CV 35/37; 9/30] START model__colsample_bytree=0.5171942605576092, model__learning_rate=0.19186408041575642, model__max_depth=6, model__min_child_weight=2, model__n_estimators=971, model__subsample=0.8776807051588262\n",
      "[CV 24/37; 9/30] END model__colsample_bytree=0.5171942605576092, model__learning_rate=0.19186408041575642, model__max_depth=6, model__min_child_weight=2, model__n_estimators=971, model__subsample=0.8776807051588262;, score=-6.278 total time=   6.0s\n",
      "[CV 36/37; 9/30] START model__colsample_bytree=0.5171942605576092, model__learning_rate=0.19186408041575642, model__max_depth=6, model__min_child_weight=2, model__n_estimators=971, model__subsample=0.8776807051588262\n",
      "[CV 25/37; 9/30] END model__colsample_bytree=0.5171942605576092, model__learning_rate=0.19186408041575642, model__max_depth=6, model__min_child_weight=2, model__n_estimators=971, model__subsample=0.8776807051588262;, score=-1.480 total time=   6.4s\n",
      "[CV 37/37; 9/30] START model__colsample_bytree=0.5171942605576092, model__learning_rate=0.19186408041575642, model__max_depth=6, model__min_child_weight=2, model__n_estimators=971, model__subsample=0.8776807051588262\n",
      "[CV 26/37; 9/30] END model__colsample_bytree=0.5171942605576092, model__learning_rate=0.19186408041575642, model__max_depth=6, model__min_child_weight=2, model__n_estimators=971, model__subsample=0.8776807051588262;, score=-2.222 total time=   6.8s\n",
      "[CV 1/37; 10/30] START model__colsample_bytree=0.7125779372456224, model__learning_rate=0.05158833257363777, model__max_depth=6, model__min_child_weight=6, model__n_estimators=576, model__subsample=0.9847923138822793\n",
      "[CV 1/37; 10/30] END model__colsample_bytree=0.7125779372456224, model__learning_rate=0.05158833257363777, model__max_depth=6, model__min_child_weight=6, model__n_estimators=576, model__subsample=0.9847923138822793;, score=-40.059 total time=   0.4s\n",
      "[CV 2/37; 10/30] START model__colsample_bytree=0.7125779372456224, model__learning_rate=0.05158833257363777, model__max_depth=6, model__min_child_weight=6, model__n_estimators=576, model__subsample=0.9847923138822793\n",
      "[CV 27/37; 9/30] END model__colsample_bytree=0.5171942605576092, model__learning_rate=0.19186408041575642, model__max_depth=6, model__min_child_weight=2, model__n_estimators=971, model__subsample=0.8776807051588262;, score=-3.928 total time=   7.1s\n",
      "[CV 3/37; 10/30] START model__colsample_bytree=0.7125779372456224, model__learning_rate=0.05158833257363777, model__max_depth=6, model__min_child_weight=6, model__n_estimators=576, model__subsample=0.9847923138822793\n",
      "[CV 2/37; 10/30] END model__colsample_bytree=0.7125779372456224, model__learning_rate=0.05158833257363777, model__max_depth=6, model__min_child_weight=6, model__n_estimators=576, model__subsample=0.9847923138822793;, score=-0.492 total time=   0.5s\n",
      "[CV 4/37; 10/30] START model__colsample_bytree=0.7125779372456224, model__learning_rate=0.05158833257363777, model__max_depth=6, model__min_child_weight=6, model__n_estimators=576, model__subsample=0.9847923138822793\n",
      "[CV 28/37; 9/30] END model__colsample_bytree=0.5171942605576092, model__learning_rate=0.19186408041575642, model__max_depth=6, model__min_child_weight=2, model__n_estimators=971, model__subsample=0.8776807051588262;, score=-2.259 total time=   7.4s\n",
      "[CV 5/37; 10/30] START model__colsample_bytree=0.7125779372456224, model__learning_rate=0.05158833257363777, model__max_depth=6, model__min_child_weight=6, model__n_estimators=576, model__subsample=0.9847923138822793\n",
      "[CV 3/37; 10/30] END model__colsample_bytree=0.7125779372456224, model__learning_rate=0.05158833257363777, model__max_depth=6, model__min_child_weight=6, model__n_estimators=576, model__subsample=0.9847923138822793;, score=-16.448 total time=   0.9s\n",
      "[CV 6/37; 10/30] START model__colsample_bytree=0.7125779372456224, model__learning_rate=0.05158833257363777, model__max_depth=6, model__min_child_weight=6, model__n_estimators=576, model__subsample=0.9847923138822793\n",
      "[CV 4/37; 10/30] END model__colsample_bytree=0.7125779372456224, model__learning_rate=0.05158833257363777, model__max_depth=6, model__min_child_weight=6, model__n_estimators=576, model__subsample=0.9847923138822793;, score=-7.400 total time=   1.1s\n",
      "[CV 7/37; 10/30] START model__colsample_bytree=0.7125779372456224, model__learning_rate=0.05158833257363777, model__max_depth=6, model__min_child_weight=6, model__n_estimators=576, model__subsample=0.9847923138822793\n",
      "[CV 29/37; 9/30] END model__colsample_bytree=0.5171942605576092, model__learning_rate=0.19186408041575642, model__max_depth=6, model__min_child_weight=2, model__n_estimators=971, model__subsample=0.8776807051588262;, score=-10.278 total time=   7.8s\n",
      "[CV 8/37; 10/30] START model__colsample_bytree=0.7125779372456224, model__learning_rate=0.05158833257363777, model__max_depth=6, model__min_child_weight=6, model__n_estimators=576, model__subsample=0.9847923138822793\n",
      "[CV 5/37; 10/30] END model__colsample_bytree=0.7125779372456224, model__learning_rate=0.05158833257363777, model__max_depth=6, model__min_child_weight=6, model__n_estimators=576, model__subsample=0.9847923138822793;, score=-36.992 total time=   1.4s\n",
      "[CV 9/37; 10/30] START model__colsample_bytree=0.7125779372456224, model__learning_rate=0.05158833257363777, model__max_depth=6, model__min_child_weight=6, model__n_estimators=576, model__subsample=0.9847923138822793\n",
      "[CV 30/37; 9/30] END model__colsample_bytree=0.5171942605576092, model__learning_rate=0.19186408041575642, model__max_depth=6, model__min_child_weight=2, model__n_estimators=971, model__subsample=0.8776807051588262;, score=-0.365 total time=   8.1s\n",
      "[CV 10/37; 10/30] START model__colsample_bytree=0.7125779372456224, model__learning_rate=0.05158833257363777, model__max_depth=6, model__min_child_weight=6, model__n_estimators=576, model__subsample=0.9847923138822793\n",
      "[CV 6/37; 10/30] END model__colsample_bytree=0.7125779372456224, model__learning_rate=0.05158833257363777, model__max_depth=6, model__min_child_weight=6, model__n_estimators=576, model__subsample=0.9847923138822793;, score=-1.019 total time=   1.7s\n",
      "[CV 11/37; 10/30] START model__colsample_bytree=0.7125779372456224, model__learning_rate=0.05158833257363777, model__max_depth=6, model__min_child_weight=6, model__n_estimators=576, model__subsample=0.9847923138822793\n",
      "[CV 31/37; 9/30] END model__colsample_bytree=0.5171942605576092, model__learning_rate=0.19186408041575642, model__max_depth=6, model__min_child_weight=2, model__n_estimators=971, model__subsample=0.8776807051588262;, score=-1.362 total time=   8.3s\n",
      "[CV 12/37; 10/30] START model__colsample_bytree=0.7125779372456224, model__learning_rate=0.05158833257363777, model__max_depth=6, model__min_child_weight=6, model__n_estimators=576, model__subsample=0.9847923138822793\n",
      "[CV 7/37; 10/30] END model__colsample_bytree=0.7125779372456224, model__learning_rate=0.05158833257363777, model__max_depth=6, model__min_child_weight=6, model__n_estimators=576, model__subsample=0.9847923138822793;, score=-5.889 total time=   1.8s\n",
      "[CV 13/37; 10/30] START model__colsample_bytree=0.7125779372456224, model__learning_rate=0.05158833257363777, model__max_depth=6, model__min_child_weight=6, model__n_estimators=576, model__subsample=0.9847923138822793\n",
      "[CV 8/37; 10/30] END model__colsample_bytree=0.7125779372456224, model__learning_rate=0.05158833257363777, model__max_depth=6, model__min_child_weight=6, model__n_estimators=576, model__subsample=0.9847923138822793;, score=-8.252 total time=   2.0s\n",
      "[CV 14/37; 10/30] START model__colsample_bytree=0.7125779372456224, model__learning_rate=0.05158833257363777, model__max_depth=6, model__min_child_weight=6, model__n_estimators=576, model__subsample=0.9847923138822793\n",
      "[CV 9/37; 10/30] END model__colsample_bytree=0.7125779372456224, model__learning_rate=0.05158833257363777, model__max_depth=6, model__min_child_weight=6, model__n_estimators=576, model__subsample=0.9847923138822793;, score=-0.785 total time=   2.3s\n",
      "[CV 15/37; 10/30] START model__colsample_bytree=0.7125779372456224, model__learning_rate=0.05158833257363777, model__max_depth=6, model__min_child_weight=6, model__n_estimators=576, model__subsample=0.9847923138822793\n",
      "[CV 32/37; 9/30] END model__colsample_bytree=0.5171942605576092, model__learning_rate=0.19186408041575642, model__max_depth=6, model__min_child_weight=2, model__n_estimators=971, model__subsample=0.8776807051588262;, score=-3.425 total time=   8.8s\n",
      "[CV 16/37; 10/30] START model__colsample_bytree=0.7125779372456224, model__learning_rate=0.05158833257363777, model__max_depth=6, model__min_child_weight=6, model__n_estimators=576, model__subsample=0.9847923138822793\n",
      "[CV 10/37; 10/30] END model__colsample_bytree=0.7125779372456224, model__learning_rate=0.05158833257363777, model__max_depth=6, model__min_child_weight=6, model__n_estimators=576, model__subsample=0.9847923138822793;, score=-29.206 total time=   2.4s\n",
      "[CV 17/37; 10/30] START model__colsample_bytree=0.7125779372456224, model__learning_rate=0.05158833257363777, model__max_depth=6, model__min_child_weight=6, model__n_estimators=576, model__subsample=0.9847923138822793\n",
      "[CV 33/37; 9/30] END model__colsample_bytree=0.5171942605576092, model__learning_rate=0.19186408041575642, model__max_depth=6, model__min_child_weight=2, model__n_estimators=971, model__subsample=0.8776807051588262;, score=-19.041 total time=   9.1s\n",
      "[CV 18/37; 10/30] START model__colsample_bytree=0.7125779372456224, model__learning_rate=0.05158833257363777, model__max_depth=6, model__min_child_weight=6, model__n_estimators=576, model__subsample=0.9847923138822793\n",
      "[CV 11/37; 10/30] END model__colsample_bytree=0.7125779372456224, model__learning_rate=0.05158833257363777, model__max_depth=6, model__min_child_weight=6, model__n_estimators=576, model__subsample=0.9847923138822793;, score=-3.178 total time=   2.7s\n",
      "[CV 19/37; 10/30] START model__colsample_bytree=0.7125779372456224, model__learning_rate=0.05158833257363777, model__max_depth=6, model__min_child_weight=6, model__n_estimators=576, model__subsample=0.9847923138822793\n",
      "[CV 34/37; 9/30] END model__colsample_bytree=0.5171942605576092, model__learning_rate=0.19186408041575642, model__max_depth=6, model__min_child_weight=2, model__n_estimators=971, model__subsample=0.8776807051588262;, score=0.158 total time=   9.3s\n",
      "[CV 20/37; 10/30] START model__colsample_bytree=0.7125779372456224, model__learning_rate=0.05158833257363777, model__max_depth=6, model__min_child_weight=6, model__n_estimators=576, model__subsample=0.9847923138822793\n",
      "[CV 12/37; 10/30] END model__colsample_bytree=0.7125779372456224, model__learning_rate=0.05158833257363777, model__max_depth=6, model__min_child_weight=6, model__n_estimators=576, model__subsample=0.9847923138822793;, score=-17.788 total time=   2.9s\n",
      "[CV 21/37; 10/30] START model__colsample_bytree=0.7125779372456224, model__learning_rate=0.05158833257363777, model__max_depth=6, model__min_child_weight=6, model__n_estimators=576, model__subsample=0.9847923138822793\n",
      "[CV 13/37; 10/30] END model__colsample_bytree=0.7125779372456224, model__learning_rate=0.05158833257363777, model__max_depth=6, model__min_child_weight=6, model__n_estimators=576, model__subsample=0.9847923138822793;, score=0.090 total time=   3.1s\n",
      "[CV 22/37; 10/30] START model__colsample_bytree=0.7125779372456224, model__learning_rate=0.05158833257363777, model__max_depth=6, model__min_child_weight=6, model__n_estimators=576, model__subsample=0.9847923138822793\n",
      "[CV 14/37; 10/30] END model__colsample_bytree=0.7125779372456224, model__learning_rate=0.05158833257363777, model__max_depth=6, model__min_child_weight=6, model__n_estimators=576, model__subsample=0.9847923138822793;, score=-21.454 total time=   3.3s\n",
      "[CV 23/37; 10/30] START model__colsample_bytree=0.7125779372456224, model__learning_rate=0.05158833257363777, model__max_depth=6, model__min_child_weight=6, model__n_estimators=576, model__subsample=0.9847923138822793\n",
      "[CV 35/37; 9/30] END model__colsample_bytree=0.5171942605576092, model__learning_rate=0.19186408041575642, model__max_depth=6, model__min_child_weight=2, model__n_estimators=971, model__subsample=0.8776807051588262;, score=-19.860 total time=   9.9s\n",
      "[CV 24/37; 10/30] START model__colsample_bytree=0.7125779372456224, model__learning_rate=0.05158833257363777, model__max_depth=6, model__min_child_weight=6, model__n_estimators=576, model__subsample=0.9847923138822793\n",
      "[CV 15/37; 10/30] END model__colsample_bytree=0.7125779372456224, model__learning_rate=0.05158833257363777, model__max_depth=6, model__min_child_weight=6, model__n_estimators=576, model__subsample=0.9847923138822793;, score=-0.208 total time=   3.4s\n",
      "[CV 25/37; 10/30] START model__colsample_bytree=0.7125779372456224, model__learning_rate=0.05158833257363777, model__max_depth=6, model__min_child_weight=6, model__n_estimators=576, model__subsample=0.9847923138822793\n",
      "[CV 16/37; 10/30] END model__colsample_bytree=0.7125779372456224, model__learning_rate=0.05158833257363777, model__max_depth=6, model__min_child_weight=6, model__n_estimators=576, model__subsample=0.9847923138822793;, score=-0.606 total time=   3.7s\n",
      "[CV 26/37; 10/30] START model__colsample_bytree=0.7125779372456224, model__learning_rate=0.05158833257363777, model__max_depth=6, model__min_child_weight=6, model__n_estimators=576, model__subsample=0.9847923138822793\n",
      "[CV 36/37; 9/30] END model__colsample_bytree=0.5171942605576092, model__learning_rate=0.19186408041575642, model__max_depth=6, model__min_child_weight=2, model__n_estimators=971, model__subsample=0.8776807051588262;, score=-1.294 total time=  10.0s\n",
      "[CV 27/37; 10/30] START model__colsample_bytree=0.7125779372456224, model__learning_rate=0.05158833257363777, model__max_depth=6, model__min_child_weight=6, model__n_estimators=576, model__subsample=0.9847923138822793\n",
      "[CV 17/37; 10/30] END model__colsample_bytree=0.7125779372456224, model__learning_rate=0.05158833257363777, model__max_depth=6, model__min_child_weight=6, model__n_estimators=576, model__subsample=0.9847923138822793;, score=-17.997 total time=   3.9s\n",
      "[CV 28/37; 10/30] START model__colsample_bytree=0.7125779372456224, model__learning_rate=0.05158833257363777, model__max_depth=6, model__min_child_weight=6, model__n_estimators=576, model__subsample=0.9847923138822793\n",
      "[CV 37/37; 9/30] END model__colsample_bytree=0.5171942605576092, model__learning_rate=0.19186408041575642, model__max_depth=6, model__min_child_weight=2, model__n_estimators=971, model__subsample=0.8776807051588262;, score=-0.440 total time=  10.1s\n",
      "[CV 29/37; 10/30] START model__colsample_bytree=0.7125779372456224, model__learning_rate=0.05158833257363777, model__max_depth=6, model__min_child_weight=6, model__n_estimators=576, model__subsample=0.9847923138822793\n",
      "[CV 18/37; 10/30] END model__colsample_bytree=0.7125779372456224, model__learning_rate=0.05158833257363777, model__max_depth=6, model__min_child_weight=6, model__n_estimators=576, model__subsample=0.9847923138822793;, score=-0.743 total time=   4.1s\n",
      "[CV 30/37; 10/30] START model__colsample_bytree=0.7125779372456224, model__learning_rate=0.05158833257363777, model__max_depth=6, model__min_child_weight=6, model__n_estimators=576, model__subsample=0.9847923138822793\n",
      "[CV 19/37; 10/30] END model__colsample_bytree=0.7125779372456224, model__learning_rate=0.05158833257363777, model__max_depth=6, model__min_child_weight=6, model__n_estimators=576, model__subsample=0.9847923138822793;, score=-0.792 total time=   4.2s\n",
      "[CV 31/37; 10/30] START model__colsample_bytree=0.7125779372456224, model__learning_rate=0.05158833257363777, model__max_depth=6, model__min_child_weight=6, model__n_estimators=576, model__subsample=0.9847923138822793\n",
      "[CV 20/37; 10/30] END model__colsample_bytree=0.7125779372456224, model__learning_rate=0.05158833257363777, model__max_depth=6, model__min_child_weight=6, model__n_estimators=576, model__subsample=0.9847923138822793;, score=-3.744 total time=   4.4s\n",
      "[CV 32/37; 10/30] START model__colsample_bytree=0.7125779372456224, model__learning_rate=0.05158833257363777, model__max_depth=6, model__min_child_weight=6, model__n_estimators=576, model__subsample=0.9847923138822793\n",
      "[CV 21/37; 10/30] END model__colsample_bytree=0.7125779372456224, model__learning_rate=0.05158833257363777, model__max_depth=6, model__min_child_weight=6, model__n_estimators=576, model__subsample=0.9847923138822793;, score=-1.152 total time=   4.8s\n",
      "[CV 33/37; 10/30] START model__colsample_bytree=0.7125779372456224, model__learning_rate=0.05158833257363777, model__max_depth=6, model__min_child_weight=6, model__n_estimators=576, model__subsample=0.9847923138822793\n",
      "[CV 22/37; 10/30] END model__colsample_bytree=0.7125779372456224, model__learning_rate=0.05158833257363777, model__max_depth=6, model__min_child_weight=6, model__n_estimators=576, model__subsample=0.9847923138822793;, score=-0.590 total time=   4.8s\n",
      "[CV 34/37; 10/30] START model__colsample_bytree=0.7125779372456224, model__learning_rate=0.05158833257363777, model__max_depth=6, model__min_child_weight=6, model__n_estimators=576, model__subsample=0.9847923138822793\n",
      "[CV 23/37; 10/30] END model__colsample_bytree=0.7125779372456224, model__learning_rate=0.05158833257363777, model__max_depth=6, model__min_child_weight=6, model__n_estimators=576, model__subsample=0.9847923138822793;, score=-11.121 total time=   5.1s\n",
      "[CV 35/37; 10/30] START model__colsample_bytree=0.7125779372456224, model__learning_rate=0.05158833257363777, model__max_depth=6, model__min_child_weight=6, model__n_estimators=576, model__subsample=0.9847923138822793\n",
      "[CV 24/37; 10/30] END model__colsample_bytree=0.7125779372456224, model__learning_rate=0.05158833257363777, model__max_depth=6, model__min_child_weight=6, model__n_estimators=576, model__subsample=0.9847923138822793;, score=-4.229 total time=   5.4s\n",
      "[CV 36/37; 10/30] START model__colsample_bytree=0.7125779372456224, model__learning_rate=0.05158833257363777, model__max_depth=6, model__min_child_weight=6, model__n_estimators=576, model__subsample=0.9847923138822793\n",
      "[CV 25/37; 10/30] END model__colsample_bytree=0.7125779372456224, model__learning_rate=0.05158833257363777, model__max_depth=6, model__min_child_weight=6, model__n_estimators=576, model__subsample=0.9847923138822793;, score=-1.271 total time=   5.7s\n",
      "[CV 37/37; 10/30] START model__colsample_bytree=0.7125779372456224, model__learning_rate=0.05158833257363777, model__max_depth=6, model__min_child_weight=6, model__n_estimators=576, model__subsample=0.9847923138822793\n",
      "[CV 26/37; 10/30] END model__colsample_bytree=0.7125779372456224, model__learning_rate=0.05158833257363777, model__max_depth=6, model__min_child_weight=6, model__n_estimators=576, model__subsample=0.9847923138822793;, score=-1.569 total time=   5.7s\n",
      "[CV 1/37; 11/30] START model__colsample_bytree=0.8875664116805573, model__learning_rate=0.19789978831283783, model__max_depth=8, model__min_child_weight=4, model__n_estimators=369, model__subsample=0.8636359979282104\n",
      "[CV 1/37; 11/30] END model__colsample_bytree=0.8875664116805573, model__learning_rate=0.19789978831283783, model__max_depth=8, model__min_child_weight=4, model__n_estimators=369, model__subsample=0.8636359979282104;, score=-43.062 total time=   0.2s\n",
      "[CV 2/37; 11/30] START model__colsample_bytree=0.8875664116805573, model__learning_rate=0.19789978831283783, model__max_depth=8, model__min_child_weight=4, model__n_estimators=369, model__subsample=0.8636359979282104\n",
      "[CV 2/37; 11/30] END model__colsample_bytree=0.8875664116805573, model__learning_rate=0.19789978831283783, model__max_depth=8, model__min_child_weight=4, model__n_estimators=369, model__subsample=0.8636359979282104;, score=-0.436 total time=   0.3s\n",
      "[CV 3/37; 11/30] START model__colsample_bytree=0.8875664116805573, model__learning_rate=0.19789978831283783, model__max_depth=8, model__min_child_weight=4, model__n_estimators=369, model__subsample=0.8636359979282104\n",
      "[CV 27/37; 10/30] END model__colsample_bytree=0.7125779372456224, model__learning_rate=0.05158833257363777, model__max_depth=6, model__min_child_weight=6, model__n_estimators=576, model__subsample=0.9847923138822793;, score=-2.597 total time=   6.3s\n",
      "[CV 4/37; 11/30] START model__colsample_bytree=0.8875664116805573, model__learning_rate=0.19789978831283783, model__max_depth=8, model__min_child_weight=4, model__n_estimators=369, model__subsample=0.8636359979282104\n",
      "[CV 3/37; 11/30] END model__colsample_bytree=0.8875664116805573, model__learning_rate=0.19789978831283783, model__max_depth=8, model__min_child_weight=4, model__n_estimators=369, model__subsample=0.8636359979282104;, score=-19.227 total time=   0.3s\n",
      "[CV 5/37; 11/30] START model__colsample_bytree=0.8875664116805573, model__learning_rate=0.19789978831283783, model__max_depth=8, model__min_child_weight=4, model__n_estimators=369, model__subsample=0.8636359979282104\n",
      "[CV 4/37; 11/30] END model__colsample_bytree=0.8875664116805573, model__learning_rate=0.19789978831283783, model__max_depth=8, model__min_child_weight=4, model__n_estimators=369, model__subsample=0.8636359979282104;, score=-7.810 total time=   0.5s\n",
      "[CV 6/37; 11/30] START model__colsample_bytree=0.8875664116805573, model__learning_rate=0.19789978831283783, model__max_depth=8, model__min_child_weight=4, model__n_estimators=369, model__subsample=0.8636359979282104\n",
      "[CV 28/37; 10/30] END model__colsample_bytree=0.7125779372456224, model__learning_rate=0.05158833257363777, model__max_depth=6, model__min_child_weight=6, model__n_estimators=576, model__subsample=0.9847923138822793;, score=-1.203 total time=   6.4s\n",
      "[CV 7/37; 11/30] START model__colsample_bytree=0.8875664116805573, model__learning_rate=0.19789978831283783, model__max_depth=8, model__min_child_weight=4, model__n_estimators=369, model__subsample=0.8636359979282104\n",
      "[CV 5/37; 11/30] END model__colsample_bytree=0.8875664116805573, model__learning_rate=0.19789978831283783, model__max_depth=8, model__min_child_weight=4, model__n_estimators=369, model__subsample=0.8636359979282104;, score=-38.805 total time=   0.6s\n",
      "[CV 8/37; 11/30] START model__colsample_bytree=0.8875664116805573, model__learning_rate=0.19789978831283783, model__max_depth=8, model__min_child_weight=4, model__n_estimators=369, model__subsample=0.8636359979282104\n",
      "[CV 29/37; 10/30] END model__colsample_bytree=0.7125779372456224, model__learning_rate=0.05158833257363777, model__max_depth=6, model__min_child_weight=6, model__n_estimators=576, model__subsample=0.9847923138822793;, score=-8.225 total time=   6.7s\n",
      "[CV 9/37; 11/30] START model__colsample_bytree=0.8875664116805573, model__learning_rate=0.19789978831283783, model__max_depth=8, model__min_child_weight=4, model__n_estimators=369, model__subsample=0.8636359979282104\n",
      "[CV 6/37; 11/30] END model__colsample_bytree=0.8875664116805573, model__learning_rate=0.19789978831283783, model__max_depth=8, model__min_child_weight=4, model__n_estimators=369, model__subsample=0.8636359979282104;, score=-1.458 total time=   0.7s\n",
      "[CV 10/37; 11/30] START model__colsample_bytree=0.8875664116805573, model__learning_rate=0.19789978831283783, model__max_depth=8, model__min_child_weight=4, model__n_estimators=369, model__subsample=0.8636359979282104\n",
      "[CV 30/37; 10/30] END model__colsample_bytree=0.7125779372456224, model__learning_rate=0.05158833257363777, model__max_depth=6, model__min_child_weight=6, model__n_estimators=576, model__subsample=0.9847923138822793;, score=-0.181 total time=   6.8s\n",
      "[CV 11/37; 11/30] START model__colsample_bytree=0.8875664116805573, model__learning_rate=0.19789978831283783, model__max_depth=8, model__min_child_weight=4, model__n_estimators=369, model__subsample=0.8636359979282104\n",
      "[CV 7/37; 11/30] END model__colsample_bytree=0.8875664116805573, model__learning_rate=0.19789978831283783, model__max_depth=8, model__min_child_weight=4, model__n_estimators=369, model__subsample=0.8636359979282104;, score=-6.526 total time=   0.9s\n",
      "[CV 12/37; 11/30] START model__colsample_bytree=0.8875664116805573, model__learning_rate=0.19789978831283783, model__max_depth=8, model__min_child_weight=4, model__n_estimators=369, model__subsample=0.8636359979282104\n",
      "[CV 8/37; 11/30] END model__colsample_bytree=0.8875664116805573, model__learning_rate=0.19789978831283783, model__max_depth=8, model__min_child_weight=4, model__n_estimators=369, model__subsample=0.8636359979282104;, score=-9.179 total time=   1.1s\n",
      "[CV 13/37; 11/30] START model__colsample_bytree=0.8875664116805573, model__learning_rate=0.19789978831283783, model__max_depth=8, model__min_child_weight=4, model__n_estimators=369, model__subsample=0.8636359979282104\n",
      "[CV 31/37; 10/30] END model__colsample_bytree=0.7125779372456224, model__learning_rate=0.05158833257363777, model__max_depth=6, model__min_child_weight=6, model__n_estimators=576, model__subsample=0.9847923138822793;, score=-0.643 total time=   7.0s\n",
      "[CV 14/37; 11/30] START model__colsample_bytree=0.8875664116805573, model__learning_rate=0.19789978831283783, model__max_depth=8, model__min_child_weight=4, model__n_estimators=369, model__subsample=0.8636359979282104\n",
      "[CV 9/37; 11/30] END model__colsample_bytree=0.8875664116805573, model__learning_rate=0.19789978831283783, model__max_depth=8, model__min_child_weight=4, model__n_estimators=369, model__subsample=0.8636359979282104;, score=-0.496 total time=   1.2s\n",
      "[CV 15/37; 11/30] START model__colsample_bytree=0.8875664116805573, model__learning_rate=0.19789978831283783, model__max_depth=8, model__min_child_weight=4, model__n_estimators=369, model__subsample=0.8636359979282104\n",
      "[CV 10/37; 11/30] END model__colsample_bytree=0.8875664116805573, model__learning_rate=0.19789978831283783, model__max_depth=8, model__min_child_weight=4, model__n_estimators=369, model__subsample=0.8636359979282104;, score=-33.934 total time=   1.5s\n",
      "[CV 16/37; 11/30] START model__colsample_bytree=0.8875664116805573, model__learning_rate=0.19789978831283783, model__max_depth=8, model__min_child_weight=4, model__n_estimators=369, model__subsample=0.8636359979282104\n",
      "[CV 11/37; 11/30] END model__colsample_bytree=0.8875664116805573, model__learning_rate=0.19789978831283783, model__max_depth=8, model__min_child_weight=4, model__n_estimators=369, model__subsample=0.8636359979282104;, score=-4.008 total time=   1.7s\n",
      "[CV 17/37; 11/30] START model__colsample_bytree=0.8875664116805573, model__learning_rate=0.19789978831283783, model__max_depth=8, model__min_child_weight=4, model__n_estimators=369, model__subsample=0.8636359979282104\n",
      "[CV 32/37; 10/30] END model__colsample_bytree=0.7125779372456224, model__learning_rate=0.05158833257363777, model__max_depth=6, model__min_child_weight=6, model__n_estimators=576, model__subsample=0.9847923138822793;, score=-3.285 total time=   7.2s\n",
      "[CV 18/37; 11/30] START model__colsample_bytree=0.8875664116805573, model__learning_rate=0.19789978831283783, model__max_depth=8, model__min_child_weight=4, model__n_estimators=369, model__subsample=0.8636359979282104\n",
      "[CV 12/37; 11/30] END model__colsample_bytree=0.8875664116805573, model__learning_rate=0.19789978831283783, model__max_depth=8, model__min_child_weight=4, model__n_estimators=369, model__subsample=0.8636359979282104;, score=-19.400 total time=   1.8s\n",
      "[CV 19/37; 11/30] START model__colsample_bytree=0.8875664116805573, model__learning_rate=0.19789978831283783, model__max_depth=8, model__min_child_weight=4, model__n_estimators=369, model__subsample=0.8636359979282104\n",
      "[CV 33/37; 10/30] END model__colsample_bytree=0.7125779372456224, model__learning_rate=0.05158833257363777, model__max_depth=6, model__min_child_weight=6, model__n_estimators=576, model__subsample=0.9847923138822793;, score=-19.620 total time=   7.5s\n",
      "[CV 20/37; 11/30] START model__colsample_bytree=0.8875664116805573, model__learning_rate=0.19789978831283783, model__max_depth=8, model__min_child_weight=4, model__n_estimators=369, model__subsample=0.8636359979282104\n",
      "[CV 13/37; 11/30] END model__colsample_bytree=0.8875664116805573, model__learning_rate=0.19789978831283783, model__max_depth=8, model__min_child_weight=4, model__n_estimators=369, model__subsample=0.8636359979282104;, score=0.188 total time=   2.0s\n",
      "[CV 21/37; 11/30] START model__colsample_bytree=0.8875664116805573, model__learning_rate=0.19789978831283783, model__max_depth=8, model__min_child_weight=4, model__n_estimators=369, model__subsample=0.8636359979282104\n",
      "[CV 34/37; 10/30] END model__colsample_bytree=0.7125779372456224, model__learning_rate=0.05158833257363777, model__max_depth=6, model__min_child_weight=6, model__n_estimators=576, model__subsample=0.9847923138822793;, score=0.113 total time=   7.6s\n",
      "[CV 22/37; 11/30] START model__colsample_bytree=0.8875664116805573, model__learning_rate=0.19789978831283783, model__max_depth=8, model__min_child_weight=4, model__n_estimators=369, model__subsample=0.8636359979282104\n",
      "[CV 14/37; 11/30] END model__colsample_bytree=0.8875664116805573, model__learning_rate=0.19789978831283783, model__max_depth=8, model__min_child_weight=4, model__n_estimators=369, model__subsample=0.8636359979282104;, score=-20.008 total time=   2.3s\n",
      "[CV 23/37; 11/30] START model__colsample_bytree=0.8875664116805573, model__learning_rate=0.19789978831283783, model__max_depth=8, model__min_child_weight=4, model__n_estimators=369, model__subsample=0.8636359979282104\n",
      "[CV 15/37; 11/30] END model__colsample_bytree=0.8875664116805573, model__learning_rate=0.19789978831283783, model__max_depth=8, model__min_child_weight=4, model__n_estimators=369, model__subsample=0.8636359979282104;, score=-0.253 total time=   2.5s\n",
      "[CV 24/37; 11/30] START model__colsample_bytree=0.8875664116805573, model__learning_rate=0.19789978831283783, model__max_depth=8, model__min_child_weight=4, model__n_estimators=369, model__subsample=0.8636359979282104\n",
      "[CV 35/37; 10/30] END model__colsample_bytree=0.7125779372456224, model__learning_rate=0.05158833257363777, model__max_depth=6, model__min_child_weight=6, model__n_estimators=576, model__subsample=0.9847923138822793;, score=-18.705 total time=   7.9s\n",
      "[CV 25/37; 11/30] START model__colsample_bytree=0.8875664116805573, model__learning_rate=0.19789978831283783, model__max_depth=8, model__min_child_weight=4, model__n_estimators=369, model__subsample=0.8636359979282104\n",
      "[CV 16/37; 11/30] END model__colsample_bytree=0.8875664116805573, model__learning_rate=0.19789978831283783, model__max_depth=8, model__min_child_weight=4, model__n_estimators=369, model__subsample=0.8636359979282104;, score=-0.982 total time=   2.8s\n",
      "[CV 26/37; 11/30] START model__colsample_bytree=0.8875664116805573, model__learning_rate=0.19789978831283783, model__max_depth=8, model__min_child_weight=4, model__n_estimators=369, model__subsample=0.8636359979282104\n",
      "[CV 17/37; 11/30] END model__colsample_bytree=0.8875664116805573, model__learning_rate=0.19789978831283783, model__max_depth=8, model__min_child_weight=4, model__n_estimators=369, model__subsample=0.8636359979282104;, score=-18.670 total time=   3.1s\n",
      "[CV 27/37; 11/30] START model__colsample_bytree=0.8875664116805573, model__learning_rate=0.19789978831283783, model__max_depth=8, model__min_child_weight=4, model__n_estimators=369, model__subsample=0.8636359979282104\n",
      "[CV 18/37; 11/30] END model__colsample_bytree=0.8875664116805573, model__learning_rate=0.19789978831283783, model__max_depth=8, model__min_child_weight=4, model__n_estimators=369, model__subsample=0.8636359979282104;, score=-0.511 total time=   3.2s\n",
      "[CV 28/37; 11/30] START model__colsample_bytree=0.8875664116805573, model__learning_rate=0.19789978831283783, model__max_depth=8, model__min_child_weight=4, model__n_estimators=369, model__subsample=0.8636359979282104\n",
      "[CV 36/37; 10/30] END model__colsample_bytree=0.7125779372456224, model__learning_rate=0.05158833257363777, model__max_depth=6, model__min_child_weight=6, model__n_estimators=576, model__subsample=0.9847923138822793;, score=-1.183 total time=   8.1s\n",
      "[CV 29/37; 11/30] START model__colsample_bytree=0.8875664116805573, model__learning_rate=0.19789978831283783, model__max_depth=8, model__min_child_weight=4, model__n_estimators=369, model__subsample=0.8636359979282104\n",
      "[CV 19/37; 11/30] END model__colsample_bytree=0.8875664116805573, model__learning_rate=0.19789978831283783, model__max_depth=8, model__min_child_weight=4, model__n_estimators=369, model__subsample=0.8636359979282104;, score=-1.100 total time=   3.6s\n",
      "[CV 30/37; 11/30] START model__colsample_bytree=0.8875664116805573, model__learning_rate=0.19789978831283783, model__max_depth=8, model__min_child_weight=4, model__n_estimators=369, model__subsample=0.8636359979282104\n",
      "[CV 37/37; 10/30] END model__colsample_bytree=0.7125779372456224, model__learning_rate=0.05158833257363777, model__max_depth=6, model__min_child_weight=6, model__n_estimators=576, model__subsample=0.9847923138822793;, score=-0.073 total time=   8.2s\n",
      "[CV 31/37; 11/30] START model__colsample_bytree=0.8875664116805573, model__learning_rate=0.19789978831283783, model__max_depth=8, model__min_child_weight=4, model__n_estimators=369, model__subsample=0.8636359979282104\n",
      "[CV 20/37; 11/30] END model__colsample_bytree=0.8875664116805573, model__learning_rate=0.19789978831283783, model__max_depth=8, model__min_child_weight=4, model__n_estimators=369, model__subsample=0.8636359979282104;, score=-4.716 total time=   4.1s\n",
      "[CV 32/37; 11/30] START model__colsample_bytree=0.8875664116805573, model__learning_rate=0.19789978831283783, model__max_depth=8, model__min_child_weight=4, model__n_estimators=369, model__subsample=0.8636359979282104\n",
      "[CV 21/37; 11/30] END model__colsample_bytree=0.8875664116805573, model__learning_rate=0.19789978831283783, model__max_depth=8, model__min_child_weight=4, model__n_estimators=369, model__subsample=0.8636359979282104;, score=-2.050 total time=   4.3s\n",
      "[CV 33/37; 11/30] START model__colsample_bytree=0.8875664116805573, model__learning_rate=0.19789978831283783, model__max_depth=8, model__min_child_weight=4, model__n_estimators=369, model__subsample=0.8636359979282104\n",
      "[CV 22/37; 11/30] END model__colsample_bytree=0.8875664116805573, model__learning_rate=0.19789978831283783, model__max_depth=8, model__min_child_weight=4, model__n_estimators=369, model__subsample=0.8636359979282104;, score=-0.555 total time=   4.5s\n",
      "[CV 34/37; 11/30] START model__colsample_bytree=0.8875664116805573, model__learning_rate=0.19789978831283783, model__max_depth=8, model__min_child_weight=4, model__n_estimators=369, model__subsample=0.8636359979282104\n",
      "[CV 23/37; 11/30] END model__colsample_bytree=0.8875664116805573, model__learning_rate=0.19789978831283783, model__max_depth=8, model__min_child_weight=4, model__n_estimators=369, model__subsample=0.8636359979282104;, score=-11.541 total time=   4.9s\n",
      "[CV 35/37; 11/30] START model__colsample_bytree=0.8875664116805573, model__learning_rate=0.19789978831283783, model__max_depth=8, model__min_child_weight=4, model__n_estimators=369, model__subsample=0.8636359979282104\n",
      "[CV 24/37; 11/30] END model__colsample_bytree=0.8875664116805573, model__learning_rate=0.19789978831283783, model__max_depth=8, model__min_child_weight=4, model__n_estimators=369, model__subsample=0.8636359979282104;, score=-8.399 total time=   5.4s\n",
      "[CV 36/37; 11/30] START model__colsample_bytree=0.8875664116805573, model__learning_rate=0.19789978831283783, model__max_depth=8, model__min_child_weight=4, model__n_estimators=369, model__subsample=0.8636359979282104\n",
      "[CV 25/37; 11/30] END model__colsample_bytree=0.8875664116805573, model__learning_rate=0.19789978831283783, model__max_depth=8, model__min_child_weight=4, model__n_estimators=369, model__subsample=0.8636359979282104;, score=-1.721 total time=   5.7s\n",
      "[CV 37/37; 11/30] START model__colsample_bytree=0.8875664116805573, model__learning_rate=0.19789978831283783, model__max_depth=8, model__min_child_weight=4, model__n_estimators=369, model__subsample=0.8636359979282104\n",
      "[CV 26/37; 11/30] END model__colsample_bytree=0.8875664116805573, model__learning_rate=0.19789978831283783, model__max_depth=8, model__min_child_weight=4, model__n_estimators=369, model__subsample=0.8636359979282104;, score=-1.312 total time=   5.9s\n",
      "[CV 1/37; 12/30] START model__colsample_bytree=0.6632703844029177, model__learning_rate=0.12408879488107988, model__max_depth=6, model__min_child_weight=9, model__n_estimators=801, model__subsample=0.6626651653816322\n",
      "[CV 1/37; 12/30] END model__colsample_bytree=0.6632703844029177, model__learning_rate=0.12408879488107988, model__max_depth=6, model__min_child_weight=9, model__n_estimators=801, model__subsample=0.6626651653816322;, score=-42.670 total time=   0.3s\n",
      "[CV 2/37; 12/30] START model__colsample_bytree=0.6632703844029177, model__learning_rate=0.12408879488107988, model__max_depth=6, model__min_child_weight=9, model__n_estimators=801, model__subsample=0.6626651653816322\n",
      "[CV 2/37; 12/30] END model__colsample_bytree=0.6632703844029177, model__learning_rate=0.12408879488107988, model__max_depth=6, model__min_child_weight=9, model__n_estimators=801, model__subsample=0.6626651653816322;, score=-0.443 total time=   0.5s\n",
      "[CV 3/37; 12/30] START model__colsample_bytree=0.6632703844029177, model__learning_rate=0.12408879488107988, model__max_depth=6, model__min_child_weight=9, model__n_estimators=801, model__subsample=0.6626651653816322\n",
      "[CV 27/37; 11/30] END model__colsample_bytree=0.8875664116805573, model__learning_rate=0.19789978831283783, model__max_depth=8, model__min_child_weight=4, model__n_estimators=369, model__subsample=0.8636359979282104;, score=-3.832 total time=   6.2s\n",
      "[CV 4/37; 12/30] START model__colsample_bytree=0.6632703844029177, model__learning_rate=0.12408879488107988, model__max_depth=6, model__min_child_weight=9, model__n_estimators=801, model__subsample=0.6626651653816322\n",
      "[CV 3/37; 12/30] END model__colsample_bytree=0.6632703844029177, model__learning_rate=0.12408879488107988, model__max_depth=6, model__min_child_weight=9, model__n_estimators=801, model__subsample=0.6626651653816322;, score=-14.950 total time=   0.6s\n",
      "[CV 5/37; 12/30] START model__colsample_bytree=0.6632703844029177, model__learning_rate=0.12408879488107988, model__max_depth=6, model__min_child_weight=9, model__n_estimators=801, model__subsample=0.6626651653816322\n",
      "[CV 28/37; 11/30] END model__colsample_bytree=0.8875664116805573, model__learning_rate=0.19789978831283783, model__max_depth=8, model__min_child_weight=4, model__n_estimators=369, model__subsample=0.8636359979282104;, score=-1.598 total time=   6.7s\n",
      "[CV 6/37; 12/30] START model__colsample_bytree=0.6632703844029177, model__learning_rate=0.12408879488107988, model__max_depth=6, model__min_child_weight=9, model__n_estimators=801, model__subsample=0.6626651653816322\n",
      "[CV 4/37; 12/30] END model__colsample_bytree=0.6632703844029177, model__learning_rate=0.12408879488107988, model__max_depth=6, model__min_child_weight=9, model__n_estimators=801, model__subsample=0.6626651653816322;, score=-7.036 total time=   0.9s\n",
      "[CV 7/37; 12/30] START model__colsample_bytree=0.6632703844029177, model__learning_rate=0.12408879488107988, model__max_depth=6, model__min_child_weight=9, model__n_estimators=801, model__subsample=0.6626651653816322\n",
      "[CV 29/37; 11/30] END model__colsample_bytree=0.8875664116805573, model__learning_rate=0.19789978831283783, model__max_depth=8, model__min_child_weight=4, model__n_estimators=369, model__subsample=0.8636359979282104;, score=-8.378 total time=   7.0s\n",
      "[CV 8/37; 12/30] START model__colsample_bytree=0.6632703844029177, model__learning_rate=0.12408879488107988, model__max_depth=6, model__min_child_weight=9, model__n_estimators=801, model__subsample=0.6626651653816322\n",
      "[CV 5/37; 12/30] END model__colsample_bytree=0.6632703844029177, model__learning_rate=0.12408879488107988, model__max_depth=6, model__min_child_weight=9, model__n_estimators=801, model__subsample=0.6626651653816322;, score=-38.088 total time=   1.1s\n",
      "[CV 9/37; 12/30] START model__colsample_bytree=0.6632703844029177, model__learning_rate=0.12408879488107988, model__max_depth=6, model__min_child_weight=9, model__n_estimators=801, model__subsample=0.6626651653816322\n",
      "[CV 30/37; 11/30] END model__colsample_bytree=0.8875664116805573, model__learning_rate=0.19789978831283783, model__max_depth=8, model__min_child_weight=4, model__n_estimators=369, model__subsample=0.8636359979282104;, score=-0.589 total time=   7.4s\n",
      "[CV 10/37; 12/30] START model__colsample_bytree=0.6632703844029177, model__learning_rate=0.12408879488107988, model__max_depth=6, model__min_child_weight=9, model__n_estimators=801, model__subsample=0.6626651653816322\n",
      "[CV 6/37; 12/30] END model__colsample_bytree=0.6632703844029177, model__learning_rate=0.12408879488107988, model__max_depth=6, model__min_child_weight=9, model__n_estimators=801, model__subsample=0.6626651653816322;, score=-1.377 total time=   1.4s\n",
      "[CV 11/37; 12/30] START model__colsample_bytree=0.6632703844029177, model__learning_rate=0.12408879488107988, model__max_depth=6, model__min_child_weight=9, model__n_estimators=801, model__subsample=0.6626651653816322\n",
      "[CV 31/37; 11/30] END model__colsample_bytree=0.8875664116805573, model__learning_rate=0.19789978831283783, model__max_depth=8, model__min_child_weight=4, model__n_estimators=369, model__subsample=0.8636359979282104;, score=-0.526 total time=   7.6s\n",
      "[CV 12/37; 12/30] START model__colsample_bytree=0.6632703844029177, model__learning_rate=0.12408879488107988, model__max_depth=6, model__min_child_weight=9, model__n_estimators=801, model__subsample=0.6626651653816322\n",
      "[CV 7/37; 12/30] END model__colsample_bytree=0.6632703844029177, model__learning_rate=0.12408879488107988, model__max_depth=6, model__min_child_weight=9, model__n_estimators=801, model__subsample=0.6626651653816322;, score=-6.561 total time=   1.8s\n",
      "[CV 13/37; 12/30] START model__colsample_bytree=0.6632703844029177, model__learning_rate=0.12408879488107988, model__max_depth=6, model__min_child_weight=9, model__n_estimators=801, model__subsample=0.6626651653816322\n",
      "[CV 8/37; 12/30] END model__colsample_bytree=0.6632703844029177, model__learning_rate=0.12408879488107988, model__max_depth=6, model__min_child_weight=9, model__n_estimators=801, model__subsample=0.6626651653816322;, score=-9.233 total time=   2.1s\n",
      "[CV 14/37; 12/30] START model__colsample_bytree=0.6632703844029177, model__learning_rate=0.12408879488107988, model__max_depth=6, model__min_child_weight=9, model__n_estimators=801, model__subsample=0.6626651653816322\n",
      "[CV 32/37; 11/30] END model__colsample_bytree=0.8875664116805573, model__learning_rate=0.19789978831283783, model__max_depth=8, model__min_child_weight=4, model__n_estimators=369, model__subsample=0.8636359979282104;, score=-3.381 total time=   8.1s\n",
      "[CV 15/37; 12/30] START model__colsample_bytree=0.6632703844029177, model__learning_rate=0.12408879488107988, model__max_depth=6, model__min_child_weight=9, model__n_estimators=801, model__subsample=0.6626651653816322\n",
      "[CV 9/37; 12/30] END model__colsample_bytree=0.6632703844029177, model__learning_rate=0.12408879488107988, model__max_depth=6, model__min_child_weight=9, model__n_estimators=801, model__subsample=0.6626651653816322;, score=-0.686 total time=   2.5s\n",
      "[CV 16/37; 12/30] START model__colsample_bytree=0.6632703844029177, model__learning_rate=0.12408879488107988, model__max_depth=6, model__min_child_weight=9, model__n_estimators=801, model__subsample=0.6626651653816322\n",
      "[CV 33/37; 11/30] END model__colsample_bytree=0.8875664116805573, model__learning_rate=0.19789978831283783, model__max_depth=8, model__min_child_weight=4, model__n_estimators=369, model__subsample=0.8636359979282104;, score=-21.032 total time=   8.4s\n",
      "[CV 17/37; 12/30] START model__colsample_bytree=0.6632703844029177, model__learning_rate=0.12408879488107988, model__max_depth=6, model__min_child_weight=9, model__n_estimators=801, model__subsample=0.6626651653816322\n",
      "[CV 10/37; 12/30] END model__colsample_bytree=0.6632703844029177, model__learning_rate=0.12408879488107988, model__max_depth=6, model__min_child_weight=9, model__n_estimators=801, model__subsample=0.6626651653816322;, score=-27.019 total time=   2.8s\n",
      "[CV 18/37; 12/30] START model__colsample_bytree=0.6632703844029177, model__learning_rate=0.12408879488107988, model__max_depth=6, model__min_child_weight=9, model__n_estimators=801, model__subsample=0.6626651653816322\n",
      "[CV 34/37; 11/30] END model__colsample_bytree=0.8875664116805573, model__learning_rate=0.19789978831283783, model__max_depth=8, model__min_child_weight=4, model__n_estimators=369, model__subsample=0.8636359979282104;, score=-0.325 total time=   8.7s\n",
      "[CV 19/37; 12/30] START model__colsample_bytree=0.6632703844029177, model__learning_rate=0.12408879488107988, model__max_depth=6, model__min_child_weight=9, model__n_estimators=801, model__subsample=0.6626651653816322\n",
      "[CV 11/37; 12/30] END model__colsample_bytree=0.6632703844029177, model__learning_rate=0.12408879488107988, model__max_depth=6, model__min_child_weight=9, model__n_estimators=801, model__subsample=0.6626651653816322;, score=-4.085 total time=   3.2s\n",
      "[CV 20/37; 12/30] START model__colsample_bytree=0.6632703844029177, model__learning_rate=0.12408879488107988, model__max_depth=6, model__min_child_weight=9, model__n_estimators=801, model__subsample=0.6626651653816322\n",
      "[CV 12/37; 12/30] END model__colsample_bytree=0.6632703844029177, model__learning_rate=0.12408879488107988, model__max_depth=6, model__min_child_weight=9, model__n_estimators=801, model__subsample=0.6626651653816322;, score=-17.488 total time=   3.6s\n",
      "[CV 21/37; 12/30] START model__colsample_bytree=0.6632703844029177, model__learning_rate=0.12408879488107988, model__max_depth=6, model__min_child_weight=9, model__n_estimators=801, model__subsample=0.6626651653816322\n",
      "[CV 35/37; 11/30] END model__colsample_bytree=0.8875664116805573, model__learning_rate=0.19789978831283783, model__max_depth=8, model__min_child_weight=4, model__n_estimators=369, model__subsample=0.8636359979282104;, score=-20.046 total time=   9.0s\n",
      "[CV 22/37; 12/30] START model__colsample_bytree=0.6632703844029177, model__learning_rate=0.12408879488107988, model__max_depth=6, model__min_child_weight=9, model__n_estimators=801, model__subsample=0.6626651653816322\n",
      "[CV 13/37; 12/30] END model__colsample_bytree=0.6632703844029177, model__learning_rate=0.12408879488107988, model__max_depth=6, model__min_child_weight=9, model__n_estimators=801, model__subsample=0.6626651653816322;, score=0.193 total time=   3.8s\n",
      "[CV 23/37; 12/30] START model__colsample_bytree=0.6632703844029177, model__learning_rate=0.12408879488107988, model__max_depth=6, model__min_child_weight=9, model__n_estimators=801, model__subsample=0.6626651653816322\n",
      "[CV 36/37; 11/30] END model__colsample_bytree=0.8875664116805573, model__learning_rate=0.19789978831283783, model__max_depth=8, model__min_child_weight=4, model__n_estimators=369, model__subsample=0.8636359979282104;, score=-1.798 total time=   9.2s\n",
      "[CV 24/37; 12/30] START model__colsample_bytree=0.6632703844029177, model__learning_rate=0.12408879488107988, model__max_depth=6, model__min_child_weight=9, model__n_estimators=801, model__subsample=0.6626651653816322\n",
      "[CV 14/37; 12/30] END model__colsample_bytree=0.6632703844029177, model__learning_rate=0.12408879488107988, model__max_depth=6, model__min_child_weight=9, model__n_estimators=801, model__subsample=0.6626651653816322;, score=-25.597 total time=   4.1s\n",
      "[CV 25/37; 12/30] START model__colsample_bytree=0.6632703844029177, model__learning_rate=0.12408879488107988, model__max_depth=6, model__min_child_weight=9, model__n_estimators=801, model__subsample=0.6626651653816322\n",
      "[CV 15/37; 12/30] END model__colsample_bytree=0.6632703844029177, model__learning_rate=0.12408879488107988, model__max_depth=6, model__min_child_weight=9, model__n_estimators=801, model__subsample=0.6626651653816322;, score=-0.628 total time=   4.3s\n",
      "[CV 26/37; 12/30] START model__colsample_bytree=0.6632703844029177, model__learning_rate=0.12408879488107988, model__max_depth=6, model__min_child_weight=9, model__n_estimators=801, model__subsample=0.6626651653816322\n",
      "[CV 37/37; 11/30] END model__colsample_bytree=0.8875664116805573, model__learning_rate=0.19789978831283783, model__max_depth=8, model__min_child_weight=4, model__n_estimators=369, model__subsample=0.8636359979282104;, score=-0.437 total time=   9.5s\n",
      "[CV 27/37; 12/30] START model__colsample_bytree=0.6632703844029177, model__learning_rate=0.12408879488107988, model__max_depth=6, model__min_child_weight=9, model__n_estimators=801, model__subsample=0.6626651653816322\n",
      "[CV 16/37; 12/30] END model__colsample_bytree=0.6632703844029177, model__learning_rate=0.12408879488107988, model__max_depth=6, model__min_child_weight=9, model__n_estimators=801, model__subsample=0.6626651653816322;, score=-0.943 total time=   4.6s\n",
      "[CV 28/37; 12/30] START model__colsample_bytree=0.6632703844029177, model__learning_rate=0.12408879488107988, model__max_depth=6, model__min_child_weight=9, model__n_estimators=801, model__subsample=0.6626651653816322\n",
      "[CV 17/37; 12/30] END model__colsample_bytree=0.6632703844029177, model__learning_rate=0.12408879488107988, model__max_depth=6, model__min_child_weight=9, model__n_estimators=801, model__subsample=0.6626651653816322;, score=-18.502 total time=   4.7s\n",
      "[CV 29/37; 12/30] START model__colsample_bytree=0.6632703844029177, model__learning_rate=0.12408879488107988, model__max_depth=6, model__min_child_weight=9, model__n_estimators=801, model__subsample=0.6626651653816322\n",
      "[CV 18/37; 12/30] END model__colsample_bytree=0.6632703844029177, model__learning_rate=0.12408879488107988, model__max_depth=6, model__min_child_weight=9, model__n_estimators=801, model__subsample=0.6626651653816322;, score=-0.692 total time=   4.9s\n",
      "[CV 30/37; 12/30] START model__colsample_bytree=0.6632703844029177, model__learning_rate=0.12408879488107988, model__max_depth=6, model__min_child_weight=9, model__n_estimators=801, model__subsample=0.6626651653816322\n",
      "[CV 19/37; 12/30] END model__colsample_bytree=0.6632703844029177, model__learning_rate=0.12408879488107988, model__max_depth=6, model__min_child_weight=9, model__n_estimators=801, model__subsample=0.6626651653816322;, score=-1.150 total time=   5.3s\n",
      "[CV 31/37; 12/30] START model__colsample_bytree=0.6632703844029177, model__learning_rate=0.12408879488107988, model__max_depth=6, model__min_child_weight=9, model__n_estimators=801, model__subsample=0.6626651653816322\n",
      "[CV 20/37; 12/30] END model__colsample_bytree=0.6632703844029177, model__learning_rate=0.12408879488107988, model__max_depth=6, model__min_child_weight=9, model__n_estimators=801, model__subsample=0.6626651653816322;, score=-5.404 total time=   5.5s\n",
      "[CV 32/37; 12/30] START model__colsample_bytree=0.6632703844029177, model__learning_rate=0.12408879488107988, model__max_depth=6, model__min_child_weight=9, model__n_estimators=801, model__subsample=0.6626651653816322\n",
      "[CV 21/37; 12/30] END model__colsample_bytree=0.6632703844029177, model__learning_rate=0.12408879488107988, model__max_depth=6, model__min_child_weight=9, model__n_estimators=801, model__subsample=0.6626651653816322;, score=-1.589 total time=   5.8s\n",
      "[CV 33/37; 12/30] START model__colsample_bytree=0.6632703844029177, model__learning_rate=0.12408879488107988, model__max_depth=6, model__min_child_weight=9, model__n_estimators=801, model__subsample=0.6626651653816322\n",
      "[CV 22/37; 12/30] END model__colsample_bytree=0.6632703844029177, model__learning_rate=0.12408879488107988, model__max_depth=6, model__min_child_weight=9, model__n_estimators=801, model__subsample=0.6626651653816322;, score=-0.571 total time=   6.1s\n",
      "[CV 34/37; 12/30] START model__colsample_bytree=0.6632703844029177, model__learning_rate=0.12408879488107988, model__max_depth=6, model__min_child_weight=9, model__n_estimators=801, model__subsample=0.6626651653816322\n",
      "[CV 23/37; 12/30] END model__colsample_bytree=0.6632703844029177, model__learning_rate=0.12408879488107988, model__max_depth=6, model__min_child_weight=9, model__n_estimators=801, model__subsample=0.6626651653816322;, score=-11.460 total time=   6.3s\n",
      "[CV 35/37; 12/30] START model__colsample_bytree=0.6632703844029177, model__learning_rate=0.12408879488107988, model__max_depth=6, model__min_child_weight=9, model__n_estimators=801, model__subsample=0.6626651653816322\n",
      "[CV 24/37; 12/30] END model__colsample_bytree=0.6632703844029177, model__learning_rate=0.12408879488107988, model__max_depth=6, model__min_child_weight=9, model__n_estimators=801, model__subsample=0.6626651653816322;, score=-6.590 total time=   6.6s\n",
      "[CV 36/37; 12/30] START model__colsample_bytree=0.6632703844029177, model__learning_rate=0.12408879488107988, model__max_depth=6, model__min_child_weight=9, model__n_estimators=801, model__subsample=0.6626651653816322\n",
      "[CV 25/37; 12/30] END model__colsample_bytree=0.6632703844029177, model__learning_rate=0.12408879488107988, model__max_depth=6, model__min_child_weight=9, model__n_estimators=801, model__subsample=0.6626651653816322;, score=-1.095 total time=   6.8s\n",
      "[CV 37/37; 12/30] START model__colsample_bytree=0.6632703844029177, model__learning_rate=0.12408879488107988, model__max_depth=6, model__min_child_weight=9, model__n_estimators=801, model__subsample=0.6626651653816322\n",
      "[CV 26/37; 12/30] END model__colsample_bytree=0.6632703844029177, model__learning_rate=0.12408879488107988, model__max_depth=6, model__min_child_weight=9, model__n_estimators=801, model__subsample=0.6626651653816322;, score=-2.358 total time=   7.0s\n",
      "[CV 1/37; 13/30] START model__colsample_bytree=0.6943386448447411, model__learning_rate=0.06426980635477918, model__max_depth=7, model__min_child_weight=8, model__n_estimators=316, model__subsample=0.6404672548436904\n",
      "[CV 1/37; 13/30] END model__colsample_bytree=0.6943386448447411, model__learning_rate=0.06426980635477918, model__max_depth=7, model__min_child_weight=8, model__n_estimators=316, model__subsample=0.6404672548436904;, score=-39.134 total time=   0.3s\n",
      "[CV 2/37; 13/30] START model__colsample_bytree=0.6943386448447411, model__learning_rate=0.06426980635477918, model__max_depth=7, model__min_child_weight=8, model__n_estimators=316, model__subsample=0.6404672548436904\n",
      "[CV 27/37; 12/30] END model__colsample_bytree=0.6632703844029177, model__learning_rate=0.12408879488107988, model__max_depth=6, model__min_child_weight=9, model__n_estimators=801, model__subsample=0.6626651653816322;, score=-3.847 total time=   7.4s\n",
      "[CV 3/37; 13/30] START model__colsample_bytree=0.6943386448447411, model__learning_rate=0.06426980635477918, model__max_depth=7, model__min_child_weight=8, model__n_estimators=316, model__subsample=0.6404672548436904\n",
      "[CV 2/37; 13/30] END model__colsample_bytree=0.6943386448447411, model__learning_rate=0.06426980635477918, model__max_depth=7, model__min_child_weight=8, model__n_estimators=316, model__subsample=0.6404672548436904;, score=-0.392 total time=   0.5s\n",
      "[CV 4/37; 13/30] START model__colsample_bytree=0.6943386448447411, model__learning_rate=0.06426980635477918, model__max_depth=7, model__min_child_weight=8, model__n_estimators=316, model__subsample=0.6404672548436904\n",
      "[CV 3/37; 13/30] END model__colsample_bytree=0.6943386448447411, model__learning_rate=0.06426980635477918, model__max_depth=7, model__min_child_weight=8, model__n_estimators=316, model__subsample=0.6404672548436904;, score=-13.520 total time=   0.5s\n",
      "[CV 5/37; 13/30] START model__colsample_bytree=0.6943386448447411, model__learning_rate=0.06426980635477918, model__max_depth=7, model__min_child_weight=8, model__n_estimators=316, model__subsample=0.6404672548436904\n",
      "[CV 28/37; 12/30] END model__colsample_bytree=0.6632703844029177, model__learning_rate=0.12408879488107988, model__max_depth=6, model__min_child_weight=9, model__n_estimators=801, model__subsample=0.6626651653816322;, score=-1.541 total time=   7.7s\n",
      "[CV 4/37; 13/30] END model__colsample_bytree=0.6943386448447411, model__learning_rate=0.06426980635477918, model__max_depth=7, model__min_child_weight=8, model__n_estimators=316, model__subsample=0.6404672548436904;, score=-7.663 total time=   0.7s\n",
      "[CV 6/37; 13/30] START model__colsample_bytree=0.6943386448447411, model__learning_rate=0.06426980635477918, model__max_depth=7, model__min_child_weight=8, model__n_estimators=316, model__subsample=0.6404672548436904\n",
      "[CV 5/37; 13/30] END model__colsample_bytree=0.6943386448447411, model__learning_rate=0.06426980635477918, model__max_depth=7, model__min_child_weight=8, model__n_estimators=316, model__subsample=0.6404672548436904;, score=-36.936 total time=   0.7s\n",
      "[CV 8/37; 13/30] START model__colsample_bytree=0.6943386448447411, model__learning_rate=0.06426980635477918, model__max_depth=7, model__min_child_weight=8, model__n_estimators=316, model__subsample=0.6404672548436904\n",
      "[CV 29/37; 12/30] END model__colsample_bytree=0.6632703844029177, model__learning_rate=0.12408879488107988, model__max_depth=6, model__min_child_weight=9, model__n_estimators=801, model__subsample=0.6626651653816322;, score=-9.777 total time=   8.0s\n",
      "[CV 9/37; 13/30] START model__colsample_bytree=0.6943386448447411, model__learning_rate=0.06426980635477918, model__max_depth=7, model__min_child_weight=8, model__n_estimators=316, model__subsample=0.6404672548436904\n",
      "[CV 7/37; 13/30] START model__colsample_bytree=0.6943386448447411, model__learning_rate=0.06426980635477918, model__max_depth=7, model__min_child_weight=8, model__n_estimators=316, model__subsample=0.6404672548436904\n",
      "[CV 6/37; 13/30] END model__colsample_bytree=0.6943386448447411, model__learning_rate=0.06426980635477918, model__max_depth=7, model__min_child_weight=8, model__n_estimators=316, model__subsample=0.6404672548436904;, score=-1.547 total time=   1.0s\n",
      "[CV 10/37; 13/30] START model__colsample_bytree=0.6943386448447411, model__learning_rate=0.06426980635477918, model__max_depth=7, model__min_child_weight=8, model__n_estimators=316, model__subsample=0.6404672548436904\n",
      "[CV 30/37; 12/30] END model__colsample_bytree=0.6632703844029177, model__learning_rate=0.12408879488107988, model__max_depth=6, model__min_child_weight=9, model__n_estimators=801, model__subsample=0.6626651653816322;, score=-0.341 total time=   8.2s\n",
      "[CV 11/37; 13/30] START model__colsample_bytree=0.6943386448447411, model__learning_rate=0.06426980635477918, model__max_depth=7, model__min_child_weight=8, model__n_estimators=316, model__subsample=0.6404672548436904\n",
      "[CV 8/37; 13/30] END model__colsample_bytree=0.6943386448447411, model__learning_rate=0.06426980635477918, model__max_depth=7, model__min_child_weight=8, model__n_estimators=316, model__subsample=0.6404672548436904;, score=-9.220 total time=   1.2s\n",
      "[CV 12/37; 13/30] START model__colsample_bytree=0.6943386448447411, model__learning_rate=0.06426980635477918, model__max_depth=7, model__min_child_weight=8, model__n_estimators=316, model__subsample=0.6404672548436904\n",
      "[CV 9/37; 13/30] END model__colsample_bytree=0.6943386448447411, model__learning_rate=0.06426980635477918, model__max_depth=7, model__min_child_weight=8, model__n_estimators=316, model__subsample=0.6404672548436904;, score=-0.765 total time=   1.3s\n",
      "[CV 13/37; 13/30] START model__colsample_bytree=0.6943386448447411, model__learning_rate=0.06426980635477918, model__max_depth=7, model__min_child_weight=8, model__n_estimators=316, model__subsample=0.6404672548436904\n",
      "[CV 7/37; 13/30] END model__colsample_bytree=0.6943386448447411, model__learning_rate=0.06426980635477918, model__max_depth=7, model__min_child_weight=8, model__n_estimators=316, model__subsample=0.6404672548436904;, score=-5.619 total time=   1.0s\n",
      "[CV 14/37; 13/30] START model__colsample_bytree=0.6943386448447411, model__learning_rate=0.06426980635477918, model__max_depth=7, model__min_child_weight=8, model__n_estimators=316, model__subsample=0.6404672548436904\n",
      "[CV 31/37; 12/30] END model__colsample_bytree=0.6632703844029177, model__learning_rate=0.12408879488107988, model__max_depth=6, model__min_child_weight=9, model__n_estimators=801, model__subsample=0.6626651653816322;, score=-0.213 total time=   8.5s\n",
      "[CV 15/37; 13/30] START model__colsample_bytree=0.6943386448447411, model__learning_rate=0.06426980635477918, model__max_depth=7, model__min_child_weight=8, model__n_estimators=316, model__subsample=0.6404672548436904\n",
      "[CV 10/37; 13/30] END model__colsample_bytree=0.6943386448447411, model__learning_rate=0.06426980635477918, model__max_depth=7, model__min_child_weight=8, model__n_estimators=316, model__subsample=0.6404672548436904;, score=-30.485 total time=   1.4s\n",
      "[CV 16/37; 13/30] START model__colsample_bytree=0.6943386448447411, model__learning_rate=0.06426980635477918, model__max_depth=7, model__min_child_weight=8, model__n_estimators=316, model__subsample=0.6404672548436904\n",
      "[CV 32/37; 12/30] END model__colsample_bytree=0.6632703844029177, model__learning_rate=0.12408879488107988, model__max_depth=6, model__min_child_weight=9, model__n_estimators=801, model__subsample=0.6626651653816322;, score=-3.826 total time=   8.7s\n",
      "[CV 17/37; 13/30] START model__colsample_bytree=0.6943386448447411, model__learning_rate=0.06426980635477918, model__max_depth=7, model__min_child_weight=8, model__n_estimators=316, model__subsample=0.6404672548436904\n",
      "[CV 11/37; 13/30] END model__colsample_bytree=0.6943386448447411, model__learning_rate=0.06426980635477918, model__max_depth=7, model__min_child_weight=8, model__n_estimators=316, model__subsample=0.6404672548436904;, score=-3.008 total time=   1.6s\n",
      "[CV 18/37; 13/30] START model__colsample_bytree=0.6943386448447411, model__learning_rate=0.06426980635477918, model__max_depth=7, model__min_child_weight=8, model__n_estimators=316, model__subsample=0.6404672548436904\n",
      "[CV 12/37; 13/30] END model__colsample_bytree=0.6943386448447411, model__learning_rate=0.06426980635477918, model__max_depth=7, model__min_child_weight=8, model__n_estimators=316, model__subsample=0.6404672548436904;, score=-17.184 total time=   1.7s\n",
      "[CV 19/37; 13/30] START model__colsample_bytree=0.6943386448447411, model__learning_rate=0.06426980635477918, model__max_depth=7, model__min_child_weight=8, model__n_estimators=316, model__subsample=0.6404672548436904\n",
      "[CV 13/37; 13/30] END model__colsample_bytree=0.6943386448447411, model__learning_rate=0.06426980635477918, model__max_depth=7, model__min_child_weight=8, model__n_estimators=316, model__subsample=0.6404672548436904;, score=0.128 total time=   1.8s\n",
      "[CV 20/37; 13/30] START model__colsample_bytree=0.6943386448447411, model__learning_rate=0.06426980635477918, model__max_depth=7, model__min_child_weight=8, model__n_estimators=316, model__subsample=0.6404672548436904\n",
      "[CV 14/37; 13/30] END model__colsample_bytree=0.6943386448447411, model__learning_rate=0.06426980635477918, model__max_depth=7, model__min_child_weight=8, model__n_estimators=316, model__subsample=0.6404672548436904;, score=-21.617 total time=   2.0s\n",
      "[CV 21/37; 13/30] START model__colsample_bytree=0.6943386448447411, model__learning_rate=0.06426980635477918, model__max_depth=7, model__min_child_weight=8, model__n_estimators=316, model__subsample=0.6404672548436904\n",
      "[CV 33/37; 12/30] END model__colsample_bytree=0.6632703844029177, model__learning_rate=0.12408879488107988, model__max_depth=6, model__min_child_weight=9, model__n_estimators=801, model__subsample=0.6626651653816322;, score=-20.451 total time=   9.1s\n",
      "[CV 22/37; 13/30] START model__colsample_bytree=0.6943386448447411, model__learning_rate=0.06426980635477918, model__max_depth=7, model__min_child_weight=8, model__n_estimators=316, model__subsample=0.6404672548436904\n",
      "[CV 15/37; 13/30] END model__colsample_bytree=0.6943386448447411, model__learning_rate=0.06426980635477918, model__max_depth=7, model__min_child_weight=8, model__n_estimators=316, model__subsample=0.6404672548436904;, score=-0.114 total time=   2.1s\n",
      "[CV 23/37; 13/30] START model__colsample_bytree=0.6943386448447411, model__learning_rate=0.06426980635477918, model__max_depth=7, model__min_child_weight=8, model__n_estimators=316, model__subsample=0.6404672548436904\n",
      "[CV 16/37; 13/30] END model__colsample_bytree=0.6943386448447411, model__learning_rate=0.06426980635477918, model__max_depth=7, model__min_child_weight=8, model__n_estimators=316, model__subsample=0.6404672548436904;, score=-0.674 total time=   2.2s\n",
      "[CV 24/37; 13/30] START model__colsample_bytree=0.6943386448447411, model__learning_rate=0.06426980635477918, model__max_depth=7, model__min_child_weight=8, model__n_estimators=316, model__subsample=0.6404672548436904\n",
      "[CV 34/37; 12/30] END model__colsample_bytree=0.6632703844029177, model__learning_rate=0.12408879488107988, model__max_depth=6, model__min_child_weight=9, model__n_estimators=801, model__subsample=0.6626651653816322;, score=0.199 total time=   9.2s\n",
      "[CV 25/37; 13/30] START model__colsample_bytree=0.6943386448447411, model__learning_rate=0.06426980635477918, model__max_depth=7, model__min_child_weight=8, model__n_estimators=316, model__subsample=0.6404672548436904\n",
      "[CV 17/37; 13/30] END model__colsample_bytree=0.6943386448447411, model__learning_rate=0.06426980635477918, model__max_depth=7, model__min_child_weight=8, model__n_estimators=316, model__subsample=0.6404672548436904;, score=-17.699 total time=   2.3s\n",
      "[CV 26/37; 13/30] START model__colsample_bytree=0.6943386448447411, model__learning_rate=0.06426980635477918, model__max_depth=7, model__min_child_weight=8, model__n_estimators=316, model__subsample=0.6404672548436904\n",
      "[CV 18/37; 13/30] END model__colsample_bytree=0.6943386448447411, model__learning_rate=0.06426980635477918, model__max_depth=7, model__min_child_weight=8, model__n_estimators=316, model__subsample=0.6404672548436904;, score=-0.360 total time=   2.4s\n",
      "[CV 27/37; 13/30] START model__colsample_bytree=0.6943386448447411, model__learning_rate=0.06426980635477918, model__max_depth=7, model__min_child_weight=8, model__n_estimators=316, model__subsample=0.6404672548436904\n",
      "[CV 19/37; 13/30] END model__colsample_bytree=0.6943386448447411, model__learning_rate=0.06426980635477918, model__max_depth=7, model__min_child_weight=8, model__n_estimators=316, model__subsample=0.6404672548436904;, score=-0.935 total time=   2.6s\n",
      "[CV 35/37; 12/30] END model__colsample_bytree=0.6632703844029177, model__learning_rate=0.12408879488107988, model__max_depth=6, model__min_child_weight=9, model__n_estimators=801, model__subsample=0.6626651653816322;, score=-21.570 total time=   9.6s\n",
      "[CV 29/37; 13/30] START model__colsample_bytree=0.6943386448447411, model__learning_rate=0.06426980635477918, model__max_depth=7, model__min_child_weight=8, model__n_estimators=316, model__subsample=0.6404672548436904\n",
      "[CV 28/37; 13/30] START model__colsample_bytree=0.6943386448447411, model__learning_rate=0.06426980635477918, model__max_depth=7, model__min_child_weight=8, model__n_estimators=316, model__subsample=0.6404672548436904\n",
      "[CV 20/37; 13/30] END model__colsample_bytree=0.6943386448447411, model__learning_rate=0.06426980635477918, model__max_depth=7, model__min_child_weight=8, model__n_estimators=316, model__subsample=0.6404672548436904;, score=-4.093 total time=   2.7s\n",
      "[CV 30/37; 13/30] START model__colsample_bytree=0.6943386448447411, model__learning_rate=0.06426980635477918, model__max_depth=7, model__min_child_weight=8, model__n_estimators=316, model__subsample=0.6404672548436904\n",
      "[CV 21/37; 13/30] END model__colsample_bytree=0.6943386448447411, model__learning_rate=0.06426980635477918, model__max_depth=7, model__min_child_weight=8, model__n_estimators=316, model__subsample=0.6404672548436904;, score=-0.999 total time=   2.8s\n",
      "[CV 31/37; 13/30] START model__colsample_bytree=0.6943386448447411, model__learning_rate=0.06426980635477918, model__max_depth=7, model__min_child_weight=8, model__n_estimators=316, model__subsample=0.6404672548436904\n",
      "[CV 36/37; 12/30] END model__colsample_bytree=0.6632703844029177, model__learning_rate=0.12408879488107988, model__max_depth=6, model__min_child_weight=9, model__n_estimators=801, model__subsample=0.6626651653816322;, score=-1.488 total time=   9.8s\n",
      "[CV 32/37; 13/30] START model__colsample_bytree=0.6943386448447411, model__learning_rate=0.06426980635477918, model__max_depth=7, model__min_child_weight=8, model__n_estimators=316, model__subsample=0.6404672548436904\n",
      "[CV 22/37; 13/30] END model__colsample_bytree=0.6943386448447411, model__learning_rate=0.06426980635477918, model__max_depth=7, model__min_child_weight=8, model__n_estimators=316, model__subsample=0.6404672548436904;, score=-0.426 total time=   2.8s\n",
      "[CV 33/37; 13/30] START model__colsample_bytree=0.6943386448447411, model__learning_rate=0.06426980635477918, model__max_depth=7, model__min_child_weight=8, model__n_estimators=316, model__subsample=0.6404672548436904\n",
      "[CV 37/37; 12/30] END model__colsample_bytree=0.6632703844029177, model__learning_rate=0.12408879488107988, model__max_depth=6, model__min_child_weight=9, model__n_estimators=801, model__subsample=0.6626651653816322;, score=-0.449 total time=   9.9s\n",
      "[CV 34/37; 13/30] START model__colsample_bytree=0.6943386448447411, model__learning_rate=0.06426980635477918, model__max_depth=7, model__min_child_weight=8, model__n_estimators=316, model__subsample=0.6404672548436904\n",
      "[CV 23/37; 13/30] END model__colsample_bytree=0.6943386448447411, model__learning_rate=0.06426980635477918, model__max_depth=7, model__min_child_weight=8, model__n_estimators=316, model__subsample=0.6404672548436904;, score=-10.697 total time=   3.1s\n",
      "[CV 35/37; 13/30] START model__colsample_bytree=0.6943386448447411, model__learning_rate=0.06426980635477918, model__max_depth=7, model__min_child_weight=8, model__n_estimators=316, model__subsample=0.6404672548436904\n",
      "[CV 24/37; 13/30] END model__colsample_bytree=0.6943386448447411, model__learning_rate=0.06426980635477918, model__max_depth=7, model__min_child_weight=8, model__n_estimators=316, model__subsample=0.6404672548436904;, score=-6.161 total time=   3.2s\n",
      "[CV 36/37; 13/30] START model__colsample_bytree=0.6943386448447411, model__learning_rate=0.06426980635477918, model__max_depth=7, model__min_child_weight=8, model__n_estimators=316, model__subsample=0.6404672548436904\n",
      "[CV 25/37; 13/30] END model__colsample_bytree=0.6943386448447411, model__learning_rate=0.06426980635477918, model__max_depth=7, model__min_child_weight=8, model__n_estimators=316, model__subsample=0.6404672548436904;, score=-0.823 total time=   3.3s\n",
      "[CV 37/37; 13/30] START model__colsample_bytree=0.6943386448447411, model__learning_rate=0.06426980635477918, model__max_depth=7, model__min_child_weight=8, model__n_estimators=316, model__subsample=0.6404672548436904\n",
      "[CV 26/37; 13/30] END model__colsample_bytree=0.6943386448447411, model__learning_rate=0.06426980635477918, model__max_depth=7, model__min_child_weight=8, model__n_estimators=316, model__subsample=0.6404672548436904;, score=-1.606 total time=   3.5s\n",
      "[CV 1/37; 14/30] START model__colsample_bytree=0.7713480415791243, model__learning_rate=0.03818484499495253, model__max_depth=9, model__min_child_weight=1, model__n_estimators=956, model__subsample=0.9934434683002586\n",
      "[CV 27/37; 13/30] END model__colsample_bytree=0.6943386448447411, model__learning_rate=0.06426980635477918, model__max_depth=7, model__min_child_weight=8, model__n_estimators=316, model__subsample=0.6404672548436904;, score=-2.462 total time=   3.6s\n",
      "[CV 2/37; 14/30] START model__colsample_bytree=0.7713480415791243, model__learning_rate=0.03818484499495253, model__max_depth=9, model__min_child_weight=1, model__n_estimators=956, model__subsample=0.9934434683002586\n",
      "[CV 1/37; 14/30] END model__colsample_bytree=0.7713480415791243, model__learning_rate=0.03818484499495253, model__max_depth=9, model__min_child_weight=1, model__n_estimators=956, model__subsample=0.9934434683002586;, score=-38.556 total time=   0.4s\n",
      "[CV 3/37; 14/30] START model__colsample_bytree=0.7713480415791243, model__learning_rate=0.03818484499495253, model__max_depth=9, model__min_child_weight=1, model__n_estimators=956, model__subsample=0.9934434683002586\n",
      "[CV 28/37; 13/30] END model__colsample_bytree=0.6943386448447411, model__learning_rate=0.06426980635477918, model__max_depth=7, model__min_child_weight=8, model__n_estimators=316, model__subsample=0.6404672548436904;, score=-0.998 total time=   3.9s\n",
      "[CV 4/37; 14/30] START model__colsample_bytree=0.7713480415791243, model__learning_rate=0.03818484499495253, model__max_depth=9, model__min_child_weight=1, model__n_estimators=956, model__subsample=0.9934434683002586\n",
      "[CV 2/37; 14/30] END model__colsample_bytree=0.7713480415791243, model__learning_rate=0.03818484499495253, model__max_depth=9, model__min_child_weight=1, model__n_estimators=956, model__subsample=0.9934434683002586;, score=-0.144 total time=   0.7s\n",
      "[CV 5/37; 14/30] START model__colsample_bytree=0.7713480415791243, model__learning_rate=0.03818484499495253, model__max_depth=9, model__min_child_weight=1, model__n_estimators=956, model__subsample=0.9934434683002586\n",
      "[CV 29/37; 13/30] END model__colsample_bytree=0.6943386448447411, model__learning_rate=0.06426980635477918, model__max_depth=7, model__min_child_weight=8, model__n_estimators=316, model__subsample=0.6404672548436904;, score=-9.497 total time=   4.0s\n",
      "[CV 6/37; 14/30] START model__colsample_bytree=0.7713480415791243, model__learning_rate=0.03818484499495253, model__max_depth=9, model__min_child_weight=1, model__n_estimators=956, model__subsample=0.9934434683002586\n",
      "[CV 3/37; 14/30] END model__colsample_bytree=0.7713480415791243, model__learning_rate=0.03818484499495253, model__max_depth=9, model__min_child_weight=1, model__n_estimators=956, model__subsample=0.9934434683002586;, score=-13.995 total time=   0.9s\n",
      "[CV 7/37; 14/30] START model__colsample_bytree=0.7713480415791243, model__learning_rate=0.03818484499495253, model__max_depth=9, model__min_child_weight=1, model__n_estimators=956, model__subsample=0.9934434683002586\n",
      "[CV 30/37; 13/30] END model__colsample_bytree=0.6943386448447411, model__learning_rate=0.06426980635477918, model__max_depth=7, model__min_child_weight=8, model__n_estimators=316, model__subsample=0.6404672548436904;, score=-0.251 total time=   4.1s\n",
      "[CV 4/37; 14/30] END model__colsample_bytree=0.7713480415791243, model__learning_rate=0.03818484499495253, model__max_depth=9, model__min_child_weight=1, model__n_estimators=956, model__subsample=0.9934434683002586;, score=-7.861 total time=   1.2s\n",
      "[CV 31/37; 13/30] END model__colsample_bytree=0.6943386448447411, model__learning_rate=0.06426980635477918, model__max_depth=7, model__min_child_weight=8, model__n_estimators=316, model__subsample=0.6404672548436904;, score=0.074 total time=   4.1s\n",
      "[CV 9/37; 14/30] START model__colsample_bytree=0.7713480415791243, model__learning_rate=0.03818484499495253, model__max_depth=9, model__min_child_weight=1, model__n_estimators=956, model__subsample=0.9934434683002586\n",
      "[CV 5/37; 14/30] END model__colsample_bytree=0.7713480415791243, model__learning_rate=0.03818484499495253, model__max_depth=9, model__min_child_weight=1, model__n_estimators=956, model__subsample=0.9934434683002586;, score=-38.357 total time=   1.4s\n",
      "[CV 10/37; 14/30] START model__colsample_bytree=0.7713480415791243, model__learning_rate=0.03818484499495253, model__max_depth=9, model__min_child_weight=1, model__n_estimators=956, model__subsample=0.9934434683002586\n",
      "[CV 8/37; 14/30] START model__colsample_bytree=0.7713480415791243, model__learning_rate=0.03818484499495253, model__max_depth=9, model__min_child_weight=1, model__n_estimators=956, model__subsample=0.9934434683002586\n",
      "[CV 32/37; 13/30] END model__colsample_bytree=0.6943386448447411, model__learning_rate=0.06426980635477918, model__max_depth=7, model__min_child_weight=8, model__n_estimators=316, model__subsample=0.6404672548436904;, score=-3.454 total time=   4.4s\n",
      "[CV 12/37; 14/30] START model__colsample_bytree=0.7713480415791243, model__learning_rate=0.03818484499495253, model__max_depth=9, model__min_child_weight=1, model__n_estimators=956, model__subsample=0.9934434683002586\n",
      "[CV 33/37; 13/30] END model__colsample_bytree=0.6943386448447411, model__learning_rate=0.06426980635477918, model__max_depth=7, model__min_child_weight=8, model__n_estimators=316, model__subsample=0.6404672548436904;, score=-18.765 total time=   4.6s\n",
      "[CV 13/37; 14/30] START model__colsample_bytree=0.7713480415791243, model__learning_rate=0.03818484499495253, model__max_depth=9, model__min_child_weight=1, model__n_estimators=956, model__subsample=0.9934434683002586\n",
      "[CV 11/37; 14/30] START model__colsample_bytree=0.7713480415791243, model__learning_rate=0.03818484499495253, model__max_depth=9, model__min_child_weight=1, model__n_estimators=956, model__subsample=0.9934434683002586\n",
      "[CV 6/37; 14/30] END model__colsample_bytree=0.7713480415791243, model__learning_rate=0.03818484499495253, model__max_depth=9, model__min_child_weight=1, model__n_estimators=956, model__subsample=0.9934434683002586;, score=-1.306 total time=   2.2s\n",
      "[CV 14/37; 14/30] START model__colsample_bytree=0.7713480415791243, model__learning_rate=0.03818484499495253, model__max_depth=9, model__min_child_weight=1, model__n_estimators=956, model__subsample=0.9934434683002586\n",
      "[CV 34/37; 13/30] END model__colsample_bytree=0.6943386448447411, model__learning_rate=0.06426980635477918, model__max_depth=7, model__min_child_weight=8, model__n_estimators=316, model__subsample=0.6404672548436904;, score=0.166 total time=   4.7s\n",
      "[CV 15/37; 14/30] START model__colsample_bytree=0.7713480415791243, model__learning_rate=0.03818484499495253, model__max_depth=9, model__min_child_weight=1, model__n_estimators=956, model__subsample=0.9934434683002586\n",
      "[CV 35/37; 13/30] END model__colsample_bytree=0.6943386448447411, model__learning_rate=0.06426980635477918, model__max_depth=7, model__min_child_weight=8, model__n_estimators=316, model__subsample=0.6404672548436904;, score=-19.677 total time=   4.7s\n",
      "[CV 16/37; 14/30] START model__colsample_bytree=0.7713480415791243, model__learning_rate=0.03818484499495253, model__max_depth=9, model__min_child_weight=1, model__n_estimators=956, model__subsample=0.9934434683002586\n",
      "[CV 36/37; 13/30] END model__colsample_bytree=0.6943386448447411, model__learning_rate=0.06426980635477918, model__max_depth=7, model__min_child_weight=8, model__n_estimators=316, model__subsample=0.6404672548436904;, score=-1.241 total time=   4.9s\n",
      "[CV 17/37; 14/30] START model__colsample_bytree=0.7713480415791243, model__learning_rate=0.03818484499495253, model__max_depth=9, model__min_child_weight=1, model__n_estimators=956, model__subsample=0.9934434683002586\n",
      "[CV 7/37; 14/30] END model__colsample_bytree=0.7713480415791243, model__learning_rate=0.03818484499495253, model__max_depth=9, model__min_child_weight=1, model__n_estimators=956, model__subsample=0.9934434683002586;, score=-5.754 total time=   2.5s\n",
      "[CV 18/37; 14/30] START model__colsample_bytree=0.7713480415791243, model__learning_rate=0.03818484499495253, model__max_depth=9, model__min_child_weight=1, model__n_estimators=956, model__subsample=0.9934434683002586\n",
      "[CV 37/37; 13/30] END model__colsample_bytree=0.6943386448447411, model__learning_rate=0.06426980635477918, model__max_depth=7, model__min_child_weight=8, model__n_estimators=316, model__subsample=0.6404672548436904;, score=-0.143 total time=   5.0s\n",
      "[CV 19/37; 14/30] START model__colsample_bytree=0.7713480415791243, model__learning_rate=0.03818484499495253, model__max_depth=9, model__min_child_weight=1, model__n_estimators=956, model__subsample=0.9934434683002586\n",
      "[CV 8/37; 14/30] END model__colsample_bytree=0.7713480415791243, model__learning_rate=0.03818484499495253, model__max_depth=9, model__min_child_weight=1, model__n_estimators=956, model__subsample=0.9934434683002586;, score=-7.634 total time=   2.9s\n",
      "[CV 20/37; 14/30] START model__colsample_bytree=0.7713480415791243, model__learning_rate=0.03818484499495253, model__max_depth=9, model__min_child_weight=1, model__n_estimators=956, model__subsample=0.9934434683002586\n",
      "[CV 9/37; 14/30] END model__colsample_bytree=0.7713480415791243, model__learning_rate=0.03818484499495253, model__max_depth=9, model__min_child_weight=1, model__n_estimators=956, model__subsample=0.9934434683002586;, score=-0.863 total time=   3.9s\n",
      "[CV 21/37; 14/30] START model__colsample_bytree=0.7713480415791243, model__learning_rate=0.03818484499495253, model__max_depth=9, model__min_child_weight=1, model__n_estimators=956, model__subsample=0.9934434683002586\n",
      "[CV 10/37; 14/30] END model__colsample_bytree=0.7713480415791243, model__learning_rate=0.03818484499495253, model__max_depth=9, model__min_child_weight=1, model__n_estimators=956, model__subsample=0.9934434683002586;, score=-26.383 total time=   4.5s\n",
      "[CV 22/37; 14/30] START model__colsample_bytree=0.7713480415791243, model__learning_rate=0.03818484499495253, model__max_depth=9, model__min_child_weight=1, model__n_estimators=956, model__subsample=0.9934434683002586\n",
      "[CV 11/37; 14/30] END model__colsample_bytree=0.7713480415791243, model__learning_rate=0.03818484499495253, model__max_depth=9, model__min_child_weight=1, model__n_estimators=956, model__subsample=0.9934434683002586;, score=-3.379 total time=   4.8s\n",
      "[CV 23/37; 14/30] START model__colsample_bytree=0.7713480415791243, model__learning_rate=0.03818484499495253, model__max_depth=9, model__min_child_weight=1, model__n_estimators=956, model__subsample=0.9934434683002586\n",
      "[CV 12/37; 14/30] END model__colsample_bytree=0.7713480415791243, model__learning_rate=0.03818484499495253, model__max_depth=9, model__min_child_weight=1, model__n_estimators=956, model__subsample=0.9934434683002586;, score=-19.537 total time=   5.6s\n",
      "[CV 24/37; 14/30] START model__colsample_bytree=0.7713480415791243, model__learning_rate=0.03818484499495253, model__max_depth=9, model__min_child_weight=1, model__n_estimators=956, model__subsample=0.9934434683002586\n",
      "[CV 13/37; 14/30] END model__colsample_bytree=0.7713480415791243, model__learning_rate=0.03818484499495253, model__max_depth=9, model__min_child_weight=1, model__n_estimators=956, model__subsample=0.9934434683002586;, score=0.163 total time=   6.3s\n",
      "[CV 25/37; 14/30] START model__colsample_bytree=0.7713480415791243, model__learning_rate=0.03818484499495253, model__max_depth=9, model__min_child_weight=1, model__n_estimators=956, model__subsample=0.9934434683002586\n",
      "[CV 14/37; 14/30] END model__colsample_bytree=0.7713480415791243, model__learning_rate=0.03818484499495253, model__max_depth=9, model__min_child_weight=1, model__n_estimators=956, model__subsample=0.9934434683002586;, score=-19.962 total time=   6.9s\n",
      "[CV 15/37; 14/30] END model__colsample_bytree=0.7713480415791243, model__learning_rate=0.03818484499495253, model__max_depth=9, model__min_child_weight=1, model__n_estimators=956, model__subsample=0.9934434683002586;, score=-0.086 total time=   7.6s\n",
      "[CV 26/37; 14/30] START model__colsample_bytree=0.7713480415791243, model__learning_rate=0.03818484499495253, model__max_depth=9, model__min_child_weight=1, model__n_estimators=956, model__subsample=0.9934434683002586\n",
      "[CV 27/37; 14/30] START model__colsample_bytree=0.7713480415791243, model__learning_rate=0.03818484499495253, model__max_depth=9, model__min_child_weight=1, model__n_estimators=956, model__subsample=0.9934434683002586\n",
      "[CV 16/37; 14/30] END model__colsample_bytree=0.7713480415791243, model__learning_rate=0.03818484499495253, model__max_depth=9, model__min_child_weight=1, model__n_estimators=956, model__subsample=0.9934434683002586;, score=-0.604 total time=   9.3s\n",
      "[CV 28/37; 14/30] START model__colsample_bytree=0.7713480415791243, model__learning_rate=0.03818484499495253, model__max_depth=9, model__min_child_weight=1, model__n_estimators=956, model__subsample=0.9934434683002586\n",
      "[CV 17/37; 14/30] END model__colsample_bytree=0.7713480415791243, model__learning_rate=0.03818484499495253, model__max_depth=9, model__min_child_weight=1, model__n_estimators=956, model__subsample=0.9934434683002586;, score=-17.201 total time=  10.4s\n",
      "[CV 18/37; 14/30] END model__colsample_bytree=0.7713480415791243, model__learning_rate=0.03818484499495253, model__max_depth=9, model__min_child_weight=1, model__n_estimators=956, model__subsample=0.9934434683002586;, score=-0.730 total time=  11.4s\n",
      "[CV 29/37; 14/30] START model__colsample_bytree=0.7713480415791243, model__learning_rate=0.03818484499495253, model__max_depth=9, model__min_child_weight=1, model__n_estimators=956, model__subsample=0.9934434683002586\n",
      "[CV 30/37; 14/30] START model__colsample_bytree=0.7713480415791243, model__learning_rate=0.03818484499495253, model__max_depth=9, model__min_child_weight=1, model__n_estimators=956, model__subsample=0.9934434683002586\n",
      "[CV 19/37; 14/30] END model__colsample_bytree=0.7713480415791243, model__learning_rate=0.03818484499495253, model__max_depth=9, model__min_child_weight=1, model__n_estimators=956, model__subsample=0.9934434683002586;, score=-0.982 total time=  12.2s\n",
      "[CV 31/37; 14/30] START model__colsample_bytree=0.7713480415791243, model__learning_rate=0.03818484499495253, model__max_depth=9, model__min_child_weight=1, model__n_estimators=956, model__subsample=0.9934434683002586\n",
      "[CV 20/37; 14/30] END model__colsample_bytree=0.7713480415791243, model__learning_rate=0.03818484499495253, model__max_depth=9, model__min_child_weight=1, model__n_estimators=956, model__subsample=0.9934434683002586;, score=-4.698 total time=  13.5s\n",
      "[CV 32/37; 14/30] START model__colsample_bytree=0.7713480415791243, model__learning_rate=0.03818484499495253, model__max_depth=9, model__min_child_weight=1, model__n_estimators=956, model__subsample=0.9934434683002586\n",
      "[CV 21/37; 14/30] END model__colsample_bytree=0.7713480415791243, model__learning_rate=0.03818484499495253, model__max_depth=9, model__min_child_weight=1, model__n_estimators=956, model__subsample=0.9934434683002586;, score=-0.918 total time=  14.0s\n",
      "[CV 33/37; 14/30] START model__colsample_bytree=0.7713480415791243, model__learning_rate=0.03818484499495253, model__max_depth=9, model__min_child_weight=1, model__n_estimators=956, model__subsample=0.9934434683002586\n",
      "[CV 22/37; 14/30] END model__colsample_bytree=0.7713480415791243, model__learning_rate=0.03818484499495253, model__max_depth=9, model__min_child_weight=1, model__n_estimators=956, model__subsample=0.9934434683002586;, score=-0.455 total time=  15.0s\n",
      "[CV 34/37; 14/30] START model__colsample_bytree=0.7713480415791243, model__learning_rate=0.03818484499495253, model__max_depth=9, model__min_child_weight=1, model__n_estimators=956, model__subsample=0.9934434683002586\n",
      "[CV 23/37; 14/30] END model__colsample_bytree=0.7713480415791243, model__learning_rate=0.03818484499495253, model__max_depth=9, model__min_child_weight=1, model__n_estimators=956, model__subsample=0.9934434683002586;, score=-10.299 total time=  15.8s\n",
      "[CV 35/37; 14/30] START model__colsample_bytree=0.7713480415791243, model__learning_rate=0.03818484499495253, model__max_depth=9, model__min_child_weight=1, model__n_estimators=956, model__subsample=0.9934434683002586\n",
      "[CV 24/37; 14/30] END model__colsample_bytree=0.7713480415791243, model__learning_rate=0.03818484499495253, model__max_depth=9, model__min_child_weight=1, model__n_estimators=956, model__subsample=0.9934434683002586;, score=-5.306 total time=  16.5s\n",
      "[CV 36/37; 14/30] START model__colsample_bytree=0.7713480415791243, model__learning_rate=0.03818484499495253, model__max_depth=9, model__min_child_weight=1, model__n_estimators=956, model__subsample=0.9934434683002586\n",
      "[CV 25/37; 14/30] END model__colsample_bytree=0.7713480415791243, model__learning_rate=0.03818484499495253, model__max_depth=9, model__min_child_weight=1, model__n_estimators=956, model__subsample=0.9934434683002586;, score=-1.003 total time=  17.0s\n",
      "[CV 37/37; 14/30] START model__colsample_bytree=0.7713480415791243, model__learning_rate=0.03818484499495253, model__max_depth=9, model__min_child_weight=1, model__n_estimators=956, model__subsample=0.9934434683002586\n",
      "[CV 26/37; 14/30] END model__colsample_bytree=0.7713480415791243, model__learning_rate=0.03818484499495253, model__max_depth=9, model__min_child_weight=1, model__n_estimators=956, model__subsample=0.9934434683002586;, score=-0.671 total time=  17.4s\n",
      "[CV 1/37; 15/30] START model__colsample_bytree=0.8861223846483287, model__learning_rate=0.04974313630683449, model__max_depth=9, model__min_child_weight=3, model__n_estimators=692, model__subsample=0.855670976374325\n",
      "[CV 1/37; 15/30] END model__colsample_bytree=0.8861223846483287, model__learning_rate=0.04974313630683449, model__max_depth=9, model__min_child_weight=3, model__n_estimators=692, model__subsample=0.855670976374325;, score=-40.673 total time=   0.4s\n",
      "[CV 2/37; 15/30] START model__colsample_bytree=0.8861223846483287, model__learning_rate=0.04974313630683449, model__max_depth=9, model__min_child_weight=3, model__n_estimators=692, model__subsample=0.855670976374325\n",
      "[CV 2/37; 15/30] END model__colsample_bytree=0.8861223846483287, model__learning_rate=0.04974313630683449, model__max_depth=9, model__min_child_weight=3, model__n_estimators=692, model__subsample=0.855670976374325;, score=-0.158 total time=   0.6s\n",
      "[CV 3/37; 15/30] START model__colsample_bytree=0.8861223846483287, model__learning_rate=0.04974313630683449, model__max_depth=9, model__min_child_weight=3, model__n_estimators=692, model__subsample=0.855670976374325\n",
      "[CV 27/37; 14/30] END model__colsample_bytree=0.7713480415791243, model__learning_rate=0.03818484499495253, model__max_depth=9, model__min_child_weight=1, model__n_estimators=956, model__subsample=0.9934434683002586;, score=-2.851 total time=  18.2s\n",
      "[CV 4/37; 15/30] START model__colsample_bytree=0.8861223846483287, model__learning_rate=0.04974313630683449, model__max_depth=9, model__min_child_weight=3, model__n_estimators=692, model__subsample=0.855670976374325\n",
      "[CV 3/37; 15/30] END model__colsample_bytree=0.8861223846483287, model__learning_rate=0.04974313630683449, model__max_depth=9, model__min_child_weight=3, model__n_estimators=692, model__subsample=0.855670976374325;, score=-17.062 total time=   0.9s\n",
      "[CV 5/37; 15/30] START model__colsample_bytree=0.8861223846483287, model__learning_rate=0.04974313630683449, model__max_depth=9, model__min_child_weight=3, model__n_estimators=692, model__subsample=0.855670976374325\n",
      "[CV 4/37; 15/30] END model__colsample_bytree=0.8861223846483287, model__learning_rate=0.04974313630683449, model__max_depth=9, model__min_child_weight=3, model__n_estimators=692, model__subsample=0.855670976374325;, score=-7.311 total time=   1.2s\n",
      "[CV 6/37; 15/30] START model__colsample_bytree=0.8861223846483287, model__learning_rate=0.04974313630683449, model__max_depth=9, model__min_child_weight=3, model__n_estimators=692, model__subsample=0.855670976374325\n",
      "[CV 28/37; 14/30] END model__colsample_bytree=0.7713480415791243, model__learning_rate=0.03818484499495253, model__max_depth=9, model__min_child_weight=1, model__n_estimators=956, model__subsample=0.9934434683002586;, score=-0.983 total time=  18.9s\n",
      "[CV 5/37; 15/30] END model__colsample_bytree=0.8861223846483287, model__learning_rate=0.04974313630683449, model__max_depth=9, model__min_child_weight=3, model__n_estimators=692, model__subsample=0.855670976374325;, score=-38.134 total time=   1.4s\n",
      "[CV 8/37; 15/30] START model__colsample_bytree=0.8861223846483287, model__learning_rate=0.04974313630683449, model__max_depth=9, model__min_child_weight=3, model__n_estimators=692, model__subsample=0.855670976374325\n",
      "[CV 7/37; 15/30] START model__colsample_bytree=0.8861223846483287, model__learning_rate=0.04974313630683449, model__max_depth=9, model__min_child_weight=3, model__n_estimators=692, model__subsample=0.855670976374325\n",
      "[CV 6/37; 15/30] END model__colsample_bytree=0.8861223846483287, model__learning_rate=0.04974313630683449, model__max_depth=9, model__min_child_weight=3, model__n_estimators=692, model__subsample=0.855670976374325;, score=-1.174 total time=   1.8s\n",
      "[CV 9/37; 15/30] START model__colsample_bytree=0.8861223846483287, model__learning_rate=0.04974313630683449, model__max_depth=9, model__min_child_weight=3, model__n_estimators=692, model__subsample=0.855670976374325\n",
      "[CV 29/37; 14/30] END model__colsample_bytree=0.7713480415791243, model__learning_rate=0.03818484499495253, model__max_depth=9, model__min_child_weight=1, model__n_estimators=956, model__subsample=0.9934434683002586;, score=-6.641 total time=  18.7s\n",
      "[CV 10/37; 15/30] START model__colsample_bytree=0.8861223846483287, model__learning_rate=0.04974313630683449, model__max_depth=9, model__min_child_weight=3, model__n_estimators=692, model__subsample=0.855670976374325\n",
      "[CV 8/37; 15/30] END model__colsample_bytree=0.8861223846483287, model__learning_rate=0.04974313630683449, model__max_depth=9, model__min_child_weight=3, model__n_estimators=692, model__subsample=0.855670976374325;, score=-8.393 total time=   2.7s\n",
      "[CV 11/37; 15/30] START model__colsample_bytree=0.8861223846483287, model__learning_rate=0.04974313630683449, model__max_depth=9, model__min_child_weight=3, model__n_estimators=692, model__subsample=0.855670976374325\n",
      "[CV 7/37; 15/30] END model__colsample_bytree=0.8861223846483287, model__learning_rate=0.04974313630683449, model__max_depth=9, model__min_child_weight=3, model__n_estimators=692, model__subsample=0.855670976374325;, score=-6.061 total time=   2.2s\n",
      "[CV 12/37; 15/30] START model__colsample_bytree=0.8861223846483287, model__learning_rate=0.04974313630683449, model__max_depth=9, model__min_child_weight=3, model__n_estimators=692, model__subsample=0.855670976374325\n",
      "[CV 30/37; 14/30] END model__colsample_bytree=0.7713480415791243, model__learning_rate=0.03818484499495253, model__max_depth=9, model__min_child_weight=1, model__n_estimators=956, model__subsample=0.9934434683002586;, score=-0.084 total time=  19.2s\n",
      "[CV 13/37; 15/30] START model__colsample_bytree=0.8861223846483287, model__learning_rate=0.04974313630683449, model__max_depth=9, model__min_child_weight=3, model__n_estimators=692, model__subsample=0.855670976374325\n",
      "[CV 9/37; 15/30] END model__colsample_bytree=0.8861223846483287, model__learning_rate=0.04974313630683449, model__max_depth=9, model__min_child_weight=3, model__n_estimators=692, model__subsample=0.855670976374325;, score=-0.726 total time=   3.1s\n",
      "[CV 14/37; 15/30] START model__colsample_bytree=0.8861223846483287, model__learning_rate=0.04974313630683449, model__max_depth=9, model__min_child_weight=3, model__n_estimators=692, model__subsample=0.855670976374325\n",
      "[CV 31/37; 14/30] END model__colsample_bytree=0.7713480415791243, model__learning_rate=0.03818484499495253, model__max_depth=9, model__min_child_weight=1, model__n_estimators=956, model__subsample=0.9934434683002586;, score=-0.567 total time=  19.9s\n",
      "[CV 15/37; 15/30] START model__colsample_bytree=0.8861223846483287, model__learning_rate=0.04974313630683449, model__max_depth=9, model__min_child_weight=3, model__n_estimators=692, model__subsample=0.855670976374325\n",
      "[CV 10/37; 15/30] END model__colsample_bytree=0.8861223846483287, model__learning_rate=0.04974313630683449, model__max_depth=9, model__min_child_weight=3, model__n_estimators=692, model__subsample=0.855670976374325;, score=-30.107 total time=   3.7s\n",
      "[CV 16/37; 15/30] START model__colsample_bytree=0.8861223846483287, model__learning_rate=0.04974313630683449, model__max_depth=9, model__min_child_weight=3, model__n_estimators=692, model__subsample=0.855670976374325\n",
      "[CV 11/37; 15/30] END model__colsample_bytree=0.8861223846483287, model__learning_rate=0.04974313630683449, model__max_depth=9, model__min_child_weight=3, model__n_estimators=692, model__subsample=0.855670976374325;, score=-3.115 total time=   4.2s\n",
      "[CV 17/37; 15/30] START model__colsample_bytree=0.8861223846483287, model__learning_rate=0.04974313630683449, model__max_depth=9, model__min_child_weight=3, model__n_estimators=692, model__subsample=0.855670976374325\n",
      "[CV 32/37; 14/30] END model__colsample_bytree=0.7713480415791243, model__learning_rate=0.03818484499495253, model__max_depth=9, model__min_child_weight=1, model__n_estimators=956, model__subsample=0.9934434683002586;, score=-3.352 total time=  20.1s\n",
      "[CV 18/37; 15/30] START model__colsample_bytree=0.8861223846483287, model__learning_rate=0.04974313630683449, model__max_depth=9, model__min_child_weight=3, model__n_estimators=692, model__subsample=0.855670976374325\n",
      "[CV 12/37; 15/30] END model__colsample_bytree=0.8861223846483287, model__learning_rate=0.04974313630683449, model__max_depth=9, model__min_child_weight=3, model__n_estimators=692, model__subsample=0.855670976374325;, score=-19.080 total time=   4.7s\n",
      "[CV 19/37; 15/30] START model__colsample_bytree=0.8861223846483287, model__learning_rate=0.04974313630683449, model__max_depth=9, model__min_child_weight=3, model__n_estimators=692, model__subsample=0.855670976374325\n",
      "[CV 13/37; 15/30] END model__colsample_bytree=0.8861223846483287, model__learning_rate=0.04974313630683449, model__max_depth=9, model__min_child_weight=3, model__n_estimators=692, model__subsample=0.855670976374325;, score=0.148 total time=   5.3s\n",
      "[CV 20/37; 15/30] START model__colsample_bytree=0.8861223846483287, model__learning_rate=0.04974313630683449, model__max_depth=9, model__min_child_weight=3, model__n_estimators=692, model__subsample=0.855670976374325\n",
      "[CV 33/37; 14/30] END model__colsample_bytree=0.7713480415791243, model__learning_rate=0.03818484499495253, model__max_depth=9, model__min_child_weight=1, model__n_estimators=956, model__subsample=0.9934434683002586;, score=-21.901 total time=  20.9s\n",
      "[CV 21/37; 15/30] START model__colsample_bytree=0.8861223846483287, model__learning_rate=0.04974313630683449, model__max_depth=9, model__min_child_weight=3, model__n_estimators=692, model__subsample=0.855670976374325\n",
      "[CV 14/37; 15/30] END model__colsample_bytree=0.8861223846483287, model__learning_rate=0.04974313630683449, model__max_depth=9, model__min_child_weight=3, model__n_estimators=692, model__subsample=0.855670976374325;, score=-21.479 total time=   5.7s\n",
      "[CV 22/37; 15/30] START model__colsample_bytree=0.8861223846483287, model__learning_rate=0.04974313630683449, model__max_depth=9, model__min_child_weight=3, model__n_estimators=692, model__subsample=0.855670976374325\n",
      "[CV 34/37; 14/30] END model__colsample_bytree=0.7713480415791243, model__learning_rate=0.03818484499495253, model__max_depth=9, model__min_child_weight=1, model__n_estimators=956, model__subsample=0.9934434683002586;, score=0.009 total time=  21.1s\n",
      "[CV 15/37; 15/30] END model__colsample_bytree=0.8861223846483287, model__learning_rate=0.04974313630683449, model__max_depth=9, model__min_child_weight=3, model__n_estimators=692, model__subsample=0.855670976374325;, score=0.012 total time=   6.4s\n",
      "[CV 23/37; 15/30] START model__colsample_bytree=0.8861223846483287, model__learning_rate=0.04974313630683449, model__max_depth=9, model__min_child_weight=3, model__n_estimators=692, model__subsample=0.855670976374325\n",
      "[CV 24/37; 15/30] START model__colsample_bytree=0.8861223846483287, model__learning_rate=0.04974313630683449, model__max_depth=9, model__min_child_weight=3, model__n_estimators=692, model__subsample=0.855670976374325\n",
      "[CV 16/37; 15/30] END model__colsample_bytree=0.8861223846483287, model__learning_rate=0.04974313630683449, model__max_depth=9, model__min_child_weight=3, model__n_estimators=692, model__subsample=0.855670976374325;, score=-0.740 total time=   7.4s\n",
      "[CV 25/37; 15/30] START model__colsample_bytree=0.8861223846483287, model__learning_rate=0.04974313630683449, model__max_depth=9, model__min_child_weight=3, model__n_estimators=692, model__subsample=0.855670976374325\n",
      "[CV 35/37; 14/30] END model__colsample_bytree=0.7713480415791243, model__learning_rate=0.03818484499495253, model__max_depth=9, model__min_child_weight=1, model__n_estimators=956, model__subsample=0.9934434683002586;, score=-17.263 total time=  21.8s\n",
      "[CV 26/37; 15/30] START model__colsample_bytree=0.8861223846483287, model__learning_rate=0.04974313630683449, model__max_depth=9, model__min_child_weight=3, model__n_estimators=692, model__subsample=0.855670976374325\n",
      "[CV 17/37; 15/30] END model__colsample_bytree=0.8861223846483287, model__learning_rate=0.04974313630683449, model__max_depth=9, model__min_child_weight=3, model__n_estimators=692, model__subsample=0.855670976374325;, score=-18.203 total time=   8.2s\n",
      "[CV 27/37; 15/30] START model__colsample_bytree=0.8861223846483287, model__learning_rate=0.04974313630683449, model__max_depth=9, model__min_child_weight=3, model__n_estimators=692, model__subsample=0.855670976374325\n",
      "[CV 36/37; 14/30] END model__colsample_bytree=0.7713480415791243, model__learning_rate=0.03818484499495253, model__max_depth=9, model__min_child_weight=1, model__n_estimators=956, model__subsample=0.9934434683002586;, score=-1.502 total time=  22.0s\n",
      "[CV 28/37; 15/30] START model__colsample_bytree=0.8861223846483287, model__learning_rate=0.04974313630683449, model__max_depth=9, model__min_child_weight=3, model__n_estimators=692, model__subsample=0.855670976374325\n",
      "[CV 18/37; 15/30] END model__colsample_bytree=0.8861223846483287, model__learning_rate=0.04974313630683449, model__max_depth=9, model__min_child_weight=3, model__n_estimators=692, model__subsample=0.855670976374325;, score=-0.502 total time=   9.0s\n",
      "[CV 29/37; 15/30] START model__colsample_bytree=0.8861223846483287, model__learning_rate=0.04974313630683449, model__max_depth=9, model__min_child_weight=3, model__n_estimators=692, model__subsample=0.855670976374325\n",
      "[CV 19/37; 15/30] END model__colsample_bytree=0.8861223846483287, model__learning_rate=0.04974313630683449, model__max_depth=9, model__min_child_weight=3, model__n_estimators=692, model__subsample=0.855670976374325;, score=-1.051 total time=   9.5s\n",
      "[CV 30/37; 15/30] START model__colsample_bytree=0.8861223846483287, model__learning_rate=0.04974313630683449, model__max_depth=9, model__min_child_weight=3, model__n_estimators=692, model__subsample=0.855670976374325\n",
      "[CV 37/37; 14/30] END model__colsample_bytree=0.7713480415791243, model__learning_rate=0.03818484499495253, model__max_depth=9, model__min_child_weight=1, model__n_estimators=956, model__subsample=0.9934434683002586;, score=-0.242 total time=  22.9s\n",
      "[CV 31/37; 15/30] START model__colsample_bytree=0.8861223846483287, model__learning_rate=0.04974313630683449, model__max_depth=9, model__min_child_weight=3, model__n_estimators=692, model__subsample=0.855670976374325\n",
      "[CV 20/37; 15/30] END model__colsample_bytree=0.8861223846483287, model__learning_rate=0.04974313630683449, model__max_depth=9, model__min_child_weight=3, model__n_estimators=692, model__subsample=0.855670976374325;, score=-5.356 total time=  10.3s\n",
      "[CV 32/37; 15/30] START model__colsample_bytree=0.8861223846483287, model__learning_rate=0.04974313630683449, model__max_depth=9, model__min_child_weight=3, model__n_estimators=692, model__subsample=0.855670976374325\n",
      "[CV 21/37; 15/30] END model__colsample_bytree=0.8861223846483287, model__learning_rate=0.04974313630683449, model__max_depth=9, model__min_child_weight=3, model__n_estimators=692, model__subsample=0.855670976374325;, score=-1.059 total time=  11.1s\n",
      "[CV 33/37; 15/30] START model__colsample_bytree=0.8861223846483287, model__learning_rate=0.04974313630683449, model__max_depth=9, model__min_child_weight=3, model__n_estimators=692, model__subsample=0.855670976374325\n",
      "[CV 22/37; 15/30] END model__colsample_bytree=0.8861223846483287, model__learning_rate=0.04974313630683449, model__max_depth=9, model__min_child_weight=3, model__n_estimators=692, model__subsample=0.855670976374325;, score=-0.357 total time=  11.3s\n",
      "[CV 34/37; 15/30] START model__colsample_bytree=0.8861223846483287, model__learning_rate=0.04974313630683449, model__max_depth=9, model__min_child_weight=3, model__n_estimators=692, model__subsample=0.855670976374325\n",
      "[CV 23/37; 15/30] END model__colsample_bytree=0.8861223846483287, model__learning_rate=0.04974313630683449, model__max_depth=9, model__min_child_weight=3, model__n_estimators=692, model__subsample=0.855670976374325;, score=-10.397 total time=  12.0s\n",
      "[CV 35/37; 15/30] START model__colsample_bytree=0.8861223846483287, model__learning_rate=0.04974313630683449, model__max_depth=9, model__min_child_weight=3, model__n_estimators=692, model__subsample=0.855670976374325\n",
      "[CV 24/37; 15/30] END model__colsample_bytree=0.8861223846483287, model__learning_rate=0.04974313630683449, model__max_depth=9, model__min_child_weight=3, model__n_estimators=692, model__subsample=0.855670976374325;, score=-7.122 total time=  12.6s\n",
      "[CV 36/37; 15/30] START model__colsample_bytree=0.8861223846483287, model__learning_rate=0.04974313630683449, model__max_depth=9, model__min_child_weight=3, model__n_estimators=692, model__subsample=0.855670976374325\n",
      "[CV 25/37; 15/30] END model__colsample_bytree=0.8861223846483287, model__learning_rate=0.04974313630683449, model__max_depth=9, model__min_child_weight=3, model__n_estimators=692, model__subsample=0.855670976374325;, score=-0.752 total time=  12.9s\n",
      "[CV 37/37; 15/30] START model__colsample_bytree=0.8861223846483287, model__learning_rate=0.04974313630683449, model__max_depth=9, model__min_child_weight=3, model__n_estimators=692, model__subsample=0.855670976374325\n",
      "[CV 26/37; 15/30] END model__colsample_bytree=0.8861223846483287, model__learning_rate=0.04974313630683449, model__max_depth=9, model__min_child_weight=3, model__n_estimators=692, model__subsample=0.855670976374325;, score=-1.056 total time=  13.4s\n",
      "[CV 1/37; 16/30] START model__colsample_bytree=0.8950877702656028, model__learning_rate=0.1311919949562023, model__max_depth=4, model__min_child_weight=7, model__n_estimators=140, model__subsample=0.9574798377718904\n",
      "[CV 1/37; 16/30] END model__colsample_bytree=0.8950877702656028, model__learning_rate=0.1311919949562023, model__max_depth=4, model__min_child_weight=7, model__n_estimators=140, model__subsample=0.9574798377718904;, score=-42.332 total time=   0.1s\n",
      "[CV 2/37; 16/30] START model__colsample_bytree=0.8950877702656028, model__learning_rate=0.1311919949562023, model__max_depth=4, model__min_child_weight=7, model__n_estimators=140, model__subsample=0.9574798377718904\n",
      "[CV 2/37; 16/30] END model__colsample_bytree=0.8950877702656028, model__learning_rate=0.1311919949562023, model__max_depth=4, model__min_child_weight=7, model__n_estimators=140, model__subsample=0.9574798377718904;, score=-0.207 total time=   0.1s\n",
      "[CV 3/37; 16/30] START model__colsample_bytree=0.8950877702656028, model__learning_rate=0.1311919949562023, model__max_depth=4, model__min_child_weight=7, model__n_estimators=140, model__subsample=0.9574798377718904\n",
      "[CV 3/37; 16/30] END model__colsample_bytree=0.8950877702656028, model__learning_rate=0.1311919949562023, model__max_depth=4, model__min_child_weight=7, model__n_estimators=140, model__subsample=0.9574798377718904;, score=-27.060 total time=   0.2s\n",
      "[CV 4/37; 16/30] START model__colsample_bytree=0.8950877702656028, model__learning_rate=0.1311919949562023, model__max_depth=4, model__min_child_weight=7, model__n_estimators=140, model__subsample=0.9574798377718904\n",
      "[CV 4/37; 16/30] END model__colsample_bytree=0.8950877702656028, model__learning_rate=0.1311919949562023, model__max_depth=4, model__min_child_weight=7, model__n_estimators=140, model__subsample=0.9574798377718904;, score=-8.044 total time=   0.3s\n",
      "[CV 5/37; 16/30] START model__colsample_bytree=0.8950877702656028, model__learning_rate=0.1311919949562023, model__max_depth=4, model__min_child_weight=7, model__n_estimators=140, model__subsample=0.9574798377718904\n",
      "[CV 5/37; 16/30] END model__colsample_bytree=0.8950877702656028, model__learning_rate=0.1311919949562023, model__max_depth=4, model__min_child_weight=7, model__n_estimators=140, model__subsample=0.9574798377718904;, score=-38.113 total time=   0.3s\n",
      "[CV 6/37; 16/30] START model__colsample_bytree=0.8950877702656028, model__learning_rate=0.1311919949562023, model__max_depth=4, model__min_child_weight=7, model__n_estimators=140, model__subsample=0.9574798377718904\n",
      "[CV 6/37; 16/30] END model__colsample_bytree=0.8950877702656028, model__learning_rate=0.1311919949562023, model__max_depth=4, model__min_child_weight=7, model__n_estimators=140, model__subsample=0.9574798377718904;, score=-2.246 total time=   0.3s\n",
      "[CV 7/37; 16/30] START model__colsample_bytree=0.8950877702656028, model__learning_rate=0.1311919949562023, model__max_depth=4, model__min_child_weight=7, model__n_estimators=140, model__subsample=0.9574798377718904\n",
      "[CV 7/37; 16/30] END model__colsample_bytree=0.8950877702656028, model__learning_rate=0.1311919949562023, model__max_depth=4, model__min_child_weight=7, model__n_estimators=140, model__subsample=0.9574798377718904;, score=-5.908 total time=   0.4s\n",
      "[CV 8/37; 16/30] START model__colsample_bytree=0.8950877702656028, model__learning_rate=0.1311919949562023, model__max_depth=4, model__min_child_weight=7, model__n_estimators=140, model__subsample=0.9574798377718904\n",
      "[CV 27/37; 15/30] END model__colsample_bytree=0.8861223846483287, model__learning_rate=0.04974313630683449, model__max_depth=9, model__min_child_weight=3, model__n_estimators=692, model__subsample=0.855670976374325;, score=-2.908 total time=  14.1s\n",
      "[CV 8/37; 16/30] END model__colsample_bytree=0.8950877702656028, model__learning_rate=0.1311919949562023, model__max_depth=4, model__min_child_weight=7, model__n_estimators=140, model__subsample=0.9574798377718904;, score=-8.442 total time=   0.4s\n",
      "[CV 9/37; 16/30] START model__colsample_bytree=0.8950877702656028, model__learning_rate=0.1311919949562023, model__max_depth=4, model__min_child_weight=7, model__n_estimators=140, model__subsample=0.9574798377718904\n",
      "[CV 10/37; 16/30] START model__colsample_bytree=0.8950877702656028, model__learning_rate=0.1311919949562023, model__max_depth=4, model__min_child_weight=7, model__n_estimators=140, model__subsample=0.9574798377718904\n",
      "[CV 9/37; 16/30] END model__colsample_bytree=0.8950877702656028, model__learning_rate=0.1311919949562023, model__max_depth=4, model__min_child_weight=7, model__n_estimators=140, model__subsample=0.9574798377718904;, score=-0.585 total time=   0.5s\n",
      "[CV 11/37; 16/30] START model__colsample_bytree=0.8950877702656028, model__learning_rate=0.1311919949562023, model__max_depth=4, model__min_child_weight=7, model__n_estimators=140, model__subsample=0.9574798377718904\n",
      "[CV 10/37; 16/30] END model__colsample_bytree=0.8950877702656028, model__learning_rate=0.1311919949562023, model__max_depth=4, model__min_child_weight=7, model__n_estimators=140, model__subsample=0.9574798377718904;, score=-25.939 total time=   0.5s\n",
      "[CV 12/37; 16/30] START model__colsample_bytree=0.8950877702656028, model__learning_rate=0.1311919949562023, model__max_depth=4, model__min_child_weight=7, model__n_estimators=140, model__subsample=0.9574798377718904\n",
      "[CV 11/37; 16/30] END model__colsample_bytree=0.8950877702656028, model__learning_rate=0.1311919949562023, model__max_depth=4, model__min_child_weight=7, model__n_estimators=140, model__subsample=0.9574798377718904;, score=-4.031 total time=   0.5s\n",
      "[CV 13/37; 16/30] START model__colsample_bytree=0.8950877702656028, model__learning_rate=0.1311919949562023, model__max_depth=4, model__min_child_weight=7, model__n_estimators=140, model__subsample=0.9574798377718904\n",
      "[CV 12/37; 16/30] END model__colsample_bytree=0.8950877702656028, model__learning_rate=0.1311919949562023, model__max_depth=4, model__min_child_weight=7, model__n_estimators=140, model__subsample=0.9574798377718904;, score=-17.228 total time=   0.7s\n",
      "[CV 14/37; 16/30] START model__colsample_bytree=0.8950877702656028, model__learning_rate=0.1311919949562023, model__max_depth=4, model__min_child_weight=7, model__n_estimators=140, model__subsample=0.9574798377718904\n",
      "[CV 28/37; 15/30] END model__colsample_bytree=0.8861223846483287, model__learning_rate=0.04974313630683449, model__max_depth=9, model__min_child_weight=3, model__n_estimators=692, model__subsample=0.855670976374325;, score=-0.700 total time=  14.8s\n",
      "[CV 15/37; 16/30] START model__colsample_bytree=0.8950877702656028, model__learning_rate=0.1311919949562023, model__max_depth=4, model__min_child_weight=7, model__n_estimators=140, model__subsample=0.9574798377718904\n",
      "[CV 13/37; 16/30] END model__colsample_bytree=0.8950877702656028, model__learning_rate=0.1311919949562023, model__max_depth=4, model__min_child_weight=7, model__n_estimators=140, model__subsample=0.9574798377718904;, score=0.238 total time=   0.6s\n",
      "[CV 16/37; 16/30] START model__colsample_bytree=0.8950877702656028, model__learning_rate=0.1311919949562023, model__max_depth=4, model__min_child_weight=7, model__n_estimators=140, model__subsample=0.9574798377718904\n",
      "[CV 14/37; 16/30] END model__colsample_bytree=0.8950877702656028, model__learning_rate=0.1311919949562023, model__max_depth=4, model__min_child_weight=7, model__n_estimators=140, model__subsample=0.9574798377718904;, score=-22.254 total time=   0.7s\n",
      "[CV 17/37; 16/30] START model__colsample_bytree=0.8950877702656028, model__learning_rate=0.1311919949562023, model__max_depth=4, model__min_child_weight=7, model__n_estimators=140, model__subsample=0.9574798377718904\n",
      "[CV 29/37; 15/30] END model__colsample_bytree=0.8861223846483287, model__learning_rate=0.04974313630683449, model__max_depth=9, model__min_child_weight=3, model__n_estimators=692, model__subsample=0.855670976374325;, score=-7.219 total time=  15.2s\n",
      "[CV 18/37; 16/30] START model__colsample_bytree=0.8950877702656028, model__learning_rate=0.1311919949562023, model__max_depth=4, model__min_child_weight=7, model__n_estimators=140, model__subsample=0.9574798377718904\n",
      "[CV 15/37; 16/30] END model__colsample_bytree=0.8950877702656028, model__learning_rate=0.1311919949562023, model__max_depth=4, model__min_child_weight=7, model__n_estimators=140, model__subsample=0.9574798377718904;, score=0.197 total time=   0.8s\n",
      "[CV 19/37; 16/30] START model__colsample_bytree=0.8950877702656028, model__learning_rate=0.1311919949562023, model__max_depth=4, model__min_child_weight=7, model__n_estimators=140, model__subsample=0.9574798377718904\n",
      "[CV 16/37; 16/30] END model__colsample_bytree=0.8950877702656028, model__learning_rate=0.1311919949562023, model__max_depth=4, model__min_child_weight=7, model__n_estimators=140, model__subsample=0.9574798377718904;, score=-0.777 total time=   0.8s\n",
      "[CV 20/37; 16/30] START model__colsample_bytree=0.8950877702656028, model__learning_rate=0.1311919949562023, model__max_depth=4, model__min_child_weight=7, model__n_estimators=140, model__subsample=0.9574798377718904\n",
      "[CV 17/37; 16/30] END model__colsample_bytree=0.8950877702656028, model__learning_rate=0.1311919949562023, model__max_depth=4, model__min_child_weight=7, model__n_estimators=140, model__subsample=0.9574798377718904;, score=-18.198 total time=   0.9s\n",
      "[CV 21/37; 16/30] START model__colsample_bytree=0.8950877702656028, model__learning_rate=0.1311919949562023, model__max_depth=4, model__min_child_weight=7, model__n_estimators=140, model__subsample=0.9574798377718904\n",
      "[CV 18/37; 16/30] END model__colsample_bytree=0.8950877702656028, model__learning_rate=0.1311919949562023, model__max_depth=4, model__min_child_weight=7, model__n_estimators=140, model__subsample=0.9574798377718904;, score=-0.559 total time=   0.8s\n",
      "[CV 22/37; 16/30] START model__colsample_bytree=0.8950877702656028, model__learning_rate=0.1311919949562023, model__max_depth=4, model__min_child_weight=7, model__n_estimators=140, model__subsample=0.9574798377718904\n",
      "[CV 19/37; 16/30] END model__colsample_bytree=0.8950877702656028, model__learning_rate=0.1311919949562023, model__max_depth=4, model__min_child_weight=7, model__n_estimators=140, model__subsample=0.9574798377718904;, score=-0.888 total time=   0.9s\n",
      "[CV 23/37; 16/30] START model__colsample_bytree=0.8950877702656028, model__learning_rate=0.1311919949562023, model__max_depth=4, model__min_child_weight=7, model__n_estimators=140, model__subsample=0.9574798377718904\n",
      "[CV 20/37; 16/30] END model__colsample_bytree=0.8950877702656028, model__learning_rate=0.1311919949562023, model__max_depth=4, model__min_child_weight=7, model__n_estimators=140, model__subsample=0.9574798377718904;, score=-4.613 total time=   0.9s\n",
      "[CV 24/37; 16/30] START model__colsample_bytree=0.8950877702656028, model__learning_rate=0.1311919949562023, model__max_depth=4, model__min_child_weight=7, model__n_estimators=140, model__subsample=0.9574798377718904\n",
      "[CV 30/37; 15/30] END model__colsample_bytree=0.8861223846483287, model__learning_rate=0.04974313630683449, model__max_depth=9, model__min_child_weight=3, model__n_estimators=692, model__subsample=0.855670976374325;, score=-0.127 total time=  15.8s\n",
      "[CV 25/37; 16/30] START model__colsample_bytree=0.8950877702656028, model__learning_rate=0.1311919949562023, model__max_depth=4, model__min_child_weight=7, model__n_estimators=140, model__subsample=0.9574798377718904\n",
      "[CV 21/37; 16/30] END model__colsample_bytree=0.8950877702656028, model__learning_rate=0.1311919949562023, model__max_depth=4, model__min_child_weight=7, model__n_estimators=140, model__subsample=0.9574798377718904;, score=-1.349 total time=   1.0s\n",
      "[CV 26/37; 16/30] START model__colsample_bytree=0.8950877702656028, model__learning_rate=0.1311919949562023, model__max_depth=4, model__min_child_weight=7, model__n_estimators=140, model__subsample=0.9574798377718904\n",
      "[CV 22/37; 16/30] END model__colsample_bytree=0.8950877702656028, model__learning_rate=0.1311919949562023, model__max_depth=4, model__min_child_weight=7, model__n_estimators=140, model__subsample=0.9574798377718904;, score=-0.632 total time=   1.0s\n",
      "[CV 27/37; 16/30] START model__colsample_bytree=0.8950877702656028, model__learning_rate=0.1311919949562023, model__max_depth=4, model__min_child_weight=7, model__n_estimators=140, model__subsample=0.9574798377718904\n",
      "[CV 23/37; 16/30] END model__colsample_bytree=0.8950877702656028, model__learning_rate=0.1311919949562023, model__max_depth=4, model__min_child_weight=7, model__n_estimators=140, model__subsample=0.9574798377718904;, score=-11.812 total time=   1.1s\n",
      "[CV 28/37; 16/30] START model__colsample_bytree=0.8950877702656028, model__learning_rate=0.1311919949562023, model__max_depth=4, model__min_child_weight=7, model__n_estimators=140, model__subsample=0.9574798377718904\n",
      "[CV 24/37; 16/30] END model__colsample_bytree=0.8950877702656028, model__learning_rate=0.1311919949562023, model__max_depth=4, model__min_child_weight=7, model__n_estimators=140, model__subsample=0.9574798377718904;, score=-7.899 total time=   1.1s\n",
      "[CV 29/37; 16/30] START model__colsample_bytree=0.8950877702656028, model__learning_rate=0.1311919949562023, model__max_depth=4, model__min_child_weight=7, model__n_estimators=140, model__subsample=0.9574798377718904\n",
      "[CV 31/37; 15/30] END model__colsample_bytree=0.8861223846483287, model__learning_rate=0.04974313630683449, model__max_depth=9, model__min_child_weight=3, model__n_estimators=692, model__subsample=0.855670976374325;, score=-0.213 total time=  16.1s\n",
      "[CV 30/37; 16/30] START model__colsample_bytree=0.8950877702656028, model__learning_rate=0.1311919949562023, model__max_depth=4, model__min_child_weight=7, model__n_estimators=140, model__subsample=0.9574798377718904\n",
      "[CV 25/37; 16/30] END model__colsample_bytree=0.8950877702656028, model__learning_rate=0.1311919949562023, model__max_depth=4, model__min_child_weight=7, model__n_estimators=140, model__subsample=0.9574798377718904;, score=-1.065 total time=   1.2s\n",
      "[CV 31/37; 16/30] START model__colsample_bytree=0.8950877702656028, model__learning_rate=0.1311919949562023, model__max_depth=4, model__min_child_weight=7, model__n_estimators=140, model__subsample=0.9574798377718904\n",
      "[CV 26/37; 16/30] END model__colsample_bytree=0.8950877702656028, model__learning_rate=0.1311919949562023, model__max_depth=4, model__min_child_weight=7, model__n_estimators=140, model__subsample=0.9574798377718904;, score=-1.854 total time=   1.2s\n",
      "[CV 32/37; 16/30] START model__colsample_bytree=0.8950877702656028, model__learning_rate=0.1311919949562023, model__max_depth=4, model__min_child_weight=7, model__n_estimators=140, model__subsample=0.9574798377718904\n",
      "[CV 27/37; 16/30] END model__colsample_bytree=0.8950877702656028, model__learning_rate=0.1311919949562023, model__max_depth=4, model__min_child_weight=7, model__n_estimators=140, model__subsample=0.9574798377718904;, score=-2.936 total time=   1.3s\n",
      "[CV 33/37; 16/30] START model__colsample_bytree=0.8950877702656028, model__learning_rate=0.1311919949562023, model__max_depth=4, model__min_child_weight=7, model__n_estimators=140, model__subsample=0.9574798377718904\n",
      "[CV 28/37; 16/30] END model__colsample_bytree=0.8950877702656028, model__learning_rate=0.1311919949562023, model__max_depth=4, model__min_child_weight=7, model__n_estimators=140, model__subsample=0.9574798377718904;, score=-1.351 total time=   1.3s\n",
      "[CV 34/37; 16/30] START model__colsample_bytree=0.8950877702656028, model__learning_rate=0.1311919949562023, model__max_depth=4, model__min_child_weight=7, model__n_estimators=140, model__subsample=0.9574798377718904\n",
      "[CV 29/37; 16/30] END model__colsample_bytree=0.8950877702656028, model__learning_rate=0.1311919949562023, model__max_depth=4, model__min_child_weight=7, model__n_estimators=140, model__subsample=0.9574798377718904;, score=-8.858 total time=   1.3s\n",
      "[CV 35/37; 16/30] START model__colsample_bytree=0.8950877702656028, model__learning_rate=0.1311919949562023, model__max_depth=4, model__min_child_weight=7, model__n_estimators=140, model__subsample=0.9574798377718904\n",
      "[CV 30/37; 16/30] END model__colsample_bytree=0.8950877702656028, model__learning_rate=0.1311919949562023, model__max_depth=4, model__min_child_weight=7, model__n_estimators=140, model__subsample=0.9574798377718904;, score=-0.186 total time=   1.3s\n",
      "[CV 36/37; 16/30] START model__colsample_bytree=0.8950877702656028, model__learning_rate=0.1311919949562023, model__max_depth=4, model__min_child_weight=7, model__n_estimators=140, model__subsample=0.9574798377718904\n",
      "[CV 31/37; 16/30] END model__colsample_bytree=0.8950877702656028, model__learning_rate=0.1311919949562023, model__max_depth=4, model__min_child_weight=7, model__n_estimators=140, model__subsample=0.9574798377718904;, score=0.169 total time=   1.4s\n",
      "[CV 37/37; 16/30] START model__colsample_bytree=0.8950877702656028, model__learning_rate=0.1311919949562023, model__max_depth=4, model__min_child_weight=7, model__n_estimators=140, model__subsample=0.9574798377718904\n",
      "[CV 32/37; 16/30] END model__colsample_bytree=0.8950877702656028, model__learning_rate=0.1311919949562023, model__max_depth=4, model__min_child_weight=7, model__n_estimators=140, model__subsample=0.9574798377718904;, score=-3.204 total time=   1.4s\n",
      "[CV 1/37; 17/30] START model__colsample_bytree=0.9250192888948996, model__learning_rate=0.09989013482764068, model__max_depth=3, model__min_child_weight=7, model__n_estimators=506, model__subsample=0.8344206263318037\n",
      "[CV 32/37; 15/30] END model__colsample_bytree=0.8861223846483287, model__learning_rate=0.04974313630683449, model__max_depth=9, model__min_child_weight=3, model__n_estimators=692, model__subsample=0.855670976374325;, score=-3.557 total time=  16.5s\n",
      "[CV 2/37; 17/30] START model__colsample_bytree=0.9250192888948996, model__learning_rate=0.09989013482764068, model__max_depth=3, model__min_child_weight=7, model__n_estimators=506, model__subsample=0.8344206263318037\n",
      "[CV 33/37; 16/30] END model__colsample_bytree=0.8950877702656028, model__learning_rate=0.1311919949562023, model__max_depth=4, model__min_child_weight=7, model__n_estimators=140, model__subsample=0.9574798377718904;, score=-16.870 total time=   1.5s\n",
      "[CV 3/37; 17/30] START model__colsample_bytree=0.9250192888948996, model__learning_rate=0.09989013482764068, model__max_depth=3, model__min_child_weight=7, model__n_estimators=506, model__subsample=0.8344206263318037\n",
      "[CV 1/37; 17/30] END model__colsample_bytree=0.9250192888948996, model__learning_rate=0.09989013482764068, model__max_depth=3, model__min_child_weight=7, model__n_estimators=506, model__subsample=0.8344206263318037;, score=-43.306 total time=   0.3s\n",
      "[CV 4/37; 17/30] START model__colsample_bytree=0.9250192888948996, model__learning_rate=0.09989013482764068, model__max_depth=3, model__min_child_weight=7, model__n_estimators=506, model__subsample=0.8344206263318037\n",
      "[CV 34/37; 16/30] END model__colsample_bytree=0.8950877702656028, model__learning_rate=0.1311919949562023, model__max_depth=4, model__min_child_weight=7, model__n_estimators=140, model__subsample=0.9574798377718904;, score=0.184 total time=   1.6s\n",
      "[CV 5/37; 17/30] START model__colsample_bytree=0.9250192888948996, model__learning_rate=0.09989013482764068, model__max_depth=3, model__min_child_weight=7, model__n_estimators=506, model__subsample=0.8344206263318037\n",
      "[CV 2/37; 17/30] END model__colsample_bytree=0.9250192888948996, model__learning_rate=0.09989013482764068, model__max_depth=3, model__min_child_weight=7, model__n_estimators=506, model__subsample=0.8344206263318037;, score=-0.546 total time=   0.4s\n",
      "[CV 6/37; 17/30] START model__colsample_bytree=0.9250192888948996, model__learning_rate=0.09989013482764068, model__max_depth=3, model__min_child_weight=7, model__n_estimators=506, model__subsample=0.8344206263318037\n",
      "[CV 3/37; 17/30] END model__colsample_bytree=0.9250192888948996, model__learning_rate=0.09989013482764068, model__max_depth=3, model__min_child_weight=7, model__n_estimators=506, model__subsample=0.8344206263318037;, score=-22.891 total time=   0.5s\n",
      "[CV 7/37; 17/30] START model__colsample_bytree=0.9250192888948996, model__learning_rate=0.09989013482764068, model__max_depth=3, model__min_child_weight=7, model__n_estimators=506, model__subsample=0.8344206263318037\n",
      "[CV 4/37; 17/30] END model__colsample_bytree=0.9250192888948996, model__learning_rate=0.09989013482764068, model__max_depth=3, model__min_child_weight=7, model__n_estimators=506, model__subsample=0.8344206263318037;, score=-7.429 total time=   0.6s\n",
      "[CV 8/37; 17/30] START model__colsample_bytree=0.9250192888948996, model__learning_rate=0.09989013482764068, model__max_depth=3, model__min_child_weight=7, model__n_estimators=506, model__subsample=0.8344206263318037\n",
      "[CV 35/37; 16/30] END model__colsample_bytree=0.8950877702656028, model__learning_rate=0.1311919949562023, model__max_depth=4, model__min_child_weight=7, model__n_estimators=140, model__subsample=0.9574798377718904;, score=-18.212 total time=   1.5s\n",
      "[CV 9/37; 17/30] START model__colsample_bytree=0.9250192888948996, model__learning_rate=0.09989013482764068, model__max_depth=3, model__min_child_weight=7, model__n_estimators=506, model__subsample=0.8344206263318037\n",
      "[CV 5/37; 17/30] END model__colsample_bytree=0.9250192888948996, model__learning_rate=0.09989013482764068, model__max_depth=3, model__min_child_weight=7, model__n_estimators=506, model__subsample=0.8344206263318037;, score=-37.749 total time=   0.7s\n",
      "[CV 10/37; 17/30] START model__colsample_bytree=0.9250192888948996, model__learning_rate=0.09989013482764068, model__max_depth=3, model__min_child_weight=7, model__n_estimators=506, model__subsample=0.8344206263318037\n",
      "[CV 36/37; 16/30] END model__colsample_bytree=0.8950877702656028, model__learning_rate=0.1311919949562023, model__max_depth=4, model__min_child_weight=7, model__n_estimators=140, model__subsample=0.9574798377718904;, score=-1.158 total time=   1.6s\n",
      "[CV 11/37; 17/30] START model__colsample_bytree=0.9250192888948996, model__learning_rate=0.09989013482764068, model__max_depth=3, model__min_child_weight=7, model__n_estimators=506, model__subsample=0.8344206263318037\n",
      "[CV 6/37; 17/30] END model__colsample_bytree=0.9250192888948996, model__learning_rate=0.09989013482764068, model__max_depth=3, model__min_child_weight=7, model__n_estimators=506, model__subsample=0.8344206263318037;, score=-3.166 total time=   0.8s\n",
      "[CV 12/37; 17/30] START model__colsample_bytree=0.9250192888948996, model__learning_rate=0.09989013482764068, model__max_depth=3, model__min_child_weight=7, model__n_estimators=506, model__subsample=0.8344206263318037\n",
      "[CV 37/37; 16/30] END model__colsample_bytree=0.8950877702656028, model__learning_rate=0.1311919949562023, model__max_depth=4, model__min_child_weight=7, model__n_estimators=140, model__subsample=0.9574798377718904;, score=0.250 total time=   1.6s\n",
      "[CV 13/37; 17/30] START model__colsample_bytree=0.9250192888948996, model__learning_rate=0.09989013482764068, model__max_depth=3, model__min_child_weight=7, model__n_estimators=506, model__subsample=0.8344206263318037\n",
      "[CV 33/37; 15/30] END model__colsample_bytree=0.8861223846483287, model__learning_rate=0.04974313630683449, model__max_depth=9, model__min_child_weight=3, model__n_estimators=692, model__subsample=0.855670976374325;, score=-23.190 total time=  17.0s\n",
      "[CV 7/37; 17/30] END model__colsample_bytree=0.9250192888948996, model__learning_rate=0.09989013482764068, model__max_depth=3, model__min_child_weight=7, model__n_estimators=506, model__subsample=0.8344206263318037;, score=-6.420 total time=   0.9s\n",
      "[CV 14/37; 17/30] START model__colsample_bytree=0.9250192888948996, model__learning_rate=0.09989013482764068, model__max_depth=3, model__min_child_weight=7, model__n_estimators=506, model__subsample=0.8344206263318037\n",
      "[CV 8/37; 17/30] END model__colsample_bytree=0.9250192888948996, model__learning_rate=0.09989013482764068, model__max_depth=3, model__min_child_weight=7, model__n_estimators=506, model__subsample=0.8344206263318037;, score=-9.229 total time=   1.1s\n",
      "[CV 16/37; 17/30] START model__colsample_bytree=0.9250192888948996, model__learning_rate=0.09989013482764068, model__max_depth=3, model__min_child_weight=7, model__n_estimators=506, model__subsample=0.8344206263318037\n",
      "[CV 9/37; 17/30] END model__colsample_bytree=0.9250192888948996, model__learning_rate=0.09989013482764068, model__max_depth=3, model__min_child_weight=7, model__n_estimators=506, model__subsample=0.8344206263318037;, score=-0.780 total time=   1.2s\n",
      "[CV 17/37; 17/30] START model__colsample_bytree=0.9250192888948996, model__learning_rate=0.09989013482764068, model__max_depth=3, model__min_child_weight=7, model__n_estimators=506, model__subsample=0.8344206263318037\n",
      "[CV 15/37; 17/30] START model__colsample_bytree=0.9250192888948996, model__learning_rate=0.09989013482764068, model__max_depth=3, model__min_child_weight=7, model__n_estimators=506, model__subsample=0.8344206263318037\n",
      "[CV 10/37; 17/30] END model__colsample_bytree=0.9250192888948996, model__learning_rate=0.09989013482764068, model__max_depth=3, model__min_child_weight=7, model__n_estimators=506, model__subsample=0.8344206263318037;, score=-24.590 total time=   1.2s\n",
      "[CV 18/37; 17/30] START model__colsample_bytree=0.9250192888948996, model__learning_rate=0.09989013482764068, model__max_depth=3, model__min_child_weight=7, model__n_estimators=506, model__subsample=0.8344206263318037\n",
      "[CV 11/37; 17/30] END model__colsample_bytree=0.9250192888948996, model__learning_rate=0.09989013482764068, model__max_depth=3, model__min_child_weight=7, model__n_estimators=506, model__subsample=0.8344206263318037;, score=-3.733 total time=   1.3s\n",
      "[CV 19/37; 17/30] START model__colsample_bytree=0.9250192888948996, model__learning_rate=0.09989013482764068, model__max_depth=3, model__min_child_weight=7, model__n_estimators=506, model__subsample=0.8344206263318037\n",
      "[CV 12/37; 17/30] END model__colsample_bytree=0.9250192888948996, model__learning_rate=0.09989013482764068, model__max_depth=3, model__min_child_weight=7, model__n_estimators=506, model__subsample=0.8344206263318037;, score=-18.590 total time=   1.5s\n",
      "[CV 20/37; 17/30] START model__colsample_bytree=0.9250192888948996, model__learning_rate=0.09989013482764068, model__max_depth=3, model__min_child_weight=7, model__n_estimators=506, model__subsample=0.8344206263318037\n",
      "[CV 13/37; 17/30] END model__colsample_bytree=0.9250192888948996, model__learning_rate=0.09989013482764068, model__max_depth=3, model__min_child_weight=7, model__n_estimators=506, model__subsample=0.8344206263318037;, score=0.091 total time=   1.5s\n",
      "[CV 21/37; 17/30] START model__colsample_bytree=0.9250192888948996, model__learning_rate=0.09989013482764068, model__max_depth=3, model__min_child_weight=7, model__n_estimators=506, model__subsample=0.8344206263318037\n",
      "[CV 14/37; 17/30] END model__colsample_bytree=0.9250192888948996, model__learning_rate=0.09989013482764068, model__max_depth=3, model__min_child_weight=7, model__n_estimators=506, model__subsample=0.8344206263318037;, score=-21.099 total time=   1.7s\n",
      "[CV 22/37; 17/30] START model__colsample_bytree=0.9250192888948996, model__learning_rate=0.09989013482764068, model__max_depth=3, model__min_child_weight=7, model__n_estimators=506, model__subsample=0.8344206263318037\n",
      "[CV 34/37; 15/30] END model__colsample_bytree=0.8861223846483287, model__learning_rate=0.04974313630683449, model__max_depth=9, model__min_child_weight=3, model__n_estimators=692, model__subsample=0.855670976374325;, score=-0.051 total time=  17.8s\n",
      "[CV 23/37; 17/30] START model__colsample_bytree=0.9250192888948996, model__learning_rate=0.09989013482764068, model__max_depth=3, model__min_child_weight=7, model__n_estimators=506, model__subsample=0.8344206263318037\n",
      "[CV 16/37; 17/30] END model__colsample_bytree=0.9250192888948996, model__learning_rate=0.09989013482764068, model__max_depth=3, model__min_child_weight=7, model__n_estimators=506, model__subsample=0.8344206263318037;, score=-1.009 total time=   1.9s\n",
      "[CV 24/37; 17/30] START model__colsample_bytree=0.9250192888948996, model__learning_rate=0.09989013482764068, model__max_depth=3, model__min_child_weight=7, model__n_estimators=506, model__subsample=0.8344206263318037\n",
      "[CV 17/37; 17/30] END model__colsample_bytree=0.9250192888948996, model__learning_rate=0.09989013482764068, model__max_depth=3, model__min_child_weight=7, model__n_estimators=506, model__subsample=0.8344206263318037;, score=-18.216 total time=   1.9s\n",
      "[CV 25/37; 17/30] START model__colsample_bytree=0.9250192888948996, model__learning_rate=0.09989013482764068, model__max_depth=3, model__min_child_weight=7, model__n_estimators=506, model__subsample=0.8344206263318037\n",
      "[CV 15/37; 17/30] END model__colsample_bytree=0.9250192888948996, model__learning_rate=0.09989013482764068, model__max_depth=3, model__min_child_weight=7, model__n_estimators=506, model__subsample=0.8344206263318037;, score=-0.191 total time=   1.8s\n",
      "[CV 26/37; 17/30] START model__colsample_bytree=0.9250192888948996, model__learning_rate=0.09989013482764068, model__max_depth=3, model__min_child_weight=7, model__n_estimators=506, model__subsample=0.8344206263318037\n",
      "[CV 18/37; 17/30] END model__colsample_bytree=0.9250192888948996, model__learning_rate=0.09989013482764068, model__max_depth=3, model__min_child_weight=7, model__n_estimators=506, model__subsample=0.8344206263318037;, score=-0.983 total time=   2.0s\n",
      "[CV 27/37; 17/30] START model__colsample_bytree=0.9250192888948996, model__learning_rate=0.09989013482764068, model__max_depth=3, model__min_child_weight=7, model__n_estimators=506, model__subsample=0.8344206263318037\n",
      "[CV 19/37; 17/30] END model__colsample_bytree=0.9250192888948996, model__learning_rate=0.09989013482764068, model__max_depth=3, model__min_child_weight=7, model__n_estimators=506, model__subsample=0.8344206263318037;, score=-1.104 total time=   2.1s\n",
      "[CV 28/37; 17/30] START model__colsample_bytree=0.9250192888948996, model__learning_rate=0.09989013482764068, model__max_depth=3, model__min_child_weight=7, model__n_estimators=506, model__subsample=0.8344206263318037\n",
      "[CV 20/37; 17/30] END model__colsample_bytree=0.9250192888948996, model__learning_rate=0.09989013482764068, model__max_depth=3, model__min_child_weight=7, model__n_estimators=506, model__subsample=0.8344206263318037;, score=-3.411 total time=   2.2s\n",
      "[CV 29/37; 17/30] START model__colsample_bytree=0.9250192888948996, model__learning_rate=0.09989013482764068, model__max_depth=3, model__min_child_weight=7, model__n_estimators=506, model__subsample=0.8344206263318037\n",
      "[CV 21/37; 17/30] END model__colsample_bytree=0.9250192888948996, model__learning_rate=0.09989013482764068, model__max_depth=3, model__min_child_weight=7, model__n_estimators=506, model__subsample=0.8344206263318037;, score=-1.529 total time=   2.4s\n",
      "[CV 30/37; 17/30] START model__colsample_bytree=0.9250192888948996, model__learning_rate=0.09989013482764068, model__max_depth=3, model__min_child_weight=7, model__n_estimators=506, model__subsample=0.8344206263318037\n",
      "[CV 22/37; 17/30] END model__colsample_bytree=0.9250192888948996, model__learning_rate=0.09989013482764068, model__max_depth=3, model__min_child_weight=7, model__n_estimators=506, model__subsample=0.8344206263318037;, score=-0.646 total time=   2.5s\n",
      "[CV 31/37; 17/30] START model__colsample_bytree=0.9250192888948996, model__learning_rate=0.09989013482764068, model__max_depth=3, model__min_child_weight=7, model__n_estimators=506, model__subsample=0.8344206263318037\n",
      "[CV 23/37; 17/30] END model__colsample_bytree=0.9250192888948996, model__learning_rate=0.09989013482764068, model__max_depth=3, model__min_child_weight=7, model__n_estimators=506, model__subsample=0.8344206263318037;, score=-11.002 total time=   2.6s\n",
      "[CV 32/37; 17/30] START model__colsample_bytree=0.9250192888948996, model__learning_rate=0.09989013482764068, model__max_depth=3, model__min_child_weight=7, model__n_estimators=506, model__subsample=0.8344206263318037\n",
      "[CV 24/37; 17/30] END model__colsample_bytree=0.9250192888948996, model__learning_rate=0.09989013482764068, model__max_depth=3, model__min_child_weight=7, model__n_estimators=506, model__subsample=0.8344206263318037;, score=-6.153 total time=   2.6s\n",
      "[CV 33/37; 17/30] START model__colsample_bytree=0.9250192888948996, model__learning_rate=0.09989013482764068, model__max_depth=3, model__min_child_weight=7, model__n_estimators=506, model__subsample=0.8344206263318037\n",
      "[CV 35/37; 15/30] END model__colsample_bytree=0.8861223846483287, model__learning_rate=0.04974313630683449, model__max_depth=9, model__min_child_weight=3, model__n_estimators=692, model__subsample=0.855670976374325;, score=-19.239 total time=  18.3s\n",
      "[CV 34/37; 17/30] START model__colsample_bytree=0.9250192888948996, model__learning_rate=0.09989013482764068, model__max_depth=3, model__min_child_weight=7, model__n_estimators=506, model__subsample=0.8344206263318037\n",
      "[CV 25/37; 17/30] END model__colsample_bytree=0.9250192888948996, model__learning_rate=0.09989013482764068, model__max_depth=3, model__min_child_weight=7, model__n_estimators=506, model__subsample=0.8344206263318037;, score=-1.030 total time=   2.8s\n",
      "[CV 35/37; 17/30] START model__colsample_bytree=0.9250192888948996, model__learning_rate=0.09989013482764068, model__max_depth=3, model__min_child_weight=7, model__n_estimators=506, model__subsample=0.8344206263318037\n",
      "[CV 26/37; 17/30] END model__colsample_bytree=0.9250192888948996, model__learning_rate=0.09989013482764068, model__max_depth=3, model__min_child_weight=7, model__n_estimators=506, model__subsample=0.8344206263318037;, score=-2.256 total time=   2.9s\n",
      "[CV 36/37; 17/30] START model__colsample_bytree=0.9250192888948996, model__learning_rate=0.09989013482764068, model__max_depth=3, model__min_child_weight=7, model__n_estimators=506, model__subsample=0.8344206263318037\n",
      "[CV 36/37; 15/30] END model__colsample_bytree=0.8861223846483287, model__learning_rate=0.04974313630683449, model__max_depth=9, model__min_child_weight=3, model__n_estimators=692, model__subsample=0.855670976374325;, score=-1.495 total time=  18.7s\n",
      "[CV 37/37; 17/30] START model__colsample_bytree=0.9250192888948996, model__learning_rate=0.09989013482764068, model__max_depth=3, model__min_child_weight=7, model__n_estimators=506, model__subsample=0.8344206263318037\n",
      "[CV 27/37; 17/30] END model__colsample_bytree=0.9250192888948996, model__learning_rate=0.09989013482764068, model__max_depth=3, model__min_child_weight=7, model__n_estimators=506, model__subsample=0.8344206263318037;, score=-2.552 total time=   3.1s\n",
      "[CV 1/37; 18/30] START model__colsample_bytree=0.8329611783087483, model__learning_rate=0.12825955754154544, model__max_depth=8, model__min_child_weight=3, model__n_estimators=838, model__subsample=0.5597971229691509\n",
      "[CV 28/37; 17/30] END model__colsample_bytree=0.9250192888948996, model__learning_rate=0.09989013482764068, model__max_depth=3, model__min_child_weight=7, model__n_estimators=506, model__subsample=0.8344206263318037;, score=-1.510 total time=   3.0s\n",
      "[CV 2/37; 18/30] START model__colsample_bytree=0.8329611783087483, model__learning_rate=0.12825955754154544, model__max_depth=8, model__min_child_weight=3, model__n_estimators=838, model__subsample=0.5597971229691509\n",
      "[CV 1/37; 18/30] END model__colsample_bytree=0.8329611783087483, model__learning_rate=0.12825955754154544, model__max_depth=8, model__min_child_weight=3, model__n_estimators=838, model__subsample=0.5597971229691509;, score=-40.650 total time=   0.3s\n",
      "[CV 3/37; 18/30] START model__colsample_bytree=0.8329611783087483, model__learning_rate=0.12825955754154544, model__max_depth=8, model__min_child_weight=3, model__n_estimators=838, model__subsample=0.5597971229691509\n",
      "[CV 29/37; 17/30] END model__colsample_bytree=0.9250192888948996, model__learning_rate=0.09989013482764068, model__max_depth=3, model__min_child_weight=7, model__n_estimators=506, model__subsample=0.8344206263318037;, score=-10.518 total time=   3.2s\n",
      "[CV 4/37; 18/30] START model__colsample_bytree=0.8329611783087483, model__learning_rate=0.12825955754154544, model__max_depth=8, model__min_child_weight=3, model__n_estimators=838, model__subsample=0.5597971229691509\n",
      "[CV 2/37; 18/30] END model__colsample_bytree=0.8329611783087483, model__learning_rate=0.12825955754154544, model__max_depth=8, model__min_child_weight=3, model__n_estimators=838, model__subsample=0.5597971229691509;, score=-0.419 total time=   0.4s\n",
      "[CV 5/37; 18/30] START model__colsample_bytree=0.8329611783087483, model__learning_rate=0.12825955754154544, model__max_depth=8, model__min_child_weight=3, model__n_estimators=838, model__subsample=0.5597971229691509\n",
      "[CV 3/37; 18/30] END model__colsample_bytree=0.8329611783087483, model__learning_rate=0.12825955754154544, model__max_depth=8, model__min_child_weight=3, model__n_estimators=838, model__subsample=0.5597971229691509;, score=-19.282 total time=   0.6s\n",
      "[CV 6/37; 18/30] START model__colsample_bytree=0.8329611783087483, model__learning_rate=0.12825955754154544, model__max_depth=8, model__min_child_weight=3, model__n_estimators=838, model__subsample=0.5597971229691509\n",
      "[CV 30/37; 17/30] END model__colsample_bytree=0.9250192888948996, model__learning_rate=0.09989013482764068, model__max_depth=3, model__min_child_weight=7, model__n_estimators=506, model__subsample=0.8344206263318037;, score=-0.290 total time=   3.2s\n",
      "[CV 7/37; 18/30] START model__colsample_bytree=0.8329611783087483, model__learning_rate=0.12825955754154544, model__max_depth=8, model__min_child_weight=3, model__n_estimators=838, model__subsample=0.5597971229691509\n",
      "[CV 4/37; 18/30] END model__colsample_bytree=0.8329611783087483, model__learning_rate=0.12825955754154544, model__max_depth=8, model__min_child_weight=3, model__n_estimators=838, model__subsample=0.5597971229691509;, score=-7.081 total time=   0.8s\n",
      "[CV 8/37; 18/30] START model__colsample_bytree=0.8329611783087483, model__learning_rate=0.12825955754154544, model__max_depth=8, model__min_child_weight=3, model__n_estimators=838, model__subsample=0.5597971229691509\n",
      "[CV 31/37; 17/30] END model__colsample_bytree=0.9250192888948996, model__learning_rate=0.09989013482764068, model__max_depth=3, model__min_child_weight=7, model__n_estimators=506, model__subsample=0.8344206263318037;, score=0.303 total time=   3.4s\n",
      "[CV 9/37; 18/30] START model__colsample_bytree=0.8329611783087483, model__learning_rate=0.12825955754154544, model__max_depth=8, model__min_child_weight=3, model__n_estimators=838, model__subsample=0.5597971229691509\n",
      "[CV 5/37; 18/30] END model__colsample_bytree=0.8329611783087483, model__learning_rate=0.12825955754154544, model__max_depth=8, model__min_child_weight=3, model__n_estimators=838, model__subsample=0.5597971229691509;, score=-38.987 total time=   1.0s\n",
      "[CV 10/37; 18/30] START model__colsample_bytree=0.8329611783087483, model__learning_rate=0.12825955754154544, model__max_depth=8, model__min_child_weight=3, model__n_estimators=838, model__subsample=0.5597971229691509\n",
      "[CV 32/37; 17/30] END model__colsample_bytree=0.9250192888948996, model__learning_rate=0.09989013482764068, model__max_depth=3, model__min_child_weight=7, model__n_estimators=506, model__subsample=0.8344206263318037;, score=-3.303 total time=   3.3s\n",
      "[CV 11/37; 18/30] START model__colsample_bytree=0.8329611783087483, model__learning_rate=0.12825955754154544, model__max_depth=8, model__min_child_weight=3, model__n_estimators=838, model__subsample=0.5597971229691509\n",
      "[CV 37/37; 15/30] END model__colsample_bytree=0.8861223846483287, model__learning_rate=0.04974313630683449, model__max_depth=9, model__min_child_weight=3, model__n_estimators=692, model__subsample=0.855670976374325;, score=-0.066 total time=  19.1s\n",
      "[CV 12/37; 18/30] START model__colsample_bytree=0.8329611783087483, model__learning_rate=0.12825955754154544, model__max_depth=8, model__min_child_weight=3, model__n_estimators=838, model__subsample=0.5597971229691509\n",
      "[CV 6/37; 18/30] END model__colsample_bytree=0.8329611783087483, model__learning_rate=0.12825955754154544, model__max_depth=8, model__min_child_weight=3, model__n_estimators=838, model__subsample=0.5597971229691509;, score=-1.316 total time=   1.2s\n",
      "[CV 13/37; 18/30] START model__colsample_bytree=0.8329611783087483, model__learning_rate=0.12825955754154544, model__max_depth=8, model__min_child_weight=3, model__n_estimators=838, model__subsample=0.5597971229691509\n",
      "[CV 33/37; 17/30] END model__colsample_bytree=0.9250192888948996, model__learning_rate=0.09989013482764068, model__max_depth=3, model__min_child_weight=7, model__n_estimators=506, model__subsample=0.8344206263318037;, score=-15.349 total time=   3.6s\n",
      "[CV 14/37; 18/30] START model__colsample_bytree=0.8329611783087483, model__learning_rate=0.12825955754154544, model__max_depth=8, model__min_child_weight=3, model__n_estimators=838, model__subsample=0.5597971229691509\n",
      "[CV 34/37; 17/30] END model__colsample_bytree=0.9250192888948996, model__learning_rate=0.09989013482764068, model__max_depth=3, model__min_child_weight=7, model__n_estimators=506, model__subsample=0.8344206263318037;, score=0.323 total time=   3.6s\n",
      "[CV 15/37; 18/30] START model__colsample_bytree=0.8329611783087483, model__learning_rate=0.12825955754154544, model__max_depth=8, model__min_child_weight=3, model__n_estimators=838, model__subsample=0.5597971229691509\n",
      "[CV 7/37; 18/30] END model__colsample_bytree=0.8329611783087483, model__learning_rate=0.12825955754154544, model__max_depth=8, model__min_child_weight=3, model__n_estimators=838, model__subsample=0.5597971229691509;, score=-6.287 total time=   1.5s\n",
      "[CV 16/37; 18/30] START model__colsample_bytree=0.8329611783087483, model__learning_rate=0.12825955754154544, model__max_depth=8, model__min_child_weight=3, model__n_estimators=838, model__subsample=0.5597971229691509\n",
      "[CV 35/37; 17/30] END model__colsample_bytree=0.9250192888948996, model__learning_rate=0.09989013482764068, model__max_depth=3, model__min_child_weight=7, model__n_estimators=506, model__subsample=0.8344206263318037;, score=-18.886 total time=   3.8s\n",
      "[CV 17/37; 18/30] START model__colsample_bytree=0.8329611783087483, model__learning_rate=0.12825955754154544, model__max_depth=8, model__min_child_weight=3, model__n_estimators=838, model__subsample=0.5597971229691509\n",
      "[CV 8/37; 18/30] END model__colsample_bytree=0.8329611783087483, model__learning_rate=0.12825955754154544, model__max_depth=8, model__min_child_weight=3, model__n_estimators=838, model__subsample=0.5597971229691509;, score=-8.030 total time=   1.7s\n",
      "[CV 18/37; 18/30] START model__colsample_bytree=0.8329611783087483, model__learning_rate=0.12825955754154544, model__max_depth=8, model__min_child_weight=3, model__n_estimators=838, model__subsample=0.5597971229691509\n",
      "[CV 36/37; 17/30] END model__colsample_bytree=0.9250192888948996, model__learning_rate=0.09989013482764068, model__max_depth=3, model__min_child_weight=7, model__n_estimators=506, model__subsample=0.8344206263318037;, score=-1.018 total time=   3.8s\n",
      "[CV 19/37; 18/30] START model__colsample_bytree=0.8329611783087483, model__learning_rate=0.12825955754154544, model__max_depth=8, model__min_child_weight=3, model__n_estimators=838, model__subsample=0.5597971229691509\n",
      "[CV 9/37; 18/30] END model__colsample_bytree=0.8329611783087483, model__learning_rate=0.12825955754154544, model__max_depth=8, model__min_child_weight=3, model__n_estimators=838, model__subsample=0.5597971229691509;, score=-0.712 total time=   2.1s\n",
      "[CV 20/37; 18/30] START model__colsample_bytree=0.8329611783087483, model__learning_rate=0.12825955754154544, model__max_depth=8, model__min_child_weight=3, model__n_estimators=838, model__subsample=0.5597971229691509\n",
      "[CV 37/37; 17/30] END model__colsample_bytree=0.9250192888948996, model__learning_rate=0.09989013482764068, model__max_depth=3, model__min_child_weight=7, model__n_estimators=506, model__subsample=0.8344206263318037;, score=-0.201 total time=   3.8s\n",
      "[CV 21/37; 18/30] START model__colsample_bytree=0.8329611783087483, model__learning_rate=0.12825955754154544, model__max_depth=8, model__min_child_weight=3, model__n_estimators=838, model__subsample=0.5597971229691509\n",
      "[CV 10/37; 18/30] END model__colsample_bytree=0.8329611783087483, model__learning_rate=0.12825955754154544, model__max_depth=8, model__min_child_weight=3, model__n_estimators=838, model__subsample=0.5597971229691509;, score=-28.086 total time=   2.4s\n",
      "[CV 22/37; 18/30] START model__colsample_bytree=0.8329611783087483, model__learning_rate=0.12825955754154544, model__max_depth=8, model__min_child_weight=3, model__n_estimators=838, model__subsample=0.5597971229691509\n",
      "[CV 11/37; 18/30] END model__colsample_bytree=0.8329611783087483, model__learning_rate=0.12825955754154544, model__max_depth=8, model__min_child_weight=3, model__n_estimators=838, model__subsample=0.5597971229691509;, score=-3.732 total time=   2.7s\n",
      "[CV 23/37; 18/30] START model__colsample_bytree=0.8329611783087483, model__learning_rate=0.12825955754154544, model__max_depth=8, model__min_child_weight=3, model__n_estimators=838, model__subsample=0.5597971229691509\n",
      "[CV 12/37; 18/30] END model__colsample_bytree=0.8329611783087483, model__learning_rate=0.12825955754154544, model__max_depth=8, model__min_child_weight=3, model__n_estimators=838, model__subsample=0.5597971229691509;, score=-20.327 total time=   3.0s\n",
      "[CV 24/37; 18/30] START model__colsample_bytree=0.8329611783087483, model__learning_rate=0.12825955754154544, model__max_depth=8, model__min_child_weight=3, model__n_estimators=838, model__subsample=0.5597971229691509\n",
      "[CV 13/37; 18/30] END model__colsample_bytree=0.8329611783087483, model__learning_rate=0.12825955754154544, model__max_depth=8, model__min_child_weight=3, model__n_estimators=838, model__subsample=0.5597971229691509;, score=0.113 total time=   3.3s\n",
      "[CV 25/37; 18/30] START model__colsample_bytree=0.8329611783087483, model__learning_rate=0.12825955754154544, model__max_depth=8, model__min_child_weight=3, model__n_estimators=838, model__subsample=0.5597971229691509\n",
      "[CV 14/37; 18/30] END model__colsample_bytree=0.8329611783087483, model__learning_rate=0.12825955754154544, model__max_depth=8, model__min_child_weight=3, model__n_estimators=838, model__subsample=0.5597971229691509;, score=-19.611 total time=   3.5s\n",
      "[CV 26/37; 18/30] START model__colsample_bytree=0.8329611783087483, model__learning_rate=0.12825955754154544, model__max_depth=8, model__min_child_weight=3, model__n_estimators=838, model__subsample=0.5597971229691509\n",
      "[CV 15/37; 18/30] END model__colsample_bytree=0.8329611783087483, model__learning_rate=0.12825955754154544, model__max_depth=8, model__min_child_weight=3, model__n_estimators=838, model__subsample=0.5597971229691509;, score=-0.022 total time=   3.9s\n",
      "[CV 27/37; 18/30] START model__colsample_bytree=0.8329611783087483, model__learning_rate=0.12825955754154544, model__max_depth=8, model__min_child_weight=3, model__n_estimators=838, model__subsample=0.5597971229691509\n",
      "[CV 16/37; 18/30] END model__colsample_bytree=0.8329611783087483, model__learning_rate=0.12825955754154544, model__max_depth=8, model__min_child_weight=3, model__n_estimators=838, model__subsample=0.5597971229691509;, score=-1.021 total time=   4.3s\n",
      "[CV 28/37; 18/30] START model__colsample_bytree=0.8329611783087483, model__learning_rate=0.12825955754154544, model__max_depth=8, model__min_child_weight=3, model__n_estimators=838, model__subsample=0.5597971229691509\n",
      "[CV 17/37; 18/30] END model__colsample_bytree=0.8329611783087483, model__learning_rate=0.12825955754154544, model__max_depth=8, model__min_child_weight=3, model__n_estimators=838, model__subsample=0.5597971229691509;, score=-19.055 total time=   4.9s\n",
      "[CV 29/37; 18/30] START model__colsample_bytree=0.8329611783087483, model__learning_rate=0.12825955754154544, model__max_depth=8, model__min_child_weight=3, model__n_estimators=838, model__subsample=0.5597971229691509\n",
      "[CV 18/37; 18/30] END model__colsample_bytree=0.8329611783087483, model__learning_rate=0.12825955754154544, model__max_depth=8, model__min_child_weight=3, model__n_estimators=838, model__subsample=0.5597971229691509;, score=-0.486 total time=   5.3s\n",
      "[CV 30/37; 18/30] START model__colsample_bytree=0.8329611783087483, model__learning_rate=0.12825955754154544, model__max_depth=8, model__min_child_weight=3, model__n_estimators=838, model__subsample=0.5597971229691509\n",
      "[CV 19/37; 18/30] END model__colsample_bytree=0.8329611783087483, model__learning_rate=0.12825955754154544, model__max_depth=8, model__min_child_weight=3, model__n_estimators=838, model__subsample=0.5597971229691509;, score=-1.298 total time=   5.6s\n",
      "[CV 31/37; 18/30] START model__colsample_bytree=0.8329611783087483, model__learning_rate=0.12825955754154544, model__max_depth=8, model__min_child_weight=3, model__n_estimators=838, model__subsample=0.5597971229691509\n",
      "[CV 20/37; 18/30] END model__colsample_bytree=0.8329611783087483, model__learning_rate=0.12825955754154544, model__max_depth=8, model__min_child_weight=3, model__n_estimators=838, model__subsample=0.5597971229691509;, score=-4.985 total time=   6.0s\n",
      "[CV 32/37; 18/30] START model__colsample_bytree=0.8329611783087483, model__learning_rate=0.12825955754154544, model__max_depth=8, model__min_child_weight=3, model__n_estimators=838, model__subsample=0.5597971229691509\n",
      "[CV 21/37; 18/30] END model__colsample_bytree=0.8329611783087483, model__learning_rate=0.12825955754154544, model__max_depth=8, model__min_child_weight=3, model__n_estimators=838, model__subsample=0.5597971229691509;, score=-1.360 total time=   6.4s\n",
      "[CV 33/37; 18/30] START model__colsample_bytree=0.8329611783087483, model__learning_rate=0.12825955754154544, model__max_depth=8, model__min_child_weight=3, model__n_estimators=838, model__subsample=0.5597971229691509\n",
      "[CV 22/37; 18/30] END model__colsample_bytree=0.8329611783087483, model__learning_rate=0.12825955754154544, model__max_depth=8, model__min_child_weight=3, model__n_estimators=838, model__subsample=0.5597971229691509;, score=-0.449 total time=   6.7s\n",
      "[CV 34/37; 18/30] START model__colsample_bytree=0.8329611783087483, model__learning_rate=0.12825955754154544, model__max_depth=8, model__min_child_weight=3, model__n_estimators=838, model__subsample=0.5597971229691509\n",
      "[CV 23/37; 18/30] END model__colsample_bytree=0.8329611783087483, model__learning_rate=0.12825955754154544, model__max_depth=8, model__min_child_weight=3, model__n_estimators=838, model__subsample=0.5597971229691509;, score=-10.664 total time=   7.4s\n",
      "[CV 35/37; 18/30] START model__colsample_bytree=0.8329611783087483, model__learning_rate=0.12825955754154544, model__max_depth=8, model__min_child_weight=3, model__n_estimators=838, model__subsample=0.5597971229691509\n",
      "[CV 24/37; 18/30] END model__colsample_bytree=0.8329611783087483, model__learning_rate=0.12825955754154544, model__max_depth=8, model__min_child_weight=3, model__n_estimators=838, model__subsample=0.5597971229691509;, score=-8.060 total time=   7.7s\n",
      "[CV 36/37; 18/30] START model__colsample_bytree=0.8329611783087483, model__learning_rate=0.12825955754154544, model__max_depth=8, model__min_child_weight=3, model__n_estimators=838, model__subsample=0.5597971229691509\n",
      "[CV 25/37; 18/30] END model__colsample_bytree=0.8329611783087483, model__learning_rate=0.12825955754154544, model__max_depth=8, model__min_child_weight=3, model__n_estimators=838, model__subsample=0.5597971229691509;, score=-0.601 total time=   8.0s\n",
      "[CV 37/37; 18/30] START model__colsample_bytree=0.8329611783087483, model__learning_rate=0.12825955754154544, model__max_depth=8, model__min_child_weight=3, model__n_estimators=838, model__subsample=0.5597971229691509\n",
      "[CV 26/37; 18/30] END model__colsample_bytree=0.8329611783087483, model__learning_rate=0.12825955754154544, model__max_depth=8, model__min_child_weight=3, model__n_estimators=838, model__subsample=0.5597971229691509;, score=-1.995 total time=   8.6s\n",
      "[CV 1/37; 19/30] START model__colsample_bytree=0.8566223936114975, model__learning_rate=0.1621570097233795, model__max_depth=4, model__min_child_weight=7, model__n_estimators=866, model__subsample=0.6280341613806619\n",
      "[CV 1/37; 19/30] END model__colsample_bytree=0.8566223936114975, model__learning_rate=0.1621570097233795, model__max_depth=4, model__min_child_weight=7, model__n_estimators=866, model__subsample=0.6280341613806619;, score=-42.707 total time=   0.4s\n",
      "[CV 2/37; 19/30] START model__colsample_bytree=0.8566223936114975, model__learning_rate=0.1621570097233795, model__max_depth=4, model__min_child_weight=7, model__n_estimators=866, model__subsample=0.6280341613806619\n",
      "[CV 2/37; 19/30] END model__colsample_bytree=0.8566223936114975, model__learning_rate=0.1621570097233795, model__max_depth=4, model__min_child_weight=7, model__n_estimators=866, model__subsample=0.6280341613806619;, score=-0.716 total time=   0.5s\n",
      "[CV 3/37; 19/30] START model__colsample_bytree=0.8566223936114975, model__learning_rate=0.1621570097233795, model__max_depth=4, model__min_child_weight=7, model__n_estimators=866, model__subsample=0.6280341613806619\n",
      "[CV 27/37; 18/30] END model__colsample_bytree=0.8329611783087483, model__learning_rate=0.12825955754154544, model__max_depth=8, model__min_child_weight=3, model__n_estimators=838, model__subsample=0.5597971229691509;, score=-2.801 total time=   9.2s\n",
      "[CV 4/37; 19/30] START model__colsample_bytree=0.8566223936114975, model__learning_rate=0.1621570097233795, model__max_depth=4, model__min_child_weight=7, model__n_estimators=866, model__subsample=0.6280341613806619\n",
      "[CV 3/37; 19/30] END model__colsample_bytree=0.8566223936114975, model__learning_rate=0.1621570097233795, model__max_depth=4, model__min_child_weight=7, model__n_estimators=866, model__subsample=0.6280341613806619;, score=-35.273 total time=   0.8s\n",
      "[CV 5/37; 19/30] START model__colsample_bytree=0.8566223936114975, model__learning_rate=0.1621570097233795, model__max_depth=4, model__min_child_weight=7, model__n_estimators=866, model__subsample=0.6280341613806619\n",
      "[CV 28/37; 18/30] END model__colsample_bytree=0.8329611783087483, model__learning_rate=0.12825955754154544, model__max_depth=8, model__min_child_weight=3, model__n_estimators=838, model__subsample=0.5597971229691509;, score=-1.431 total time=   9.7s\n",
      "[CV 6/37; 19/30] START model__colsample_bytree=0.8566223936114975, model__learning_rate=0.1621570097233795, model__max_depth=4, model__min_child_weight=7, model__n_estimators=866, model__subsample=0.6280341613806619\n",
      "[CV 4/37; 19/30] END model__colsample_bytree=0.8566223936114975, model__learning_rate=0.1621570097233795, model__max_depth=4, model__min_child_weight=7, model__n_estimators=866, model__subsample=0.6280341613806619;, score=-7.789 total time=   1.0s\n",
      "[CV 7/37; 19/30] START model__colsample_bytree=0.8566223936114975, model__learning_rate=0.1621570097233795, model__max_depth=4, model__min_child_weight=7, model__n_estimators=866, model__subsample=0.6280341613806619\n",
      "[CV 5/37; 19/30] END model__colsample_bytree=0.8566223936114975, model__learning_rate=0.1621570097233795, model__max_depth=4, model__min_child_weight=7, model__n_estimators=866, model__subsample=0.6280341613806619;, score=-36.309 total time=   1.2s\n",
      "[CV 8/37; 19/30] START model__colsample_bytree=0.8566223936114975, model__learning_rate=0.1621570097233795, model__max_depth=4, model__min_child_weight=7, model__n_estimators=866, model__subsample=0.6280341613806619\n",
      "[CV 29/37; 18/30] END model__colsample_bytree=0.8329611783087483, model__learning_rate=0.12825955754154544, model__max_depth=8, model__min_child_weight=3, model__n_estimators=838, model__subsample=0.5597971229691509;, score=-8.984 total time=  10.1s\n",
      "[CV 9/37; 19/30] START model__colsample_bytree=0.8566223936114975, model__learning_rate=0.1621570097233795, model__max_depth=4, model__min_child_weight=7, model__n_estimators=866, model__subsample=0.6280341613806619\n",
      "[CV 6/37; 19/30] END model__colsample_bytree=0.8566223936114975, model__learning_rate=0.1621570097233795, model__max_depth=4, model__min_child_weight=7, model__n_estimators=866, model__subsample=0.6280341613806619;, score=-2.507 total time=   1.7s\n",
      "[CV 10/37; 19/30] START model__colsample_bytree=0.8566223936114975, model__learning_rate=0.1621570097233795, model__max_depth=4, model__min_child_weight=7, model__n_estimators=866, model__subsample=0.6280341613806619\n",
      "[CV 7/37; 19/30] END model__colsample_bytree=0.8566223936114975, model__learning_rate=0.1621570097233795, model__max_depth=4, model__min_child_weight=7, model__n_estimators=866, model__subsample=0.6280341613806619;, score=-6.820 total time=   1.9s\n",
      "[CV 11/37; 19/30] START model__colsample_bytree=0.8566223936114975, model__learning_rate=0.1621570097233795, model__max_depth=4, model__min_child_weight=7, model__n_estimators=866, model__subsample=0.6280341613806619\n",
      "[CV 30/37; 18/30] END model__colsample_bytree=0.8329611783087483, model__learning_rate=0.12825955754154544, model__max_depth=8, model__min_child_weight=3, model__n_estimators=838, model__subsample=0.5597971229691509;, score=-0.286 total time=  10.5s\n",
      "[CV 12/37; 19/30] START model__colsample_bytree=0.8566223936114975, model__learning_rate=0.1621570097233795, model__max_depth=4, model__min_child_weight=7, model__n_estimators=866, model__subsample=0.6280341613806619\n",
      "[CV 8/37; 19/30] END model__colsample_bytree=0.8566223936114975, model__learning_rate=0.1621570097233795, model__max_depth=4, model__min_child_weight=7, model__n_estimators=866, model__subsample=0.6280341613806619;, score=-10.064 total time=   2.3s\n",
      "[CV 13/37; 19/30] START model__colsample_bytree=0.8566223936114975, model__learning_rate=0.1621570097233795, model__max_depth=4, model__min_child_weight=7, model__n_estimators=866, model__subsample=0.6280341613806619\n",
      "[CV 31/37; 18/30] END model__colsample_bytree=0.8329611783087483, model__learning_rate=0.12825955754154544, model__max_depth=8, model__min_child_weight=3, model__n_estimators=838, model__subsample=0.5597971229691509;, score=-0.436 total time=  11.2s\n",
      "[CV 14/37; 19/30] START model__colsample_bytree=0.8566223936114975, model__learning_rate=0.1621570097233795, model__max_depth=4, model__min_child_weight=7, model__n_estimators=866, model__subsample=0.6280341613806619\n",
      "[CV 9/37; 19/30] END model__colsample_bytree=0.8566223936114975, model__learning_rate=0.1621570097233795, model__max_depth=4, model__min_child_weight=7, model__n_estimators=866, model__subsample=0.6280341613806619;, score=-0.769 total time=   2.4s\n",
      "[CV 15/37; 19/30] START model__colsample_bytree=0.8566223936114975, model__learning_rate=0.1621570097233795, model__max_depth=4, model__min_child_weight=7, model__n_estimators=866, model__subsample=0.6280341613806619\n",
      "[CV 10/37; 19/30] END model__colsample_bytree=0.8566223936114975, model__learning_rate=0.1621570097233795, model__max_depth=4, model__min_child_weight=7, model__n_estimators=866, model__subsample=0.6280341613806619;, score=-31.384 total time=   2.6s\n",
      "[CV 16/37; 19/30] START model__colsample_bytree=0.8566223936114975, model__learning_rate=0.1621570097233795, model__max_depth=4, model__min_child_weight=7, model__n_estimators=866, model__subsample=0.6280341613806619\n",
      "[CV 11/37; 19/30] END model__colsample_bytree=0.8566223936114975, model__learning_rate=0.1621570097233795, model__max_depth=4, model__min_child_weight=7, model__n_estimators=866, model__subsample=0.6280341613806619;, score=-4.994 total time=   2.8s\n",
      "[CV 17/37; 19/30] START model__colsample_bytree=0.8566223936114975, model__learning_rate=0.1621570097233795, model__max_depth=4, model__min_child_weight=7, model__n_estimators=866, model__subsample=0.6280341613806619\n",
      "[CV 32/37; 18/30] END model__colsample_bytree=0.8329611783087483, model__learning_rate=0.12825955754154544, model__max_depth=8, model__min_child_weight=3, model__n_estimators=838, model__subsample=0.5597971229691509;, score=-3.511 total time=  12.0s\n",
      "[CV 18/37; 19/30] START model__colsample_bytree=0.8566223936114975, model__learning_rate=0.1621570097233795, model__max_depth=4, model__min_child_weight=7, model__n_estimators=866, model__subsample=0.6280341613806619\n",
      "[CV 12/37; 19/30] END model__colsample_bytree=0.8566223936114975, model__learning_rate=0.1621570097233795, model__max_depth=4, model__min_child_weight=7, model__n_estimators=866, model__subsample=0.6280341613806619;, score=-17.666 total time=   3.1s\n",
      "[CV 19/37; 19/30] START model__colsample_bytree=0.8566223936114975, model__learning_rate=0.1621570097233795, model__max_depth=4, model__min_child_weight=7, model__n_estimators=866, model__subsample=0.6280341613806619\n",
      "[CV 33/37; 18/30] END model__colsample_bytree=0.8329611783087483, model__learning_rate=0.12825955754154544, model__max_depth=8, model__min_child_weight=3, model__n_estimators=838, model__subsample=0.5597971229691509;, score=-21.387 total time=  12.5s\n",
      "[CV 20/37; 19/30] START model__colsample_bytree=0.8566223936114975, model__learning_rate=0.1621570097233795, model__max_depth=4, model__min_child_weight=7, model__n_estimators=866, model__subsample=0.6280341613806619\n",
      "[CV 13/37; 19/30] END model__colsample_bytree=0.8566223936114975, model__learning_rate=0.1621570097233795, model__max_depth=4, model__min_child_weight=7, model__n_estimators=866, model__subsample=0.6280341613806619;, score=0.016 total time=   3.2s\n",
      "[CV 21/37; 19/30] START model__colsample_bytree=0.8566223936114975, model__learning_rate=0.1621570097233795, model__max_depth=4, model__min_child_weight=7, model__n_estimators=866, model__subsample=0.6280341613806619\n",
      "[CV 14/37; 19/30] END model__colsample_bytree=0.8566223936114975, model__learning_rate=0.1621570097233795, model__max_depth=4, model__min_child_weight=7, model__n_estimators=866, model__subsample=0.6280341613806619;, score=-23.864 total time=   3.5s\n",
      "[CV 22/37; 19/30] START model__colsample_bytree=0.8566223936114975, model__learning_rate=0.1621570097233795, model__max_depth=4, model__min_child_weight=7, model__n_estimators=866, model__subsample=0.6280341613806619\n",
      "[CV 34/37; 18/30] END model__colsample_bytree=0.8329611783087483, model__learning_rate=0.12825955754154544, model__max_depth=8, model__min_child_weight=3, model__n_estimators=838, model__subsample=0.5597971229691509;, score=0.144 total time=  12.8s\n",
      "[CV 23/37; 19/30] START model__colsample_bytree=0.8566223936114975, model__learning_rate=0.1621570097233795, model__max_depth=4, model__min_child_weight=7, model__n_estimators=866, model__subsample=0.6280341613806619\n",
      "[CV 15/37; 19/30] END model__colsample_bytree=0.8566223936114975, model__learning_rate=0.1621570097233795, model__max_depth=4, model__min_child_weight=7, model__n_estimators=866, model__subsample=0.6280341613806619;, score=-0.357 total time=   3.7s\n",
      "[CV 24/37; 19/30] START model__colsample_bytree=0.8566223936114975, model__learning_rate=0.1621570097233795, model__max_depth=4, model__min_child_weight=7, model__n_estimators=866, model__subsample=0.6280341613806619\n",
      "[CV 16/37; 19/30] END model__colsample_bytree=0.8566223936114975, model__learning_rate=0.1621570097233795, model__max_depth=4, model__min_child_weight=7, model__n_estimators=866, model__subsample=0.6280341613806619;, score=-1.027 total time=   3.9s\n",
      "[CV 25/37; 19/30] START model__colsample_bytree=0.8566223936114975, model__learning_rate=0.1621570097233795, model__max_depth=4, model__min_child_weight=7, model__n_estimators=866, model__subsample=0.6280341613806619\n",
      "[CV 17/37; 19/30] END model__colsample_bytree=0.8566223936114975, model__learning_rate=0.1621570097233795, model__max_depth=4, model__min_child_weight=7, model__n_estimators=866, model__subsample=0.6280341613806619;, score=-19.030 total time=   4.1s\n",
      "[CV 35/37; 18/30] END model__colsample_bytree=0.8329611783087483, model__learning_rate=0.12825955754154544, model__max_depth=8, model__min_child_weight=3, model__n_estimators=838, model__subsample=0.5597971229691509;, score=-19.339 total time=  13.7s\n",
      "[CV 26/37; 19/30] START model__colsample_bytree=0.8566223936114975, model__learning_rate=0.1621570097233795, model__max_depth=4, model__min_child_weight=7, model__n_estimators=866, model__subsample=0.6280341613806619\n",
      "[CV 27/37; 19/30] START model__colsample_bytree=0.8566223936114975, model__learning_rate=0.1621570097233795, model__max_depth=4, model__min_child_weight=7, model__n_estimators=866, model__subsample=0.6280341613806619\n",
      "[CV 18/37; 19/30] END model__colsample_bytree=0.8566223936114975, model__learning_rate=0.1621570097233795, model__max_depth=4, model__min_child_weight=7, model__n_estimators=866, model__subsample=0.6280341613806619;, score=-0.896 total time=   4.3s\n",
      "[CV 28/37; 19/30] START model__colsample_bytree=0.8566223936114975, model__learning_rate=0.1621570097233795, model__max_depth=4, model__min_child_weight=7, model__n_estimators=866, model__subsample=0.6280341613806619\n",
      "[CV 19/37; 19/30] END model__colsample_bytree=0.8566223936114975, model__learning_rate=0.1621570097233795, model__max_depth=4, model__min_child_weight=7, model__n_estimators=866, model__subsample=0.6280341613806619;, score=-1.689 total time=   4.6s\n",
      "[CV 29/37; 19/30] START model__colsample_bytree=0.8566223936114975, model__learning_rate=0.1621570097233795, model__max_depth=4, model__min_child_weight=7, model__n_estimators=866, model__subsample=0.6280341613806619\n",
      "[CV 36/37; 18/30] END model__colsample_bytree=0.8329611783087483, model__learning_rate=0.12825955754154544, model__max_depth=8, model__min_child_weight=3, model__n_estimators=838, model__subsample=0.5597971229691509;, score=-1.344 total time=  14.2s\n",
      "[CV 30/37; 19/30] START model__colsample_bytree=0.8566223936114975, model__learning_rate=0.1621570097233795, model__max_depth=4, model__min_child_weight=7, model__n_estimators=866, model__subsample=0.6280341613806619\n",
      "[CV 20/37; 19/30] END model__colsample_bytree=0.8566223936114975, model__learning_rate=0.1621570097233795, model__max_depth=4, model__min_child_weight=7, model__n_estimators=866, model__subsample=0.6280341613806619;, score=-4.648 total time=   4.7s\n",
      "[CV 31/37; 19/30] START model__colsample_bytree=0.8566223936114975, model__learning_rate=0.1621570097233795, model__max_depth=4, model__min_child_weight=7, model__n_estimators=866, model__subsample=0.6280341613806619\n",
      "[CV 21/37; 19/30] END model__colsample_bytree=0.8566223936114975, model__learning_rate=0.1621570097233795, model__max_depth=4, model__min_child_weight=7, model__n_estimators=866, model__subsample=0.6280341613806619;, score=-2.117 total time=   5.0s\n",
      "[CV 32/37; 19/30] START model__colsample_bytree=0.8566223936114975, model__learning_rate=0.1621570097233795, model__max_depth=4, model__min_child_weight=7, model__n_estimators=866, model__subsample=0.6280341613806619\n",
      "[CV 37/37; 18/30] END model__colsample_bytree=0.8329611783087483, model__learning_rate=0.12825955754154544, model__max_depth=8, model__min_child_weight=3, model__n_estimators=838, model__subsample=0.5597971229691509;, score=-0.520 total time=  15.1s\n",
      "[CV 33/37; 19/30] START model__colsample_bytree=0.8566223936114975, model__learning_rate=0.1621570097233795, model__max_depth=4, model__min_child_weight=7, model__n_estimators=866, model__subsample=0.6280341613806619\n",
      "[CV 22/37; 19/30] END model__colsample_bytree=0.8566223936114975, model__learning_rate=0.1621570097233795, model__max_depth=4, model__min_child_weight=7, model__n_estimators=866, model__subsample=0.6280341613806619;, score=-0.694 total time=   5.3s\n",
      "[CV 34/37; 19/30] START model__colsample_bytree=0.8566223936114975, model__learning_rate=0.1621570097233795, model__max_depth=4, model__min_child_weight=7, model__n_estimators=866, model__subsample=0.6280341613806619\n",
      "[CV 23/37; 19/30] END model__colsample_bytree=0.8566223936114975, model__learning_rate=0.1621570097233795, model__max_depth=4, model__min_child_weight=7, model__n_estimators=866, model__subsample=0.6280341613806619;, score=-11.937 total time=   5.5s\n",
      "[CV 35/37; 19/30] START model__colsample_bytree=0.8566223936114975, model__learning_rate=0.1621570097233795, model__max_depth=4, model__min_child_weight=7, model__n_estimators=866, model__subsample=0.6280341613806619\n",
      "[CV 24/37; 19/30] END model__colsample_bytree=0.8566223936114975, model__learning_rate=0.1621570097233795, model__max_depth=4, model__min_child_weight=7, model__n_estimators=866, model__subsample=0.6280341613806619;, score=-7.224 total time=   5.6s\n",
      "[CV 36/37; 19/30] START model__colsample_bytree=0.8566223936114975, model__learning_rate=0.1621570097233795, model__max_depth=4, model__min_child_weight=7, model__n_estimators=866, model__subsample=0.6280341613806619\n",
      "[CV 25/37; 19/30] END model__colsample_bytree=0.8566223936114975, model__learning_rate=0.1621570097233795, model__max_depth=4, model__min_child_weight=7, model__n_estimators=866, model__subsample=0.6280341613806619;, score=-1.710 total time=   5.9s\n",
      "[CV 37/37; 19/30] START model__colsample_bytree=0.8566223936114975, model__learning_rate=0.1621570097233795, model__max_depth=4, model__min_child_weight=7, model__n_estimators=866, model__subsample=0.6280341613806619\n",
      "[CV 26/37; 19/30] END model__colsample_bytree=0.8566223936114975, model__learning_rate=0.1621570097233795, model__max_depth=4, model__min_child_weight=7, model__n_estimators=866, model__subsample=0.6280341613806619;, score=-3.356 total time=   6.2s\n",
      "[CV 1/37; 20/30] START model__colsample_bytree=0.5202167947692157, model__learning_rate=0.15213257793715748, model__max_depth=4, model__min_child_weight=3, model__n_estimators=674, model__subsample=0.9478817978367597\n",
      "[CV 27/37; 19/30] END model__colsample_bytree=0.8566223936114975, model__learning_rate=0.1621570097233795, model__max_depth=4, model__min_child_weight=7, model__n_estimators=866, model__subsample=0.6280341613806619;, score=-4.313 total time=   6.4s\n",
      "[CV 2/37; 20/30] START model__colsample_bytree=0.5202167947692157, model__learning_rate=0.15213257793715748, model__max_depth=4, model__min_child_weight=3, model__n_estimators=674, model__subsample=0.9478817978367597\n",
      "[CV 1/37; 20/30] END model__colsample_bytree=0.5202167947692157, model__learning_rate=0.15213257793715748, model__max_depth=4, model__min_child_weight=3, model__n_estimators=674, model__subsample=0.9478817978367597;, score=-41.185 total time=   0.2s\n",
      "[CV 3/37; 20/30] START model__colsample_bytree=0.5202167947692157, model__learning_rate=0.15213257793715748, model__max_depth=4, model__min_child_weight=3, model__n_estimators=674, model__subsample=0.9478817978367597\n",
      "[CV 2/37; 20/30] END model__colsample_bytree=0.5202167947692157, model__learning_rate=0.15213257793715748, model__max_depth=4, model__min_child_weight=3, model__n_estimators=674, model__subsample=0.9478817978367597;, score=-0.734 total time=   0.3s\n",
      "[CV 4/37; 20/30] START model__colsample_bytree=0.5202167947692157, model__learning_rate=0.15213257793715748, model__max_depth=4, model__min_child_weight=3, model__n_estimators=674, model__subsample=0.9478817978367597\n",
      "[CV 3/37; 20/30] END model__colsample_bytree=0.5202167947692157, model__learning_rate=0.15213257793715748, model__max_depth=4, model__min_child_weight=3, model__n_estimators=674, model__subsample=0.9478817978367597;, score=-19.381 total time=   0.4s\n",
      "[CV 5/37; 20/30] START model__colsample_bytree=0.5202167947692157, model__learning_rate=0.15213257793715748, model__max_depth=4, model__min_child_weight=3, model__n_estimators=674, model__subsample=0.9478817978367597\n",
      "[CV 28/37; 19/30] END model__colsample_bytree=0.8566223936114975, model__learning_rate=0.1621570097233795, model__max_depth=4, model__min_child_weight=7, model__n_estimators=866, model__subsample=0.6280341613806619;, score=-2.358 total time=   6.6s\n",
      "[CV 6/37; 20/30] START model__colsample_bytree=0.5202167947692157, model__learning_rate=0.15213257793715748, model__max_depth=4, model__min_child_weight=3, model__n_estimators=674, model__subsample=0.9478817978367597\n",
      "[CV 4/37; 20/30] END model__colsample_bytree=0.5202167947692157, model__learning_rate=0.15213257793715748, model__max_depth=4, model__min_child_weight=3, model__n_estimators=674, model__subsample=0.9478817978367597;, score=-6.931 total time=   0.6s\n",
      "[CV 7/37; 20/30] START model__colsample_bytree=0.5202167947692157, model__learning_rate=0.15213257793715748, model__max_depth=4, model__min_child_weight=3, model__n_estimators=674, model__subsample=0.9478817978367597\n",
      "[CV 5/37; 20/30] END model__colsample_bytree=0.5202167947692157, model__learning_rate=0.15213257793715748, model__max_depth=4, model__min_child_weight=3, model__n_estimators=674, model__subsample=0.9478817978367597;, score=-37.220 total time=   0.8s\n",
      "[CV 8/37; 20/30] START model__colsample_bytree=0.5202167947692157, model__learning_rate=0.15213257793715748, model__max_depth=4, model__min_child_weight=3, model__n_estimators=674, model__subsample=0.9478817978367597\n",
      "[CV 6/37; 20/30] END model__colsample_bytree=0.5202167947692157, model__learning_rate=0.15213257793715748, model__max_depth=4, model__min_child_weight=3, model__n_estimators=674, model__subsample=0.9478817978367597;, score=-1.441 total time=   1.0s\n",
      "[CV 9/37; 20/30] START model__colsample_bytree=0.5202167947692157, model__learning_rate=0.15213257793715748, model__max_depth=4, model__min_child_weight=3, model__n_estimators=674, model__subsample=0.9478817978367597\n",
      "[CV 29/37; 19/30] END model__colsample_bytree=0.8566223936114975, model__learning_rate=0.1621570097233795, model__max_depth=4, model__min_child_weight=7, model__n_estimators=866, model__subsample=0.6280341613806619;, score=-12.755 total time=   6.9s\n",
      "[CV 10/37; 20/30] START model__colsample_bytree=0.5202167947692157, model__learning_rate=0.15213257793715748, model__max_depth=4, model__min_child_weight=3, model__n_estimators=674, model__subsample=0.9478817978367597\n",
      "[CV 7/37; 20/30] END model__colsample_bytree=0.5202167947692157, model__learning_rate=0.15213257793715748, model__max_depth=4, model__min_child_weight=3, model__n_estimators=674, model__subsample=0.9478817978367597;, score=-5.930 total time=   1.0s\n",
      "[CV 11/37; 20/30] START model__colsample_bytree=0.5202167947692157, model__learning_rate=0.15213257793715748, model__max_depth=4, model__min_child_weight=3, model__n_estimators=674, model__subsample=0.9478817978367597\n",
      "[CV 30/37; 19/30] END model__colsample_bytree=0.8566223936114975, model__learning_rate=0.1621570097233795, model__max_depth=4, model__min_child_weight=7, model__n_estimators=866, model__subsample=0.6280341613806619;, score=-0.629 total time=   7.1s\n",
      "[CV 12/37; 20/30] START model__colsample_bytree=0.5202167947692157, model__learning_rate=0.15213257793715748, model__max_depth=4, model__min_child_weight=3, model__n_estimators=674, model__subsample=0.9478817978367597\n",
      "[CV 8/37; 20/30] END model__colsample_bytree=0.5202167947692157, model__learning_rate=0.15213257793715748, model__max_depth=4, model__min_child_weight=3, model__n_estimators=674, model__subsample=0.9478817978367597;, score=-8.288 total time=   1.2s\n",
      "[CV 13/37; 20/30] START model__colsample_bytree=0.5202167947692157, model__learning_rate=0.15213257793715748, model__max_depth=4, model__min_child_weight=3, model__n_estimators=674, model__subsample=0.9478817978367597\n",
      "[CV 31/37; 19/30] END model__colsample_bytree=0.8566223936114975, model__learning_rate=0.1621570097233795, model__max_depth=4, model__min_child_weight=7, model__n_estimators=866, model__subsample=0.6280341613806619;, score=-0.642 total time=   7.2s\n",
      "[CV 14/37; 20/30] START model__colsample_bytree=0.5202167947692157, model__learning_rate=0.15213257793715748, model__max_depth=4, model__min_child_weight=3, model__n_estimators=674, model__subsample=0.9478817978367597\n",
      "[CV 9/37; 20/30] END model__colsample_bytree=0.5202167947692157, model__learning_rate=0.15213257793715748, model__max_depth=4, model__min_child_weight=3, model__n_estimators=674, model__subsample=0.9478817978367597;, score=-1.202 total time=   1.3s\n",
      "[CV 15/37; 20/30] START model__colsample_bytree=0.5202167947692157, model__learning_rate=0.15213257793715748, model__max_depth=4, model__min_child_weight=3, model__n_estimators=674, model__subsample=0.9478817978367597\n",
      "[CV 10/37; 20/30] END model__colsample_bytree=0.5202167947692157, model__learning_rate=0.15213257793715748, model__max_depth=4, model__min_child_weight=3, model__n_estimators=674, model__subsample=0.9478817978367597;, score=-29.618 total time=   1.4s\n",
      "[CV 16/37; 20/30] START model__colsample_bytree=0.5202167947692157, model__learning_rate=0.15213257793715748, model__max_depth=4, model__min_child_weight=3, model__n_estimators=674, model__subsample=0.9478817978367597\n",
      "[CV 11/37; 20/30] END model__colsample_bytree=0.5202167947692157, model__learning_rate=0.15213257793715748, model__max_depth=4, model__min_child_weight=3, model__n_estimators=674, model__subsample=0.9478817978367597;, score=-3.230 total time=   1.6s\n",
      "[CV 17/37; 20/30] START model__colsample_bytree=0.5202167947692157, model__learning_rate=0.15213257793715748, model__max_depth=4, model__min_child_weight=3, model__n_estimators=674, model__subsample=0.9478817978367597\n",
      "[CV 32/37; 19/30] END model__colsample_bytree=0.8566223936114975, model__learning_rate=0.1621570097233795, model__max_depth=4, model__min_child_weight=7, model__n_estimators=866, model__subsample=0.6280341613806619;, score=-3.799 total time=   7.5s\n",
      "[CV 18/37; 20/30] START model__colsample_bytree=0.5202167947692157, model__learning_rate=0.15213257793715748, model__max_depth=4, model__min_child_weight=3, model__n_estimators=674, model__subsample=0.9478817978367597\n",
      "[CV 12/37; 20/30] END model__colsample_bytree=0.5202167947692157, model__learning_rate=0.15213257793715748, model__max_depth=4, model__min_child_weight=3, model__n_estimators=674, model__subsample=0.9478817978367597;, score=-17.721 total time=   1.7s\n",
      "[CV 19/37; 20/30] START model__colsample_bytree=0.5202167947692157, model__learning_rate=0.15213257793715748, model__max_depth=4, model__min_child_weight=3, model__n_estimators=674, model__subsample=0.9478817978367597\n",
      "[CV 13/37; 20/30] END model__colsample_bytree=0.5202167947692157, model__learning_rate=0.15213257793715748, model__max_depth=4, model__min_child_weight=3, model__n_estimators=674, model__subsample=0.9478817978367597;, score=0.111 total time=   1.8s\n",
      "[CV 20/37; 20/30] START model__colsample_bytree=0.5202167947692157, model__learning_rate=0.15213257793715748, model__max_depth=4, model__min_child_weight=3, model__n_estimators=674, model__subsample=0.9478817978367597\n",
      "[CV 33/37; 19/30] END model__colsample_bytree=0.8566223936114975, model__learning_rate=0.1621570097233795, model__max_depth=4, model__min_child_weight=7, model__n_estimators=866, model__subsample=0.6280341613806619;, score=-19.870 total time=   7.6s\n",
      "[CV 21/37; 20/30] START model__colsample_bytree=0.5202167947692157, model__learning_rate=0.15213257793715748, model__max_depth=4, model__min_child_weight=3, model__n_estimators=674, model__subsample=0.9478817978367597\n",
      "[CV 14/37; 20/30] END model__colsample_bytree=0.5202167947692157, model__learning_rate=0.15213257793715748, model__max_depth=4, model__min_child_weight=3, model__n_estimators=674, model__subsample=0.9478817978367597;, score=-21.583 total time=   2.0s\n",
      "[CV 22/37; 20/30] START model__colsample_bytree=0.5202167947692157, model__learning_rate=0.15213257793715748, model__max_depth=4, model__min_child_weight=3, model__n_estimators=674, model__subsample=0.9478817978367597\n",
      "[CV 34/37; 19/30] END model__colsample_bytree=0.8566223936114975, model__learning_rate=0.1621570097233795, model__max_depth=4, model__min_child_weight=7, model__n_estimators=866, model__subsample=0.6280341613806619;, score=0.188 total time=   7.9s\n",
      "[CV 23/37; 20/30] START model__colsample_bytree=0.5202167947692157, model__learning_rate=0.15213257793715748, model__max_depth=4, model__min_child_weight=3, model__n_estimators=674, model__subsample=0.9478817978367597\n",
      "[CV 15/37; 20/30] END model__colsample_bytree=0.5202167947692157, model__learning_rate=0.15213257793715748, model__max_depth=4, model__min_child_weight=3, model__n_estimators=674, model__subsample=0.9478817978367597;, score=-0.304 total time=   2.1s\n",
      "[CV 24/37; 20/30] START model__colsample_bytree=0.5202167947692157, model__learning_rate=0.15213257793715748, model__max_depth=4, model__min_child_weight=3, model__n_estimators=674, model__subsample=0.9478817978367597\n",
      "[CV 35/37; 19/30] END model__colsample_bytree=0.8566223936114975, model__learning_rate=0.1621570097233795, model__max_depth=4, model__min_child_weight=7, model__n_estimators=866, model__subsample=0.6280341613806619;, score=-21.580 total time=   8.1s\n",
      "[CV 25/37; 20/30] START model__colsample_bytree=0.5202167947692157, model__learning_rate=0.15213257793715748, model__max_depth=4, model__min_child_weight=3, model__n_estimators=674, model__subsample=0.9478817978367597\n",
      "[CV 16/37; 20/30] END model__colsample_bytree=0.5202167947692157, model__learning_rate=0.15213257793715748, model__max_depth=4, model__min_child_weight=3, model__n_estimators=674, model__subsample=0.9478817978367597;, score=-0.960 total time=   2.2s\n",
      "[CV 26/37; 20/30] START model__colsample_bytree=0.5202167947692157, model__learning_rate=0.15213257793715748, model__max_depth=4, model__min_child_weight=3, model__n_estimators=674, model__subsample=0.9478817978367597\n",
      "[CV 17/37; 20/30] END model__colsample_bytree=0.5202167947692157, model__learning_rate=0.15213257793715748, model__max_depth=4, model__min_child_weight=3, model__n_estimators=674, model__subsample=0.9478817978367597;, score=-18.695 total time=   2.2s\n",
      "[CV 27/37; 20/30] START model__colsample_bytree=0.5202167947692157, model__learning_rate=0.15213257793715748, model__max_depth=4, model__min_child_weight=3, model__n_estimators=674, model__subsample=0.9478817978367597\n",
      "[CV 18/37; 20/30] END model__colsample_bytree=0.5202167947692157, model__learning_rate=0.15213257793715748, model__max_depth=4, model__min_child_weight=3, model__n_estimators=674, model__subsample=0.9478817978367597;, score=-0.950 total time=   2.4s\n",
      "[CV 28/37; 20/30] START model__colsample_bytree=0.5202167947692157, model__learning_rate=0.15213257793715748, model__max_depth=4, model__min_child_weight=3, model__n_estimators=674, model__subsample=0.9478817978367597\n",
      "[CV 36/37; 19/30] END model__colsample_bytree=0.8566223936114975, model__learning_rate=0.1621570097233795, model__max_depth=4, model__min_child_weight=7, model__n_estimators=866, model__subsample=0.6280341613806619;, score=-1.726 total time=   8.4s\n",
      "[CV 19/37; 20/30] END model__colsample_bytree=0.5202167947692157, model__learning_rate=0.15213257793715748, model__max_depth=4, model__min_child_weight=3, model__n_estimators=674, model__subsample=0.9478817978367597;, score=-1.374 total time=   2.5s\n",
      "[CV 30/37; 20/30] START model__colsample_bytree=0.5202167947692157, model__learning_rate=0.15213257793715748, model__max_depth=4, model__min_child_weight=3, model__n_estimators=674, model__subsample=0.9478817978367597\n",
      "[CV 29/37; 20/30] START model__colsample_bytree=0.5202167947692157, model__learning_rate=0.15213257793715748, model__max_depth=4, model__min_child_weight=3, model__n_estimators=674, model__subsample=0.9478817978367597\n",
      "[CV 20/37; 20/30] END model__colsample_bytree=0.5202167947692157, model__learning_rate=0.15213257793715748, model__max_depth=4, model__min_child_weight=3, model__n_estimators=674, model__subsample=0.9478817978367597;, score=-3.917 total time=   2.5s\n",
      "[CV 31/37; 20/30] START model__colsample_bytree=0.5202167947692157, model__learning_rate=0.15213257793715748, model__max_depth=4, model__min_child_weight=3, model__n_estimators=674, model__subsample=0.9478817978367597\n",
      "[CV 21/37; 20/30] END model__colsample_bytree=0.5202167947692157, model__learning_rate=0.15213257793715748, model__max_depth=4, model__min_child_weight=3, model__n_estimators=674, model__subsample=0.9478817978367597;, score=-2.529 total time=   2.7s\n",
      "[CV 32/37; 20/30] START model__colsample_bytree=0.5202167947692157, model__learning_rate=0.15213257793715748, model__max_depth=4, model__min_child_weight=3, model__n_estimators=674, model__subsample=0.9478817978367597\n",
      "[CV 37/37; 19/30] END model__colsample_bytree=0.8566223936114975, model__learning_rate=0.1621570097233795, model__max_depth=4, model__min_child_weight=7, model__n_estimators=866, model__subsample=0.6280341613806619;, score=-0.521 total time=   8.3s\n",
      "[CV 33/37; 20/30] START model__colsample_bytree=0.5202167947692157, model__learning_rate=0.15213257793715748, model__max_depth=4, model__min_child_weight=3, model__n_estimators=674, model__subsample=0.9478817978367597\n",
      "[CV 22/37; 20/30] END model__colsample_bytree=0.5202167947692157, model__learning_rate=0.15213257793715748, model__max_depth=4, model__min_child_weight=3, model__n_estimators=674, model__subsample=0.9478817978367597;, score=-0.693 total time=   2.9s\n",
      "[CV 34/37; 20/30] START model__colsample_bytree=0.5202167947692157, model__learning_rate=0.15213257793715748, model__max_depth=4, model__min_child_weight=3, model__n_estimators=674, model__subsample=0.9478817978367597\n",
      "[CV 23/37; 20/30] END model__colsample_bytree=0.5202167947692157, model__learning_rate=0.15213257793715748, model__max_depth=4, model__min_child_weight=3, model__n_estimators=674, model__subsample=0.9478817978367597;, score=-11.271 total time=   3.0s\n",
      "[CV 35/37; 20/30] START model__colsample_bytree=0.5202167947692157, model__learning_rate=0.15213257793715748, model__max_depth=4, model__min_child_weight=3, model__n_estimators=674, model__subsample=0.9478817978367597\n",
      "[CV 24/37; 20/30] END model__colsample_bytree=0.5202167947692157, model__learning_rate=0.15213257793715748, model__max_depth=4, model__min_child_weight=3, model__n_estimators=674, model__subsample=0.9478817978367597;, score=-4.978 total time=   3.0s\n",
      "[CV 36/37; 20/30] START model__colsample_bytree=0.5202167947692157, model__learning_rate=0.15213257793715748, model__max_depth=4, model__min_child_weight=3, model__n_estimators=674, model__subsample=0.9478817978367597\n",
      "[CV 25/37; 20/30] END model__colsample_bytree=0.5202167947692157, model__learning_rate=0.15213257793715748, model__max_depth=4, model__min_child_weight=3, model__n_estimators=674, model__subsample=0.9478817978367597;, score=-1.575 total time=   3.1s\n",
      "[CV 37/37; 20/30] START model__colsample_bytree=0.5202167947692157, model__learning_rate=0.15213257793715748, model__max_depth=4, model__min_child_weight=3, model__n_estimators=674, model__subsample=0.9478817978367597\n",
      "[CV 26/37; 20/30] END model__colsample_bytree=0.5202167947692157, model__learning_rate=0.15213257793715748, model__max_depth=4, model__min_child_weight=3, model__n_estimators=674, model__subsample=0.9478817978367597;, score=-2.912 total time=   3.2s\n",
      "[CV 1/37; 21/30] START model__colsample_bytree=0.7376851115910559, model__learning_rate=0.12265511439527674, model__max_depth=6, model__min_child_weight=5, model__n_estimators=506, model__subsample=0.8022086896389087\n",
      "[CV 1/37; 21/30] END model__colsample_bytree=0.7376851115910559, model__learning_rate=0.12265511439527674, model__max_depth=6, model__min_child_weight=5, model__n_estimators=506, model__subsample=0.8022086896389087;, score=-41.823 total time=   0.2s\n",
      "[CV 2/37; 21/30] START model__colsample_bytree=0.7376851115910559, model__learning_rate=0.12265511439527674, model__max_depth=6, model__min_child_weight=5, model__n_estimators=506, model__subsample=0.8022086896389087\n",
      "[CV 27/37; 20/30] END model__colsample_bytree=0.5202167947692157, model__learning_rate=0.15213257793715748, model__max_depth=4, model__min_child_weight=3, model__n_estimators=674, model__subsample=0.9478817978367597;, score=-3.734 total time=   3.5s\n",
      "[CV 3/37; 21/30] START model__colsample_bytree=0.7376851115910559, model__learning_rate=0.12265511439527674, model__max_depth=6, model__min_child_weight=5, model__n_estimators=506, model__subsample=0.8022086896389087\n",
      "[CV 2/37; 21/30] END model__colsample_bytree=0.7376851115910559, model__learning_rate=0.12265511439527674, model__max_depth=6, model__min_child_weight=5, model__n_estimators=506, model__subsample=0.8022086896389087;, score=-0.255 total time=   0.3s\n",
      "[CV 4/37; 21/30] START model__colsample_bytree=0.7376851115910559, model__learning_rate=0.12265511439527674, model__max_depth=6, model__min_child_weight=5, model__n_estimators=506, model__subsample=0.8022086896389087\n",
      "[CV 28/37; 20/30] END model__colsample_bytree=0.5202167947692157, model__learning_rate=0.15213257793715748, model__max_depth=4, model__min_child_weight=3, model__n_estimators=674, model__subsample=0.9478817978367597;, score=-2.444 total time=   3.5s\n",
      "[CV 5/37; 21/30] START model__colsample_bytree=0.7376851115910559, model__learning_rate=0.12265511439527674, model__max_depth=6, model__min_child_weight=5, model__n_estimators=506, model__subsample=0.8022086896389087\n",
      "[CV 3/37; 21/30] END model__colsample_bytree=0.7376851115910559, model__learning_rate=0.12265511439527674, model__max_depth=6, model__min_child_weight=5, model__n_estimators=506, model__subsample=0.8022086896389087;, score=-20.226 total time=   0.5s\n",
      "[CV 6/37; 21/30] START model__colsample_bytree=0.7376851115910559, model__learning_rate=0.12265511439527674, model__max_depth=6, model__min_child_weight=5, model__n_estimators=506, model__subsample=0.8022086896389087\n",
      "[CV 4/37; 21/30] END model__colsample_bytree=0.7376851115910559, model__learning_rate=0.12265511439527674, model__max_depth=6, model__min_child_weight=5, model__n_estimators=506, model__subsample=0.8022086896389087;, score=-6.483 total time=   0.7s\n",
      "[CV 7/37; 21/30] START model__colsample_bytree=0.7376851115910559, model__learning_rate=0.12265511439527674, model__max_depth=6, model__min_child_weight=5, model__n_estimators=506, model__subsample=0.8022086896389087\n",
      "[CV 29/37; 20/30] END model__colsample_bytree=0.5202167947692157, model__learning_rate=0.15213257793715748, model__max_depth=4, model__min_child_weight=3, model__n_estimators=674, model__subsample=0.9478817978367597;, score=-11.342 total time=   3.7s\n",
      "[CV 8/37; 21/30] START model__colsample_bytree=0.7376851115910559, model__learning_rate=0.12265511439527674, model__max_depth=6, model__min_child_weight=5, model__n_estimators=506, model__subsample=0.8022086896389087\n",
      "[CV 30/37; 20/30] END model__colsample_bytree=0.5202167947692157, model__learning_rate=0.15213257793715748, model__max_depth=4, model__min_child_weight=3, model__n_estimators=674, model__subsample=0.9478817978367597;, score=-0.268 total time=   3.8s\n",
      "[CV 9/37; 21/30] START model__colsample_bytree=0.7376851115910559, model__learning_rate=0.12265511439527674, model__max_depth=6, model__min_child_weight=5, model__n_estimators=506, model__subsample=0.8022086896389087\n",
      "[CV 5/37; 21/30] END model__colsample_bytree=0.7376851115910559, model__learning_rate=0.12265511439527674, model__max_depth=6, model__min_child_weight=5, model__n_estimators=506, model__subsample=0.8022086896389087;, score=-38.121 total time=   0.8s\n",
      "[CV 10/37; 21/30] START model__colsample_bytree=0.7376851115910559, model__learning_rate=0.12265511439527674, model__max_depth=6, model__min_child_weight=5, model__n_estimators=506, model__subsample=0.8022086896389087\n",
      "[CV 31/37; 20/30] END model__colsample_bytree=0.5202167947692157, model__learning_rate=0.15213257793715748, model__max_depth=4, model__min_child_weight=3, model__n_estimators=674, model__subsample=0.9478817978367597;, score=0.081 total time=   3.8s\n",
      "[CV 11/37; 21/30] START model__colsample_bytree=0.7376851115910559, model__learning_rate=0.12265511439527674, model__max_depth=6, model__min_child_weight=5, model__n_estimators=506, model__subsample=0.8022086896389087\n",
      "[CV 6/37; 21/30] END model__colsample_bytree=0.7376851115910559, model__learning_rate=0.12265511439527674, model__max_depth=6, model__min_child_weight=5, model__n_estimators=506, model__subsample=0.8022086896389087;, score=-1.576 total time=   1.1s\n",
      "[CV 12/37; 21/30] START model__colsample_bytree=0.7376851115910559, model__learning_rate=0.12265511439527674, model__max_depth=6, model__min_child_weight=5, model__n_estimators=506, model__subsample=0.8022086896389087\n",
      "[CV 32/37; 20/30] END model__colsample_bytree=0.5202167947692157, model__learning_rate=0.15213257793715748, model__max_depth=4, model__min_child_weight=3, model__n_estimators=674, model__subsample=0.9478817978367597;, score=-3.057 total time=   3.9s\n",
      "[CV 13/37; 21/30] START model__colsample_bytree=0.7376851115910559, model__learning_rate=0.12265511439527674, model__max_depth=6, model__min_child_weight=5, model__n_estimators=506, model__subsample=0.8022086896389087\n",
      "[CV 33/37; 20/30] END model__colsample_bytree=0.5202167947692157, model__learning_rate=0.15213257793715748, model__max_depth=4, model__min_child_weight=3, model__n_estimators=674, model__subsample=0.9478817978367597;, score=-17.708 total time=   3.9s\n",
      "[CV 14/37; 21/30] START model__colsample_bytree=0.7376851115910559, model__learning_rate=0.12265511439527674, model__max_depth=6, model__min_child_weight=5, model__n_estimators=506, model__subsample=0.8022086896389087\n",
      "[CV 7/37; 21/30] END model__colsample_bytree=0.7376851115910559, model__learning_rate=0.12265511439527674, model__max_depth=6, model__min_child_weight=5, model__n_estimators=506, model__subsample=0.8022086896389087;, score=-6.478 total time=   1.3s\n",
      "[CV 15/37; 21/30] START model__colsample_bytree=0.7376851115910559, model__learning_rate=0.12265511439527674, model__max_depth=6, model__min_child_weight=5, model__n_estimators=506, model__subsample=0.8022086896389087\n",
      "[CV 34/37; 20/30] END model__colsample_bytree=0.5202167947692157, model__learning_rate=0.15213257793715748, model__max_depth=4, model__min_child_weight=3, model__n_estimators=674, model__subsample=0.9478817978367597;, score=0.255 total time=   3.9s\n",
      "[CV 16/37; 21/30] START model__colsample_bytree=0.7376851115910559, model__learning_rate=0.12265511439527674, model__max_depth=6, model__min_child_weight=5, model__n_estimators=506, model__subsample=0.8022086896389087\n",
      "[CV 8/37; 21/30] END model__colsample_bytree=0.7376851115910559, model__learning_rate=0.12265511439527674, model__max_depth=6, model__min_child_weight=5, model__n_estimators=506, model__subsample=0.8022086896389087;, score=-9.811 total time=   1.6s\n",
      "[CV 17/37; 21/30] START model__colsample_bytree=0.7376851115910559, model__learning_rate=0.12265511439527674, model__max_depth=6, model__min_child_weight=5, model__n_estimators=506, model__subsample=0.8022086896389087\n",
      "[CV 35/37; 20/30] END model__colsample_bytree=0.5202167947692157, model__learning_rate=0.15213257793715748, model__max_depth=4, model__min_child_weight=3, model__n_estimators=674, model__subsample=0.9478817978367597;, score=-19.958 total time=   4.1s\n",
      "[CV 18/37; 21/30] START model__colsample_bytree=0.7376851115910559, model__learning_rate=0.12265511439527674, model__max_depth=6, model__min_child_weight=5, model__n_estimators=506, model__subsample=0.8022086896389087\n",
      "[CV 9/37; 21/30] END model__colsample_bytree=0.7376851115910559, model__learning_rate=0.12265511439527674, model__max_depth=6, model__min_child_weight=5, model__n_estimators=506, model__subsample=0.8022086896389087;, score=-0.885 total time=   2.0s\n",
      "[CV 19/37; 21/30] START model__colsample_bytree=0.7376851115910559, model__learning_rate=0.12265511439527674, model__max_depth=6, model__min_child_weight=5, model__n_estimators=506, model__subsample=0.8022086896389087\n",
      "[CV 36/37; 20/30] END model__colsample_bytree=0.5202167947692157, model__learning_rate=0.15213257793715748, model__max_depth=4, model__min_child_weight=3, model__n_estimators=674, model__subsample=0.9478817978367597;, score=-1.210 total time=   4.3s\n",
      "[CV 20/37; 21/30] START model__colsample_bytree=0.7376851115910559, model__learning_rate=0.12265511439527674, model__max_depth=6, model__min_child_weight=5, model__n_estimators=506, model__subsample=0.8022086896389087\n",
      "[CV 10/37; 21/30] END model__colsample_bytree=0.7376851115910559, model__learning_rate=0.12265511439527674, model__max_depth=6, model__min_child_weight=5, model__n_estimators=506, model__subsample=0.8022086896389087;, score=-31.834 total time=   2.2s\n",
      "[CV 21/37; 21/30] START model__colsample_bytree=0.7376851115910559, model__learning_rate=0.12265511439527674, model__max_depth=6, model__min_child_weight=5, model__n_estimators=506, model__subsample=0.8022086896389087\n",
      "[CV 37/37; 20/30] END model__colsample_bytree=0.5202167947692157, model__learning_rate=0.15213257793715748, model__max_depth=4, model__min_child_weight=3, model__n_estimators=674, model__subsample=0.9478817978367597;, score=-0.387 total time=   4.5s\n",
      "[CV 22/37; 21/30] START model__colsample_bytree=0.7376851115910559, model__learning_rate=0.12265511439527674, model__max_depth=6, model__min_child_weight=5, model__n_estimators=506, model__subsample=0.8022086896389087\n",
      "[CV 11/37; 21/30] END model__colsample_bytree=0.7376851115910559, model__learning_rate=0.12265511439527674, model__max_depth=6, model__min_child_weight=5, model__n_estimators=506, model__subsample=0.8022086896389087;, score=-4.187 total time=   2.4s\n",
      "[CV 23/37; 21/30] START model__colsample_bytree=0.7376851115910559, model__learning_rate=0.12265511439527674, model__max_depth=6, model__min_child_weight=5, model__n_estimators=506, model__subsample=0.8022086896389087\n",
      "[CV 12/37; 21/30] END model__colsample_bytree=0.7376851115910559, model__learning_rate=0.12265511439527674, model__max_depth=6, model__min_child_weight=5, model__n_estimators=506, model__subsample=0.8022086896389087;, score=-18.677 total time=   2.6s\n",
      "[CV 24/37; 21/30] START model__colsample_bytree=0.7376851115910559, model__learning_rate=0.12265511439527674, model__max_depth=6, model__min_child_weight=5, model__n_estimators=506, model__subsample=0.8022086896389087\n",
      "[CV 13/37; 21/30] END model__colsample_bytree=0.7376851115910559, model__learning_rate=0.12265511439527674, model__max_depth=6, model__min_child_weight=5, model__n_estimators=506, model__subsample=0.8022086896389087;, score=0.045 total time=   2.8s\n",
      "[CV 25/37; 21/30] START model__colsample_bytree=0.7376851115910559, model__learning_rate=0.12265511439527674, model__max_depth=6, model__min_child_weight=5, model__n_estimators=506, model__subsample=0.8022086896389087\n",
      "[CV 14/37; 21/30] END model__colsample_bytree=0.7376851115910559, model__learning_rate=0.12265511439527674, model__max_depth=6, model__min_child_weight=5, model__n_estimators=506, model__subsample=0.8022086896389087;, score=-21.318 total time=   2.9s\n",
      "[CV 26/37; 21/30] START model__colsample_bytree=0.7376851115910559, model__learning_rate=0.12265511439527674, model__max_depth=6, model__min_child_weight=5, model__n_estimators=506, model__subsample=0.8022086896389087\n",
      "[CV 15/37; 21/30] END model__colsample_bytree=0.7376851115910559, model__learning_rate=0.12265511439527674, model__max_depth=6, model__min_child_weight=5, model__n_estimators=506, model__subsample=0.8022086896389087;, score=-0.193 total time=   3.1s\n",
      "[CV 27/37; 21/30] START model__colsample_bytree=0.7376851115910559, model__learning_rate=0.12265511439527674, model__max_depth=6, model__min_child_weight=5, model__n_estimators=506, model__subsample=0.8022086896389087\n",
      "[CV 16/37; 21/30] END model__colsample_bytree=0.7376851115910559, model__learning_rate=0.12265511439527674, model__max_depth=6, model__min_child_weight=5, model__n_estimators=506, model__subsample=0.8022086896389087;, score=-0.793 total time=   3.4s\n",
      "[CV 28/37; 21/30] START model__colsample_bytree=0.7376851115910559, model__learning_rate=0.12265511439527674, model__max_depth=6, model__min_child_weight=5, model__n_estimators=506, model__subsample=0.8022086896389087\n",
      "[CV 17/37; 21/30] END model__colsample_bytree=0.7376851115910559, model__learning_rate=0.12265511439527674, model__max_depth=6, model__min_child_weight=5, model__n_estimators=506, model__subsample=0.8022086896389087;, score=-19.515 total time=   3.5s\n",
      "[CV 29/37; 21/30] START model__colsample_bytree=0.7376851115910559, model__learning_rate=0.12265511439527674, model__max_depth=6, model__min_child_weight=5, model__n_estimators=506, model__subsample=0.8022086896389087\n",
      "[CV 18/37; 21/30] END model__colsample_bytree=0.7376851115910559, model__learning_rate=0.12265511439527674, model__max_depth=6, model__min_child_weight=5, model__n_estimators=506, model__subsample=0.8022086896389087;, score=-0.527 total time=   3.6s\n",
      "[CV 30/37; 21/30] START model__colsample_bytree=0.7376851115910559, model__learning_rate=0.12265511439527674, model__max_depth=6, model__min_child_weight=5, model__n_estimators=506, model__subsample=0.8022086896389087\n",
      "[CV 19/37; 21/30] END model__colsample_bytree=0.7376851115910559, model__learning_rate=0.12265511439527674, model__max_depth=6, model__min_child_weight=5, model__n_estimators=506, model__subsample=0.8022086896389087;, score=-1.131 total time=   3.8s\n",
      "[CV 31/37; 21/30] START model__colsample_bytree=0.7376851115910559, model__learning_rate=0.12265511439527674, model__max_depth=6, model__min_child_weight=5, model__n_estimators=506, model__subsample=0.8022086896389087\n",
      "[CV 20/37; 21/30] END model__colsample_bytree=0.7376851115910559, model__learning_rate=0.12265511439527674, model__max_depth=6, model__min_child_weight=5, model__n_estimators=506, model__subsample=0.8022086896389087;, score=-5.532 total time=   4.1s\n",
      "[CV 32/37; 21/30] START model__colsample_bytree=0.7376851115910559, model__learning_rate=0.12265511439527674, model__max_depth=6, model__min_child_weight=5, model__n_estimators=506, model__subsample=0.8022086896389087\n",
      "[CV 21/37; 21/30] END model__colsample_bytree=0.7376851115910559, model__learning_rate=0.12265511439527674, model__max_depth=6, model__min_child_weight=5, model__n_estimators=506, model__subsample=0.8022086896389087;, score=-1.640 total time=   4.3s\n",
      "[CV 33/37; 21/30] START model__colsample_bytree=0.7376851115910559, model__learning_rate=0.12265511439527674, model__max_depth=6, model__min_child_weight=5, model__n_estimators=506, model__subsample=0.8022086896389087\n",
      "[CV 22/37; 21/30] END model__colsample_bytree=0.7376851115910559, model__learning_rate=0.12265511439527674, model__max_depth=6, model__min_child_weight=5, model__n_estimators=506, model__subsample=0.8022086896389087;, score=-0.474 total time=   4.4s\n",
      "[CV 34/37; 21/30] START model__colsample_bytree=0.7376851115910559, model__learning_rate=0.12265511439527674, model__max_depth=6, model__min_child_weight=5, model__n_estimators=506, model__subsample=0.8022086896389087\n",
      "[CV 23/37; 21/30] END model__colsample_bytree=0.7376851115910559, model__learning_rate=0.12265511439527674, model__max_depth=6, model__min_child_weight=5, model__n_estimators=506, model__subsample=0.8022086896389087;, score=-10.862 total time=   4.6s\n",
      "[CV 35/37; 21/30] START model__colsample_bytree=0.7376851115910559, model__learning_rate=0.12265511439527674, model__max_depth=6, model__min_child_weight=5, model__n_estimators=506, model__subsample=0.8022086896389087\n",
      "[CV 24/37; 21/30] END model__colsample_bytree=0.7376851115910559, model__learning_rate=0.12265511439527674, model__max_depth=6, model__min_child_weight=5, model__n_estimators=506, model__subsample=0.8022086896389087;, score=-5.878 total time=   4.9s\n",
      "[CV 36/37; 21/30] START model__colsample_bytree=0.7376851115910559, model__learning_rate=0.12265511439527674, model__max_depth=6, model__min_child_weight=5, model__n_estimators=506, model__subsample=0.8022086896389087\n",
      "[CV 25/37; 21/30] END model__colsample_bytree=0.7376851115910559, model__learning_rate=0.12265511439527674, model__max_depth=6, model__min_child_weight=5, model__n_estimators=506, model__subsample=0.8022086896389087;, score=-1.132 total time=   5.2s\n",
      "[CV 37/37; 21/30] START model__colsample_bytree=0.7376851115910559, model__learning_rate=0.12265511439527674, model__max_depth=6, model__min_child_weight=5, model__n_estimators=506, model__subsample=0.8022086896389087\n",
      "[CV 26/37; 21/30] END model__colsample_bytree=0.7376851115910559, model__learning_rate=0.12265511439527674, model__max_depth=6, model__min_child_weight=5, model__n_estimators=506, model__subsample=0.8022086896389087;, score=-1.948 total time=   5.2s\n",
      "[CV 1/37; 22/30] START model__colsample_bytree=0.7699205456508366, model__learning_rate=0.050612244946953884, model__max_depth=7, model__min_child_weight=7, model__n_estimators=798, model__subsample=0.8473924665198522\n",
      "[CV 1/37; 22/30] END model__colsample_bytree=0.7699205456508366, model__learning_rate=0.050612244946953884, model__max_depth=7, model__min_child_weight=7, model__n_estimators=798, model__subsample=0.8473924665198522;, score=-40.807 total time=   0.4s\n",
      "[CV 2/37; 22/30] START model__colsample_bytree=0.7699205456508366, model__learning_rate=0.050612244946953884, model__max_depth=7, model__min_child_weight=7, model__n_estimators=798, model__subsample=0.8473924665198522\n",
      "[CV 27/37; 21/30] END model__colsample_bytree=0.7376851115910559, model__learning_rate=0.12265511439527674, model__max_depth=6, model__min_child_weight=5, model__n_estimators=506, model__subsample=0.8022086896389087;, score=-2.979 total time=   5.5s\n",
      "[CV 3/37; 22/30] START model__colsample_bytree=0.7699205456508366, model__learning_rate=0.050612244946953884, model__max_depth=7, model__min_child_weight=7, model__n_estimators=798, model__subsample=0.8473924665198522\n",
      "[CV 2/37; 22/30] END model__colsample_bytree=0.7699205456508366, model__learning_rate=0.050612244946953884, model__max_depth=7, model__min_child_weight=7, model__n_estimators=798, model__subsample=0.8473924665198522;, score=-0.317 total time=   0.7s\n",
      "[CV 4/37; 22/30] START model__colsample_bytree=0.7699205456508366, model__learning_rate=0.050612244946953884, model__max_depth=7, model__min_child_weight=7, model__n_estimators=798, model__subsample=0.8473924665198522\n",
      "[CV 28/37; 21/30] END model__colsample_bytree=0.7376851115910559, model__learning_rate=0.12265511439527674, model__max_depth=6, model__min_child_weight=5, model__n_estimators=506, model__subsample=0.8022086896389087;, score=-1.616 total time=   5.6s\n",
      "[CV 5/37; 22/30] START model__colsample_bytree=0.7699205456508366, model__learning_rate=0.050612244946953884, model__max_depth=7, model__min_child_weight=7, model__n_estimators=798, model__subsample=0.8473924665198522\n",
      "[CV 3/37; 22/30] END model__colsample_bytree=0.7699205456508366, model__learning_rate=0.050612244946953884, model__max_depth=7, model__min_child_weight=7, model__n_estimators=798, model__subsample=0.8473924665198522;, score=-12.947 total time=   1.1s\n",
      "[CV 6/37; 22/30] START model__colsample_bytree=0.7699205456508366, model__learning_rate=0.050612244946953884, model__max_depth=7, model__min_child_weight=7, model__n_estimators=798, model__subsample=0.8473924665198522\n",
      "[CV 29/37; 21/30] END model__colsample_bytree=0.7376851115910559, model__learning_rate=0.12265511439527674, model__max_depth=6, model__min_child_weight=5, model__n_estimators=506, model__subsample=0.8022086896389087;, score=-10.062 total time=   5.8s\n",
      "[CV 7/37; 22/30] START model__colsample_bytree=0.7699205456508366, model__learning_rate=0.050612244946953884, model__max_depth=7, model__min_child_weight=7, model__n_estimators=798, model__subsample=0.8473924665198522\n",
      "[CV 30/37; 21/30] END model__colsample_bytree=0.7376851115910559, model__learning_rate=0.12265511439527674, model__max_depth=6, model__min_child_weight=5, model__n_estimators=506, model__subsample=0.8022086896389087;, score=-0.196 total time=   6.0s\n",
      "[CV 8/37; 22/30] START model__colsample_bytree=0.7699205456508366, model__learning_rate=0.050612244946953884, model__max_depth=7, model__min_child_weight=7, model__n_estimators=798, model__subsample=0.8473924665198522\n",
      "[CV 4/37; 22/30] END model__colsample_bytree=0.7699205456508366, model__learning_rate=0.050612244946953884, model__max_depth=7, model__min_child_weight=7, model__n_estimators=798, model__subsample=0.8473924665198522;, score=-7.521 total time=   1.4s\n",
      "[CV 9/37; 22/30] START model__colsample_bytree=0.7699205456508366, model__learning_rate=0.050612244946953884, model__max_depth=7, model__min_child_weight=7, model__n_estimators=798, model__subsample=0.8473924665198522\n",
      "[CV 31/37; 21/30] END model__colsample_bytree=0.7376851115910559, model__learning_rate=0.12265511439527674, model__max_depth=6, model__min_child_weight=5, model__n_estimators=506, model__subsample=0.8022086896389087;, score=-0.089 total time=   6.1s\n",
      "[CV 10/37; 22/30] START model__colsample_bytree=0.7699205456508366, model__learning_rate=0.050612244946953884, model__max_depth=7, model__min_child_weight=7, model__n_estimators=798, model__subsample=0.8473924665198522\n",
      "[CV 5/37; 22/30] END model__colsample_bytree=0.7699205456508366, model__learning_rate=0.050612244946953884, model__max_depth=7, model__min_child_weight=7, model__n_estimators=798, model__subsample=0.8473924665198522;, score=-37.997 total time=   1.7s\n",
      "[CV 11/37; 22/30] START model__colsample_bytree=0.7699205456508366, model__learning_rate=0.050612244946953884, model__max_depth=7, model__min_child_weight=7, model__n_estimators=798, model__subsample=0.8473924665198522\n",
      "[CV 32/37; 21/30] END model__colsample_bytree=0.7376851115910559, model__learning_rate=0.12265511439527674, model__max_depth=6, model__min_child_weight=5, model__n_estimators=506, model__subsample=0.8022086896389087;, score=-3.628 total time=   6.3s\n",
      "[CV 12/37; 22/30] START model__colsample_bytree=0.7699205456508366, model__learning_rate=0.050612244946953884, model__max_depth=7, model__min_child_weight=7, model__n_estimators=798, model__subsample=0.8473924665198522\n",
      "[CV 6/37; 22/30] END model__colsample_bytree=0.7699205456508366, model__learning_rate=0.050612244946953884, model__max_depth=7, model__min_child_weight=7, model__n_estimators=798, model__subsample=0.8473924665198522;, score=-1.431 total time=   2.2s\n",
      "[CV 33/37; 21/30] END model__colsample_bytree=0.7376851115910559, model__learning_rate=0.12265511439527674, model__max_depth=6, model__min_child_weight=5, model__n_estimators=506, model__subsample=0.8022086896389087;, score=-20.695 total time=   6.4s\n",
      "[CV 14/37; 22/30] START model__colsample_bytree=0.7699205456508366, model__learning_rate=0.050612244946953884, model__max_depth=7, model__min_child_weight=7, model__n_estimators=798, model__subsample=0.8473924665198522\n",
      "[CV 13/37; 22/30] START model__colsample_bytree=0.7699205456508366, model__learning_rate=0.050612244946953884, model__max_depth=7, model__min_child_weight=7, model__n_estimators=798, model__subsample=0.8473924665198522\n",
      "[CV 34/37; 21/30] END model__colsample_bytree=0.7376851115910559, model__learning_rate=0.12265511439527674, model__max_depth=6, model__min_child_weight=5, model__n_estimators=506, model__subsample=0.8022086896389087;, score=0.210 total time=   6.6s\n",
      "[CV 15/37; 22/30] START model__colsample_bytree=0.7699205456508366, model__learning_rate=0.050612244946953884, model__max_depth=7, model__min_child_weight=7, model__n_estimators=798, model__subsample=0.8473924665198522\n",
      "[CV 7/37; 22/30] END model__colsample_bytree=0.7699205456508366, model__learning_rate=0.050612244946953884, model__max_depth=7, model__min_child_weight=7, model__n_estimators=798, model__subsample=0.8473924665198522;, score=-6.450 total time=   2.8s\n",
      "[CV 16/37; 22/30] START model__colsample_bytree=0.7699205456508366, model__learning_rate=0.050612244946953884, model__max_depth=7, model__min_child_weight=7, model__n_estimators=798, model__subsample=0.8473924665198522\n",
      "[CV 35/37; 21/30] END model__colsample_bytree=0.7376851115910559, model__learning_rate=0.12265511439527674, model__max_depth=6, model__min_child_weight=5, model__n_estimators=506, model__subsample=0.8022086896389087;, score=-19.570 total time=   6.8s\n",
      "[CV 17/37; 22/30] START model__colsample_bytree=0.7699205456508366, model__learning_rate=0.050612244946953884, model__max_depth=7, model__min_child_weight=7, model__n_estimators=798, model__subsample=0.8473924665198522\n",
      "[CV 8/37; 22/30] END model__colsample_bytree=0.7699205456508366, model__learning_rate=0.050612244946953884, model__max_depth=7, model__min_child_weight=7, model__n_estimators=798, model__subsample=0.8473924665198522;, score=-8.554 total time=   3.3s\n",
      "[CV 18/37; 22/30] START model__colsample_bytree=0.7699205456508366, model__learning_rate=0.050612244946953884, model__max_depth=7, model__min_child_weight=7, model__n_estimators=798, model__subsample=0.8473924665198522\n",
      "[CV 9/37; 22/30] END model__colsample_bytree=0.7699205456508366, model__learning_rate=0.050612244946953884, model__max_depth=7, model__min_child_weight=7, model__n_estimators=798, model__subsample=0.8473924665198522;, score=-0.561 total time=   3.7s\n",
      "[CV 19/37; 22/30] START model__colsample_bytree=0.7699205456508366, model__learning_rate=0.050612244946953884, model__max_depth=7, model__min_child_weight=7, model__n_estimators=798, model__subsample=0.8473924665198522\n",
      "[CV 36/37; 21/30] END model__colsample_bytree=0.7376851115910559, model__learning_rate=0.12265511439527674, model__max_depth=6, model__min_child_weight=5, model__n_estimators=506, model__subsample=0.8022086896389087;, score=-1.539 total time=   7.1s\n",
      "[CV 20/37; 22/30] START model__colsample_bytree=0.7699205456508366, model__learning_rate=0.050612244946953884, model__max_depth=7, model__min_child_weight=7, model__n_estimators=798, model__subsample=0.8473924665198522\n",
      "[CV 10/37; 22/30] END model__colsample_bytree=0.7699205456508366, model__learning_rate=0.050612244946953884, model__max_depth=7, model__min_child_weight=7, model__n_estimators=798, model__subsample=0.8473924665198522;, score=-28.964 total time=   4.0s\n",
      "[CV 21/37; 22/30] START model__colsample_bytree=0.7699205456508366, model__learning_rate=0.050612244946953884, model__max_depth=7, model__min_child_weight=7, model__n_estimators=798, model__subsample=0.8473924665198522\n",
      "[CV 37/37; 21/30] END model__colsample_bytree=0.7376851115910559, model__learning_rate=0.12265511439527674, model__max_depth=6, model__min_child_weight=5, model__n_estimators=506, model__subsample=0.8022086896389087;, score=-0.416 total time=   7.3s\n",
      "[CV 22/37; 22/30] START model__colsample_bytree=0.7699205456508366, model__learning_rate=0.050612244946953884, model__max_depth=7, model__min_child_weight=7, model__n_estimators=798, model__subsample=0.8473924665198522\n",
      "[CV 11/37; 22/30] END model__colsample_bytree=0.7699205456508366, model__learning_rate=0.050612244946953884, model__max_depth=7, model__min_child_weight=7, model__n_estimators=798, model__subsample=0.8473924665198522;, score=-3.278 total time=   4.4s\n",
      "[CV 23/37; 22/30] START model__colsample_bytree=0.7699205456508366, model__learning_rate=0.050612244946953884, model__max_depth=7, model__min_child_weight=7, model__n_estimators=798, model__subsample=0.8473924665198522\n",
      "[CV 12/37; 22/30] END model__colsample_bytree=0.7699205456508366, model__learning_rate=0.050612244946953884, model__max_depth=7, model__min_child_weight=7, model__n_estimators=798, model__subsample=0.8473924665198522;, score=-18.782 total time=   4.8s\n",
      "[CV 24/37; 22/30] START model__colsample_bytree=0.7699205456508366, model__learning_rate=0.050612244946953884, model__max_depth=7, model__min_child_weight=7, model__n_estimators=798, model__subsample=0.8473924665198522\n",
      "[CV 13/37; 22/30] END model__colsample_bytree=0.7699205456508366, model__learning_rate=0.050612244946953884, model__max_depth=7, model__min_child_weight=7, model__n_estimators=798, model__subsample=0.8473924665198522;, score=0.127 total time=   5.0s\n",
      "[CV 25/37; 22/30] START model__colsample_bytree=0.7699205456508366, model__learning_rate=0.050612244946953884, model__max_depth=7, model__min_child_weight=7, model__n_estimators=798, model__subsample=0.8473924665198522\n",
      "[CV 14/37; 22/30] END model__colsample_bytree=0.7699205456508366, model__learning_rate=0.050612244946953884, model__max_depth=7, model__min_child_weight=7, model__n_estimators=798, model__subsample=0.8473924665198522;, score=-20.574 total time=   5.6s\n",
      "[CV 26/37; 22/30] START model__colsample_bytree=0.7699205456508366, model__learning_rate=0.050612244946953884, model__max_depth=7, model__min_child_weight=7, model__n_estimators=798, model__subsample=0.8473924665198522\n",
      "[CV 15/37; 22/30] END model__colsample_bytree=0.7699205456508366, model__learning_rate=0.050612244946953884, model__max_depth=7, model__min_child_weight=7, model__n_estimators=798, model__subsample=0.8473924665198522;, score=-0.158 total time=   5.8s\n",
      "[CV 27/37; 22/30] START model__colsample_bytree=0.7699205456508366, model__learning_rate=0.050612244946953884, model__max_depth=7, model__min_child_weight=7, model__n_estimators=798, model__subsample=0.8473924665198522\n",
      "[CV 16/37; 22/30] END model__colsample_bytree=0.7699205456508366, model__learning_rate=0.050612244946953884, model__max_depth=7, model__min_child_weight=7, model__n_estimators=798, model__subsample=0.8473924665198522;, score=-0.658 total time=   6.1s\n",
      "[CV 28/37; 22/30] START model__colsample_bytree=0.7699205456508366, model__learning_rate=0.050612244946953884, model__max_depth=7, model__min_child_weight=7, model__n_estimators=798, model__subsample=0.8473924665198522\n",
      "[CV 17/37; 22/30] END model__colsample_bytree=0.7699205456508366, model__learning_rate=0.050612244946953884, model__max_depth=7, model__min_child_weight=7, model__n_estimators=798, model__subsample=0.8473924665198522;, score=-18.299 total time=   6.6s\n",
      "[CV 29/37; 22/30] START model__colsample_bytree=0.7699205456508366, model__learning_rate=0.050612244946953884, model__max_depth=7, model__min_child_weight=7, model__n_estimators=798, model__subsample=0.8473924665198522\n",
      "[CV 18/37; 22/30] END model__colsample_bytree=0.7699205456508366, model__learning_rate=0.050612244946953884, model__max_depth=7, model__min_child_weight=7, model__n_estimators=798, model__subsample=0.8473924665198522;, score=-0.597 total time=   6.6s\n",
      "[CV 30/37; 22/30] START model__colsample_bytree=0.7699205456508366, model__learning_rate=0.050612244946953884, model__max_depth=7, model__min_child_weight=7, model__n_estimators=798, model__subsample=0.8473924665198522\n",
      "[CV 19/37; 22/30] END model__colsample_bytree=0.7699205456508366, model__learning_rate=0.050612244946953884, model__max_depth=7, model__min_child_weight=7, model__n_estimators=798, model__subsample=0.8473924665198522;, score=-0.962 total time=   7.2s\n",
      "[CV 31/37; 22/30] START model__colsample_bytree=0.7699205456508366, model__learning_rate=0.050612244946953884, model__max_depth=7, model__min_child_weight=7, model__n_estimators=798, model__subsample=0.8473924665198522\n",
      "[CV 20/37; 22/30] END model__colsample_bytree=0.7699205456508366, model__learning_rate=0.050612244946953884, model__max_depth=7, model__min_child_weight=7, model__n_estimators=798, model__subsample=0.8473924665198522;, score=-4.892 total time=   7.6s\n",
      "[CV 32/37; 22/30] START model__colsample_bytree=0.7699205456508366, model__learning_rate=0.050612244946953884, model__max_depth=7, model__min_child_weight=7, model__n_estimators=798, model__subsample=0.8473924665198522\n",
      "[CV 21/37; 22/30] END model__colsample_bytree=0.7699205456508366, model__learning_rate=0.050612244946953884, model__max_depth=7, model__min_child_weight=7, model__n_estimators=798, model__subsample=0.8473924665198522;, score=-0.908 total time=   8.1s\n",
      "[CV 33/37; 22/30] START model__colsample_bytree=0.7699205456508366, model__learning_rate=0.050612244946953884, model__max_depth=7, model__min_child_weight=7, model__n_estimators=798, model__subsample=0.8473924665198522\n",
      "[CV 22/37; 22/30] END model__colsample_bytree=0.7699205456508366, model__learning_rate=0.050612244946953884, model__max_depth=7, model__min_child_weight=7, model__n_estimators=798, model__subsample=0.8473924665198522;, score=-0.599 total time=   8.3s\n",
      "[CV 34/37; 22/30] START model__colsample_bytree=0.7699205456508366, model__learning_rate=0.050612244946953884, model__max_depth=7, model__min_child_weight=7, model__n_estimators=798, model__subsample=0.8473924665198522\n",
      "[CV 23/37; 22/30] END model__colsample_bytree=0.7699205456508366, model__learning_rate=0.050612244946953884, model__max_depth=7, model__min_child_weight=7, model__n_estimators=798, model__subsample=0.8473924665198522;, score=-11.207 total time=   8.7s\n",
      "[CV 35/37; 22/30] START model__colsample_bytree=0.7699205456508366, model__learning_rate=0.050612244946953884, model__max_depth=7, model__min_child_weight=7, model__n_estimators=798, model__subsample=0.8473924665198522\n",
      "[CV 24/37; 22/30] END model__colsample_bytree=0.7699205456508366, model__learning_rate=0.050612244946953884, model__max_depth=7, model__min_child_weight=7, model__n_estimators=798, model__subsample=0.8473924665198522;, score=-5.995 total time=   9.2s\n",
      "[CV 36/37; 22/30] START model__colsample_bytree=0.7699205456508366, model__learning_rate=0.050612244946953884, model__max_depth=7, model__min_child_weight=7, model__n_estimators=798, model__subsample=0.8473924665198522\n",
      "[CV 25/37; 22/30] END model__colsample_bytree=0.7699205456508366, model__learning_rate=0.050612244946953884, model__max_depth=7, model__min_child_weight=7, model__n_estimators=798, model__subsample=0.8473924665198522;, score=-1.097 total time=   9.4s\n",
      "[CV 37/37; 22/30] START model__colsample_bytree=0.7699205456508366, model__learning_rate=0.050612244946953884, model__max_depth=7, model__min_child_weight=7, model__n_estimators=798, model__subsample=0.8473924665198522\n",
      "[CV 26/37; 22/30] END model__colsample_bytree=0.7699205456508366, model__learning_rate=0.050612244946953884, model__max_depth=7, model__min_child_weight=7, model__n_estimators=798, model__subsample=0.8473924665198522;, score=-1.714 total time=   9.9s\n",
      "[CV 1/37; 23/30] START model__colsample_bytree=0.9402339195076288, model__learning_rate=0.13487080962675865, model__max_depth=8, model__min_child_weight=9, model__n_estimators=745, model__subsample=0.7282672852414551\n",
      "[CV 1/37; 23/30] END model__colsample_bytree=0.9402339195076288, model__learning_rate=0.13487080962675865, model__max_depth=8, model__min_child_weight=9, model__n_estimators=745, model__subsample=0.7282672852414551;, score=-42.714 total time=   0.4s\n",
      "[CV 2/37; 23/30] START model__colsample_bytree=0.9402339195076288, model__learning_rate=0.13487080962675865, model__max_depth=8, model__min_child_weight=9, model__n_estimators=745, model__subsample=0.7282672852414551\n",
      "[CV 2/37; 23/30] END model__colsample_bytree=0.9402339195076288, model__learning_rate=0.13487080962675865, model__max_depth=8, model__min_child_weight=9, model__n_estimators=745, model__subsample=0.7282672852414551;, score=-0.379 total time=   0.6s\n",
      "[CV 3/37; 23/30] START model__colsample_bytree=0.9402339195076288, model__learning_rate=0.13487080962675865, model__max_depth=8, model__min_child_weight=9, model__n_estimators=745, model__subsample=0.7282672852414551\n",
      "[CV 27/37; 22/30] END model__colsample_bytree=0.7699205456508366, model__learning_rate=0.050612244946953884, model__max_depth=7, model__min_child_weight=7, model__n_estimators=798, model__subsample=0.8473924665198522;, score=-2.816 total time=  10.3s\n",
      "[CV 4/37; 23/30] START model__colsample_bytree=0.9402339195076288, model__learning_rate=0.13487080962675865, model__max_depth=8, model__min_child_weight=9, model__n_estimators=745, model__subsample=0.7282672852414551\n",
      "[CV 3/37; 23/30] END model__colsample_bytree=0.9402339195076288, model__learning_rate=0.13487080962675865, model__max_depth=8, model__min_child_weight=9, model__n_estimators=745, model__subsample=0.7282672852414551;, score=-20.272 total time=   0.7s\n",
      "[CV 5/37; 23/30] START model__colsample_bytree=0.9402339195076288, model__learning_rate=0.13487080962675865, model__max_depth=8, model__min_child_weight=9, model__n_estimators=745, model__subsample=0.7282672852414551\n",
      "[CV 28/37; 22/30] END model__colsample_bytree=0.7699205456508366, model__learning_rate=0.050612244946953884, model__max_depth=7, model__min_child_weight=7, model__n_estimators=798, model__subsample=0.8473924665198522;, score=-1.026 total time=  10.6s\n",
      "[CV 6/37; 23/30] START model__colsample_bytree=0.9402339195076288, model__learning_rate=0.13487080962675865, model__max_depth=8, model__min_child_weight=9, model__n_estimators=745, model__subsample=0.7282672852414551\n",
      "[CV 4/37; 23/30] END model__colsample_bytree=0.9402339195076288, model__learning_rate=0.13487080962675865, model__max_depth=8, model__min_child_weight=9, model__n_estimators=745, model__subsample=0.7282672852414551;, score=-7.527 total time=   0.9s\n",
      "[CV 7/37; 23/30] START model__colsample_bytree=0.9402339195076288, model__learning_rate=0.13487080962675865, model__max_depth=8, model__min_child_weight=9, model__n_estimators=745, model__subsample=0.7282672852414551\n",
      "[CV 5/37; 23/30] END model__colsample_bytree=0.9402339195076288, model__learning_rate=0.13487080962675865, model__max_depth=8, model__min_child_weight=9, model__n_estimators=745, model__subsample=0.7282672852414551;, score=-38.097 total time=   1.3s\n",
      "[CV 8/37; 23/30] START model__colsample_bytree=0.9402339195076288, model__learning_rate=0.13487080962675865, model__max_depth=8, model__min_child_weight=9, model__n_estimators=745, model__subsample=0.7282672852414551\n",
      "[CV 29/37; 22/30] END model__colsample_bytree=0.7699205456508366, model__learning_rate=0.050612244946953884, model__max_depth=7, model__min_child_weight=7, model__n_estimators=798, model__subsample=0.8473924665198522;, score=-8.860 total time=  10.9s\n",
      "[CV 9/37; 23/30] START model__colsample_bytree=0.9402339195076288, model__learning_rate=0.13487080962675865, model__max_depth=8, model__min_child_weight=9, model__n_estimators=745, model__subsample=0.7282672852414551\n",
      "[CV 6/37; 23/30] END model__colsample_bytree=0.9402339195076288, model__learning_rate=0.13487080962675865, model__max_depth=8, model__min_child_weight=9, model__n_estimators=745, model__subsample=0.7282672852414551;, score=-1.529 total time=   1.4s\n",
      "[CV 10/37; 23/30] START model__colsample_bytree=0.9402339195076288, model__learning_rate=0.13487080962675865, model__max_depth=8, model__min_child_weight=9, model__n_estimators=745, model__subsample=0.7282672852414551\n",
      "[CV 30/37; 22/30] END model__colsample_bytree=0.7699205456508366, model__learning_rate=0.050612244946953884, model__max_depth=7, model__min_child_weight=7, model__n_estimators=798, model__subsample=0.8473924665198522;, score=-0.133 total time=  11.2s\n",
      "[CV 7/37; 23/30] END model__colsample_bytree=0.9402339195076288, model__learning_rate=0.13487080962675865, model__max_depth=8, model__min_child_weight=9, model__n_estimators=745, model__subsample=0.7282672852414551;, score=-7.255 total time=   1.8s\n",
      "[CV 11/37; 23/30] START model__colsample_bytree=0.9402339195076288, model__learning_rate=0.13487080962675865, model__max_depth=8, model__min_child_weight=9, model__n_estimators=745, model__subsample=0.7282672852414551[CV 12/37; 23/30] START model__colsample_bytree=0.9402339195076288, model__learning_rate=0.13487080962675865, model__max_depth=8, model__min_child_weight=9, model__n_estimators=745, model__subsample=0.7282672852414551\n",
      "\n",
      "[CV 8/37; 23/30] END model__colsample_bytree=0.9402339195076288, model__learning_rate=0.13487080962675865, model__max_depth=8, model__min_child_weight=9, model__n_estimators=745, model__subsample=0.7282672852414551;, score=-9.708 total time=   2.1s\n",
      "[CV 13/37; 23/30] START model__colsample_bytree=0.9402339195076288, model__learning_rate=0.13487080962675865, model__max_depth=8, model__min_child_weight=9, model__n_estimators=745, model__subsample=0.7282672852414551\n",
      "[CV 31/37; 22/30] END model__colsample_bytree=0.7699205456508366, model__learning_rate=0.050612244946953884, model__max_depth=7, model__min_child_weight=7, model__n_estimators=798, model__subsample=0.8473924665198522;, score=-0.196 total time=  11.8s\n",
      "[CV 14/37; 23/30] START model__colsample_bytree=0.9402339195076288, model__learning_rate=0.13487080962675865, model__max_depth=8, model__min_child_weight=9, model__n_estimators=745, model__subsample=0.7282672852414551\n",
      "[CV 9/37; 23/30] END model__colsample_bytree=0.9402339195076288, model__learning_rate=0.13487080962675865, model__max_depth=8, model__min_child_weight=9, model__n_estimators=745, model__subsample=0.7282672852414551;, score=-0.660 total time=   2.5s\n",
      "[CV 15/37; 23/30] START model__colsample_bytree=0.9402339195076288, model__learning_rate=0.13487080962675865, model__max_depth=8, model__min_child_weight=9, model__n_estimators=745, model__subsample=0.7282672852414551\n",
      "[CV 10/37; 23/30] END model__colsample_bytree=0.9402339195076288, model__learning_rate=0.13487080962675865, model__max_depth=8, model__min_child_weight=9, model__n_estimators=745, model__subsample=0.7282672852414551;, score=-30.265 total time=   2.7s\n",
      "[CV 16/37; 23/30] START model__colsample_bytree=0.9402339195076288, model__learning_rate=0.13487080962675865, model__max_depth=8, model__min_child_weight=9, model__n_estimators=745, model__subsample=0.7282672852414551\n",
      "[CV 32/37; 22/30] END model__colsample_bytree=0.7699205456508366, model__learning_rate=0.050612244946953884, model__max_depth=7, model__min_child_weight=7, model__n_estimators=798, model__subsample=0.8473924665198522;, score=-3.440 total time=  11.9s\n",
      "[CV 17/37; 23/30] START model__colsample_bytree=0.9402339195076288, model__learning_rate=0.13487080962675865, model__max_depth=8, model__min_child_weight=9, model__n_estimators=745, model__subsample=0.7282672852414551\n",
      "[CV 11/37; 23/30] END model__colsample_bytree=0.9402339195076288, model__learning_rate=0.13487080962675865, model__max_depth=8, model__min_child_weight=9, model__n_estimators=745, model__subsample=0.7282672852414551;, score=-3.773 total time=   3.1s\n",
      "[CV 18/37; 23/30] START model__colsample_bytree=0.9402339195076288, model__learning_rate=0.13487080962675865, model__max_depth=8, model__min_child_weight=9, model__n_estimators=745, model__subsample=0.7282672852414551\n",
      "[CV 12/37; 23/30] END model__colsample_bytree=0.9402339195076288, model__learning_rate=0.13487080962675865, model__max_depth=8, model__min_child_weight=9, model__n_estimators=745, model__subsample=0.7282672852414551;, score=-19.000 total time=   3.3s\n",
      "[CV 19/37; 23/30] START model__colsample_bytree=0.9402339195076288, model__learning_rate=0.13487080962675865, model__max_depth=8, model__min_child_weight=9, model__n_estimators=745, model__subsample=0.7282672852414551\n",
      "[CV 33/37; 22/30] END model__colsample_bytree=0.7699205456508366, model__learning_rate=0.050612244946953884, model__max_depth=7, model__min_child_weight=7, model__n_estimators=798, model__subsample=0.8473924665198522;, score=-19.568 total time=  12.4s\n",
      "[CV 20/37; 23/30] START model__colsample_bytree=0.9402339195076288, model__learning_rate=0.13487080962675865, model__max_depth=8, model__min_child_weight=9, model__n_estimators=745, model__subsample=0.7282672852414551\n",
      "[CV 34/37; 22/30] END model__colsample_bytree=0.7699205456508366, model__learning_rate=0.050612244946953884, model__max_depth=7, model__min_child_weight=7, model__n_estimators=798, model__subsample=0.8473924665198522;, score=0.191 total time=  12.4s\n",
      "[CV 21/37; 23/30] START model__colsample_bytree=0.9402339195076288, model__learning_rate=0.13487080962675865, model__max_depth=8, model__min_child_weight=9, model__n_estimators=745, model__subsample=0.7282672852414551\n",
      "[CV 13/37; 23/30] END model__colsample_bytree=0.9402339195076288, model__learning_rate=0.13487080962675865, model__max_depth=8, model__min_child_weight=9, model__n_estimators=745, model__subsample=0.7282672852414551;, score=0.046 total time=   3.7s\n",
      "[CV 22/37; 23/30] START model__colsample_bytree=0.9402339195076288, model__learning_rate=0.13487080962675865, model__max_depth=8, model__min_child_weight=9, model__n_estimators=745, model__subsample=0.7282672852414551\n",
      "[CV 35/37; 22/30] END model__colsample_bytree=0.7699205456508366, model__learning_rate=0.050612244946953884, model__max_depth=7, model__min_child_weight=7, model__n_estimators=798, model__subsample=0.8473924665198522;, score=-19.107 total time=  13.2s\n",
      "[CV 23/37; 23/30] START model__colsample_bytree=0.9402339195076288, model__learning_rate=0.13487080962675865, model__max_depth=8, model__min_child_weight=9, model__n_estimators=745, model__subsample=0.7282672852414551\n",
      "[CV 14/37; 23/30] END model__colsample_bytree=0.9402339195076288, model__learning_rate=0.13487080962675865, model__max_depth=8, model__min_child_weight=9, model__n_estimators=745, model__subsample=0.7282672852414551;, score=-23.034 total time=   4.1s\n",
      "[CV 24/37; 23/30] START model__colsample_bytree=0.9402339195076288, model__learning_rate=0.13487080962675865, model__max_depth=8, model__min_child_weight=9, model__n_estimators=745, model__subsample=0.7282672852414551\n",
      "[CV 15/37; 23/30] END model__colsample_bytree=0.9402339195076288, model__learning_rate=0.13487080962675865, model__max_depth=8, model__min_child_weight=9, model__n_estimators=745, model__subsample=0.7282672852414551;, score=-0.022 total time=   4.7s\n",
      "[CV 25/37; 23/30] START model__colsample_bytree=0.9402339195076288, model__learning_rate=0.13487080962675865, model__max_depth=8, model__min_child_weight=9, model__n_estimators=745, model__subsample=0.7282672852414551\n",
      "[CV 16/37; 23/30] END model__colsample_bytree=0.9402339195076288, model__learning_rate=0.13487080962675865, model__max_depth=8, model__min_child_weight=9, model__n_estimators=745, model__subsample=0.7282672852414551;, score=-0.732 total time=   5.3s\n",
      "[CV 26/37; 23/30] START model__colsample_bytree=0.9402339195076288, model__learning_rate=0.13487080962675865, model__max_depth=8, model__min_child_weight=9, model__n_estimators=745, model__subsample=0.7282672852414551\n",
      "[CV 36/37; 22/30] END model__colsample_bytree=0.7699205456508366, model__learning_rate=0.050612244946953884, model__max_depth=7, model__min_child_weight=7, model__n_estimators=798, model__subsample=0.8473924665198522;, score=-1.523 total time=  13.4s\n",
      "[CV 27/37; 23/30] START model__colsample_bytree=0.9402339195076288, model__learning_rate=0.13487080962675865, model__max_depth=8, model__min_child_weight=9, model__n_estimators=745, model__subsample=0.7282672852414551\n",
      "[CV 17/37; 23/30] END model__colsample_bytree=0.9402339195076288, model__learning_rate=0.13487080962675865, model__max_depth=8, model__min_child_weight=9, model__n_estimators=745, model__subsample=0.7282672852414551;, score=-19.269 total time=   6.0s\n",
      "[CV 28/37; 23/30] START model__colsample_bytree=0.9402339195076288, model__learning_rate=0.13487080962675865, model__max_depth=8, model__min_child_weight=9, model__n_estimators=745, model__subsample=0.7282672852414551\n",
      "[CV 37/37; 22/30] END model__colsample_bytree=0.7699205456508366, model__learning_rate=0.050612244946953884, model__max_depth=7, model__min_child_weight=7, model__n_estimators=798, model__subsample=0.8473924665198522;, score=-0.310 total time=  13.9s\n",
      "[CV 29/37; 23/30] START model__colsample_bytree=0.9402339195076288, model__learning_rate=0.13487080962675865, model__max_depth=8, model__min_child_weight=9, model__n_estimators=745, model__subsample=0.7282672852414551\n",
      "[CV 18/37; 23/30] END model__colsample_bytree=0.9402339195076288, model__learning_rate=0.13487080962675865, model__max_depth=8, model__min_child_weight=9, model__n_estimators=745, model__subsample=0.7282672852414551;, score=-0.547 total time=   6.6s\n",
      "[CV 30/37; 23/30] START model__colsample_bytree=0.9402339195076288, model__learning_rate=0.13487080962675865, model__max_depth=8, model__min_child_weight=9, model__n_estimators=745, model__subsample=0.7282672852414551\n",
      "[CV 19/37; 23/30] END model__colsample_bytree=0.9402339195076288, model__learning_rate=0.13487080962675865, model__max_depth=8, model__min_child_weight=9, model__n_estimators=745, model__subsample=0.7282672852414551;, score=-1.297 total time=   7.0s\n",
      "[CV 31/37; 23/30] START model__colsample_bytree=0.9402339195076288, model__learning_rate=0.13487080962675865, model__max_depth=8, model__min_child_weight=9, model__n_estimators=745, model__subsample=0.7282672852414551\n",
      "[CV 20/37; 23/30] END model__colsample_bytree=0.9402339195076288, model__learning_rate=0.13487080962675865, model__max_depth=8, model__min_child_weight=9, model__n_estimators=745, model__subsample=0.7282672852414551;, score=-4.867 total time=   7.9s\n",
      "[CV 32/37; 23/30] START model__colsample_bytree=0.9402339195076288, model__learning_rate=0.13487080962675865, model__max_depth=8, model__min_child_weight=9, model__n_estimators=745, model__subsample=0.7282672852414551\n",
      "[CV 21/37; 23/30] END model__colsample_bytree=0.9402339195076288, model__learning_rate=0.13487080962675865, model__max_depth=8, model__min_child_weight=9, model__n_estimators=745, model__subsample=0.7282672852414551;, score=-1.317 total time=   8.4s\n",
      "[CV 33/37; 23/30] START model__colsample_bytree=0.9402339195076288, model__learning_rate=0.13487080962675865, model__max_depth=8, model__min_child_weight=9, model__n_estimators=745, model__subsample=0.7282672852414551\n",
      "[CV 22/37; 23/30] END model__colsample_bytree=0.9402339195076288, model__learning_rate=0.13487080962675865, model__max_depth=8, model__min_child_weight=9, model__n_estimators=745, model__subsample=0.7282672852414551;, score=-0.577 total time=   9.1s\n",
      "[CV 34/37; 23/30] START model__colsample_bytree=0.9402339195076288, model__learning_rate=0.13487080962675865, model__max_depth=8, model__min_child_weight=9, model__n_estimators=745, model__subsample=0.7282672852414551\n",
      "[CV 23/37; 23/30] END model__colsample_bytree=0.9402339195076288, model__learning_rate=0.13487080962675865, model__max_depth=8, model__min_child_weight=9, model__n_estimators=745, model__subsample=0.7282672852414551;, score=-10.769 total time=   9.8s\n",
      "[CV 35/37; 23/30] START model__colsample_bytree=0.9402339195076288, model__learning_rate=0.13487080962675865, model__max_depth=8, model__min_child_weight=9, model__n_estimators=745, model__subsample=0.7282672852414551\n",
      "[CV 24/37; 23/30] END model__colsample_bytree=0.9402339195076288, model__learning_rate=0.13487080962675865, model__max_depth=8, model__min_child_weight=9, model__n_estimators=745, model__subsample=0.7282672852414551;, score=-7.598 total time=  10.3s\n",
      "[CV 36/37; 23/30] START model__colsample_bytree=0.9402339195076288, model__learning_rate=0.13487080962675865, model__max_depth=8, model__min_child_weight=9, model__n_estimators=745, model__subsample=0.7282672852414551\n",
      "[CV 25/37; 23/30] END model__colsample_bytree=0.9402339195076288, model__learning_rate=0.13487080962675865, model__max_depth=8, model__min_child_weight=9, model__n_estimators=745, model__subsample=0.7282672852414551;, score=-1.109 total time=  11.0s\n",
      "[CV 37/37; 23/30] START model__colsample_bytree=0.9402339195076288, model__learning_rate=0.13487080962675865, model__max_depth=8, model__min_child_weight=9, model__n_estimators=745, model__subsample=0.7282672852414551\n",
      "[CV 26/37; 23/30] END model__colsample_bytree=0.9402339195076288, model__learning_rate=0.13487080962675865, model__max_depth=8, model__min_child_weight=9, model__n_estimators=745, model__subsample=0.7282672852414551;, score=-1.685 total time=  11.5s\n",
      "[CV 1/37; 24/30] START model__colsample_bytree=0.6092202186084168, model__learning_rate=0.09330198957407325, model__max_depth=8, model__min_child_weight=7, model__n_estimators=447, model__subsample=0.6781489190384875\n",
      "[CV 1/37; 24/30] END model__colsample_bytree=0.6092202186084168, model__learning_rate=0.09330198957407325, model__max_depth=8, model__min_child_weight=7, model__n_estimators=447, model__subsample=0.6781489190384875;, score=-40.793 total time=   0.3s\n",
      "[CV 2/37; 24/30] START model__colsample_bytree=0.6092202186084168, model__learning_rate=0.09330198957407325, model__max_depth=8, model__min_child_weight=7, model__n_estimators=447, model__subsample=0.6781489190384875\n",
      "[CV 27/37; 23/30] END model__colsample_bytree=0.9402339195076288, model__learning_rate=0.13487080962675865, model__max_depth=8, model__min_child_weight=9, model__n_estimators=745, model__subsample=0.7282672852414551;, score=-2.671 total time=  11.9s\n",
      "[CV 3/37; 24/30] START model__colsample_bytree=0.6092202186084168, model__learning_rate=0.09330198957407325, model__max_depth=8, model__min_child_weight=7, model__n_estimators=447, model__subsample=0.6781489190384875\n",
      "[CV 2/37; 24/30] END model__colsample_bytree=0.6092202186084168, model__learning_rate=0.09330198957407325, model__max_depth=8, model__min_child_weight=7, model__n_estimators=447, model__subsample=0.6781489190384875;, score=-0.321 total time=   0.4s\n",
      "[CV 4/37; 24/30] START model__colsample_bytree=0.6092202186084168, model__learning_rate=0.09330198957407325, model__max_depth=8, model__min_child_weight=7, model__n_estimators=447, model__subsample=0.6781489190384875\n",
      "[CV 3/37; 24/30] END model__colsample_bytree=0.6092202186084168, model__learning_rate=0.09330198957407325, model__max_depth=8, model__min_child_weight=7, model__n_estimators=447, model__subsample=0.6781489190384875;, score=-13.625 total time=   0.6s\n",
      "[CV 5/37; 24/30] START model__colsample_bytree=0.6092202186084168, model__learning_rate=0.09330198957407325, model__max_depth=8, model__min_child_weight=7, model__n_estimators=447, model__subsample=0.6781489190384875\n",
      "[CV 4/37; 24/30] END model__colsample_bytree=0.6092202186084168, model__learning_rate=0.09330198957407325, model__max_depth=8, model__min_child_weight=7, model__n_estimators=447, model__subsample=0.6781489190384875;, score=-7.354 total time=   0.9s\n",
      "[CV 6/37; 24/30] START model__colsample_bytree=0.6092202186084168, model__learning_rate=0.09330198957407325, model__max_depth=8, model__min_child_weight=7, model__n_estimators=447, model__subsample=0.6781489190384875\n",
      "[CV 28/37; 23/30] END model__colsample_bytree=0.9402339195076288, model__learning_rate=0.13487080962675865, model__max_depth=8, model__min_child_weight=9, model__n_estimators=745, model__subsample=0.7282672852414551;, score=-1.318 total time=  12.5s\n",
      "[CV 7/37; 24/30] START model__colsample_bytree=0.6092202186084168, model__learning_rate=0.09330198957407325, model__max_depth=8, model__min_child_weight=7, model__n_estimators=447, model__subsample=0.6781489190384875\n",
      "[CV 5/37; 24/30] END model__colsample_bytree=0.6092202186084168, model__learning_rate=0.09330198957407325, model__max_depth=8, model__min_child_weight=7, model__n_estimators=447, model__subsample=0.6781489190384875;, score=-37.629 total time=   1.0s\n",
      "[CV 8/37; 24/30] START model__colsample_bytree=0.6092202186084168, model__learning_rate=0.09330198957407325, model__max_depth=8, model__min_child_weight=7, model__n_estimators=447, model__subsample=0.6781489190384875\n",
      "[CV 6/37; 24/30] END model__colsample_bytree=0.6092202186084168, model__learning_rate=0.09330198957407325, model__max_depth=8, model__min_child_weight=7, model__n_estimators=447, model__subsample=0.6781489190384875;, score=-1.320 total time=   1.3s\n",
      "[CV 9/37; 24/30] START model__colsample_bytree=0.6092202186084168, model__learning_rate=0.09330198957407325, model__max_depth=8, model__min_child_weight=7, model__n_estimators=447, model__subsample=0.6781489190384875\n",
      "[CV 29/37; 23/30] END model__colsample_bytree=0.9402339195076288, model__learning_rate=0.13487080962675865, model__max_depth=8, model__min_child_weight=9, model__n_estimators=745, model__subsample=0.7282672852414551;, score=-7.799 total time=  13.4s\n",
      "[CV 10/37; 24/30] START model__colsample_bytree=0.6092202186084168, model__learning_rate=0.09330198957407325, model__max_depth=8, model__min_child_weight=7, model__n_estimators=447, model__subsample=0.6781489190384875\n",
      "[CV 7/37; 24/30] END model__colsample_bytree=0.6092202186084168, model__learning_rate=0.09330198957407325, model__max_depth=8, model__min_child_weight=7, model__n_estimators=447, model__subsample=0.6781489190384875;, score=-6.263 total time=   1.5s\n",
      "[CV 11/37; 24/30] START model__colsample_bytree=0.6092202186084168, model__learning_rate=0.09330198957407325, model__max_depth=8, model__min_child_weight=7, model__n_estimators=447, model__subsample=0.6781489190384875\n",
      "[CV 8/37; 24/30] END model__colsample_bytree=0.6092202186084168, model__learning_rate=0.09330198957407325, model__max_depth=8, model__min_child_weight=7, model__n_estimators=447, model__subsample=0.6781489190384875;, score=-8.554 total time=   1.8s\n",
      "[CV 12/37; 24/30] START model__colsample_bytree=0.6092202186084168, model__learning_rate=0.09330198957407325, model__max_depth=8, model__min_child_weight=7, model__n_estimators=447, model__subsample=0.6781489190384875\n",
      "[CV 30/37; 23/30] END model__colsample_bytree=0.9402339195076288, model__learning_rate=0.13487080962675865, model__max_depth=8, model__min_child_weight=9, model__n_estimators=745, model__subsample=0.7282672852414551;, score=-0.361 total time=  14.0s\n",
      "[CV 13/37; 24/30] START model__colsample_bytree=0.6092202186084168, model__learning_rate=0.09330198957407325, model__max_depth=8, model__min_child_weight=7, model__n_estimators=447, model__subsample=0.6781489190384875\n",
      "[CV 9/37; 24/30] END model__colsample_bytree=0.6092202186084168, model__learning_rate=0.09330198957407325, model__max_depth=8, model__min_child_weight=7, model__n_estimators=447, model__subsample=0.6781489190384875;, score=-0.661 total time=   2.0s\n",
      "[CV 14/37; 24/30] START model__colsample_bytree=0.6092202186084168, model__learning_rate=0.09330198957407325, model__max_depth=8, model__min_child_weight=7, model__n_estimators=447, model__subsample=0.6781489190384875\n",
      "[CV 10/37; 24/30] END model__colsample_bytree=0.6092202186084168, model__learning_rate=0.09330198957407325, model__max_depth=8, model__min_child_weight=7, model__n_estimators=447, model__subsample=0.6781489190384875;, score=-28.144 total time=   2.2s\n",
      "[CV 15/37; 24/30] START model__colsample_bytree=0.6092202186084168, model__learning_rate=0.09330198957407325, model__max_depth=8, model__min_child_weight=7, model__n_estimators=447, model__subsample=0.6781489190384875\n",
      "[CV 11/37; 24/30] END model__colsample_bytree=0.6092202186084168, model__learning_rate=0.09330198957407325, model__max_depth=8, model__min_child_weight=7, model__n_estimators=447, model__subsample=0.6781489190384875;, score=-3.697 total time=   2.4s\n",
      "[CV 16/37; 24/30] START model__colsample_bytree=0.6092202186084168, model__learning_rate=0.09330198957407325, model__max_depth=8, model__min_child_weight=7, model__n_estimators=447, model__subsample=0.6781489190384875\n",
      "[CV 31/37; 23/30] END model__colsample_bytree=0.9402339195076288, model__learning_rate=0.13487080962675865, model__max_depth=8, model__min_child_weight=9, model__n_estimators=745, model__subsample=0.7282672852414551;, score=-0.586 total time=  14.6s\n",
      "[CV 17/37; 24/30] START model__colsample_bytree=0.6092202186084168, model__learning_rate=0.09330198957407325, model__max_depth=8, model__min_child_weight=7, model__n_estimators=447, model__subsample=0.6781489190384875\n",
      "[CV 12/37; 24/30] END model__colsample_bytree=0.6092202186084168, model__learning_rate=0.09330198957407325, model__max_depth=8, model__min_child_weight=7, model__n_estimators=447, model__subsample=0.6781489190384875;, score=-18.209 total time=   2.5s\n",
      "[CV 18/37; 24/30] START model__colsample_bytree=0.6092202186084168, model__learning_rate=0.09330198957407325, model__max_depth=8, model__min_child_weight=7, model__n_estimators=447, model__subsample=0.6781489190384875\n",
      "[CV 13/37; 24/30] END model__colsample_bytree=0.6092202186084168, model__learning_rate=0.09330198957407325, model__max_depth=8, model__min_child_weight=7, model__n_estimators=447, model__subsample=0.6781489190384875;, score=-0.002 total time=   2.8s\n",
      "[CV 19/37; 24/30] START model__colsample_bytree=0.6092202186084168, model__learning_rate=0.09330198957407325, model__max_depth=8, model__min_child_weight=7, model__n_estimators=447, model__subsample=0.6781489190384875\n",
      "[CV 32/37; 23/30] END model__colsample_bytree=0.9402339195076288, model__learning_rate=0.13487080962675865, model__max_depth=8, model__min_child_weight=9, model__n_estimators=745, model__subsample=0.7282672852414551;, score=-3.563 total time=  14.9s\n",
      "[CV 20/37; 24/30] START model__colsample_bytree=0.6092202186084168, model__learning_rate=0.09330198957407325, model__max_depth=8, model__min_child_weight=7, model__n_estimators=447, model__subsample=0.6781489190384875\n",
      "[CV 14/37; 24/30] END model__colsample_bytree=0.6092202186084168, model__learning_rate=0.09330198957407325, model__max_depth=8, model__min_child_weight=7, model__n_estimators=447, model__subsample=0.6781489190384875;, score=-22.211 total time=   3.0s\n",
      "[CV 21/37; 24/30] START model__colsample_bytree=0.6092202186084168, model__learning_rate=0.09330198957407325, model__max_depth=8, model__min_child_weight=7, model__n_estimators=447, model__subsample=0.6781489190384875\n",
      "[CV 15/37; 24/30] END model__colsample_bytree=0.6092202186084168, model__learning_rate=0.09330198957407325, model__max_depth=8, model__min_child_weight=7, model__n_estimators=447, model__subsample=0.6781489190384875;, score=-0.346 total time=   3.2s\n",
      "[CV 22/37; 24/30] START model__colsample_bytree=0.6092202186084168, model__learning_rate=0.09330198957407325, model__max_depth=8, model__min_child_weight=7, model__n_estimators=447, model__subsample=0.6781489190384875\n",
      "[CV 16/37; 24/30] END model__colsample_bytree=0.6092202186084168, model__learning_rate=0.09330198957407325, model__max_depth=8, model__min_child_weight=7, model__n_estimators=447, model__subsample=0.6781489190384875;, score=-0.561 total time=   3.5s\n",
      "[CV 23/37; 24/30] START model__colsample_bytree=0.6092202186084168, model__learning_rate=0.09330198957407325, model__max_depth=8, model__min_child_weight=7, model__n_estimators=447, model__subsample=0.6781489190384875\n",
      "[CV 17/37; 24/30] END model__colsample_bytree=0.6092202186084168, model__learning_rate=0.09330198957407325, model__max_depth=8, model__min_child_weight=7, model__n_estimators=447, model__subsample=0.6781489190384875;, score=-17.636 total time=   3.7s\n",
      "[CV 24/37; 24/30] START model__colsample_bytree=0.6092202186084168, model__learning_rate=0.09330198957407325, model__max_depth=8, model__min_child_weight=7, model__n_estimators=447, model__subsample=0.6781489190384875\n",
      "[CV 33/37; 23/30] END model__colsample_bytree=0.9402339195076288, model__learning_rate=0.13487080962675865, model__max_depth=8, model__min_child_weight=9, model__n_estimators=745, model__subsample=0.7282672852414551;, score=-19.548 total time=  16.1s\n",
      "[CV 25/37; 24/30] START model__colsample_bytree=0.6092202186084168, model__learning_rate=0.09330198957407325, model__max_depth=8, model__min_child_weight=7, model__n_estimators=447, model__subsample=0.6781489190384875\n",
      "[CV 18/37; 24/30] END model__colsample_bytree=0.6092202186084168, model__learning_rate=0.09330198957407325, model__max_depth=8, model__min_child_weight=7, model__n_estimators=447, model__subsample=0.6781489190384875;, score=-0.504 total time=   4.0s\n",
      "[CV 26/37; 24/30] START model__colsample_bytree=0.6092202186084168, model__learning_rate=0.09330198957407325, model__max_depth=8, model__min_child_weight=7, model__n_estimators=447, model__subsample=0.6781489190384875\n",
      "[CV 34/37; 23/30] END model__colsample_bytree=0.9402339195076288, model__learning_rate=0.13487080962675865, model__max_depth=8, model__min_child_weight=9, model__n_estimators=745, model__subsample=0.7282672852414551;, score=0.228 total time=  16.4s\n",
      "[CV 27/37; 24/30] START model__colsample_bytree=0.6092202186084168, model__learning_rate=0.09330198957407325, model__max_depth=8, model__min_child_weight=7, model__n_estimators=447, model__subsample=0.6781489190384875\n",
      "[CV 19/37; 24/30] END model__colsample_bytree=0.6092202186084168, model__learning_rate=0.09330198957407325, model__max_depth=8, model__min_child_weight=7, model__n_estimators=447, model__subsample=0.6781489190384875;, score=-1.207 total time=   4.1s\n",
      "[CV 28/37; 24/30] START model__colsample_bytree=0.6092202186084168, model__learning_rate=0.09330198957407325, model__max_depth=8, model__min_child_weight=7, model__n_estimators=447, model__subsample=0.6781489190384875\n",
      "[CV 20/37; 24/30] END model__colsample_bytree=0.6092202186084168, model__learning_rate=0.09330198957407325, model__max_depth=8, model__min_child_weight=7, model__n_estimators=447, model__subsample=0.6781489190384875;, score=-5.375 total time=   4.3s\n",
      "[CV 29/37; 24/30] START model__colsample_bytree=0.6092202186084168, model__learning_rate=0.09330198957407325, model__max_depth=8, model__min_child_weight=7, model__n_estimators=447, model__subsample=0.6781489190384875\n",
      "[CV 21/37; 24/30] END model__colsample_bytree=0.6092202186084168, model__learning_rate=0.09330198957407325, model__max_depth=8, model__min_child_weight=7, model__n_estimators=447, model__subsample=0.6781489190384875;, score=-1.547 total time=   4.5s\n",
      "[CV 30/37; 24/30] START model__colsample_bytree=0.6092202186084168, model__learning_rate=0.09330198957407325, model__max_depth=8, model__min_child_weight=7, model__n_estimators=447, model__subsample=0.6781489190384875\n",
      "[CV 22/37; 24/30] END model__colsample_bytree=0.6092202186084168, model__learning_rate=0.09330198957407325, model__max_depth=8, model__min_child_weight=7, model__n_estimators=447, model__subsample=0.6781489190384875;, score=-0.421 total time=   4.6s\n",
      "[CV 31/37; 24/30] START model__colsample_bytree=0.6092202186084168, model__learning_rate=0.09330198957407325, model__max_depth=8, model__min_child_weight=7, model__n_estimators=447, model__subsample=0.6781489190384875\n",
      "[CV 35/37; 23/30] END model__colsample_bytree=0.9402339195076288, model__learning_rate=0.13487080962675865, model__max_depth=8, model__min_child_weight=9, model__n_estimators=745, model__subsample=0.7282672852414551;, score=-20.559 total time=  16.7s\n",
      "[CV 32/37; 24/30] START model__colsample_bytree=0.6092202186084168, model__learning_rate=0.09330198957407325, model__max_depth=8, model__min_child_weight=7, model__n_estimators=447, model__subsample=0.6781489190384875\n",
      "[CV 23/37; 24/30] END model__colsample_bytree=0.6092202186084168, model__learning_rate=0.09330198957407325, model__max_depth=8, model__min_child_weight=7, model__n_estimators=447, model__subsample=0.6781489190384875;, score=-10.173 total time=   4.9s\n",
      "[CV 33/37; 24/30] START model__colsample_bytree=0.6092202186084168, model__learning_rate=0.09330198957407325, model__max_depth=8, model__min_child_weight=7, model__n_estimators=447, model__subsample=0.6781489190384875\n",
      "[CV 36/37; 23/30] END model__colsample_bytree=0.9402339195076288, model__learning_rate=0.13487080962675865, model__max_depth=8, model__min_child_weight=9, model__n_estimators=745, model__subsample=0.7282672852414551;, score=-1.357 total time=  17.2s\n",
      "[CV 24/37; 24/30] END model__colsample_bytree=0.6092202186084168, model__learning_rate=0.09330198957407325, model__max_depth=8, model__min_child_weight=7, model__n_estimators=447, model__subsample=0.6781489190384875;, score=-5.402 total time=   5.1s\n",
      "[CV 35/37; 24/30] START model__colsample_bytree=0.6092202186084168, model__learning_rate=0.09330198957407325, model__max_depth=8, model__min_child_weight=7, model__n_estimators=447, model__subsample=0.6781489190384875\n",
      "[CV 25/37; 24/30] END model__colsample_bytree=0.6092202186084168, model__learning_rate=0.09330198957407325, model__max_depth=8, model__min_child_weight=7, model__n_estimators=447, model__subsample=0.6781489190384875;, score=-0.648 total time=   5.3s\n",
      "[CV 36/37; 24/30] START model__colsample_bytree=0.6092202186084168, model__learning_rate=0.09330198957407325, model__max_depth=8, model__min_child_weight=7, model__n_estimators=447, model__subsample=0.6781489190384875\n",
      "[CV 34/37; 24/30] START model__colsample_bytree=0.6092202186084168, model__learning_rate=0.09330198957407325, model__max_depth=8, model__min_child_weight=7, model__n_estimators=447, model__subsample=0.6781489190384875\n",
      "[CV 26/37; 24/30] END model__colsample_bytree=0.6092202186084168, model__learning_rate=0.09330198957407325, model__max_depth=8, model__min_child_weight=7, model__n_estimators=447, model__subsample=0.6781489190384875;, score=-1.749 total time=   5.5s\n",
      "[CV 37/37; 24/30] START model__colsample_bytree=0.6092202186084168, model__learning_rate=0.09330198957407325, model__max_depth=8, model__min_child_weight=7, model__n_estimators=447, model__subsample=0.6781489190384875\n",
      "[CV 37/37; 23/30] END model__colsample_bytree=0.9402339195076288, model__learning_rate=0.13487080962675865, model__max_depth=8, model__min_child_weight=9, model__n_estimators=745, model__subsample=0.7282672852414551;, score=-0.589 total time=  18.5s\n",
      "[CV 1/37; 25/30] START model__colsample_bytree=0.9534142207728771, model__learning_rate=0.06442644987692707, model__max_depth=5, model__min_child_weight=9, model__n_estimators=727, model__subsample=0.6762844281670846\n",
      "[CV 27/37; 24/30] END model__colsample_bytree=0.6092202186084168, model__learning_rate=0.09330198957407325, model__max_depth=8, model__min_child_weight=7, model__n_estimators=447, model__subsample=0.6781489190384875;, score=-3.376 total time=   5.7s\n",
      "[CV 2/37; 25/30] START model__colsample_bytree=0.9534142207728771, model__learning_rate=0.06442644987692707, model__max_depth=5, model__min_child_weight=9, model__n_estimators=727, model__subsample=0.6762844281670846\n",
      "[CV 28/37; 24/30] END model__colsample_bytree=0.6092202186084168, model__learning_rate=0.09330198957407325, model__max_depth=8, model__min_child_weight=7, model__n_estimators=447, model__subsample=0.6781489190384875;, score=-1.370 total time=   5.8s\n",
      "[CV 3/37; 25/30] START model__colsample_bytree=0.9534142207728771, model__learning_rate=0.06442644987692707, model__max_depth=5, model__min_child_weight=9, model__n_estimators=727, model__subsample=0.6762844281670846\n",
      "[CV 1/37; 25/30] END model__colsample_bytree=0.9534142207728771, model__learning_rate=0.06442644987692707, model__max_depth=5, model__min_child_weight=9, model__n_estimators=727, model__subsample=0.6762844281670846;, score=-43.382 total time=   0.5s\n",
      "[CV 4/37; 25/30] START model__colsample_bytree=0.9534142207728771, model__learning_rate=0.06442644987692707, model__max_depth=5, model__min_child_weight=9, model__n_estimators=727, model__subsample=0.6762844281670846\n",
      "[CV 2/37; 25/30] END model__colsample_bytree=0.9534142207728771, model__learning_rate=0.06442644987692707, model__max_depth=5, model__min_child_weight=9, model__n_estimators=727, model__subsample=0.6762844281670846;, score=-0.309 total time=   0.8s\n",
      "[CV 5/37; 25/30] START model__colsample_bytree=0.9534142207728771, model__learning_rate=0.06442644987692707, model__max_depth=5, model__min_child_weight=9, model__n_estimators=727, model__subsample=0.6762844281670846\n",
      "[CV 29/37; 24/30] END model__colsample_bytree=0.6092202186084168, model__learning_rate=0.09330198957407325, model__max_depth=8, model__min_child_weight=7, model__n_estimators=447, model__subsample=0.6781489190384875;, score=-9.921 total time=   6.1s\n",
      "[CV 6/37; 25/30] START model__colsample_bytree=0.9534142207728771, model__learning_rate=0.06442644987692707, model__max_depth=5, model__min_child_weight=9, model__n_estimators=727, model__subsample=0.6762844281670846\n",
      "[CV 3/37; 25/30] END model__colsample_bytree=0.9534142207728771, model__learning_rate=0.06442644987692707, model__max_depth=5, model__min_child_weight=9, model__n_estimators=727, model__subsample=0.6762844281670846;, score=-27.657 total time=   1.1s\n",
      "[CV 7/37; 25/30] START model__colsample_bytree=0.9534142207728771, model__learning_rate=0.06442644987692707, model__max_depth=5, model__min_child_weight=9, model__n_estimators=727, model__subsample=0.6762844281670846\n",
      "[CV 30/37; 24/30] END model__colsample_bytree=0.6092202186084168, model__learning_rate=0.09330198957407325, model__max_depth=8, model__min_child_weight=7, model__n_estimators=447, model__subsample=0.6781489190384875;, score=-0.161 total time=   6.2s\n",
      "[CV 8/37; 25/30] START model__colsample_bytree=0.9534142207728771, model__learning_rate=0.06442644987692707, model__max_depth=5, model__min_child_weight=9, model__n_estimators=727, model__subsample=0.6762844281670846\n",
      "[CV 4/37; 25/30] END model__colsample_bytree=0.9534142207728771, model__learning_rate=0.06442644987692707, model__max_depth=5, model__min_child_weight=9, model__n_estimators=727, model__subsample=0.6762844281670846;, score=-7.269 total time=   1.5s\n",
      "[CV 9/37; 25/30] START model__colsample_bytree=0.9534142207728771, model__learning_rate=0.06442644987692707, model__max_depth=5, model__min_child_weight=9, model__n_estimators=727, model__subsample=0.6762844281670846\n",
      "[CV 5/37; 25/30] END model__colsample_bytree=0.9534142207728771, model__learning_rate=0.06442644987692707, model__max_depth=5, model__min_child_weight=9, model__n_estimators=727, model__subsample=0.6762844281670846;, score=-38.265 total time=   1.8s\n",
      "[CV 10/37; 25/30] START model__colsample_bytree=0.9534142207728771, model__learning_rate=0.06442644987692707, model__max_depth=5, model__min_child_weight=9, model__n_estimators=727, model__subsample=0.6762844281670846\n",
      "[CV 31/37; 24/30] END model__colsample_bytree=0.6092202186084168, model__learning_rate=0.09330198957407325, model__max_depth=8, model__min_child_weight=7, model__n_estimators=447, model__subsample=0.6781489190384875;, score=-0.134 total time=   6.5s\n",
      "[CV 11/37; 25/30] START model__colsample_bytree=0.9534142207728771, model__learning_rate=0.06442644987692707, model__max_depth=5, model__min_child_weight=9, model__n_estimators=727, model__subsample=0.6762844281670846\n",
      "[CV 32/37; 24/30] END model__colsample_bytree=0.6092202186084168, model__learning_rate=0.09330198957407325, model__max_depth=8, model__min_child_weight=7, model__n_estimators=447, model__subsample=0.6781489190384875;, score=-3.589 total time=   6.7s\n",
      "[CV 12/37; 25/30] START model__colsample_bytree=0.9534142207728771, model__learning_rate=0.06442644987692707, model__max_depth=5, model__min_child_weight=9, model__n_estimators=727, model__subsample=0.6762844281670846\n",
      "[CV 6/37; 25/30] END model__colsample_bytree=0.9534142207728771, model__learning_rate=0.06442644987692707, model__max_depth=5, model__min_child_weight=9, model__n_estimators=727, model__subsample=0.6762844281670846;, score=-1.941 total time=   2.1s\n",
      "[CV 13/37; 25/30] START model__colsample_bytree=0.9534142207728771, model__learning_rate=0.06442644987692707, model__max_depth=5, model__min_child_weight=9, model__n_estimators=727, model__subsample=0.6762844281670846\n",
      "[CV 7/37; 25/30] END model__colsample_bytree=0.9534142207728771, model__learning_rate=0.06442644987692707, model__max_depth=5, model__min_child_weight=9, model__n_estimators=727, model__subsample=0.6762844281670846;, score=-6.853 total time=   2.4s\n",
      "[CV 14/37; 25/30] START model__colsample_bytree=0.9534142207728771, model__learning_rate=0.06442644987692707, model__max_depth=5, model__min_child_weight=9, model__n_estimators=727, model__subsample=0.6762844281670846\n",
      "[CV 33/37; 24/30] END model__colsample_bytree=0.6092202186084168, model__learning_rate=0.09330198957407325, model__max_depth=8, model__min_child_weight=7, model__n_estimators=447, model__subsample=0.6781489190384875;, score=-18.820 total time=   7.0s\n",
      "[CV 8/37; 25/30] END model__colsample_bytree=0.9534142207728771, model__learning_rate=0.06442644987692707, model__max_depth=5, model__min_child_weight=9, model__n_estimators=727, model__subsample=0.6762844281670846;, score=-10.405 total time=   2.7s\n",
      "[CV 15/37; 25/30] START model__colsample_bytree=0.9534142207728771, model__learning_rate=0.06442644987692707, model__max_depth=5, model__min_child_weight=9, model__n_estimators=727, model__subsample=0.6762844281670846\n",
      "[CV 16/37; 25/30] START model__colsample_bytree=0.9534142207728771, model__learning_rate=0.06442644987692707, model__max_depth=5, model__min_child_weight=9, model__n_estimators=727, model__subsample=0.6762844281670846\n",
      "[CV 9/37; 25/30] END model__colsample_bytree=0.9534142207728771, model__learning_rate=0.06442644987692707, model__max_depth=5, model__min_child_weight=9, model__n_estimators=727, model__subsample=0.6762844281670846;, score=-0.536 total time=   3.0s\n",
      "[CV 17/37; 25/30] START model__colsample_bytree=0.9534142207728771, model__learning_rate=0.06442644987692707, model__max_depth=5, model__min_child_weight=9, model__n_estimators=727, model__subsample=0.6762844281670846\n",
      "[CV 35/37; 24/30] END model__colsample_bytree=0.6092202186084168, model__learning_rate=0.09330198957407325, model__max_depth=8, model__min_child_weight=7, model__n_estimators=447, model__subsample=0.6781489190384875;, score=-19.906 total time=   7.4s\n",
      "[CV 18/37; 25/30] START model__colsample_bytree=0.9534142207728771, model__learning_rate=0.06442644987692707, model__max_depth=5, model__min_child_weight=9, model__n_estimators=727, model__subsample=0.6762844281670846\n",
      "[CV 34/37; 24/30] END model__colsample_bytree=0.6092202186084168, model__learning_rate=0.09330198957407325, model__max_depth=8, model__min_child_weight=7, model__n_estimators=447, model__subsample=0.6781489190384875;, score=0.162 total time=   7.2s\n",
      "[CV 19/37; 25/30] START model__colsample_bytree=0.9534142207728771, model__learning_rate=0.06442644987692707, model__max_depth=5, model__min_child_weight=9, model__n_estimators=727, model__subsample=0.6762844281670846\n",
      "[CV 36/37; 24/30] END model__colsample_bytree=0.6092202186084168, model__learning_rate=0.09330198957407325, model__max_depth=8, model__min_child_weight=7, model__n_estimators=447, model__subsample=0.6781489190384875;, score=-1.340 total time=   7.6s\n",
      "[CV 20/37; 25/30] START model__colsample_bytree=0.9534142207728771, model__learning_rate=0.06442644987692707, model__max_depth=5, model__min_child_weight=9, model__n_estimators=727, model__subsample=0.6762844281670846\n",
      "[CV 10/37; 25/30] END model__colsample_bytree=0.9534142207728771, model__learning_rate=0.06442644987692707, model__max_depth=5, model__min_child_weight=9, model__n_estimators=727, model__subsample=0.6762844281670846;, score=-31.699 total time=   3.3s\n",
      "[CV 21/37; 25/30] START model__colsample_bytree=0.9534142207728771, model__learning_rate=0.06442644987692707, model__max_depth=5, model__min_child_weight=9, model__n_estimators=727, model__subsample=0.6762844281670846\n",
      "[CV 11/37; 25/30] END model__colsample_bytree=0.9534142207728771, model__learning_rate=0.06442644987692707, model__max_depth=5, model__min_child_weight=9, model__n_estimators=727, model__subsample=0.6762844281670846;, score=-3.725 total time=   3.6s\n",
      "[CV 22/37; 25/30] START model__colsample_bytree=0.9534142207728771, model__learning_rate=0.06442644987692707, model__max_depth=5, model__min_child_weight=9, model__n_estimators=727, model__subsample=0.6762844281670846\n",
      "[CV 37/37; 24/30] END model__colsample_bytree=0.6092202186084168, model__learning_rate=0.09330198957407325, model__max_depth=8, model__min_child_weight=7, model__n_estimators=447, model__subsample=0.6781489190384875;, score=-0.180 total time=   8.1s\n",
      "[CV 23/37; 25/30] START model__colsample_bytree=0.9534142207728771, model__learning_rate=0.06442644987692707, model__max_depth=5, model__min_child_weight=9, model__n_estimators=727, model__subsample=0.6762844281670846\n",
      "[CV 12/37; 25/30] END model__colsample_bytree=0.9534142207728771, model__learning_rate=0.06442644987692707, model__max_depth=5, model__min_child_weight=9, model__n_estimators=727, model__subsample=0.6762844281670846;, score=-19.524 total time=   4.0s\n",
      "[CV 24/37; 25/30] START model__colsample_bytree=0.9534142207728771, model__learning_rate=0.06442644987692707, model__max_depth=5, model__min_child_weight=9, model__n_estimators=727, model__subsample=0.6762844281670846\n",
      "[CV 13/37; 25/30] END model__colsample_bytree=0.9534142207728771, model__learning_rate=0.06442644987692707, model__max_depth=5, model__min_child_weight=9, model__n_estimators=727, model__subsample=0.6762844281670846;, score=0.068 total time=   4.3s\n",
      "[CV 25/37; 25/30] START model__colsample_bytree=0.9534142207728771, model__learning_rate=0.06442644987692707, model__max_depth=5, model__min_child_weight=9, model__n_estimators=727, model__subsample=0.6762844281670846\n",
      "[CV 14/37; 25/30] END model__colsample_bytree=0.9534142207728771, model__learning_rate=0.06442644987692707, model__max_depth=5, model__min_child_weight=9, model__n_estimators=727, model__subsample=0.6762844281670846;, score=-24.791 total time=   4.5s\n",
      "[CV 26/37; 25/30] START model__colsample_bytree=0.9534142207728771, model__learning_rate=0.06442644987692707, model__max_depth=5, model__min_child_weight=9, model__n_estimators=727, model__subsample=0.6762844281670846\n",
      "[CV 15/37; 25/30] END model__colsample_bytree=0.9534142207728771, model__learning_rate=0.06442644987692707, model__max_depth=5, model__min_child_weight=9, model__n_estimators=727, model__subsample=0.6762844281670846;, score=-0.153 total time=   4.9s\n",
      "[CV 27/37; 25/30] START model__colsample_bytree=0.9534142207728771, model__learning_rate=0.06442644987692707, model__max_depth=5, model__min_child_weight=9, model__n_estimators=727, model__subsample=0.6762844281670846\n",
      "[CV 16/37; 25/30] END model__colsample_bytree=0.9534142207728771, model__learning_rate=0.06442644987692707, model__max_depth=5, model__min_child_weight=9, model__n_estimators=727, model__subsample=0.6762844281670846;, score=-0.867 total time=   5.1s\n",
      "[CV 28/37; 25/30] START model__colsample_bytree=0.9534142207728771, model__learning_rate=0.06442644987692707, model__max_depth=5, model__min_child_weight=9, model__n_estimators=727, model__subsample=0.6762844281670846\n",
      "[CV 17/37; 25/30] END model__colsample_bytree=0.9534142207728771, model__learning_rate=0.06442644987692707, model__max_depth=5, model__min_child_weight=9, model__n_estimators=727, model__subsample=0.6762844281670846;, score=-18.678 total time=   5.3s\n",
      "[CV 29/37; 25/30] START model__colsample_bytree=0.9534142207728771, model__learning_rate=0.06442644987692707, model__max_depth=5, model__min_child_weight=9, model__n_estimators=727, model__subsample=0.6762844281670846\n",
      "[CV 18/37; 25/30] END model__colsample_bytree=0.9534142207728771, model__learning_rate=0.06442644987692707, model__max_depth=5, model__min_child_weight=9, model__n_estimators=727, model__subsample=0.6762844281670846;, score=-0.609 total time=   5.8s\n",
      "[CV 30/37; 25/30] START model__colsample_bytree=0.9534142207728771, model__learning_rate=0.06442644987692707, model__max_depth=5, model__min_child_weight=9, model__n_estimators=727, model__subsample=0.6762844281670846\n",
      "[CV 19/37; 25/30] END model__colsample_bytree=0.9534142207728771, model__learning_rate=0.06442644987692707, model__max_depth=5, model__min_child_weight=9, model__n_estimators=727, model__subsample=0.6762844281670846;, score=-0.979 total time=   6.1s\n",
      "[CV 31/37; 25/30] START model__colsample_bytree=0.9534142207728771, model__learning_rate=0.06442644987692707, model__max_depth=5, model__min_child_weight=9, model__n_estimators=727, model__subsample=0.6762844281670846\n",
      "[CV 20/37; 25/30] END model__colsample_bytree=0.9534142207728771, model__learning_rate=0.06442644987692707, model__max_depth=5, model__min_child_weight=9, model__n_estimators=727, model__subsample=0.6762844281670846;, score=-4.213 total time=   6.4s\n",
      "[CV 32/37; 25/30] START model__colsample_bytree=0.9534142207728771, model__learning_rate=0.06442644987692707, model__max_depth=5, model__min_child_weight=9, model__n_estimators=727, model__subsample=0.6762844281670846\n",
      "[CV 21/37; 25/30] END model__colsample_bytree=0.9534142207728771, model__learning_rate=0.06442644987692707, model__max_depth=5, model__min_child_weight=9, model__n_estimators=727, model__subsample=0.6762844281670846;, score=-1.611 total time=   6.6s\n",
      "[CV 33/37; 25/30] START model__colsample_bytree=0.9534142207728771, model__learning_rate=0.06442644987692707, model__max_depth=5, model__min_child_weight=9, model__n_estimators=727, model__subsample=0.6762844281670846\n",
      "[CV 22/37; 25/30] END model__colsample_bytree=0.9534142207728771, model__learning_rate=0.06442644987692707, model__max_depth=5, model__min_child_weight=9, model__n_estimators=727, model__subsample=0.6762844281670846;, score=-0.493 total time=   6.9s\n",
      "[CV 34/37; 25/30] START model__colsample_bytree=0.9534142207728771, model__learning_rate=0.06442644987692707, model__max_depth=5, model__min_child_weight=9, model__n_estimators=727, model__subsample=0.6762844281670846\n",
      "[CV 23/37; 25/30] END model__colsample_bytree=0.9534142207728771, model__learning_rate=0.06442644987692707, model__max_depth=5, model__min_child_weight=9, model__n_estimators=727, model__subsample=0.6762844281670846;, score=-11.116 total time=   7.1s\n",
      "[CV 24/37; 25/30] END model__colsample_bytree=0.9534142207728771, model__learning_rate=0.06442644987692707, model__max_depth=5, model__min_child_weight=9, model__n_estimators=727, model__subsample=0.6762844281670846;, score=-7.350 total time=   7.5s\n",
      "[CV 36/37; 25/30] START model__colsample_bytree=0.9534142207728771, model__learning_rate=0.06442644987692707, model__max_depth=5, model__min_child_weight=9, model__n_estimators=727, model__subsample=0.6762844281670846\n",
      "[CV 35/37; 25/30] START model__colsample_bytree=0.9534142207728771, model__learning_rate=0.06442644987692707, model__max_depth=5, model__min_child_weight=9, model__n_estimators=727, model__subsample=0.6762844281670846\n",
      "[CV 25/37; 25/30] END model__colsample_bytree=0.9534142207728771, model__learning_rate=0.06442644987692707, model__max_depth=5, model__min_child_weight=9, model__n_estimators=727, model__subsample=0.6762844281670846;, score=-1.085 total time=   7.7s\n",
      "[CV 37/37; 25/30] START model__colsample_bytree=0.9534142207728771, model__learning_rate=0.06442644987692707, model__max_depth=5, model__min_child_weight=9, model__n_estimators=727, model__subsample=0.6762844281670846\n",
      "[CV 26/37; 25/30] END model__colsample_bytree=0.9534142207728771, model__learning_rate=0.06442644987692707, model__max_depth=5, model__min_child_weight=9, model__n_estimators=727, model__subsample=0.6762844281670846;, score=-2.215 total time=   8.2s\n",
      "[CV 1/37; 26/30] START model__colsample_bytree=0.6523906290790145, model__learning_rate=0.04293117062858835, model__max_depth=5, model__min_child_weight=9, model__n_estimators=417, model__subsample=0.6110539052353652\n",
      "[CV 1/37; 26/30] END model__colsample_bytree=0.6523906290790145, model__learning_rate=0.04293117062858835, model__max_depth=5, model__min_child_weight=9, model__n_estimators=417, model__subsample=0.6110539052353652;, score=-40.641 total time=   0.3s\n",
      "[CV 2/37; 26/30] START model__colsample_bytree=0.6523906290790145, model__learning_rate=0.04293117062858835, model__max_depth=5, model__min_child_weight=9, model__n_estimators=417, model__subsample=0.6110539052353652\n",
      "[CV 2/37; 26/30] END model__colsample_bytree=0.6523906290790145, model__learning_rate=0.04293117062858835, model__max_depth=5, model__min_child_weight=9, model__n_estimators=417, model__subsample=0.6110539052353652;, score=-0.379 total time=   0.4s\n",
      "[CV 3/37; 26/30] START model__colsample_bytree=0.6523906290790145, model__learning_rate=0.04293117062858835, model__max_depth=5, model__min_child_weight=9, model__n_estimators=417, model__subsample=0.6110539052353652\n",
      "[CV 27/37; 25/30] END model__colsample_bytree=0.9534142207728771, model__learning_rate=0.06442644987692707, model__max_depth=5, model__min_child_weight=9, model__n_estimators=727, model__subsample=0.6762844281670846;, score=-3.020 total time=   8.4s\n",
      "[CV 4/37; 26/30] START model__colsample_bytree=0.6523906290790145, model__learning_rate=0.04293117062858835, model__max_depth=5, model__min_child_weight=9, model__n_estimators=417, model__subsample=0.6110539052353652\n",
      "[CV 3/37; 26/30] END model__colsample_bytree=0.6523906290790145, model__learning_rate=0.04293117062858835, model__max_depth=5, model__min_child_weight=9, model__n_estimators=417, model__subsample=0.6110539052353652;, score=-18.278 total time=   0.5s\n",
      "[CV 5/37; 26/30] START model__colsample_bytree=0.6523906290790145, model__learning_rate=0.04293117062858835, model__max_depth=5, model__min_child_weight=9, model__n_estimators=417, model__subsample=0.6110539052353652\n",
      "[CV 28/37; 25/30] END model__colsample_bytree=0.9534142207728771, model__learning_rate=0.06442644987692707, model__max_depth=5, model__min_child_weight=9, model__n_estimators=727, model__subsample=0.6762844281670846;, score=-1.418 total time=   8.6s\n",
      "[CV 6/37; 26/30] START model__colsample_bytree=0.6523906290790145, model__learning_rate=0.04293117062858835, model__max_depth=5, model__min_child_weight=9, model__n_estimators=417, model__subsample=0.6110539052353652\n",
      "[CV 4/37; 26/30] END model__colsample_bytree=0.6523906290790145, model__learning_rate=0.04293117062858835, model__max_depth=5, model__min_child_weight=9, model__n_estimators=417, model__subsample=0.6110539052353652;, score=-7.336 total time=   0.6s\n",
      "[CV 7/37; 26/30] START model__colsample_bytree=0.6523906290790145, model__learning_rate=0.04293117062858835, model__max_depth=5, model__min_child_weight=9, model__n_estimators=417, model__subsample=0.6110539052353652\n",
      "[CV 5/37; 26/30] END model__colsample_bytree=0.6523906290790145, model__learning_rate=0.04293117062858835, model__max_depth=5, model__min_child_weight=9, model__n_estimators=417, model__subsample=0.6110539052353652;, score=-37.541 total time=   0.7s\n",
      "[CV 8/37; 26/30] START model__colsample_bytree=0.6523906290790145, model__learning_rate=0.04293117062858835, model__max_depth=5, model__min_child_weight=9, model__n_estimators=417, model__subsample=0.6110539052353652\n",
      "[CV 6/37; 26/30] END model__colsample_bytree=0.6523906290790145, model__learning_rate=0.04293117062858835, model__max_depth=5, model__min_child_weight=9, model__n_estimators=417, model__subsample=0.6110539052353652;, score=-1.722 total time=   0.8s\n",
      "[CV 9/37; 26/30] START model__colsample_bytree=0.6523906290790145, model__learning_rate=0.04293117062858835, model__max_depth=5, model__min_child_weight=9, model__n_estimators=417, model__subsample=0.6110539052353652\n",
      "[CV 7/37; 26/30] END model__colsample_bytree=0.6523906290790145, model__learning_rate=0.04293117062858835, model__max_depth=5, model__min_child_weight=9, model__n_estimators=417, model__subsample=0.6110539052353652;, score=-5.818 total time=   1.0s\n",
      "[CV 10/37; 26/30] START model__colsample_bytree=0.6523906290790145, model__learning_rate=0.04293117062858835, model__max_depth=5, model__min_child_weight=9, model__n_estimators=417, model__subsample=0.6110539052353652\n",
      "[CV 29/37; 25/30] END model__colsample_bytree=0.9534142207728771, model__learning_rate=0.06442644987692707, model__max_depth=5, model__min_child_weight=9, model__n_estimators=727, model__subsample=0.6762844281670846;, score=-9.513 total time=   9.1s\n",
      "[CV 11/37; 26/30] START model__colsample_bytree=0.6523906290790145, model__learning_rate=0.04293117062858835, model__max_depth=5, model__min_child_weight=9, model__n_estimators=417, model__subsample=0.6110539052353652\n",
      "[CV 8/37; 26/30] END model__colsample_bytree=0.6523906290790145, model__learning_rate=0.04293117062858835, model__max_depth=5, model__min_child_weight=9, model__n_estimators=417, model__subsample=0.6110539052353652;, score=-9.233 total time=   1.0s\n",
      "[CV 12/37; 26/30] START model__colsample_bytree=0.6523906290790145, model__learning_rate=0.04293117062858835, model__max_depth=5, model__min_child_weight=9, model__n_estimators=417, model__subsample=0.6110539052353652\n",
      "[CV 9/37; 26/30] END model__colsample_bytree=0.6523906290790145, model__learning_rate=0.04293117062858835, model__max_depth=5, model__min_child_weight=9, model__n_estimators=417, model__subsample=0.6110539052353652;, score=-0.835 total time=   1.2s\n",
      "[CV 13/37; 26/30] START model__colsample_bytree=0.6523906290790145, model__learning_rate=0.04293117062858835, model__max_depth=5, model__min_child_weight=9, model__n_estimators=417, model__subsample=0.6110539052353652\n",
      "[CV 30/37; 25/30] END model__colsample_bytree=0.9534142207728771, model__learning_rate=0.06442644987692707, model__max_depth=5, model__min_child_weight=9, model__n_estimators=727, model__subsample=0.6762844281670846;, score=-0.231 total time=   9.1s\n",
      "[CV 14/37; 26/30] START model__colsample_bytree=0.6523906290790145, model__learning_rate=0.04293117062858835, model__max_depth=5, model__min_child_weight=9, model__n_estimators=417, model__subsample=0.6110539052353652\n",
      "[CV 10/37; 26/30] END model__colsample_bytree=0.6523906290790145, model__learning_rate=0.04293117062858835, model__max_depth=5, model__min_child_weight=9, model__n_estimators=417, model__subsample=0.6110539052353652;, score=-25.432 total time=   1.3s\n",
      "[CV 15/37; 26/30] START model__colsample_bytree=0.6523906290790145, model__learning_rate=0.04293117062858835, model__max_depth=5, model__min_child_weight=9, model__n_estimators=417, model__subsample=0.6110539052353652\n",
      "[CV 11/37; 26/30] END model__colsample_bytree=0.6523906290790145, model__learning_rate=0.04293117062858835, model__max_depth=5, model__min_child_weight=9, model__n_estimators=417, model__subsample=0.6110539052353652;, score=-3.188 total time=   1.4s\n",
      "[CV 16/37; 26/30] START model__colsample_bytree=0.6523906290790145, model__learning_rate=0.04293117062858835, model__max_depth=5, model__min_child_weight=9, model__n_estimators=417, model__subsample=0.6110539052353652\n",
      "[CV 31/37; 25/30] END model__colsample_bytree=0.9534142207728771, model__learning_rate=0.06442644987692707, model__max_depth=5, model__min_child_weight=9, model__n_estimators=727, model__subsample=0.6762844281670846;, score=-0.042 total time=   9.5s\n",
      "[CV 17/37; 26/30] START model__colsample_bytree=0.6523906290790145, model__learning_rate=0.04293117062858835, model__max_depth=5, model__min_child_weight=9, model__n_estimators=417, model__subsample=0.6110539052353652\n",
      "[CV 12/37; 26/30] END model__colsample_bytree=0.6523906290790145, model__learning_rate=0.04293117062858835, model__max_depth=5, model__min_child_weight=9, model__n_estimators=417, model__subsample=0.6110539052353652;, score=-17.035 total time=   1.5s\n",
      "[CV 18/37; 26/30] START model__colsample_bytree=0.6523906290790145, model__learning_rate=0.04293117062858835, model__max_depth=5, model__min_child_weight=9, model__n_estimators=417, model__subsample=0.6110539052353652\n",
      "[CV 13/37; 26/30] END model__colsample_bytree=0.6523906290790145, model__learning_rate=0.04293117062858835, model__max_depth=5, model__min_child_weight=9, model__n_estimators=417, model__subsample=0.6110539052353652;, score=0.157 total time=   1.6s\n",
      "[CV 19/37; 26/30] START model__colsample_bytree=0.6523906290790145, model__learning_rate=0.04293117062858835, model__max_depth=5, model__min_child_weight=9, model__n_estimators=417, model__subsample=0.6110539052353652\n",
      "[CV 14/37; 26/30] END model__colsample_bytree=0.6523906290790145, model__learning_rate=0.04293117062858835, model__max_depth=5, model__min_child_weight=9, model__n_estimators=417, model__subsample=0.6110539052353652;, score=-21.823 total time=   1.7s\n",
      "[CV 20/37; 26/30] START model__colsample_bytree=0.6523906290790145, model__learning_rate=0.04293117062858835, model__max_depth=5, model__min_child_weight=9, model__n_estimators=417, model__subsample=0.6110539052353652\n",
      "[CV 32/37; 25/30] END model__colsample_bytree=0.9534142207728771, model__learning_rate=0.06442644987692707, model__max_depth=5, model__min_child_weight=9, model__n_estimators=727, model__subsample=0.6762844281670846;, score=-3.729 total time=   9.7s\n",
      "[CV 21/37; 26/30] START model__colsample_bytree=0.6523906290790145, model__learning_rate=0.04293117062858835, model__max_depth=5, model__min_child_weight=9, model__n_estimators=417, model__subsample=0.6110539052353652\n",
      "[CV 15/37; 26/30] END model__colsample_bytree=0.6523906290790145, model__learning_rate=0.04293117062858835, model__max_depth=5, model__min_child_weight=9, model__n_estimators=417, model__subsample=0.6110539052353652;, score=-0.029 total time=   1.9s\n",
      "[CV 22/37; 26/30] START model__colsample_bytree=0.6523906290790145, model__learning_rate=0.04293117062858835, model__max_depth=5, model__min_child_weight=9, model__n_estimators=417, model__subsample=0.6110539052353652\n",
      "[CV 33/37; 25/30] END model__colsample_bytree=0.9534142207728771, model__learning_rate=0.06442644987692707, model__max_depth=5, model__min_child_weight=9, model__n_estimators=727, model__subsample=0.6762844281670846;, score=-19.627 total time=  10.1s\n",
      "[CV 16/37; 26/30] END model__colsample_bytree=0.6523906290790145, model__learning_rate=0.04293117062858835, model__max_depth=5, model__min_child_weight=9, model__n_estimators=417, model__subsample=0.6110539052353652;, score=-0.628 total time=   1.9s\n",
      "[CV 23/37; 26/30] START model__colsample_bytree=0.6523906290790145, model__learning_rate=0.04293117062858835, model__max_depth=5, model__min_child_weight=9, model__n_estimators=417, model__subsample=0.6110539052353652\n",
      "[CV 24/37; 26/30] START model__colsample_bytree=0.6523906290790145, model__learning_rate=0.04293117062858835, model__max_depth=5, model__min_child_weight=9, model__n_estimators=417, model__subsample=0.6110539052353652\n",
      "[CV 17/37; 26/30] END model__colsample_bytree=0.6523906290790145, model__learning_rate=0.04293117062858835, model__max_depth=5, model__min_child_weight=9, model__n_estimators=417, model__subsample=0.6110539052353652;, score=-18.243 total time=   2.1s\n",
      "[CV 25/37; 26/30] START model__colsample_bytree=0.6523906290790145, model__learning_rate=0.04293117062858835, model__max_depth=5, model__min_child_weight=9, model__n_estimators=417, model__subsample=0.6110539052353652\n",
      "[CV 18/37; 26/30] END model__colsample_bytree=0.6523906290790145, model__learning_rate=0.04293117062858835, model__max_depth=5, model__min_child_weight=9, model__n_estimators=417, model__subsample=0.6110539052353652;, score=-0.240 total time=   2.2s\n",
      "[CV 26/37; 26/30] START model__colsample_bytree=0.6523906290790145, model__learning_rate=0.04293117062858835, model__max_depth=5, model__min_child_weight=9, model__n_estimators=417, model__subsample=0.6110539052353652\n",
      "[CV 34/37; 25/30] END model__colsample_bytree=0.9534142207728771, model__learning_rate=0.06442644987692707, model__max_depth=5, model__min_child_weight=9, model__n_estimators=727, model__subsample=0.6762844281670846;, score=0.254 total time=  10.3s\n",
      "[CV 27/37; 26/30] START model__colsample_bytree=0.6523906290790145, model__learning_rate=0.04293117062858835, model__max_depth=5, model__min_child_weight=9, model__n_estimators=417, model__subsample=0.6110539052353652\n",
      "[CV 19/37; 26/30] END model__colsample_bytree=0.6523906290790145, model__learning_rate=0.04293117062858835, model__max_depth=5, model__min_child_weight=9, model__n_estimators=417, model__subsample=0.6110539052353652;, score=-0.728 total time=   2.3s\n",
      "[CV 28/37; 26/30] START model__colsample_bytree=0.6523906290790145, model__learning_rate=0.04293117062858835, model__max_depth=5, model__min_child_weight=9, model__n_estimators=417, model__subsample=0.6110539052353652\n",
      "[CV 20/37; 26/30] END model__colsample_bytree=0.6523906290790145, model__learning_rate=0.04293117062858835, model__max_depth=5, model__min_child_weight=9, model__n_estimators=417, model__subsample=0.6110539052353652;, score=-4.330 total time=   2.4s\n",
      "[CV 29/37; 26/30] START model__colsample_bytree=0.6523906290790145, model__learning_rate=0.04293117062858835, model__max_depth=5, model__min_child_weight=9, model__n_estimators=417, model__subsample=0.6110539052353652\n",
      "[CV 21/37; 26/30] END model__colsample_bytree=0.6523906290790145, model__learning_rate=0.04293117062858835, model__max_depth=5, model__min_child_weight=9, model__n_estimators=417, model__subsample=0.6110539052353652;, score=-1.080 total time=   2.5s\n",
      "[CV 30/37; 26/30] START model__colsample_bytree=0.6523906290790145, model__learning_rate=0.04293117062858835, model__max_depth=5, model__min_child_weight=9, model__n_estimators=417, model__subsample=0.6110539052353652\n",
      "[CV 22/37; 26/30] END model__colsample_bytree=0.6523906290790145, model__learning_rate=0.04293117062858835, model__max_depth=5, model__min_child_weight=9, model__n_estimators=417, model__subsample=0.6110539052353652;, score=-0.365 total time=   2.6s\n",
      "[CV 31/37; 26/30] START model__colsample_bytree=0.6523906290790145, model__learning_rate=0.04293117062858835, model__max_depth=5, model__min_child_weight=9, model__n_estimators=417, model__subsample=0.6110539052353652\n",
      "[CV 23/37; 26/30] END model__colsample_bytree=0.6523906290790145, model__learning_rate=0.04293117062858835, model__max_depth=5, model__min_child_weight=9, model__n_estimators=417, model__subsample=0.6110539052353652;, score=-11.301 total time=   2.6s\n",
      "[CV 32/37; 26/30] START model__colsample_bytree=0.6523906290790145, model__learning_rate=0.04293117062858835, model__max_depth=5, model__min_child_weight=9, model__n_estimators=417, model__subsample=0.6110539052353652\n",
      "[CV 36/37; 25/30] END model__colsample_bytree=0.9534142207728771, model__learning_rate=0.06442644987692707, model__max_depth=5, model__min_child_weight=9, model__n_estimators=727, model__subsample=0.6762844281670846;, score=-1.599 total time=  10.8s\n",
      "[CV 33/37; 26/30] START model__colsample_bytree=0.6523906290790145, model__learning_rate=0.04293117062858835, model__max_depth=5, model__min_child_weight=9, model__n_estimators=417, model__subsample=0.6110539052353652\n",
      "[CV 24/37; 26/30] END model__colsample_bytree=0.6523906290790145, model__learning_rate=0.04293117062858835, model__max_depth=5, model__min_child_weight=9, model__n_estimators=417, model__subsample=0.6110539052353652;, score=-5.731 total time=   2.8s\n",
      "[CV 34/37; 26/30] START model__colsample_bytree=0.6523906290790145, model__learning_rate=0.04293117062858835, model__max_depth=5, model__min_child_weight=9, model__n_estimators=417, model__subsample=0.6110539052353652\n",
      "[CV 35/37; 25/30] END model__colsample_bytree=0.9534142207728771, model__learning_rate=0.06442644987692707, model__max_depth=5, model__min_child_weight=9, model__n_estimators=727, model__subsample=0.6762844281670846;, score=-20.655 total time=  10.6s\n",
      "[CV 35/37; 26/30] START model__colsample_bytree=0.6523906290790145, model__learning_rate=0.04293117062858835, model__max_depth=5, model__min_child_weight=9, model__n_estimators=417, model__subsample=0.6110539052353652\n",
      "[CV 25/37; 26/30] END model__colsample_bytree=0.6523906290790145, model__learning_rate=0.04293117062858835, model__max_depth=5, model__min_child_weight=9, model__n_estimators=417, model__subsample=0.6110539052353652;, score=-0.817 total time=   2.9s\n",
      "[CV 36/37; 26/30] START model__colsample_bytree=0.6523906290790145, model__learning_rate=0.04293117062858835, model__max_depth=5, model__min_child_weight=9, model__n_estimators=417, model__subsample=0.6110539052353652\n",
      "[CV 37/37; 25/30] END model__colsample_bytree=0.9534142207728771, model__learning_rate=0.06442644987692707, model__max_depth=5, model__min_child_weight=9, model__n_estimators=727, model__subsample=0.6762844281670846;, score=-0.332 total time=  11.1s\n",
      "[CV 37/37; 26/30] START model__colsample_bytree=0.6523906290790145, model__learning_rate=0.04293117062858835, model__max_depth=5, model__min_child_weight=9, model__n_estimators=417, model__subsample=0.6110539052353652\n",
      "[CV 26/37; 26/30] END model__colsample_bytree=0.6523906290790145, model__learning_rate=0.04293117062858835, model__max_depth=5, model__min_child_weight=9, model__n_estimators=417, model__subsample=0.6110539052353652;, score=-1.420 total time=   3.0s\n",
      "[CV 1/37; 27/30] START model__colsample_bytree=0.5599326836668415, model__learning_rate=0.07752303428072559, model__max_depth=9, model__min_child_weight=6, model__n_estimators=771, model__subsample=0.7593953108716831\n",
      "[CV 1/37; 27/30] END model__colsample_bytree=0.5599326836668415, model__learning_rate=0.07752303428072559, model__max_depth=9, model__min_child_weight=6, model__n_estimators=771, model__subsample=0.7593953108716831;, score=-41.040 total time=   0.3s\n",
      "[CV 27/37; 26/30] END model__colsample_bytree=0.6523906290790145, model__learning_rate=0.04293117062858835, model__max_depth=5, model__min_child_weight=9, model__n_estimators=417, model__subsample=0.6110539052353652;, score=-2.595 total time=   3.1s\n",
      "[CV 2/37; 27/30] START model__colsample_bytree=0.5599326836668415, model__learning_rate=0.07752303428072559, model__max_depth=9, model__min_child_weight=6, model__n_estimators=771, model__subsample=0.7593953108716831\n",
      "[CV 3/37; 27/30] START model__colsample_bytree=0.5599326836668415, model__learning_rate=0.07752303428072559, model__max_depth=9, model__min_child_weight=6, model__n_estimators=771, model__subsample=0.7593953108716831\n",
      "[CV 28/37; 26/30] END model__colsample_bytree=0.6523906290790145, model__learning_rate=0.04293117062858835, model__max_depth=5, model__min_child_weight=9, model__n_estimators=417, model__subsample=0.6110539052353652;, score=-1.199 total time=   3.2s\n",
      "[CV 4/37; 27/30] START model__colsample_bytree=0.5599326836668415, model__learning_rate=0.07752303428072559, model__max_depth=9, model__min_child_weight=6, model__n_estimators=771, model__subsample=0.7593953108716831\n",
      "[CV 2/37; 27/30] END model__colsample_bytree=0.5599326836668415, model__learning_rate=0.07752303428072559, model__max_depth=9, model__min_child_weight=6, model__n_estimators=771, model__subsample=0.7593953108716831;, score=-0.455 total time=   0.5s\n",
      "[CV 5/37; 27/30] START model__colsample_bytree=0.5599326836668415, model__learning_rate=0.07752303428072559, model__max_depth=9, model__min_child_weight=6, model__n_estimators=771, model__subsample=0.7593953108716831\n",
      "[CV 3/37; 27/30] END model__colsample_bytree=0.5599326836668415, model__learning_rate=0.07752303428072559, model__max_depth=9, model__min_child_weight=6, model__n_estimators=771, model__subsample=0.7593953108716831;, score=-10.014 total time=   0.7s\n",
      "[CV 6/37; 27/30] START model__colsample_bytree=0.5599326836668415, model__learning_rate=0.07752303428072559, model__max_depth=9, model__min_child_weight=6, model__n_estimators=771, model__subsample=0.7593953108716831\n",
      "[CV 29/37; 26/30] END model__colsample_bytree=0.6523906290790145, model__learning_rate=0.04293117062858835, model__max_depth=5, model__min_child_weight=9, model__n_estimators=417, model__subsample=0.6110539052353652;, score=-9.700 total time=   3.3s\n",
      "[CV 7/37; 27/30] START model__colsample_bytree=0.5599326836668415, model__learning_rate=0.07752303428072559, model__max_depth=9, model__min_child_weight=6, model__n_estimators=771, model__subsample=0.7593953108716831\n",
      "[CV 30/37; 26/30] END model__colsample_bytree=0.6523906290790145, model__learning_rate=0.04293117062858835, model__max_depth=5, model__min_child_weight=9, model__n_estimators=417, model__subsample=0.6110539052353652;, score=-0.240 total time=   3.3s\n",
      "[CV 8/37; 27/30] START model__colsample_bytree=0.5599326836668415, model__learning_rate=0.07752303428072559, model__max_depth=9, model__min_child_weight=6, model__n_estimators=771, model__subsample=0.7593953108716831\n",
      "[CV 4/37; 27/30] END model__colsample_bytree=0.5599326836668415, model__learning_rate=0.07752303428072559, model__max_depth=9, model__min_child_weight=6, model__n_estimators=771, model__subsample=0.7593953108716831;, score=-7.424 total time=   0.8s\n",
      "[CV 9/37; 27/30] START model__colsample_bytree=0.5599326836668415, model__learning_rate=0.07752303428072559, model__max_depth=9, model__min_child_weight=6, model__n_estimators=771, model__subsample=0.7593953108716831\n",
      "[CV 5/37; 27/30] END model__colsample_bytree=0.5599326836668415, model__learning_rate=0.07752303428072559, model__max_depth=9, model__min_child_weight=6, model__n_estimators=771, model__subsample=0.7593953108716831;, score=-37.247 total time=   1.1s\n",
      "[CV 10/37; 27/30] START model__colsample_bytree=0.5599326836668415, model__learning_rate=0.07752303428072559, model__max_depth=9, model__min_child_weight=6, model__n_estimators=771, model__subsample=0.7593953108716831\n",
      "[CV 31/37; 26/30] END model__colsample_bytree=0.6523906290790145, model__learning_rate=0.04293117062858835, model__max_depth=5, model__min_child_weight=9, model__n_estimators=417, model__subsample=0.6110539052353652;, score=0.301 total time=   3.5s\n",
      "[CV 11/37; 27/30] START model__colsample_bytree=0.5599326836668415, model__learning_rate=0.07752303428072559, model__max_depth=9, model__min_child_weight=6, model__n_estimators=771, model__subsample=0.7593953108716831\n",
      "[CV 6/37; 27/30] END model__colsample_bytree=0.5599326836668415, model__learning_rate=0.07752303428072559, model__max_depth=9, model__min_child_weight=6, model__n_estimators=771, model__subsample=0.7593953108716831;, score=-1.223 total time=   1.3s\n",
      "[CV 12/37; 27/30] START model__colsample_bytree=0.5599326836668415, model__learning_rate=0.07752303428072559, model__max_depth=9, model__min_child_weight=6, model__n_estimators=771, model__subsample=0.7593953108716831\n",
      "[CV 32/37; 26/30] END model__colsample_bytree=0.6523906290790145, model__learning_rate=0.04293117062858835, model__max_depth=5, model__min_child_weight=9, model__n_estimators=417, model__subsample=0.6110539052353652;, score=-3.235 total time=   3.6s\n",
      "[CV 13/37; 27/30] START model__colsample_bytree=0.5599326836668415, model__learning_rate=0.07752303428072559, model__max_depth=9, model__min_child_weight=6, model__n_estimators=771, model__subsample=0.7593953108716831\n",
      "[CV 33/37; 26/30] END model__colsample_bytree=0.6523906290790145, model__learning_rate=0.04293117062858835, model__max_depth=5, model__min_child_weight=9, model__n_estimators=417, model__subsample=0.6110539052353652;, score=-16.344 total time=   3.7s\n",
      "[CV 14/37; 27/30] START model__colsample_bytree=0.5599326836668415, model__learning_rate=0.07752303428072559, model__max_depth=9, model__min_child_weight=6, model__n_estimators=771, model__subsample=0.7593953108716831\n",
      "[CV 7/37; 27/30] END model__colsample_bytree=0.5599326836668415, model__learning_rate=0.07752303428072559, model__max_depth=9, model__min_child_weight=6, model__n_estimators=771, model__subsample=0.7593953108716831;, score=-6.169 total time=   1.6s\n",
      "[CV 15/37; 27/30] START model__colsample_bytree=0.5599326836668415, model__learning_rate=0.07752303428072559, model__max_depth=9, model__min_child_weight=6, model__n_estimators=771, model__subsample=0.7593953108716831\n",
      "[CV 34/37; 26/30] END model__colsample_bytree=0.6523906290790145, model__learning_rate=0.04293117062858835, model__max_depth=5, model__min_child_weight=9, model__n_estimators=417, model__subsample=0.6110539052353652;, score=0.193 total time=   3.8s\n",
      "[CV 16/37; 27/30] START model__colsample_bytree=0.5599326836668415, model__learning_rate=0.07752303428072559, model__max_depth=9, model__min_child_weight=6, model__n_estimators=771, model__subsample=0.7593953108716831\n",
      "[CV 35/37; 26/30] END model__colsample_bytree=0.6523906290790145, model__learning_rate=0.04293117062858835, model__max_depth=5, model__min_child_weight=9, model__n_estimators=417, model__subsample=0.6110539052353652;, score=-19.170 total time=   3.8s\n",
      "[CV 17/37; 27/30] START model__colsample_bytree=0.5599326836668415, model__learning_rate=0.07752303428072559, model__max_depth=9, model__min_child_weight=6, model__n_estimators=771, model__subsample=0.7593953108716831\n",
      "[CV 8/37; 27/30] END model__colsample_bytree=0.5599326836668415, model__learning_rate=0.07752303428072559, model__max_depth=9, model__min_child_weight=6, model__n_estimators=771, model__subsample=0.7593953108716831;, score=-8.875 total time=   1.8s\n",
      "[CV 18/37; 27/30] START model__colsample_bytree=0.5599326836668415, model__learning_rate=0.07752303428072559, model__max_depth=9, model__min_child_weight=6, model__n_estimators=771, model__subsample=0.7593953108716831\n",
      "[CV 36/37; 26/30] END model__colsample_bytree=0.6523906290790145, model__learning_rate=0.04293117062858835, model__max_depth=5, model__min_child_weight=9, model__n_estimators=417, model__subsample=0.6110539052353652;, score=-1.130 total time=   3.9s\n",
      "[CV 19/37; 27/30] START model__colsample_bytree=0.5599326836668415, model__learning_rate=0.07752303428072559, model__max_depth=9, model__min_child_weight=6, model__n_estimators=771, model__subsample=0.7593953108716831\n",
      "[CV 9/37; 27/30] END model__colsample_bytree=0.5599326836668415, model__learning_rate=0.07752303428072559, model__max_depth=9, model__min_child_weight=6, model__n_estimators=771, model__subsample=0.7593953108716831;, score=-0.636 total time=   2.2s\n",
      "[CV 20/37; 27/30] START model__colsample_bytree=0.5599326836668415, model__learning_rate=0.07752303428072559, model__max_depth=9, model__min_child_weight=6, model__n_estimators=771, model__subsample=0.7593953108716831\n",
      "[CV 37/37; 26/30] END model__colsample_bytree=0.6523906290790145, model__learning_rate=0.04293117062858835, model__max_depth=5, model__min_child_weight=9, model__n_estimators=417, model__subsample=0.6110539052353652;, score=0.148 total time=   4.1s\n",
      "[CV 21/37; 27/30] START model__colsample_bytree=0.5599326836668415, model__learning_rate=0.07752303428072559, model__max_depth=9, model__min_child_weight=6, model__n_estimators=771, model__subsample=0.7593953108716831\n",
      "[CV 10/37; 27/30] END model__colsample_bytree=0.5599326836668415, model__learning_rate=0.07752303428072559, model__max_depth=9, model__min_child_weight=6, model__n_estimators=771, model__subsample=0.7593953108716831;, score=-26.041 total time=   2.5s\n",
      "[CV 22/37; 27/30] START model__colsample_bytree=0.5599326836668415, model__learning_rate=0.07752303428072559, model__max_depth=9, model__min_child_weight=6, model__n_estimators=771, model__subsample=0.7593953108716831\n",
      "[CV 11/37; 27/30] END model__colsample_bytree=0.5599326836668415, model__learning_rate=0.07752303428072559, model__max_depth=9, model__min_child_weight=6, model__n_estimators=771, model__subsample=0.7593953108716831;, score=-2.865 total time=   2.9s\n",
      "[CV 23/37; 27/30] START model__colsample_bytree=0.5599326836668415, model__learning_rate=0.07752303428072559, model__max_depth=9, model__min_child_weight=6, model__n_estimators=771, model__subsample=0.7593953108716831\n",
      "[CV 12/37; 27/30] END model__colsample_bytree=0.5599326836668415, model__learning_rate=0.07752303428072559, model__max_depth=9, model__min_child_weight=6, model__n_estimators=771, model__subsample=0.7593953108716831;, score=-19.479 total time=   3.0s\n",
      "[CV 24/37; 27/30] START model__colsample_bytree=0.5599326836668415, model__learning_rate=0.07752303428072559, model__max_depth=9, model__min_child_weight=6, model__n_estimators=771, model__subsample=0.7593953108716831\n",
      "[CV 13/37; 27/30] END model__colsample_bytree=0.5599326836668415, model__learning_rate=0.07752303428072559, model__max_depth=9, model__min_child_weight=6, model__n_estimators=771, model__subsample=0.7593953108716831;, score=0.133 total time=   3.4s\n",
      "[CV 25/37; 27/30] START model__colsample_bytree=0.5599326836668415, model__learning_rate=0.07752303428072559, model__max_depth=9, model__min_child_weight=6, model__n_estimators=771, model__subsample=0.7593953108716831\n",
      "[CV 14/37; 27/30] END model__colsample_bytree=0.5599326836668415, model__learning_rate=0.07752303428072559, model__max_depth=9, model__min_child_weight=6, model__n_estimators=771, model__subsample=0.7593953108716831;, score=-20.176 total time=   3.8s\n",
      "[CV 26/37; 27/30] START model__colsample_bytree=0.5599326836668415, model__learning_rate=0.07752303428072559, model__max_depth=9, model__min_child_weight=6, model__n_estimators=771, model__subsample=0.7593953108716831\n",
      "[CV 15/37; 27/30] END model__colsample_bytree=0.5599326836668415, model__learning_rate=0.07752303428072559, model__max_depth=9, model__min_child_weight=6, model__n_estimators=771, model__subsample=0.7593953108716831;, score=-0.161 total time=   4.1s\n",
      "[CV 27/37; 27/30] START model__colsample_bytree=0.5599326836668415, model__learning_rate=0.07752303428072559, model__max_depth=9, model__min_child_weight=6, model__n_estimators=771, model__subsample=0.7593953108716831\n",
      "[CV 16/37; 27/30] END model__colsample_bytree=0.5599326836668415, model__learning_rate=0.07752303428072559, model__max_depth=9, model__min_child_weight=6, model__n_estimators=771, model__subsample=0.7593953108716831;, score=-0.582 total time=   4.6s\n",
      "[CV 28/37; 27/30] START model__colsample_bytree=0.5599326836668415, model__learning_rate=0.07752303428072559, model__max_depth=9, model__min_child_weight=6, model__n_estimators=771, model__subsample=0.7593953108716831\n",
      "[CV 17/37; 27/30] END model__colsample_bytree=0.5599326836668415, model__learning_rate=0.07752303428072559, model__max_depth=9, model__min_child_weight=6, model__n_estimators=771, model__subsample=0.7593953108716831;, score=-17.577 total time=   5.0s\n",
      "[CV 29/37; 27/30] START model__colsample_bytree=0.5599326836668415, model__learning_rate=0.07752303428072559, model__max_depth=9, model__min_child_weight=6, model__n_estimators=771, model__subsample=0.7593953108716831\n",
      "[CV 18/37; 27/30] END model__colsample_bytree=0.5599326836668415, model__learning_rate=0.07752303428072559, model__max_depth=9, model__min_child_weight=6, model__n_estimators=771, model__subsample=0.7593953108716831;, score=-0.412 total time=   5.6s\n",
      "[CV 30/37; 27/30] START model__colsample_bytree=0.5599326836668415, model__learning_rate=0.07752303428072559, model__max_depth=9, model__min_child_weight=6, model__n_estimators=771, model__subsample=0.7593953108716831\n",
      "[CV 19/37; 27/30] END model__colsample_bytree=0.5599326836668415, model__learning_rate=0.07752303428072559, model__max_depth=9, model__min_child_weight=6, model__n_estimators=771, model__subsample=0.7593953108716831;, score=-1.075 total time=   6.0s\n",
      "[CV 31/37; 27/30] START model__colsample_bytree=0.5599326836668415, model__learning_rate=0.07752303428072559, model__max_depth=9, model__min_child_weight=6, model__n_estimators=771, model__subsample=0.7593953108716831\n",
      "[CV 20/37; 27/30] END model__colsample_bytree=0.5599326836668415, model__learning_rate=0.07752303428072559, model__max_depth=9, model__min_child_weight=6, model__n_estimators=771, model__subsample=0.7593953108716831;, score=-4.725 total time=   6.3s\n",
      "[CV 32/37; 27/30] START model__colsample_bytree=0.5599326836668415, model__learning_rate=0.07752303428072559, model__max_depth=9, model__min_child_weight=6, model__n_estimators=771, model__subsample=0.7593953108716831\n",
      "[CV 21/37; 27/30] END model__colsample_bytree=0.5599326836668415, model__learning_rate=0.07752303428072559, model__max_depth=9, model__min_child_weight=6, model__n_estimators=771, model__subsample=0.7593953108716831;, score=-0.915 total time=   6.7s\n",
      "[CV 33/37; 27/30] START model__colsample_bytree=0.5599326836668415, model__learning_rate=0.07752303428072559, model__max_depth=9, model__min_child_weight=6, model__n_estimators=771, model__subsample=0.7593953108716831\n",
      "[CV 22/37; 27/30] END model__colsample_bytree=0.5599326836668415, model__learning_rate=0.07752303428072559, model__max_depth=9, model__min_child_weight=6, model__n_estimators=771, model__subsample=0.7593953108716831;, score=-0.303 total time=   7.5s\n",
      "[CV 34/37; 27/30] START model__colsample_bytree=0.5599326836668415, model__learning_rate=0.07752303428072559, model__max_depth=9, model__min_child_weight=6, model__n_estimators=771, model__subsample=0.7593953108716831\n",
      "[CV 23/37; 27/30] END model__colsample_bytree=0.5599326836668415, model__learning_rate=0.07752303428072559, model__max_depth=9, model__min_child_weight=6, model__n_estimators=771, model__subsample=0.7593953108716831;, score=-10.592 total time=   7.9s\n",
      "[CV 35/37; 27/30] START model__colsample_bytree=0.5599326836668415, model__learning_rate=0.07752303428072559, model__max_depth=9, model__min_child_weight=6, model__n_estimators=771, model__subsample=0.7593953108716831\n",
      "[CV 24/37; 27/30] END model__colsample_bytree=0.5599326836668415, model__learning_rate=0.07752303428072559, model__max_depth=9, model__min_child_weight=6, model__n_estimators=771, model__subsample=0.7593953108716831;, score=-4.525 total time=   8.4s\n",
      "[CV 36/37; 27/30] START model__colsample_bytree=0.5599326836668415, model__learning_rate=0.07752303428072559, model__max_depth=9, model__min_child_weight=6, model__n_estimators=771, model__subsample=0.7593953108716831\n",
      "[CV 25/37; 27/30] END model__colsample_bytree=0.5599326836668415, model__learning_rate=0.07752303428072559, model__max_depth=9, model__min_child_weight=6, model__n_estimators=771, model__subsample=0.7593953108716831;, score=-0.847 total time=   9.2s\n",
      "[CV 37/37; 27/30] START model__colsample_bytree=0.5599326836668415, model__learning_rate=0.07752303428072559, model__max_depth=9, model__min_child_weight=6, model__n_estimators=771, model__subsample=0.7593953108716831\n",
      "[CV 26/37; 27/30] END model__colsample_bytree=0.5599326836668415, model__learning_rate=0.07752303428072559, model__max_depth=9, model__min_child_weight=6, model__n_estimators=771, model__subsample=0.7593953108716831;, score=-1.226 total time=   9.6s\n",
      "[CV 1/37; 28/30] START model__colsample_bytree=0.8515094794475889, model__learning_rate=0.08272592047585879, model__max_depth=3, model__min_child_weight=4, model__n_estimators=367, model__subsample=0.6258911479126821\n",
      "[CV 1/37; 28/30] END model__colsample_bytree=0.8515094794475889, model__learning_rate=0.08272592047585879, model__max_depth=3, model__min_child_weight=4, model__n_estimators=367, model__subsample=0.6258911479126821;, score=-43.793 total time=   0.2s\n",
      "[CV 2/37; 28/30] START model__colsample_bytree=0.8515094794475889, model__learning_rate=0.08272592047585879, model__max_depth=3, model__min_child_weight=4, model__n_estimators=367, model__subsample=0.6258911479126821\n",
      "[CV 2/37; 28/30] END model__colsample_bytree=0.8515094794475889, model__learning_rate=0.08272592047585879, model__max_depth=3, model__min_child_weight=4, model__n_estimators=367, model__subsample=0.6258911479126821;, score=-0.357 total time=   0.2s\n",
      "[CV 3/37; 28/30] START model__colsample_bytree=0.8515094794475889, model__learning_rate=0.08272592047585879, model__max_depth=3, model__min_child_weight=4, model__n_estimators=367, model__subsample=0.6258911479126821\n",
      "[CV 3/37; 28/30] END model__colsample_bytree=0.8515094794475889, model__learning_rate=0.08272592047585879, model__max_depth=3, model__min_child_weight=4, model__n_estimators=367, model__subsample=0.6258911479126821;, score=-26.565 total time=   0.3s\n",
      "[CV 4/37; 28/30] START model__colsample_bytree=0.8515094794475889, model__learning_rate=0.08272592047585879, model__max_depth=3, model__min_child_weight=4, model__n_estimators=367, model__subsample=0.6258911479126821\n",
      "[CV 27/37; 27/30] END model__colsample_bytree=0.5599326836668415, model__learning_rate=0.07752303428072559, model__max_depth=9, model__min_child_weight=6, model__n_estimators=771, model__subsample=0.7593953108716831;, score=-2.489 total time=  10.0s\n",
      "[CV 5/37; 28/30] START model__colsample_bytree=0.8515094794475889, model__learning_rate=0.08272592047585879, model__max_depth=3, model__min_child_weight=4, model__n_estimators=367, model__subsample=0.6258911479126821\n",
      "[CV 4/37; 28/30] END model__colsample_bytree=0.8515094794475889, model__learning_rate=0.08272592047585879, model__max_depth=3, model__min_child_weight=4, model__n_estimators=367, model__subsample=0.6258911479126821;, score=-7.737 total time=   0.4s\n",
      "[CV 6/37; 28/30] START model__colsample_bytree=0.8515094794475889, model__learning_rate=0.08272592047585879, model__max_depth=3, model__min_child_weight=4, model__n_estimators=367, model__subsample=0.6258911479126821\n",
      "[CV 5/37; 28/30] END model__colsample_bytree=0.8515094794475889, model__learning_rate=0.08272592047585879, model__max_depth=3, model__min_child_weight=4, model__n_estimators=367, model__subsample=0.6258911479126821;, score=-39.138 total time=   0.5s\n",
      "[CV 7/37; 28/30] START model__colsample_bytree=0.8515094794475889, model__learning_rate=0.08272592047585879, model__max_depth=3, model__min_child_weight=4, model__n_estimators=367, model__subsample=0.6258911479126821\n",
      "[CV 6/37; 28/30] END model__colsample_bytree=0.8515094794475889, model__learning_rate=0.08272592047585879, model__max_depth=3, model__min_child_weight=4, model__n_estimators=367, model__subsample=0.6258911479126821;, score=-3.119 total time=   0.6s\n",
      "[CV 8/37; 28/30] START model__colsample_bytree=0.8515094794475889, model__learning_rate=0.08272592047585879, model__max_depth=3, model__min_child_weight=4, model__n_estimators=367, model__subsample=0.6258911479126821\n",
      "[CV 28/37; 27/30] END model__colsample_bytree=0.5599326836668415, model__learning_rate=0.07752303428072559, model__max_depth=9, model__min_child_weight=6, model__n_estimators=771, model__subsample=0.7593953108716831;, score=-1.028 total time=  10.4s\n",
      "[CV 9/37; 28/30] START model__colsample_bytree=0.8515094794475889, model__learning_rate=0.08272592047585879, model__max_depth=3, model__min_child_weight=4, model__n_estimators=367, model__subsample=0.6258911479126821\n",
      "[CV 7/37; 28/30] END model__colsample_bytree=0.8515094794475889, model__learning_rate=0.08272592047585879, model__max_depth=3, model__min_child_weight=4, model__n_estimators=367, model__subsample=0.6258911479126821;, score=-5.889 total time=   0.7s\n",
      "[CV 10/37; 28/30] START model__colsample_bytree=0.8515094794475889, model__learning_rate=0.08272592047585879, model__max_depth=3, model__min_child_weight=4, model__n_estimators=367, model__subsample=0.6258911479126821\n",
      "[CV 8/37; 28/30] END model__colsample_bytree=0.8515094794475889, model__learning_rate=0.08272592047585879, model__max_depth=3, model__min_child_weight=4, model__n_estimators=367, model__subsample=0.6258911479126821;, score=-8.774 total time=   0.7s\n",
      "[CV 11/37; 28/30] START model__colsample_bytree=0.8515094794475889, model__learning_rate=0.08272592047585879, model__max_depth=3, model__min_child_weight=4, model__n_estimators=367, model__subsample=0.6258911479126821\n",
      "[CV 9/37; 28/30] END model__colsample_bytree=0.8515094794475889, model__learning_rate=0.08272592047585879, model__max_depth=3, model__min_child_weight=4, model__n_estimators=367, model__subsample=0.6258911479126821;, score=-0.793 total time=   0.8s\n",
      "[CV 12/37; 28/30] START model__colsample_bytree=0.8515094794475889, model__learning_rate=0.08272592047585879, model__max_depth=3, model__min_child_weight=4, model__n_estimators=367, model__subsample=0.6258911479126821\n",
      "[CV 29/37; 27/30] END model__colsample_bytree=0.5599326836668415, model__learning_rate=0.07752303428072559, model__max_depth=9, model__min_child_weight=6, model__n_estimators=771, model__subsample=0.7593953108716831;, score=-9.007 total time=  10.9s\n",
      "[CV 13/37; 28/30] START model__colsample_bytree=0.8515094794475889, model__learning_rate=0.08272592047585879, model__max_depth=3, model__min_child_weight=4, model__n_estimators=367, model__subsample=0.6258911479126821\n",
      "[CV 10/37; 28/30] END model__colsample_bytree=0.8515094794475889, model__learning_rate=0.08272592047585879, model__max_depth=3, model__min_child_weight=4, model__n_estimators=367, model__subsample=0.6258911479126821;, score=-24.352 total time=   0.9s\n",
      "[CV 14/37; 28/30] START model__colsample_bytree=0.8515094794475889, model__learning_rate=0.08272592047585879, model__max_depth=3, model__min_child_weight=4, model__n_estimators=367, model__subsample=0.6258911479126821\n",
      "[CV 11/37; 28/30] END model__colsample_bytree=0.8515094794475889, model__learning_rate=0.08272592047585879, model__max_depth=3, model__min_child_weight=4, model__n_estimators=367, model__subsample=0.6258911479126821;, score=-3.230 total time=   1.0s\n",
      "[CV 15/37; 28/30] START model__colsample_bytree=0.8515094794475889, model__learning_rate=0.08272592047585879, model__max_depth=3, model__min_child_weight=4, model__n_estimators=367, model__subsample=0.6258911479126821\n",
      "[CV 12/37; 28/30] END model__colsample_bytree=0.8515094794475889, model__learning_rate=0.08272592047585879, model__max_depth=3, model__min_child_weight=4, model__n_estimators=367, model__subsample=0.6258911479126821;, score=-16.206 total time=   1.0s\n",
      "[CV 16/37; 28/30] START model__colsample_bytree=0.8515094794475889, model__learning_rate=0.08272592047585879, model__max_depth=3, model__min_child_weight=4, model__n_estimators=367, model__subsample=0.6258911479126821\n",
      "[CV 13/37; 28/30] END model__colsample_bytree=0.8515094794475889, model__learning_rate=0.08272592047585879, model__max_depth=3, model__min_child_weight=4, model__n_estimators=367, model__subsample=0.6258911479126821;, score=0.236 total time=   1.0s\n",
      "[CV 17/37; 28/30] START model__colsample_bytree=0.8515094794475889, model__learning_rate=0.08272592047585879, model__max_depth=3, model__min_child_weight=4, model__n_estimators=367, model__subsample=0.6258911479126821\n",
      "[CV 14/37; 28/30] END model__colsample_bytree=0.8515094794475889, model__learning_rate=0.08272592047585879, model__max_depth=3, model__min_child_weight=4, model__n_estimators=367, model__subsample=0.6258911479126821;, score=-19.301 total time=   1.2s\n",
      "[CV 18/37; 28/30] START model__colsample_bytree=0.8515094794475889, model__learning_rate=0.08272592047585879, model__max_depth=3, model__min_child_weight=4, model__n_estimators=367, model__subsample=0.6258911479126821\n",
      "[CV 30/37; 27/30] END model__colsample_bytree=0.5599326836668415, model__learning_rate=0.07752303428072559, model__max_depth=9, model__min_child_weight=6, model__n_estimators=771, model__subsample=0.7593953108716831;, score=-0.157 total time=  11.6s\n",
      "[CV 19/37; 28/30] START model__colsample_bytree=0.8515094794475889, model__learning_rate=0.08272592047585879, model__max_depth=3, model__min_child_weight=4, model__n_estimators=367, model__subsample=0.6258911479126821\n",
      "[CV 15/37; 28/30] END model__colsample_bytree=0.8515094794475889, model__learning_rate=0.08272592047585879, model__max_depth=3, model__min_child_weight=4, model__n_estimators=367, model__subsample=0.6258911479126821;, score=0.043 total time=   1.2s\n",
      "[CV 20/37; 28/30] START model__colsample_bytree=0.8515094794475889, model__learning_rate=0.08272592047585879, model__max_depth=3, model__min_child_weight=4, model__n_estimators=367, model__subsample=0.6258911479126821\n",
      "[CV 16/37; 28/30] END model__colsample_bytree=0.8515094794475889, model__learning_rate=0.08272592047585879, model__max_depth=3, model__min_child_weight=4, model__n_estimators=367, model__subsample=0.6258911479126821;, score=-0.609 total time=   1.3s\n",
      "[CV 21/37; 28/30] START model__colsample_bytree=0.8515094794475889, model__learning_rate=0.08272592047585879, model__max_depth=3, model__min_child_weight=4, model__n_estimators=367, model__subsample=0.6258911479126821\n",
      "[CV 17/37; 28/30] END model__colsample_bytree=0.8515094794475889, model__learning_rate=0.08272592047585879, model__max_depth=3, model__min_child_weight=4, model__n_estimators=367, model__subsample=0.6258911479126821;, score=-18.487 total time=   1.4s\n",
      "[CV 22/37; 28/30] START model__colsample_bytree=0.8515094794475889, model__learning_rate=0.08272592047585879, model__max_depth=3, model__min_child_weight=4, model__n_estimators=367, model__subsample=0.6258911479126821\n",
      "[CV 18/37; 28/30] END model__colsample_bytree=0.8515094794475889, model__learning_rate=0.08272592047585879, model__max_depth=3, model__min_child_weight=4, model__n_estimators=367, model__subsample=0.6258911479126821;, score=-0.586 total time=   1.5s\n",
      "[CV 23/37; 28/30] START model__colsample_bytree=0.8515094794475889, model__learning_rate=0.08272592047585879, model__max_depth=3, model__min_child_weight=4, model__n_estimators=367, model__subsample=0.6258911479126821\n",
      "[CV 31/37; 27/30] END model__colsample_bytree=0.5599326836668415, model__learning_rate=0.07752303428072559, model__max_depth=9, model__min_child_weight=6, model__n_estimators=771, model__subsample=0.7593953108716831;, score=-0.154 total time=  12.2s\n",
      "[CV 24/37; 28/30] START model__colsample_bytree=0.8515094794475889, model__learning_rate=0.08272592047585879, model__max_depth=3, model__min_child_weight=4, model__n_estimators=367, model__subsample=0.6258911479126821\n",
      "[CV 19/37; 28/30] END model__colsample_bytree=0.8515094794475889, model__learning_rate=0.08272592047585879, model__max_depth=3, model__min_child_weight=4, model__n_estimators=367, model__subsample=0.6258911479126821;, score=-0.779 total time=   1.6s\n",
      "[CV 25/37; 28/30] START model__colsample_bytree=0.8515094794475889, model__learning_rate=0.08272592047585879, model__max_depth=3, model__min_child_weight=4, model__n_estimators=367, model__subsample=0.6258911479126821\n",
      "[CV 20/37; 28/30] END model__colsample_bytree=0.8515094794475889, model__learning_rate=0.08272592047585879, model__max_depth=3, model__min_child_weight=4, model__n_estimators=367, model__subsample=0.6258911479126821;, score=-4.055 total time=   1.6s\n",
      "[CV 26/37; 28/30] START model__colsample_bytree=0.8515094794475889, model__learning_rate=0.08272592047585879, model__max_depth=3, model__min_child_weight=4, model__n_estimators=367, model__subsample=0.6258911479126821\n",
      "[CV 32/37; 27/30] END model__colsample_bytree=0.5599326836668415, model__learning_rate=0.07752303428072559, model__max_depth=9, model__min_child_weight=6, model__n_estimators=771, model__subsample=0.7593953108716831;, score=-3.034 total time=  12.6s\n",
      "[CV 21/37; 28/30] END model__colsample_bytree=0.8515094794475889, model__learning_rate=0.08272592047585879, model__max_depth=3, model__min_child_weight=4, model__n_estimators=367, model__subsample=0.6258911479126821;, score=-1.127 total time=   1.7s\n",
      "[CV 27/37; 28/30] START model__colsample_bytree=0.8515094794475889, model__learning_rate=0.08272592047585879, model__max_depth=3, model__min_child_weight=4, model__n_estimators=367, model__subsample=0.6258911479126821\n",
      "[CV 28/37; 28/30] START model__colsample_bytree=0.8515094794475889, model__learning_rate=0.08272592047585879, model__max_depth=3, model__min_child_weight=4, model__n_estimators=367, model__subsample=0.6258911479126821\n",
      "[CV 22/37; 28/30] END model__colsample_bytree=0.8515094794475889, model__learning_rate=0.08272592047585879, model__max_depth=3, model__min_child_weight=4, model__n_estimators=367, model__subsample=0.6258911479126821;, score=-0.388 total time=   1.7s\n",
      "[CV 29/37; 28/30] START model__colsample_bytree=0.8515094794475889, model__learning_rate=0.08272592047585879, model__max_depth=3, model__min_child_weight=4, model__n_estimators=367, model__subsample=0.6258911479126821\n",
      "[CV 23/37; 28/30] END model__colsample_bytree=0.8515094794475889, model__learning_rate=0.08272592047585879, model__max_depth=3, model__min_child_weight=4, model__n_estimators=367, model__subsample=0.6258911479126821;, score=-12.319 total time=   1.8s\n",
      "[CV 30/37; 28/30] START model__colsample_bytree=0.8515094794475889, model__learning_rate=0.08272592047585879, model__max_depth=3, model__min_child_weight=4, model__n_estimators=367, model__subsample=0.6258911479126821\n",
      "[CV 33/37; 27/30] END model__colsample_bytree=0.5599326836668415, model__learning_rate=0.07752303428072559, model__max_depth=9, model__min_child_weight=6, model__n_estimators=771, model__subsample=0.7593953108716831;, score=-20.668 total time=  13.0s\n",
      "[CV 31/37; 28/30] START model__colsample_bytree=0.8515094794475889, model__learning_rate=0.08272592047585879, model__max_depth=3, model__min_child_weight=4, model__n_estimators=367, model__subsample=0.6258911479126821\n",
      "[CV 24/37; 28/30] END model__colsample_bytree=0.8515094794475889, model__learning_rate=0.08272592047585879, model__max_depth=3, model__min_child_weight=4, model__n_estimators=367, model__subsample=0.6258911479126821;, score=-6.167 total time=   1.9s\n",
      "[CV 32/37; 28/30] START model__colsample_bytree=0.8515094794475889, model__learning_rate=0.08272592047585879, model__max_depth=3, model__min_child_weight=4, model__n_estimators=367, model__subsample=0.6258911479126821\n",
      "[CV 25/37; 28/30] END model__colsample_bytree=0.8515094794475889, model__learning_rate=0.08272592047585879, model__max_depth=3, model__min_child_weight=4, model__n_estimators=367, model__subsample=0.6258911479126821;, score=-0.858 total time=   1.9s\n",
      "[CV 33/37; 28/30] START model__colsample_bytree=0.8515094794475889, model__learning_rate=0.08272592047585879, model__max_depth=3, model__min_child_weight=4, model__n_estimators=367, model__subsample=0.6258911479126821\n",
      "[CV 26/37; 28/30] END model__colsample_bytree=0.8515094794475889, model__learning_rate=0.08272592047585879, model__max_depth=3, model__min_child_weight=4, model__n_estimators=367, model__subsample=0.6258911479126821;, score=-1.574 total time=   1.9s\n",
      "[CV 34/37; 28/30] START model__colsample_bytree=0.8515094794475889, model__learning_rate=0.08272592047585879, model__max_depth=3, model__min_child_weight=4, model__n_estimators=367, model__subsample=0.6258911479126821\n",
      "[CV 27/37; 28/30] END model__colsample_bytree=0.8515094794475889, model__learning_rate=0.08272592047585879, model__max_depth=3, model__min_child_weight=4, model__n_estimators=367, model__subsample=0.6258911479126821;, score=-2.551 total time=   2.1s\n",
      "[CV 35/37; 28/30] START model__colsample_bytree=0.8515094794475889, model__learning_rate=0.08272592047585879, model__max_depth=3, model__min_child_weight=4, model__n_estimators=367, model__subsample=0.6258911479126821\n",
      "[CV 28/37; 28/30] END model__colsample_bytree=0.8515094794475889, model__learning_rate=0.08272592047585879, model__max_depth=3, model__min_child_weight=4, model__n_estimators=367, model__subsample=0.6258911479126821;, score=-1.395 total time=   2.1s\n",
      "[CV 36/37; 28/30] START model__colsample_bytree=0.8515094794475889, model__learning_rate=0.08272592047585879, model__max_depth=3, model__min_child_weight=4, model__n_estimators=367, model__subsample=0.6258911479126821\n",
      "[CV 34/37; 27/30] END model__colsample_bytree=0.5599326836668415, model__learning_rate=0.07752303428072559, model__max_depth=9, model__min_child_weight=6, model__n_estimators=771, model__subsample=0.7593953108716831;, score=0.038 total time=  13.3s\n",
      "[CV 37/37; 28/30] START model__colsample_bytree=0.8515094794475889, model__learning_rate=0.08272592047585879, model__max_depth=3, model__min_child_weight=4, model__n_estimators=367, model__subsample=0.6258911479126821\n",
      "[CV 29/37; 28/30] END model__colsample_bytree=0.8515094794475889, model__learning_rate=0.08272592047585879, model__max_depth=3, model__min_child_weight=4, model__n_estimators=367, model__subsample=0.6258911479126821;, score=-8.959 total time=   2.2s\n",
      "[CV 1/37; 29/30] START model__colsample_bytree=0.7486242529461927, model__learning_rate=0.07017566196335394, model__max_depth=3, model__min_child_weight=8, model__n_estimators=180, model__subsample=0.6333905071376424\n",
      "[CV 1/37; 29/30] END model__colsample_bytree=0.7486242529461927, model__learning_rate=0.07017566196335394, model__max_depth=3, model__min_child_weight=8, model__n_estimators=180, model__subsample=0.6333905071376424;, score=-44.284 total time=   0.1s\n",
      "[CV 2/37; 29/30] START model__colsample_bytree=0.7486242529461927, model__learning_rate=0.07017566196335394, model__max_depth=3, model__min_child_weight=8, model__n_estimators=180, model__subsample=0.6333905071376424\n",
      "[CV 2/37; 29/30] END model__colsample_bytree=0.7486242529461927, model__learning_rate=0.07017566196335394, model__max_depth=3, model__min_child_weight=8, model__n_estimators=180, model__subsample=0.6333905071376424;, score=-0.355 total time=   0.1s\n",
      "[CV 3/37; 29/30] START model__colsample_bytree=0.7486242529461927, model__learning_rate=0.07017566196335394, model__max_depth=3, model__min_child_weight=8, model__n_estimators=180, model__subsample=0.6333905071376424\n",
      "[CV 3/37; 29/30] END model__colsample_bytree=0.7486242529461927, model__learning_rate=0.07017566196335394, model__max_depth=3, model__min_child_weight=8, model__n_estimators=180, model__subsample=0.6333905071376424;, score=-19.431 total time=   0.1s\n",
      "[CV 4/37; 29/30] START model__colsample_bytree=0.7486242529461927, model__learning_rate=0.07017566196335394, model__max_depth=3, model__min_child_weight=8, model__n_estimators=180, model__subsample=0.6333905071376424\n",
      "[CV 30/37; 28/30] END model__colsample_bytree=0.8515094794475889, model__learning_rate=0.08272592047585879, model__max_depth=3, model__min_child_weight=4, model__n_estimators=367, model__subsample=0.6258911479126821;, score=-0.407 total time=   2.3s\n",
      "[CV 5/37; 29/30] START model__colsample_bytree=0.7486242529461927, model__learning_rate=0.07017566196335394, model__max_depth=3, model__min_child_weight=8, model__n_estimators=180, model__subsample=0.6333905071376424\n",
      "[CV 4/37; 29/30] END model__colsample_bytree=0.7486242529461927, model__learning_rate=0.07017566196335394, model__max_depth=3, model__min_child_weight=8, model__n_estimators=180, model__subsample=0.6333905071376424;, score=-8.778 total time=   0.2s\n",
      "[CV 31/37; 28/30] END model__colsample_bytree=0.8515094794475889, model__learning_rate=0.08272592047585879, model__max_depth=3, model__min_child_weight=4, model__n_estimators=367, model__subsample=0.6258911479126821;, score=0.459 total time=   2.3s\n",
      "[CV 6/37; 29/30] START model__colsample_bytree=0.7486242529461927, model__learning_rate=0.07017566196335394, model__max_depth=3, model__min_child_weight=8, model__n_estimators=180, model__subsample=0.6333905071376424\n",
      "[CV 7/37; 29/30] START model__colsample_bytree=0.7486242529461927, model__learning_rate=0.07017566196335394, model__max_depth=3, model__min_child_weight=8, model__n_estimators=180, model__subsample=0.6333905071376424\n",
      "[CV 5/37; 29/30] END model__colsample_bytree=0.7486242529461927, model__learning_rate=0.07017566196335394, model__max_depth=3, model__min_child_weight=8, model__n_estimators=180, model__subsample=0.6333905071376424;, score=-37.855 total time=   0.2s\n",
      "[CV 8/37; 29/30] START model__colsample_bytree=0.7486242529461927, model__learning_rate=0.07017566196335394, model__max_depth=3, model__min_child_weight=8, model__n_estimators=180, model__subsample=0.6333905071376424\n",
      "[CV 35/37; 27/30] END model__colsample_bytree=0.5599326836668415, model__learning_rate=0.07752303428072559, model__max_depth=9, model__min_child_weight=6, model__n_estimators=771, model__subsample=0.7593953108716831;, score=-17.695 total time=  13.5s\n",
      "[CV 9/37; 29/30] START model__colsample_bytree=0.7486242529461927, model__learning_rate=0.07017566196335394, model__max_depth=3, model__min_child_weight=8, model__n_estimators=180, model__subsample=0.6333905071376424\n",
      "[CV 32/37; 28/30] END model__colsample_bytree=0.8515094794475889, model__learning_rate=0.08272592047585879, model__max_depth=3, model__min_child_weight=4, model__n_estimators=367, model__subsample=0.6258911479126821;, score=-3.178 total time=   2.4s\n",
      "[CV 6/37; 29/30] END model__colsample_bytree=0.7486242529461927, model__learning_rate=0.07017566196335394, model__max_depth=3, model__min_child_weight=8, model__n_estimators=180, model__subsample=0.6333905071376424;, score=-2.445 total time=   0.2s\n",
      "[CV 10/37; 29/30] START model__colsample_bytree=0.7486242529461927, model__learning_rate=0.07017566196335394, model__max_depth=3, model__min_child_weight=8, model__n_estimators=180, model__subsample=0.6333905071376424\n",
      "[CV 11/37; 29/30] START model__colsample_bytree=0.7486242529461927, model__learning_rate=0.07017566196335394, model__max_depth=3, model__min_child_weight=8, model__n_estimators=180, model__subsample=0.6333905071376424\n",
      "[CV 7/37; 29/30] END model__colsample_bytree=0.7486242529461927, model__learning_rate=0.07017566196335394, model__max_depth=3, model__min_child_weight=8, model__n_estimators=180, model__subsample=0.6333905071376424;, score=-4.481 total time=   0.3s\n",
      "[CV 12/37; 29/30] START model__colsample_bytree=0.7486242529461927, model__learning_rate=0.07017566196335394, model__max_depth=3, model__min_child_weight=8, model__n_estimators=180, model__subsample=0.6333905071376424\n",
      "[CV 8/37; 29/30] END model__colsample_bytree=0.7486242529461927, model__learning_rate=0.07017566196335394, model__max_depth=3, model__min_child_weight=8, model__n_estimators=180, model__subsample=0.6333905071376424;, score=-7.671 total time=   0.3s\n",
      "[CV 13/37; 29/30] START model__colsample_bytree=0.7486242529461927, model__learning_rate=0.07017566196335394, model__max_depth=3, model__min_child_weight=8, model__n_estimators=180, model__subsample=0.6333905071376424\n",
      "[CV 33/37; 28/30] END model__colsample_bytree=0.8515094794475889, model__learning_rate=0.08272592047585879, model__max_depth=3, model__min_child_weight=4, model__n_estimators=367, model__subsample=0.6258911479126821;, score=-14.932 total time=   2.5s\n",
      "[CV 14/37; 29/30] START model__colsample_bytree=0.7486242529461927, model__learning_rate=0.07017566196335394, model__max_depth=3, model__min_child_weight=8, model__n_estimators=180, model__subsample=0.6333905071376424\n",
      "[CV 9/37; 29/30] END model__colsample_bytree=0.7486242529461927, model__learning_rate=0.07017566196335394, model__max_depth=3, model__min_child_weight=8, model__n_estimators=180, model__subsample=0.6333905071376424;, score=-0.939 total time=   0.4s\n",
      "[CV 15/37; 29/30] START model__colsample_bytree=0.7486242529461927, model__learning_rate=0.07017566196335394, model__max_depth=3, model__min_child_weight=8, model__n_estimators=180, model__subsample=0.6333905071376424\n",
      "[CV 10/37; 29/30] END model__colsample_bytree=0.7486242529461927, model__learning_rate=0.07017566196335394, model__max_depth=3, model__min_child_weight=8, model__n_estimators=180, model__subsample=0.6333905071376424;, score=-20.279 total time=   0.4s\n",
      "[CV 16/37; 29/30] START model__colsample_bytree=0.7486242529461927, model__learning_rate=0.07017566196335394, model__max_depth=3, model__min_child_weight=8, model__n_estimators=180, model__subsample=0.6333905071376424\n",
      "[CV 11/37; 29/30] END model__colsample_bytree=0.7486242529461927, model__learning_rate=0.07017566196335394, model__max_depth=3, model__min_child_weight=8, model__n_estimators=180, model__subsample=0.6333905071376424;, score=-3.036 total time=   0.4s\n",
      "[CV 17/37; 29/30] START model__colsample_bytree=0.7486242529461927, model__learning_rate=0.07017566196335394, model__max_depth=3, model__min_child_weight=8, model__n_estimators=180, model__subsample=0.6333905071376424\n",
      "[CV 12/37; 29/30] END model__colsample_bytree=0.7486242529461927, model__learning_rate=0.07017566196335394, model__max_depth=3, model__min_child_weight=8, model__n_estimators=180, model__subsample=0.6333905071376424;, score=-15.317 total time=   0.5s\n",
      "[CV 18/37; 29/30] START model__colsample_bytree=0.7486242529461927, model__learning_rate=0.07017566196335394, model__max_depth=3, model__min_child_weight=8, model__n_estimators=180, model__subsample=0.6333905071376424\n",
      "[CV 34/37; 28/30] END model__colsample_bytree=0.8515094794475889, model__learning_rate=0.08272592047585879, model__max_depth=3, model__min_child_weight=4, model__n_estimators=367, model__subsample=0.6258911479126821;, score=0.219 total time=   2.5s\n",
      "[CV 19/37; 29/30] START model__colsample_bytree=0.7486242529461927, model__learning_rate=0.07017566196335394, model__max_depth=3, model__min_child_weight=8, model__n_estimators=180, model__subsample=0.6333905071376424\n",
      "[CV 13/37; 29/30] END model__colsample_bytree=0.7486242529461927, model__learning_rate=0.07017566196335394, model__max_depth=3, model__min_child_weight=8, model__n_estimators=180, model__subsample=0.6333905071376424;, score=0.276 total time=   0.5s\n",
      "[CV 20/37; 29/30] START model__colsample_bytree=0.7486242529461927, model__learning_rate=0.07017566196335394, model__max_depth=3, model__min_child_weight=8, model__n_estimators=180, model__subsample=0.6333905071376424\n",
      "[CV 14/37; 29/30] END model__colsample_bytree=0.7486242529461927, model__learning_rate=0.07017566196335394, model__max_depth=3, model__min_child_weight=8, model__n_estimators=180, model__subsample=0.6333905071376424;, score=-16.933 total time=   0.5s\n",
      "[CV 15/37; 29/30] END model__colsample_bytree=0.7486242529461927, model__learning_rate=0.07017566196335394, model__max_depth=3, model__min_child_weight=8, model__n_estimators=180, model__subsample=0.6333905071376424;, score=0.022 total time=   0.5s\n",
      "[CV 22/37; 29/30] START model__colsample_bytree=0.7486242529461927, model__learning_rate=0.07017566196335394, model__max_depth=3, model__min_child_weight=8, model__n_estimators=180, model__subsample=0.6333905071376424[CV 21/37; 29/30] START model__colsample_bytree=0.7486242529461927, model__learning_rate=0.07017566196335394, model__max_depth=3, model__min_child_weight=8, model__n_estimators=180, model__subsample=0.6333905071376424\n",
      "\n",
      "[CV 16/37; 29/30] END model__colsample_bytree=0.7486242529461927, model__learning_rate=0.07017566196335394, model__max_depth=3, model__min_child_weight=8, model__n_estimators=180, model__subsample=0.6333905071376424;, score=-0.387 total time=   0.6s\n",
      "[CV 23/37; 29/30] START model__colsample_bytree=0.7486242529461927, model__learning_rate=0.07017566196335394, model__max_depth=3, model__min_child_weight=8, model__n_estimators=180, model__subsample=0.6333905071376424\n",
      "[CV 17/37; 29/30] END model__colsample_bytree=0.7486242529461927, model__learning_rate=0.07017566196335394, model__max_depth=3, model__min_child_weight=8, model__n_estimators=180, model__subsample=0.6333905071376424;, score=-18.074 total time=   0.6s\n",
      "[CV 24/37; 29/30] START model__colsample_bytree=0.7486242529461927, model__learning_rate=0.07017566196335394, model__max_depth=3, model__min_child_weight=8, model__n_estimators=180, model__subsample=0.6333905071376424\n",
      "[CV 18/37; 29/30] END model__colsample_bytree=0.7486242529461927, model__learning_rate=0.07017566196335394, model__max_depth=3, model__min_child_weight=8, model__n_estimators=180, model__subsample=0.6333905071376424;, score=0.113 total time=   0.6s\n",
      "[CV 25/37; 29/30] START model__colsample_bytree=0.7486242529461927, model__learning_rate=0.07017566196335394, model__max_depth=3, model__min_child_weight=8, model__n_estimators=180, model__subsample=0.6333905071376424\n",
      "[CV 35/37; 28/30] END model__colsample_bytree=0.8515094794475889, model__learning_rate=0.08272592047585879, model__max_depth=3, model__min_child_weight=4, model__n_estimators=367, model__subsample=0.6258911479126821;, score=-17.688 total time=   2.6s\n",
      "[CV 26/37; 29/30] START model__colsample_bytree=0.7486242529461927, model__learning_rate=0.07017566196335394, model__max_depth=3, model__min_child_weight=8, model__n_estimators=180, model__subsample=0.6333905071376424\n",
      "[CV 19/37; 29/30] END model__colsample_bytree=0.7486242529461927, model__learning_rate=0.07017566196335394, model__max_depth=3, model__min_child_weight=8, model__n_estimators=180, model__subsample=0.6333905071376424;, score=-0.584 total time=   0.7s\n",
      "[CV 27/37; 29/30] START model__colsample_bytree=0.7486242529461927, model__learning_rate=0.07017566196335394, model__max_depth=3, model__min_child_weight=8, model__n_estimators=180, model__subsample=0.6333905071376424\n",
      "[CV 36/37; 28/30] END model__colsample_bytree=0.8515094794475889, model__learning_rate=0.08272592047585879, model__max_depth=3, model__min_child_weight=4, model__n_estimators=367, model__subsample=0.6258911479126821;, score=-1.397 total time=   2.7s\n",
      "[CV 28/37; 29/30] START model__colsample_bytree=0.7486242529461927, model__learning_rate=0.07017566196335394, model__max_depth=3, model__min_child_weight=8, model__n_estimators=180, model__subsample=0.6333905071376424\n",
      "[CV 20/37; 29/30] END model__colsample_bytree=0.7486242529461927, model__learning_rate=0.07017566196335394, model__max_depth=3, model__min_child_weight=8, model__n_estimators=180, model__subsample=0.6333905071376424;, score=-5.148 total time=   0.7s\n",
      "[CV 29/37; 29/30] START model__colsample_bytree=0.7486242529461927, model__learning_rate=0.07017566196335394, model__max_depth=3, model__min_child_weight=8, model__n_estimators=180, model__subsample=0.6333905071376424\n",
      "[CV 21/37; 29/30] END model__colsample_bytree=0.7486242529461927, model__learning_rate=0.07017566196335394, model__max_depth=3, model__min_child_weight=8, model__n_estimators=180, model__subsample=0.6333905071376424;, score=-1.348 total time=   0.7s\n",
      "[CV 30/37; 29/30] START model__colsample_bytree=0.7486242529461927, model__learning_rate=0.07017566196335394, model__max_depth=3, model__min_child_weight=8, model__n_estimators=180, model__subsample=0.6333905071376424\n",
      "[CV 22/37; 29/30] END model__colsample_bytree=0.7486242529461927, model__learning_rate=0.07017566196335394, model__max_depth=3, model__min_child_weight=8, model__n_estimators=180, model__subsample=0.6333905071376424;, score=-0.400 total time=   0.8s\n",
      "[CV 36/37; 27/30] END model__colsample_bytree=0.5599326836668415, model__learning_rate=0.07752303428072559, model__max_depth=9, model__min_child_weight=6, model__n_estimators=771, model__subsample=0.7593953108716831;, score=-1.630 total time=  14.1s\n",
      "[CV 37/37; 28/30] END model__colsample_bytree=0.8515094794475889, model__learning_rate=0.08272592047585879, model__max_depth=3, model__min_child_weight=4, model__n_estimators=367, model__subsample=0.6258911479126821;, score=0.072 total time=   2.7s\n",
      "[CV 32/37; 29/30] START model__colsample_bytree=0.7486242529461927, model__learning_rate=0.07017566196335394, model__max_depth=3, model__min_child_weight=8, model__n_estimators=180, model__subsample=0.6333905071376424\n",
      "[CV 31/37; 29/30] START model__colsample_bytree=0.7486242529461927, model__learning_rate=0.07017566196335394, model__max_depth=3, model__min_child_weight=8, model__n_estimators=180, model__subsample=0.6333905071376424\n",
      "[CV 33/37; 29/30] START model__colsample_bytree=0.7486242529461927, model__learning_rate=0.07017566196335394, model__max_depth=3, model__min_child_weight=8, model__n_estimators=180, model__subsample=0.6333905071376424\n",
      "[CV 23/37; 29/30] END model__colsample_bytree=0.7486242529461927, model__learning_rate=0.07017566196335394, model__max_depth=3, model__min_child_weight=8, model__n_estimators=180, model__subsample=0.6333905071376424;, score=-12.044 total time=   0.9s\n",
      "[CV 34/37; 29/30] START model__colsample_bytree=0.7486242529461927, model__learning_rate=0.07017566196335394, model__max_depth=3, model__min_child_weight=8, model__n_estimators=180, model__subsample=0.6333905071376424\n",
      "[CV 24/37; 29/30] END model__colsample_bytree=0.7486242529461927, model__learning_rate=0.07017566196335394, model__max_depth=3, model__min_child_weight=8, model__n_estimators=180, model__subsample=0.6333905071376424;, score=-6.171 total time=   0.9s\n",
      "[CV 35/37; 29/30] START model__colsample_bytree=0.7486242529461927, model__learning_rate=0.07017566196335394, model__max_depth=3, model__min_child_weight=8, model__n_estimators=180, model__subsample=0.6333905071376424\n",
      "[CV 25/37; 29/30] END model__colsample_bytree=0.7486242529461927, model__learning_rate=0.07017566196335394, model__max_depth=3, model__min_child_weight=8, model__n_estimators=180, model__subsample=0.6333905071376424;, score=-0.553 total time=   1.0s\n",
      "[CV 36/37; 29/30] START model__colsample_bytree=0.7486242529461927, model__learning_rate=0.07017566196335394, model__max_depth=3, model__min_child_weight=8, model__n_estimators=180, model__subsample=0.6333905071376424\n",
      "[CV 26/37; 29/30] END model__colsample_bytree=0.7486242529461927, model__learning_rate=0.07017566196335394, model__max_depth=3, model__min_child_weight=8, model__n_estimators=180, model__subsample=0.6333905071376424;, score=-0.782 total time=   0.9s\n",
      "[CV 37/37; 29/30] START model__colsample_bytree=0.7486242529461927, model__learning_rate=0.07017566196335394, model__max_depth=3, model__min_child_weight=8, model__n_estimators=180, model__subsample=0.6333905071376424\n",
      "[CV 27/37; 29/30] END model__colsample_bytree=0.7486242529461927, model__learning_rate=0.07017566196335394, model__max_depth=3, model__min_child_weight=8, model__n_estimators=180, model__subsample=0.6333905071376424;, score=-2.220 total time=   1.0s\n",
      "[CV 1/37; 30/30] START model__colsample_bytree=0.9883074779163264, model__learning_rate=0.09220740266364626, model__max_depth=9, model__min_child_weight=5, model__n_estimators=835, model__subsample=0.9541329429833268\n",
      "[CV 28/37; 29/30] END model__colsample_bytree=0.7486242529461927, model__learning_rate=0.07017566196335394, model__max_depth=3, model__min_child_weight=8, model__n_estimators=180, model__subsample=0.6333905071376424;, score=-1.053 total time=   1.0s\n",
      "[CV 2/37; 30/30] START model__colsample_bytree=0.9883074779163264, model__learning_rate=0.09220740266364626, model__max_depth=9, model__min_child_weight=5, model__n_estimators=835, model__subsample=0.9541329429833268\n",
      "[CV 29/37; 29/30] END model__colsample_bytree=0.7486242529461927, model__learning_rate=0.07017566196335394, model__max_depth=3, model__min_child_weight=8, model__n_estimators=180, model__subsample=0.6333905071376424;, score=-7.953 total time=   1.1s\n",
      "[CV 3/37; 30/30] START model__colsample_bytree=0.9883074779163264, model__learning_rate=0.09220740266364626, model__max_depth=9, model__min_child_weight=5, model__n_estimators=835, model__subsample=0.9541329429833268\n",
      "[CV 30/37; 29/30] END model__colsample_bytree=0.7486242529461927, model__learning_rate=0.07017566196335394, model__max_depth=3, model__min_child_weight=8, model__n_estimators=180, model__subsample=0.6333905071376424;, score=-0.702 total time=   1.1s\n",
      "[CV 1/37; 30/30] END model__colsample_bytree=0.9883074779163264, model__learning_rate=0.09220740266364626, model__max_depth=9, model__min_child_weight=5, model__n_estimators=835, model__subsample=0.9541329429833268;, score=-43.893 total time=   0.4s\n",
      "[CV 4/37; 30/30] START model__colsample_bytree=0.9883074779163264, model__learning_rate=0.09220740266364626, model__max_depth=9, model__min_child_weight=5, model__n_estimators=835, model__subsample=0.9541329429833268\n",
      "[CV 5/37; 30/30] START model__colsample_bytree=0.9883074779163264, model__learning_rate=0.09220740266364626, model__max_depth=9, model__min_child_weight=5, model__n_estimators=835, model__subsample=0.9541329429833268\n",
      "[CV 31/37; 29/30] END model__colsample_bytree=0.7486242529461927, model__learning_rate=0.07017566196335394, model__max_depth=3, model__min_child_weight=8, model__n_estimators=180, model__subsample=0.6333905071376424;, score=0.500 total time=   1.1s\n",
      "[CV 6/37; 30/30] START model__colsample_bytree=0.9883074779163264, model__learning_rate=0.09220740266364626, model__max_depth=9, model__min_child_weight=5, model__n_estimators=835, model__subsample=0.9541329429833268\n",
      "[CV 33/37; 29/30] END model__colsample_bytree=0.7486242529461927, model__learning_rate=0.07017566196335394, model__max_depth=3, model__min_child_weight=8, model__n_estimators=180, model__subsample=0.6333905071376424;, score=-13.617 total time=   1.1s\n",
      "[CV 7/37; 30/30] START model__colsample_bytree=0.9883074779163264, model__learning_rate=0.09220740266364626, model__max_depth=9, model__min_child_weight=5, model__n_estimators=835, model__subsample=0.9541329429833268\n",
      "[CV 32/37; 29/30] END model__colsample_bytree=0.7486242529461927, model__learning_rate=0.07017566196335394, model__max_depth=3, model__min_child_weight=8, model__n_estimators=180, model__subsample=0.6333905071376424;, score=-2.858 total time=   1.1s\n",
      "[CV 8/37; 30/30] START model__colsample_bytree=0.9883074779163264, model__learning_rate=0.09220740266364626, model__max_depth=9, model__min_child_weight=5, model__n_estimators=835, model__subsample=0.9541329429833268\n",
      "[CV 2/37; 30/30] END model__colsample_bytree=0.9883074779163264, model__learning_rate=0.09220740266364626, model__max_depth=9, model__min_child_weight=5, model__n_estimators=835, model__subsample=0.9541329429833268;, score=-0.154 total time=   0.5s\n",
      "[CV 9/37; 30/30] START model__colsample_bytree=0.9883074779163264, model__learning_rate=0.09220740266364626, model__max_depth=9, model__min_child_weight=5, model__n_estimators=835, model__subsample=0.9541329429833268\n",
      "[CV 34/37; 29/30] END model__colsample_bytree=0.7486242529461927, model__learning_rate=0.07017566196335394, model__max_depth=3, model__min_child_weight=8, model__n_estimators=180, model__subsample=0.6333905071376424;, score=0.033 total time=   1.2s\n",
      "[CV 10/37; 30/30] START model__colsample_bytree=0.9883074779163264, model__learning_rate=0.09220740266364626, model__max_depth=9, model__min_child_weight=5, model__n_estimators=835, model__subsample=0.9541329429833268\n",
      "[CV 35/37; 29/30] END model__colsample_bytree=0.7486242529461927, model__learning_rate=0.07017566196335394, model__max_depth=3, model__min_child_weight=8, model__n_estimators=180, model__subsample=0.6333905071376424;, score=-14.886 total time=   1.2s\n",
      "[CV 11/37; 30/30] START model__colsample_bytree=0.9883074779163264, model__learning_rate=0.09220740266364626, model__max_depth=9, model__min_child_weight=5, model__n_estimators=835, model__subsample=0.9541329429833268\n",
      "[CV 3/37; 30/30] END model__colsample_bytree=0.9883074779163264, model__learning_rate=0.09220740266364626, model__max_depth=9, model__min_child_weight=5, model__n_estimators=835, model__subsample=0.9541329429833268;, score=-18.506 total time=   0.8s\n",
      "[CV 12/37; 30/30] START model__colsample_bytree=0.9883074779163264, model__learning_rate=0.09220740266364626, model__max_depth=9, model__min_child_weight=5, model__n_estimators=835, model__subsample=0.9541329429833268\n",
      "[CV 37/37; 27/30] END model__colsample_bytree=0.5599326836668415, model__learning_rate=0.07752303428072559, model__max_depth=9, model__min_child_weight=6, model__n_estimators=771, model__subsample=0.7593953108716831;, score=-0.178 total time=  14.4s\n",
      "[CV 13/37; 30/30] START model__colsample_bytree=0.9883074779163264, model__learning_rate=0.09220740266364626, model__max_depth=9, model__min_child_weight=5, model__n_estimators=835, model__subsample=0.9541329429833268\n",
      "[CV 37/37; 29/30] END model__colsample_bytree=0.7486242529461927, model__learning_rate=0.07017566196335394, model__max_depth=3, model__min_child_weight=8, model__n_estimators=180, model__subsample=0.6333905071376424;, score=0.309 total time=   1.2s\n",
      "[CV 14/37; 30/30] START model__colsample_bytree=0.9883074779163264, model__learning_rate=0.09220740266364626, model__max_depth=9, model__min_child_weight=5, model__n_estimators=835, model__subsample=0.9541329429833268\n",
      "[CV 36/37; 29/30] END model__colsample_bytree=0.7486242529461927, model__learning_rate=0.07017566196335394, model__max_depth=3, model__min_child_weight=8, model__n_estimators=180, model__subsample=0.6333905071376424;, score=-1.120 total time=   1.3s\n",
      "[CV 15/37; 30/30] START model__colsample_bytree=0.9883074779163264, model__learning_rate=0.09220740266364626, model__max_depth=9, model__min_child_weight=5, model__n_estimators=835, model__subsample=0.9541329429833268\n",
      "[CV 4/37; 30/30] END model__colsample_bytree=0.9883074779163264, model__learning_rate=0.09220740266364626, model__max_depth=9, model__min_child_weight=5, model__n_estimators=835, model__subsample=0.9541329429833268;, score=-7.267 total time=   1.0s\n",
      "[CV 16/37; 30/30] START model__colsample_bytree=0.9883074779163264, model__learning_rate=0.09220740266364626, model__max_depth=9, model__min_child_weight=5, model__n_estimators=835, model__subsample=0.9541329429833268\n",
      "[CV 5/37; 30/30] END model__colsample_bytree=0.9883074779163264, model__learning_rate=0.09220740266364626, model__max_depth=9, model__min_child_weight=5, model__n_estimators=835, model__subsample=0.9541329429833268;, score=-39.077 total time=   1.1s\n",
      "[CV 17/37; 30/30] START model__colsample_bytree=0.9883074779163264, model__learning_rate=0.09220740266364626, model__max_depth=9, model__min_child_weight=5, model__n_estimators=835, model__subsample=0.9541329429833268\n",
      "[CV 6/37; 30/30] END model__colsample_bytree=0.9883074779163264, model__learning_rate=0.09220740266364626, model__max_depth=9, model__min_child_weight=5, model__n_estimators=835, model__subsample=0.9541329429833268;, score=-1.574 total time=   1.4s\n",
      "[CV 18/37; 30/30] START model__colsample_bytree=0.9883074779163264, model__learning_rate=0.09220740266364626, model__max_depth=9, model__min_child_weight=5, model__n_estimators=835, model__subsample=0.9541329429833268\n",
      "[CV 7/37; 30/30] END model__colsample_bytree=0.9883074779163264, model__learning_rate=0.09220740266364626, model__max_depth=9, model__min_child_weight=5, model__n_estimators=835, model__subsample=0.9541329429833268;, score=-6.263 total time=   1.8s\n",
      "[CV 19/37; 30/30] START model__colsample_bytree=0.9883074779163264, model__learning_rate=0.09220740266364626, model__max_depth=9, model__min_child_weight=5, model__n_estimators=835, model__subsample=0.9541329429833268\n",
      "[CV 8/37; 30/30] END model__colsample_bytree=0.9883074779163264, model__learning_rate=0.09220740266364626, model__max_depth=9, model__min_child_weight=5, model__n_estimators=835, model__subsample=0.9541329429833268;, score=-8.252 total time=   2.1s\n",
      "[CV 20/37; 30/30] START model__colsample_bytree=0.9883074779163264, model__learning_rate=0.09220740266364626, model__max_depth=9, model__min_child_weight=5, model__n_estimators=835, model__subsample=0.9541329429833268\n",
      "[CV 9/37; 30/30] END model__colsample_bytree=0.9883074779163264, model__learning_rate=0.09220740266364626, model__max_depth=9, model__min_child_weight=5, model__n_estimators=835, model__subsample=0.9541329429833268;, score=-0.758 total time=   2.6s\n",
      "[CV 21/37; 30/30] START model__colsample_bytree=0.9883074779163264, model__learning_rate=0.09220740266364626, model__max_depth=9, model__min_child_weight=5, model__n_estimators=835, model__subsample=0.9541329429833268\n",
      "[CV 10/37; 30/30] END model__colsample_bytree=0.9883074779163264, model__learning_rate=0.09220740266364626, model__max_depth=9, model__min_child_weight=5, model__n_estimators=835, model__subsample=0.9541329429833268;, score=-34.389 total time=   2.8s\n",
      "[CV 22/37; 30/30] START model__colsample_bytree=0.9883074779163264, model__learning_rate=0.09220740266364626, model__max_depth=9, model__min_child_weight=5, model__n_estimators=835, model__subsample=0.9541329429833268\n",
      "[CV 11/37; 30/30] END model__colsample_bytree=0.9883074779163264, model__learning_rate=0.09220740266364626, model__max_depth=9, model__min_child_weight=5, model__n_estimators=835, model__subsample=0.9541329429833268;, score=-3.268 total time=   3.1s\n",
      "[CV 23/37; 30/30] START model__colsample_bytree=0.9883074779163264, model__learning_rate=0.09220740266364626, model__max_depth=9, model__min_child_weight=5, model__n_estimators=835, model__subsample=0.9541329429833268\n",
      "[CV 12/37; 30/30] END model__colsample_bytree=0.9883074779163264, model__learning_rate=0.09220740266364626, model__max_depth=9, model__min_child_weight=5, model__n_estimators=835, model__subsample=0.9541329429833268;, score=-18.154 total time=   3.3s\n",
      "[CV 24/37; 30/30] START model__colsample_bytree=0.9883074779163264, model__learning_rate=0.09220740266364626, model__max_depth=9, model__min_child_weight=5, model__n_estimators=835, model__subsample=0.9541329429833268\n",
      "[CV 13/37; 30/30] END model__colsample_bytree=0.9883074779163264, model__learning_rate=0.09220740266364626, model__max_depth=9, model__min_child_weight=5, model__n_estimators=835, model__subsample=0.9541329429833268;, score=0.065 total time=   3.9s\n",
      "[CV 25/37; 30/30] START model__colsample_bytree=0.9883074779163264, model__learning_rate=0.09220740266364626, model__max_depth=9, model__min_child_weight=5, model__n_estimators=835, model__subsample=0.9541329429833268\n",
      "[CV 14/37; 30/30] END model__colsample_bytree=0.9883074779163264, model__learning_rate=0.09220740266364626, model__max_depth=9, model__min_child_weight=5, model__n_estimators=835, model__subsample=0.9541329429833268;, score=-24.633 total time=   4.4s\n",
      "[CV 26/37; 30/30] START model__colsample_bytree=0.9883074779163264, model__learning_rate=0.09220740266364626, model__max_depth=9, model__min_child_weight=5, model__n_estimators=835, model__subsample=0.9541329429833268\n",
      "[CV 15/37; 30/30] END model__colsample_bytree=0.9883074779163264, model__learning_rate=0.09220740266364626, model__max_depth=9, model__min_child_weight=5, model__n_estimators=835, model__subsample=0.9541329429833268;, score=0.042 total time=   4.7s\n",
      "[CV 27/37; 30/30] START model__colsample_bytree=0.9883074779163264, model__learning_rate=0.09220740266364626, model__max_depth=9, model__min_child_weight=5, model__n_estimators=835, model__subsample=0.9541329429833268\n",
      "[CV 16/37; 30/30] END model__colsample_bytree=0.9883074779163264, model__learning_rate=0.09220740266364626, model__max_depth=9, model__min_child_weight=5, model__n_estimators=835, model__subsample=0.9541329429833268;, score=-0.688 total time=   5.6s\n",
      "[CV 28/37; 30/30] START model__colsample_bytree=0.9883074779163264, model__learning_rate=0.09220740266364626, model__max_depth=9, model__min_child_weight=5, model__n_estimators=835, model__subsample=0.9541329429833268\n",
      "[CV 17/37; 30/30] END model__colsample_bytree=0.9883074779163264, model__learning_rate=0.09220740266364626, model__max_depth=9, model__min_child_weight=5, model__n_estimators=835, model__subsample=0.9541329429833268;, score=-18.635 total time=   6.1s\n",
      "[CV 29/37; 30/30] START model__colsample_bytree=0.9883074779163264, model__learning_rate=0.09220740266364626, model__max_depth=9, model__min_child_weight=5, model__n_estimators=835, model__subsample=0.9541329429833268\n",
      "[CV 18/37; 30/30] END model__colsample_bytree=0.9883074779163264, model__learning_rate=0.09220740266364626, model__max_depth=9, model__min_child_weight=5, model__n_estimators=835, model__subsample=0.9541329429833268;, score=-0.511 total time=   6.8s\n",
      "[CV 30/37; 30/30] START model__colsample_bytree=0.9883074779163264, model__learning_rate=0.09220740266364626, model__max_depth=9, model__min_child_weight=5, model__n_estimators=835, model__subsample=0.9541329429833268\n",
      "[CV 19/37; 30/30] END model__colsample_bytree=0.9883074779163264, model__learning_rate=0.09220740266364626, model__max_depth=9, model__min_child_weight=5, model__n_estimators=835, model__subsample=0.9541329429833268;, score=-0.946 total time=   7.3s\n",
      "[CV 31/37; 30/30] START model__colsample_bytree=0.9883074779163264, model__learning_rate=0.09220740266364626, model__max_depth=9, model__min_child_weight=5, model__n_estimators=835, model__subsample=0.9541329429833268\n",
      "[CV 20/37; 30/30] END model__colsample_bytree=0.9883074779163264, model__learning_rate=0.09220740266364626, model__max_depth=9, model__min_child_weight=5, model__n_estimators=835, model__subsample=0.9541329429833268;, score=-5.113 total time=   8.2s\n",
      "[CV 32/37; 30/30] START model__colsample_bytree=0.9883074779163264, model__learning_rate=0.09220740266364626, model__max_depth=9, model__min_child_weight=5, model__n_estimators=835, model__subsample=0.9541329429833268\n",
      "[CV 21/37; 30/30] END model__colsample_bytree=0.9883074779163264, model__learning_rate=0.09220740266364626, model__max_depth=9, model__min_child_weight=5, model__n_estimators=835, model__subsample=0.9541329429833268;, score=-1.240 total time=   8.5s\n",
      "[CV 33/37; 30/30] START model__colsample_bytree=0.9883074779163264, model__learning_rate=0.09220740266364626, model__max_depth=9, model__min_child_weight=5, model__n_estimators=835, model__subsample=0.9541329429833268\n",
      "[CV 22/37; 30/30] END model__colsample_bytree=0.9883074779163264, model__learning_rate=0.09220740266364626, model__max_depth=9, model__min_child_weight=5, model__n_estimators=835, model__subsample=0.9541329429833268;, score=-0.524 total time=   9.2s\n",
      "[CV 34/37; 30/30] START model__colsample_bytree=0.9883074779163264, model__learning_rate=0.09220740266364626, model__max_depth=9, model__min_child_weight=5, model__n_estimators=835, model__subsample=0.9541329429833268\n",
      "[CV 23/37; 30/30] END model__colsample_bytree=0.9883074779163264, model__learning_rate=0.09220740266364626, model__max_depth=9, model__min_child_weight=5, model__n_estimators=835, model__subsample=0.9541329429833268;, score=-10.649 total time=  10.1s\n",
      "[CV 35/37; 30/30] START model__colsample_bytree=0.9883074779163264, model__learning_rate=0.09220740266364626, model__max_depth=9, model__min_child_weight=5, model__n_estimators=835, model__subsample=0.9541329429833268\n",
      "[CV 24/37; 30/30] END model__colsample_bytree=0.9883074779163264, model__learning_rate=0.09220740266364626, model__max_depth=9, model__min_child_weight=5, model__n_estimators=835, model__subsample=0.9541329429833268;, score=-7.666 total time=  10.8s\n",
      "[CV 36/37; 30/30] START model__colsample_bytree=0.9883074779163264, model__learning_rate=0.09220740266364626, model__max_depth=9, model__min_child_weight=5, model__n_estimators=835, model__subsample=0.9541329429833268\n",
      "[CV 25/37; 30/30] END model__colsample_bytree=0.9883074779163264, model__learning_rate=0.09220740266364626, model__max_depth=9, model__min_child_weight=5, model__n_estimators=835, model__subsample=0.9541329429833268;, score=-0.642 total time=  11.4s\n",
      "[CV 37/37; 30/30] START model__colsample_bytree=0.9883074779163264, model__learning_rate=0.09220740266364626, model__max_depth=9, model__min_child_weight=5, model__n_estimators=835, model__subsample=0.9541329429833268\n",
      "[CV 26/37; 30/30] END model__colsample_bytree=0.9883074779163264, model__learning_rate=0.09220740266364626, model__max_depth=9, model__min_child_weight=5, model__n_estimators=835, model__subsample=0.9541329429833268;, score=-1.276 total time=  12.3s\n",
      "[CV 27/37; 30/30] END model__colsample_bytree=0.9883074779163264, model__learning_rate=0.09220740266364626, model__max_depth=9, model__min_child_weight=5, model__n_estimators=835, model__subsample=0.9541329429833268;, score=-3.096 total time=  13.3s\n",
      "[CV 28/37; 30/30] END model__colsample_bytree=0.9883074779163264, model__learning_rate=0.09220740266364626, model__max_depth=9, model__min_child_weight=5, model__n_estimators=835, model__subsample=0.9541329429833268;, score=-0.854 total time=  13.0s\n",
      "[CV 29/37; 30/30] END model__colsample_bytree=0.9883074779163264, model__learning_rate=0.09220740266364626, model__max_depth=9, model__min_child_weight=5, model__n_estimators=835, model__subsample=0.9541329429833268;, score=-7.914 total time=  13.9s\n",
      "[CV 30/37; 30/30] END model__colsample_bytree=0.9883074779163264, model__learning_rate=0.09220740266364626, model__max_depth=9, model__min_child_weight=5, model__n_estimators=835, model__subsample=0.9541329429833268;, score=-0.174 total time=  14.1s\n",
      "[CV 31/37; 30/30] END model__colsample_bytree=0.9883074779163264, model__learning_rate=0.09220740266364626, model__max_depth=9, model__min_child_weight=5, model__n_estimators=835, model__subsample=0.9541329429833268;, score=-0.260 total time=  14.3s\n",
      "[CV 32/37; 30/30] END model__colsample_bytree=0.9883074779163264, model__learning_rate=0.09220740266364626, model__max_depth=9, model__min_child_weight=5, model__n_estimators=835, model__subsample=0.9541329429833268;, score=-3.535 total time=  14.6s\n",
      "[CV 33/37; 30/30] END model__colsample_bytree=0.9883074779163264, model__learning_rate=0.09220740266364626, model__max_depth=9, model__min_child_weight=5, model__n_estimators=835, model__subsample=0.9541329429833268;, score=-21.517 total time=  14.6s\n",
      "[CV 34/37; 30/30] END model__colsample_bytree=0.9883074779163264, model__learning_rate=0.09220740266364626, model__max_depth=9, model__min_child_weight=5, model__n_estimators=835, model__subsample=0.9541329429833268;, score=-0.084 total time=  14.7s\n",
      "[CV 35/37; 30/30] END model__colsample_bytree=0.9883074779163264, model__learning_rate=0.09220740266364626, model__max_depth=9, model__min_child_weight=5, model__n_estimators=835, model__subsample=0.9541329429833268;, score=-18.542 total time=  14.0s\n",
      "[CV 36/37; 30/30] END model__colsample_bytree=0.9883074779163264, model__learning_rate=0.09220740266364626, model__max_depth=9, model__min_child_weight=5, model__n_estimators=835, model__subsample=0.9541329429833268;, score=-1.625 total time=  14.3s\n",
      "[CV 37/37; 30/30] END model__colsample_bytree=0.9883074779163264, model__learning_rate=0.09220740266364626, model__max_depth=9, model__min_child_weight=5, model__n_estimators=835, model__subsample=0.9541329429833268;, score=-0.239 total time=  14.1s\n",
      "Best parameters: {'model__colsample_bytree': 0.7486242529461927, 'model__learning_rate': 0.07017566196335394, 'model__max_depth': 3, 'model__min_child_weight': 8, 'model__n_estimators': 180, 'model__subsample': 0.6333905071376424}\n",
      "Best score: -7.3095211146744274\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from scipy.stats import uniform, randint\n",
    "\n",
    "# Specify hyperparameters to tune and their respective distributions\n",
    "param_dist = {\n",
    "    'model__learning_rate': uniform(0.01, 0.2),\n",
    "    'model__n_estimators': randint(100, 1000),\n",
    "    'model__max_depth': randint(3, 10),\n",
    "    'model__min_child_weight': randint(1, 10),\n",
    "    'model__subsample': uniform(0.5, 0.5),\n",
    "    'model__colsample_bytree': uniform(0.5, 0.5),\n",
    "    # add other parameters here\n",
    "}\n",
    "\n",
    "# Perform randomized search\n",
    "random_search = RandomizedSearchCV(pipeline, param_dist, n_iter=30, cv=cv, scoring=\"r2\", n_jobs=-1, verbose=10, random_state=42)\n",
    "random_search.fit(X, y)\n",
    "\n",
    "# Best parameters and score from random search\n",
    "print(f\"Best parameters: {random_search.best_params_}\")\n",
    "print(f\"Best score: {random_search.best_score_}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "55f667d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error (MSE): 0.0029896802502135554\n",
      "Root Mean Squared Error (RMSE): 0.05467796859991742\n",
      "Mean Absolute Error (MAE): 0.04177301527135101\n",
      "R-squared: -0.12356652583990857\n"
     ]
    },
    {
     "data": {
      "image/svg+xml": [
       "<svg class=\"main-svg\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" width=\"900\" height=\"200\" style=\"\" viewBox=\"0 0 900 200\"><rect x=\"0\" y=\"0\" width=\"900\" height=\"200\" style=\"fill: rgb(33, 34, 38); fill-opacity: 1;\"/><defs id=\"defs-116e2b\"><g class=\"clips\"><clipPath id=\"clip116e2bxyplot\" class=\"plotclip\"><rect width=\"703.12\" height=\"114\"/></clipPath><clipPath id=\"clip116e2bxy2plot\" class=\"plotclip\"><rect width=\"703.12\" height=\"114\"/></clipPath><clipPath class=\"axesclip\" id=\"clip116e2bx\"><rect x=\"46\" y=\"0\" width=\"703.12\" height=\"200\"/></clipPath><clipPath class=\"axesclip\" id=\"clip116e2by\"><rect x=\"0\" y=\"43\" width=\"900\" height=\"114\"/></clipPath><clipPath class=\"axesclip\" id=\"clip116e2bxy\"><rect x=\"46\" y=\"43\" width=\"703.12\" height=\"114\"/></clipPath><clipPath class=\"axesclip\" id=\"clip116e2by2\"><rect x=\"0\" y=\"43\" width=\"900\" height=\"114\"/></clipPath><clipPath class=\"axesclip\" id=\"clip116e2bxy2\"><rect x=\"46\" y=\"43\" width=\"703.12\" height=\"114\"/></clipPath></g><g class=\"gradients\"><linearGradient x1=\"0\" x2=\"0\" y1=\"1\" y2=\"0\" id=\"g116e2b-cb3ecafdc6-ccff-492f-8f39-0fcb28fbe957\"><stop offset=\"0%\" stop-color=\"rgb(13, 8, 135)\" stop-opacity=\"1\"/><stop offset=\"11.111111%\" stop-color=\"rgb(70, 3, 159)\" stop-opacity=\"1\"/><stop offset=\"22.222222%\" stop-color=\"rgb(114, 1, 168)\" stop-opacity=\"1\"/><stop offset=\"33.333333%\" stop-color=\"rgb(156, 23, 158)\" stop-opacity=\"1\"/><stop offset=\"44.444444%\" stop-color=\"rgb(189, 55, 134)\" stop-opacity=\"1\"/><stop offset=\"55.555556%\" stop-color=\"rgb(216, 87, 107)\" stop-opacity=\"1\"/><stop offset=\"66.666667%\" stop-color=\"rgb(237, 121, 83)\" stop-opacity=\"1\"/><stop offset=\"77.777778%\" stop-color=\"rgb(251, 159, 58)\" stop-opacity=\"1\"/><stop offset=\"88.888889%\" stop-color=\"rgb(253, 202, 38)\" stop-opacity=\"1\"/><stop offset=\"100%\" stop-color=\"rgb(240, 249, 33)\" stop-opacity=\"1\"/></linearGradient></g><g class=\"patterns\"/></defs><g class=\"bglayer\"/><g class=\"layer-below\"><g class=\"imagelayer\"/><g class=\"shapelayer\"/></g><g class=\"cartesianlayer\"><g class=\"subplot xy\"><g class=\"layer-subplot\"><g class=\"shapelayer\"/><g class=\"imagelayer\"/></g><g class=\"minor-gridlayer\"><g class=\"x\"/><g class=\"y\"/><g class=\"y2\"/></g><g class=\"gridlayer\"><g class=\"x\"><path class=\"xgrid crisp\" transform=\"translate(69.9,0)\" d=\"M0,43v114\" style=\"stroke: rgb(49, 52, 57); stroke-opacity: 1; stroke-width: 1px;\"/><path class=\"xgrid crisp\" transform=\"translate(153.31,0)\" d=\"M0,43v114\" style=\"stroke: rgb(49, 52, 57); stroke-opacity: 1; stroke-width: 1px;\"/><path class=\"xgrid crisp\" transform=\"translate(236.73,0)\" d=\"M0,43v114\" style=\"stroke: rgb(49, 52, 57); stroke-opacity: 1; stroke-width: 1px;\"/><path class=\"xgrid crisp\" transform=\"translate(320.15,0)\" d=\"M0,43v114\" style=\"stroke: rgb(49, 52, 57); stroke-opacity: 1; stroke-width: 1px;\"/><path class=\"xgrid crisp\" transform=\"translate(403.57,0)\" d=\"M0,43v114\" style=\"stroke: rgb(49, 52, 57); stroke-opacity: 1; stroke-width: 1px;\"/><path class=\"xgrid crisp\" transform=\"translate(486.99,0)\" d=\"M0,43v114\" style=\"stroke: rgb(49, 52, 57); stroke-opacity: 1; stroke-width: 1px;\"/><path class=\"xgrid crisp\" transform=\"translate(570.4,0)\" d=\"M0,43v114\" style=\"stroke: rgb(49, 52, 57); stroke-opacity: 1; stroke-width: 1px;\"/><path class=\"xgrid crisp\" transform=\"translate(653.82,0)\" d=\"M0,43v114\" style=\"stroke: rgb(49, 52, 57); stroke-opacity: 1; stroke-width: 1px;\"/><path class=\"xgrid crisp\" transform=\"translate(737.24,0)\" d=\"M0,43v114\" style=\"stroke: rgb(49, 52, 57); stroke-opacity: 1; stroke-width: 1px;\"/></g><g class=\"y\"><path class=\"ygrid crisp\" transform=\"translate(0,100)\" d=\"M46,0h703.12\" style=\"stroke: rgb(49, 52, 57); stroke-opacity: 1; stroke-width: 1px;\"/></g><g class=\"y2\"><path class=\"y2grid crisp\" transform=\"translate(0,145.13)\" d=\"M46,0h703.12\" style=\"stroke: rgb(49, 52, 57); stroke-opacity: 1; stroke-width: 1px;\"/><path class=\"y2grid crisp\" transform=\"translate(0,111.25)\" d=\"M46,0h703.12\" style=\"stroke: rgb(49, 52, 57); stroke-opacity: 1; stroke-width: 1px;\"/><path class=\"y2grid crisp\" transform=\"translate(0,77.37)\" d=\"M46,0h703.12\" style=\"stroke: rgb(49, 52, 57); stroke-opacity: 1; stroke-width: 1px;\"/></g></g><g class=\"zerolinelayer\"/><path class=\"xlines-below\"/><path class=\"ylines-below\"/><g class=\"overlines-below\"><path class=\"xy2-x\"/><path class=\"xy2-y\"/></g><g class=\"xaxislayer-below\"/><g class=\"yaxislayer-below\"/><g class=\"overaxes-below\"><g class=\"xy2-x\"/><g class=\"xy2-y\"/></g><g class=\"plot\" transform=\"translate(46,43)\" clip-path=\"url(#clip116e2bxyplot)\"><g class=\"heatmaplayer mlayer\"><g class=\"hm\"><image xmlns=\"http://www.w3.org/2000/svg\" preserveAspectRatio=\"none\" height=\"114\" width=\"703\" x=\"0\" y=\"0\" xlink:href=\"data:image/png;base64,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\" style=\"opacity: 1;\"/></g></g></g><g class=\"overplot\"><g class=\"xy2\" transform=\"translate(46,43)\" clip-path=\"url(#clip116e2bxy2plot)\"><g class=\"scatterlayer mlayer\"><g class=\"trace scatter trace79b4536b-adbe-44f2-8bad-1b8a2dc18620\" style=\"stroke-miterlimit: 2; opacity: 1;\"><g class=\"fills\"/><g class=\"errorbars\"/><g class=\"lines\"><path class=\"js-line\" d=\"M0.06,106.21L0.75,104.05L1.25,104.5L1.41,104.62L1.88,104.47L2.16,104.72L2.35,104.73L4.21,105.51L4.39,104.95L5.59,104.15L5.76,104.36L6.21,103.36L6.33,103.83L6.4,104.47L6.45,104.69L6.78,103.87L7.01,103.95L7.14,104.17L7.6,104.62L7.77,105.03L8.16,104.34L8.45,104.8L8.82,105.51L8.94,104.6L9.36,106.43L9.55,105.38L9.74,105.63L10.89,104.47L11.24,104.44L11.75,104.42L12.09,105.48L12.86,104.17L13.14,104.19L14.06,104.22L14.4,103.68L15.08,103.5L15.27,102.96L16.3,102.81L16.48,102.96L16.81,102.58L16.87,103.21L16.93,103.44L17.63,102.71L17.98,102.12L18.07,102.56L18.24,100.15L18.26,99.63L18.33,99.94L18.86,96.66L19.14,97.74L19.2,97.72L19.93,95.74L19.96,95.51L20.23,91.85L20.77,92.49L20.83,92.04L20.93,93.16L21.36,90.98L21.48,91.89L21.56,91.56L21.76,91.26L21.85,91.84L21.92,92.71L21.96,92.7L22.4,99.71L22.69,96.63L22.76,95.95L22.85,96.61L23.12,94.43L23.42,95.38L23.44,95.19L23.63,95.48L23.76,94.68L23.95,95.12L24.09,93.9L24.32,94.16L24.7,92.57L25.15,92.7L25.32,93.22L25.87,93.69L26.09,92.84L26.59,87.95L27.07,88.22L27.18,88.88L27.28,89.05L27.38,88.17L27.5,87.75L27.73,85.79L27.95,88.58L28.24,86.78L28.34,86.73L29.03,90.02L29.15,88.41L29.24,88.68L29.82,86.39L30.04,88.05L30.14,87.87L30.31,87.17L30.78,89.34L30.89,88.14L30.99,88.13L31.57,92.2L31.77,89.55L31.84,89.31L32.31,93.2L32.91,92.48L33.01,93.03L33.08,93.88L33.26,92.05L33.64,92.73L33.79,91.22L34.23,88.92L34.46,89.22L34.69,90.36L34.84,90.16L34.95,90.29L35.12,91.3L35.22,91.57L35.34,90.36L35.43,89.8L36.08,93.28L36.39,92.93L36.57,91.55L37.15,90.16L37.55,90.34L37.77,90.16L38.6,91.64L38.74,91.62L38.86,90.56L39.28,92.22L39.36,92.88L40.1,96.5L40.18,95.23L40.25,95.15L40.89,104.77L40.9,108.3L41.71,99.76L41.74,100.04L42.81,96.18L42.91,95.72L43.23,94.81L43.62,96.38L43.7,95.86L44.54,99.74L44.63,98.5L45.47,96.25L45.66,97.05L45.79,97.34L46.13,97.2L46.31,98.32L46.47,98.76L46.74,97.63L47.03,97.59L48.04,92.5L48.66,92.9L48.82,93.65L49.56,96.92L49.59,97.91L49.63,97.1L49.81,99.88L50.24,98.19L50.3,98.88L50.43,98.29L50.79,102.25L50.85,100.63L50.92,98.96L51.45,99.05L51.72,97.4L51.78,97.47L51.88,97.89L52.02,98.1L52.26,97.29L52.43,96.5L52.5,96.27L52.59,96.9L52.71,96.52L52.9,97.8L52.99,98.04L53.09,97.27L53.22,97.36L53.39,96.62L53.76,95.21L54.18,96.25L54.37,96.19L54.69,97.7L54.96,95.44L55.05,95.1L55.59,95.58L55.84,93.35L55.89,93.98L56.33,94.34L57.41,87.78L57.57,89.29L57.63,90.46L57.8,88.68L58.31,88.89L58.45,89.55L58.85,87.16L59.27,88.53L59.32,88.86L59.54,88.25L59.79,90.11L59.98,88.57L60.13,88.68L60.28,89.82L60.54,88.41L60.82,88.73L60.88,88.61L61.18,89.37L61.38,88.82L61.52,88.05L62.08,82.88L62.3,84.3L62.4,85.68L62.46,85.89L62.71,84.22L62.82,85.44L62.92,84.54L63.46,86.67L63.74,86.21L63.83,87.76L63.95,86.37L64.21,88.9L64.46,88.48L64.59,87.7L65.17,84.88L65.6,85.48L65.7,85.33L66.01,85.24L66.62,88.12L66.7,87.29L66.8,86.55L67.04,87.56L67.24,85.94L67.48,86.13L67.59,84.76L67.99,86.97L68.39,85.42L68.51,84.53L68.68,84.79L68.92,84.35L69.06,83.58L69.24,82.68L69.5,85.16L69.56,85.07L69.58,86.47L69.65,87.33L69.95,81.74L69.98,81.54L70.16,80.05L70.46,82.37L70.69,80.81L70.83,80.85L71.79,77.68L71.83,77.42L72.66,79.66L72.73,79.21L72.85,78.99L73.23,76.01L73.86,76.36L73.99,77.65L74.24,75.83L74.65,78.27L74.73,78.38L75.09,77.93L75.42,78.67L75.5,78.41L75.68,80.24L75.91,77.43L76.11,77.89L76.25,77.38L76.39,76.9L76.7,78.11L76.87,77.96L78.17,73.52L78.23,74.02L78.31,74.5L78.56,72.85L78.99,74.23L79.1,74.34L80.2,68.96L80.25,69.56L80.31,69.2L80.62,66.66L80.63,68.73L80.65,70L80.71,69.99L80.89,78.88L81.37,71.06L81.4,71.15L81.63,72.86L81.81,71.13L81.89,70.96L82.72,68.05L82.79,68.93L83.01,72.32L83.57,69.9L83.7,70.59L84.79,78.14L84.81,79.46L85.57,72.75L85.69,73.04L85.78,72.04L86.33,74.29L86.39,74.99L86.47,76.12L86.76,72.91L86.87,73.74L87.06,71.62L87.28,71.43L87.87,73.41L88.08,72.53L88.2,71.98L89.55,62L89.7,62.71L89.77,63.76L89.98,65.46L90.37,62.74L90.52,64.11L90.61,64.05L90.94,61.31L91.04,65.66L91.08,63.71L91.11,66.91L91.18,68.95L91.78,62.63L92.02,63.68L92.11,64.76L92.2,64.53L92.44,65.48L92.53,66.73L92.69,65.81L92.86,68.03L93.29,66.43L93.37,68.29L93.53,66.87L93.88,72.37L94.11,68.88L94.18,68.12L94.23,69.56L94.8,65.43L94.93,65.8L95.18,65.85L95.31,65.13L95.42,64.85L96.11,68.46L96.28,67.35L96.41,66.57L96.71,69.03L97.14,67.83L97.34,68.11L97.62,66.84L97.88,68.36L97.99,69.06L98.86,71.84L98.91,70.75L99,70.23L99.96,65.66L100.13,66.56L100.25,67.37L100.39,67.28L100.48,66.1L100.69,66.35L100.87,66.11L101,64.73L101.04,63.94L101.24,66.4L101.68,65.42L101.8,64.99L101.89,65.45L102.12,64.25L102.18,64.33L102.31,63.37L102.65,64.9L102.79,66.83L103.06,65.75L103.22,66.69L103.36,66.94L103.7,68.23L103.9,66.56L104.01,66.18L104.85,65.06L105,65.79L105.4,67.06L105.57,66.64L105.74,65.67L106.33,66.46L106.57,67.45L106.86,68.11L108.08,63.63L108.16,64.32L108.26,64.52L108.55,64.4L109.56,67.4L109.66,66.61L110.62,64.39L110.81,64.94L110.99,65.36L111.15,64.58L111.29,65.77L111.7,65.02L111.87,64.86L112.45,66.61L112.51,67.37L112.59,66.18L113.31,73.1L113.45,68.99L113.53,69.6L113.58,70.15L113.84,68.06L114.29,69.97L114.41,68.74L114.74,70.67L114.95,68.56L115.23,69.82L115.33,70.02L115.59,69.85L115.78,71.68L115.83,72.26L116.06,77.17L116.47,74.79L116.52,73.69L116.73,73.1L117.46,83.39L117.48,80.36L117.49,78.86L117.53,79.77L118.33,71.96L118.39,72.21L118.45,72.2L119.62,78.46L119.73,75.96L119.78,75.91L120.95,85.79L120.98,85.45L120.99,88.3L121.02,88.95L121.21,82.07L121.53,84.51L121.58,83.43L121.71,82.32L122.04,85.35L122.06,86.58L122.1,85.24L122.59,92.19L122.64,90.75L122.67,92.22L122.8,92.38L123.51,82.46L123.57,82.71L123.61,83.43L123.75,85.34L124.18,81.38L124.22,80.77L125.28,90.3L125.39,85.55L125.43,84.89L126.27,96.66L126.46,91.98L126.49,90.56L126.52,89.7L127.03,96.5L127.07,96.6L127.52,99.95L127.91,92.15L127.94,92.25L127.97,90.49L128.6,93.4L128.66,94.17L128.83,97.18L129.05,93.82L129.42,96.22L129.49,93.67L130.29,86.03L130.4,86.57L130.49,87.58L131.01,83.39L131.27,86.6L131.3,87.01L131.64,83.73L131.95,87.52L131.99,88.57L132.24,89.1L132.78,85.47L132.89,86.51L133.42,86.63L133.59,83.48L133.71,84.9L133.84,84.2L134.95,79.79L134.97,80.08L135.04,80.56L135.62,82.95L135.85,81.42L135.93,81.91L136.27,85.25L136.49,84.95L136.58,83.25L136.74,82.79L136.9,84.21L137.12,83.18L137.23,84.07L137.58,83.83L138.35,92.16L138.38,93.23L139.18,86.24L139.25,86.5L139.31,86.72L139.47,85.62L139.56,85.65L139.6,84.51L139.8,86.22L140.1,83.56L140.42,85.49L140.5,85.76L140.61,85.21L140.82,86.98L140.98,86.69L141.08,87.56L141.29,88.9L141.51,87.26L141.83,88.27L141.91,86.33L142.07,85.86L142.15,87.11L142.31,87.99L143.36,92.45L143.42,92.58L143.5,93.47L143.95,91.34L144.02,90.39L144.32,92.81L144.61,88.72L144.64,87.5L145.33,90.92L145.42,90.83L145.51,90.55L145.85,92.19L146.12,89.29L146.19,89.02L146.45,89.21L146.93,84.75L147.49,85.44L147.62,85.22L147.78,87.43L148.09,85.63L148.21,84.92L148.75,84.19L149.01,87.96L149.12,87.93L149.19,87.23L149.99,85.96L150.14,84.89L150.45,87.58L150.82,85.78L150.94,85.67L151.12,87.07L151.51,85.44L151.64,85.15L151.92,85.44L152.11,84.56L152.24,83.23L153.09,80.4L153.18,81.82L153.24,82.14L153.57,80.3L153.68,80.48L153.79,79.52L153.99,75.81L154.48,76.58L154.63,77.47L154.72,78.07L154.99,74.89L155.05,75.63L155.13,75.45L155.2,75.04L155.53,76.87L155.64,76.32L155.74,76.46L156.07,77.94L156.52,77.5L156.64,76.87L156.92,78.77L157.4,77.03L157.56,76.42L158.96,72.5L159.33,73.39L159.46,73.9L159.85,74.83L160.21,74.29L160.36,73.14L161.02,75.35L161.17,74.4L161.27,73.86L161.82,72.09L161.86,71.62L161.9,71.86L162.21,69.45L162.25,69.25L162.42,70.13L162.67,68.27L162.7,68.15L163.33,70.47L163.42,69.56L163.51,69.18L163.61,69.04L163.93,69.84L164.09,69.83L164.23,70.32L164.47,68.96L164.61,69.62L164.75,68.57L165.69,73.66L166.13,72.77L166.27,71.38L166.53,72.2L166.94,69.65L167.26,70.11L167.44,70.08L168.55,72.27L168.68,72.74L168.83,72.13L168.93,73.29L169.35,72.42L169.51,72.93L169.9,76.13L170.37,75.24L170.44,73.81L171.14,72.7L171.28,74.46L171.78,72.22L172.08,73.47L172.25,73.95L172.5,73.87L172.63,74.83L172.76,74.37L172.94,75.35L173.02,76.8L173.18,75.96L173.46,76.93L173.52,76.05L173.8,76.85L173.92,76.96L174.88,85.93L174.89,86.77L175.08,81.04L175.65,82.73L175.7,82.56L175.89,80.52L176.19,84.85L176.42,81.99L176.5,82.88L176.79,83.79L176.85,85.51L177.59,80.89L177.67,81.18L177.75,81.2L179.39,76.33L179.48,77.63L180.24,81.02L180.48,79.9L180.62,79.61L181.62,82.92L181.72,82.16L181.84,81.55L183.2,75.94L183.36,77.02L183.45,76.66L183.61,76.72L183.75,75.74L183.8,75.42L184.18,77.56L184.29,77.27L184.73,75.29L184.93,77.66L184.99,78.43L185.24,76.03L185.68,78.22L185.79,77.26L185.93,78.88L186.38,76.46L186.55,76.19L187.29,78.55L187.39,78.46L187.48,77.9L188.33,80.66L188.52,80.57L188.61,80.12L188.97,79.25L189.24,80.16L189.4,80.89L189.76,83.09L190,81.71L190.16,80.89L190.44,80.52L190.77,82.8L190.96,81.2L191.05,80.23L191.18,80.88L191.53,79.53L191.84,80.63L192.09,80.08L193.22,82.32L193.35,82.87L194.72,87.04L195.07,86.65L195.14,85.64L195.21,84.83L195.62,88.12L195.66,88.51L196.52,83.92L196.6,84.57L196.71,83.73L197.02,85.13L197.25,83.88L197.42,84.82L197.94,84.58L198.08,85.73L198.18,84.14L198.84,81.33L199.01,82.29L199.13,82.1L199.81,82.84L200.07,81.9L200.22,81.82L200.36,82.35L200.59,82.75L201.73,79.28L201.93,81.18L202.19,81.04L202.33,80.43L202.57,82.81L203,82.05L203.23,82.53L203.38,81.33L203.79,81.94L204,82.49L204.38,85.15L205.02,84.59L205.21,85.48L206.29,81.07L206.38,81.27L206.51,81.41L207.19,80L207.37,80.06L207.59,80.43L207.82,80.36L208.17,81.91L208.25,81.6L208.43,79.8L208.53,80.11L208.65,78.08L208.67,77.48L208.7,76.81L209.17,78.79L209.26,78.67L209.38,78.59L209.87,81.18L210.31,80.53L210.49,80.43L211.3,83.32L211.59,82.57L211.69,82.45L211.89,82.43L212.07,81.53L212.21,82.16L212.6,81.02L212.83,80.81L212.93,81.56L213.41,80.48L213.63,80.26L214.43,79.04L214.66,79.71L214.78,79.98L215.38,77.4L215.73,78.55L215.88,78.71L216.68,80.35L216.96,80.23L217.15,80.22L217.35,80.89L217.54,79.97L217.69,79.36L217.82,79.97L218.12,79.17L218.37,78.24L218.75,76.59L219.22,77L219.37,77.42L219.78,78.7L220.28,78.07L220.42,77.1L220.87,79.07L221.21,78.26L221.39,77.49L221.95,78.42L222.08,77.82L222.19,77.3L222.49,77.15L222.53,75.82L222.54,75.43L222.93,77.66L223.19,77.43L223.33,77.95L223.72,78.74L223.88,79.69L224,79.26L224.29,80.99L224.51,79.94L224.57,80.58L225.7,79.16L225.91,80.45L226.47,82.69L226.57,81.39L226.68,81.08L227.15,81.46L227.24,80.47L227.4,81.87L227.75,81.35L228.18,83.18L228.24,84.29L228.53,85.46L229.05,83.72L229.22,83.66L229.85,84.44L229.93,83.24L230.45,83.6L230.6,82.06L230.68,83.09L230.79,83.48L232.09,88.15L232.13,87.77L232.18,86.7L232.45,87.8L232.66,85.98L232.86,86.62L233,86.53L233.07,87L233.27,85.21L233.48,85.36L233.61,85.15L234.12,86.76L234.17,86.38L234.28,87.35L234.45,90.13L234.81,86.22L234.87,85.77L235,86.25L235.26,85.01L235.56,85.48L235.68,85.34L236.26,84.42L236.34,84.84L236.46,85.26L236.65,84.84L236.8,86.02L236.98,86.54L238.11,82.94L238.22,83.45L240.05,87.51L240.16,86.62L240.44,85.55L240.66,87.19L240.77,87.19L240.84,88.18L241.96,85.28L242.09,85.68L242.22,86.5L242.79,90.48L242.83,91.07L242.85,90.73L243.15,93.08L243.39,92.91L243.45,93.8L243.51,94.74L243.64,92L244.13,93L244.22,93.42L244.44,97.2L244.74,93.07L244.91,93.27L244.97,93.4L245.03,92.74L245.43,95.9L245.5,95.71L245.53,96.86L245.67,98.06L245.92,95.13L246.24,97.25L246.28,97.31L246.52,94.68L246.77,98.19L247.05,96.15L247.08,95.99L247.34,96.65L247.63,95.36L247.73,96.39L247.79,96.36L248.18,93.26L248.57,94.73L248.72,95.45L248.91,95.26L249.06,96.36L249.17,97.06L249.58,101.26L249.96,98.6L250.04,97.42L250.91,105.32L251.04,103.27L251.1,102.28L251.28,102.47L252.33,97.94L252.38,98.03L252.44,98.67L252.65,99.23L252.88,98.36L252.97,97.13L253.46,95.55L253.73,96L253.83,97L254.29,100.01L254.57,99.13L254.69,97.1L254.73,96.4L255.34,97.72L255.45,98.13L255.84,95.58L256.3,96.61L256.41,96.36L256.62,97.19L256.66,97.01L256.8,95.63L256.87,96L257.05,94.36L257.28,94.55L257.33,94.06L257.49,94.4L257.73,93.25L258.15,93.64L258.26,95.04L258.42,93.38L258.86,94.04L259.03,94.61L260.36,89.41L260.47,89.67L260.63,90.2L260.87,90.03L261.66,92.3L261.72,92.27L261.81,91.63L262.31,93.45L262.39,93.21L262.79,93.97L263.04,93.04L263.16,93.2L263.32,94.58L264.29,92.87L264.41,93.23L264.61,94.04L265.12,90.67L265.5,91.99L265.68,92.69L265.76,91.59L266.09,93.09L266.26,91.98L266.43,92.89L266.62,91.59L266.93,93.32L267.02,92.97L267.16,94L267.59,93.75L268.69,97.19L268.74,95.77L268.93,94.67L269.1,96.11L269.36,95.69L269.55,96.28L270.42,94.69L270.53,94.98L270.97,94.41L271.08,94.47L271.2,95.51L271.86,93.64L272.06,94.74L272.22,95.08L272.93,94.38L273.02,93.92L274.01,96.39L274.26,95.58L274.46,95.3L275.42,94.76L275.74,94.11L276.55,92.86L276.65,92.37L277.69,92.88L277.87,92.53L278.11,92.21L278.16,92.96L278.33,93.24L279.28,92.86L279.58,92.18L280.97,94.64L281.06,94.51L281.28,95.02L281.64,94.6L281.89,95.62L282.03,94.93L282.26,96.74L282.43,95.83L282.61,96.06L283.2,95.69L283.49,96.47L283.78,98.84L284.08,97.57L284.25,96.66L284.76,95.74L285.01,96.36L285.25,94.64L285.93,94.51L286.09,93.87L286.94,92.34L287.05,92.54L287.32,92.35L287.56,93.27L288,89.12L288.39,90.59L288.57,90.47L288.95,90.34L289.13,91.22L289.32,90.06L289.82,91.39L290.09,90.79L290.25,90.47L290.44,90.38L290.59,90.88L290.74,91.66L291.05,92.46L291.16,91.81L291.26,91.58L291.69,91.34L291.8,91.65L292.06,90.28L292.24,88.49L292.39,87.63L292.41,87.9L292.95,86.01L293.08,85.77L293.55,87.52L293.71,87.29L293.91,86.48L294.28,89.51L294.73,88.97L294.89,88.7L295.03,88.55L295.18,88.95L295.36,89.85L295.49,89.15L295.8,90.47L295.99,91.12L296.3,90.48L297.13,95.1L297.23,94.84L297.28,93.64L297.52,93.56L297.88,95.76L297.99,94L298.03,93.46L298.58,93.99L298.76,92.52L299.84,96.78L300.05,96.13L300.19,95.81L300.77,94.72L300.88,95.77L301.01,95.91L301.14,95.7L301.29,97.65L301.62,98.28L302.11,96L302.26,96.22L302.7,96.95L303.07,94.17L303.21,94.69L303.36,94.82L304.29,97.49L304.49,96.71L304.58,97.04L304.8,96.14L305.01,96.73L305.11,97.57L305.29,99.02L305.55,96.78L305.65,96.11L306.02,97.47L306.38,94.55L306.64,95.26L306.81,94.79L307.05,94.19L307.19,95.12L307.56,95L307.74,94.79L307.89,94.08L308.15,95.53L308.44,94.51L308.64,94.87L308.82,95.16L309.02,94.4L309.22,93.1L309.38,92.52L309.67,93.38L309.84,94.2L310.65,95.31L310.79,94.82L311.01,94.81L311.89,96.7L312,95.87L312.22,95.87L312.77,97.44L313.15,96.5L313.39,96.09L314.29,97.89L314.37,98.83L314.56,98.85L314.59,98.34L314.65,98.1L315.4,96.94L315.51,97.02L315.69,98.36L315.93,100.57L316.5,100.09L316.61,100.1L317.26,104.36L317.57,102.65L317.65,102.06L318.06,99.47L318.42,99.87L318.52,100.59L318.66,100.36L319.15,103.55L319.25,102.46L319.33,100.94L320.22,97.14L320.29,97.35L321.59,101.73L321.69,100.4L321.88,102.11L322.22,99.94L322.31,100.8L322.48,99.36L322.59,100.14L322.83,98.26L323.01,98.37L323.17,98.28L323.35,98.1L323.46,98.5L323.63,97.13L323.71,96.79L324.01,97.97L324.18,98.2L324.32,98.26L324.52,97.05L324.79,96.23L325.04,96.55L325.22,97.41L326.18,98.83L326.31,98.71L326.42,97.86L326.64,97.25L326.87,98.24L326.98,97.63L327.17,97.13L327.48,98L327.69,96.69L327.83,96.61L327.99,97.29L328.16,97.25L328.29,97.93L328.8,94.82L329.43,95.14L329.46,95.35L329.86,96.06L329.97,95L330.07,94.76L330.78,94.93L330.9,93.77L331.12,93.35L331.25,93.69L331.56,93.45L331.73,92.57L332.06,93.42L332.22,92.38L333.33,89.34L333.46,90.39L333.55,91.23L333.9,87.85L334.36,88.81L334.44,89.26L335.11,88.3L335.26,88.35L335.37,88.84L336.67,92.81L336.75,92.72L337.45,95.43L337.88,94.77L337.95,92.99L338.04,92.23L338.05,90.74L338.47,74.92L338.85,81.17L338.89,82.31L339.43,77.55L339.69,78.44L339.75,79.4L340.64,73.05L340.83,74.49L340.91,78.25L341.03,79.14L341.2,76.99L341.46,77.86L341.53,78.73L341.68,77.01L342.09,81.02L342.12,82.12L342.27,80.5L342.79,84.49L342.85,84.2L342.88,84.95L342.9,83.78L343.53,89.38L343.55,89.85L343.93,85.46L344.37,86.61L344.45,86.6L344.69,84.17L345.07,86.94L345.16,88.2L345.33,88.96L345.69,85.74L346.15,85.99L346.31,86.75L347.46,92.12L347.55,90.93L348.45,88.98L348.47,89.78L348.59,90.9L349.11,89.15L349.31,89.8L349.38,90.25L349.62,87.44L349.73,88.03L349.83,88.16L349.94,89.15L350.42,87.37L350.6,88.86L350.67,88.22L350.94,87.17L351.2,87.89L351.33,89.36L351.66,89.88L352.36,87.83L352.54,87.52L352.99,88.15L353.18,87.43L353.38,86.89L353.65,89.55L354.18,88.22L354.29,87.77L354.87,87.19L355.09,88.14L355.48,87.1L355.9,87.92L356.13,87.63L356.64,86.29L356.86,87.09L357.16,87.38L358.21,88.62L358.48,88.11L358.78,89.08L359.1,88.53L359.38,88.13L360.33,89.71L360.56,89.22L361.5,90.18L361.56,89.39L362.29,90.64L362.51,90.21L362.6,89.78L362.96,89.7L363.11,90.12L363.43,90.39L363.77,88.08L364.11,89.32L364.31,89.51L364.93,90.3L365.07,91.6L365.3,93.13L365.65,92.43L365.8,92.16L366.23,92.54L366.37,93.72L366.47,94.42L366.94,92.58L367.06,92.94L368.31,92.86L368.6,91.63L369.21,91.09L369.44,93.05L369.63,93.99L370.01,92.07L370.18,91.36L370.51,89.5L371,89.96L371.2,89.62L371.53,88.86L371.67,89.83L372.61,88.27L372.79,89.57L372.86,90.57L373.56,89.06L373.76,87.98L373.96,86.15L374.56,87.12L374.67,87.97L374.91,88.3L375.26,87.61L375.38,87.24L376.44,90.08L376.53,89.93L376.6,89.02L377.34,91.36L377.42,90.74L377.54,90.18L377.98,89.9L378.2,89.14L378.36,88.41L378.88,89.05L379.11,88.62L379.8,89.11L380.09,89.54L380.32,89.32L380.55,90.19L381.38,89.01L381.51,88.4L381.94,89.62L382.43,89.39L382.74,89.69L383.01,90.08L383.4,89.06L384.67,87.56L384.81,87.2L384.91,87.9L385.28,87.06L385.56,87.79L385.7,86.91L385.97,82.82L386.48,84.17L386.55,84.08L387.34,86.26L387.56,85.8L387.79,85.39L387.94,84.31L388.11,85.57L388.27,85.49L388.46,86.03L388.54,86.72L388.99,84.51L389.14,86.32L389.3,86.33L389.59,84.55L390.19,85.51L390.43,85.08L391.29,81.98L391.69,82.28L391.83,82.95L391.98,82.39L392.58,82.86L392.81,83.06L393.25,83.6L393.36,82.06L393.6,80.94L394.04,81.76L394.17,82L394.58,82.05L394.79,81.1L395.31,79.09L395.65,79.52L395.81,80.02L396.03,80.31L396.26,79.5L396.42,79.14L397.9,82.74L398.22,82.59L398.34,82.17L400.16,79.47L400.29,79.55L400.46,80.15L401.64,77.72L401.8,77.89L401.91,78.33L402.04,78.09L402.18,78.21L402.32,79.2L402.59,77.76L402.96,78.62L403.14,79.12L405.73,74.22L405.8,75.06L405.9,75.02L406.03,73.75L406.36,76.05L406.64,75.02L406.77,76.07L407.15,76.8L407.72,75.31L407.86,75.82L408.02,76.36L408.31,74.91L408.44,74.95L409.15,74.68L409.27,73.69L409.41,72.44L409.62,75.32L409.66,76.72L409.7,76.38L409.79,78.47L410.3,76.8L410.43,75.86L410.8,75.46L411.19,77.84L411.25,76.48L411.38,75.99L411.5,75.88L411.62,76.31L411.77,77.25L412.12,76.15L412.4,77.77L412.49,77.83L412.85,80.68L413.25,79.32L413.39,79.21L414.31,77.17L414.36,77.3L414.44,78.43L415.15,75.81L415.42,76.86L415.62,76.14L416.27,77.92L416.48,77.43L416.64,77.15L416.89,78.59L417.28,77.81L417.52,77.52L417.96,79.36L418.27,78.84L418.5,78.28L418.91,77.14L419.29,77.29L419.52,77.94L421.08,75.72L421.2,76.66L421.51,75.8L421.86,77.01L422.1,77.1L422.71,75.85L422.86,76.06L423.11,76.04L424.01,73.92L424.05,74.23L424.13,74.74L424.75,73.8L424.89,74.36L425.02,75L425.09,75.87L425.21,74.73L425.63,75.27L425.82,75.24L426.62,77.47L426.78,76.28L426.96,76.34L428.83,74.21L429.03,73.57L429.14,73.59L429.76,70.05L429.88,70.44L429.91,71.7L429.98,73.63L430.44,69.97L430.54,70.26L430.63,69.45L430.98,70.93L431.2,70.68L431.44,71.76L433.12,69.32L433.21,69.75L433.33,70.12L433.89,68.62L434.17,69.17L434.29,68.84L434.64,66.89L435.26,67.1L435.35,67.44L435.46,68.13L436.02,67.07L436.14,66.61L436.4,67.23L436.52,66.54L436.62,66.25L436.99,64.89L437.21,65.74L437.29,66.27L437.4,65.96L437.53,66.57L437.79,66.2L437.93,66.97L438.24,66.74L438.7,67.86L438.82,67.5L439.04,69.17L439.47,67.65L439.56,67.33L439.99,66.66L440.94,71.92L441.09,70.84L441.16,70L441.28,69.88L441.39,70.25L441.69,70.4L441.84,71.74L442.08,73.33L442.58,72.16L442.71,72.53L443.15,73.54L443.24,74.27L443.3,74.69L443.72,72.76L443.82,73.09L443.97,73.42L445.3,69.83L445.41,69.76L445.71,69.37L446.36,70.81L446.51,71.3L446.7,71.91L446.93,70.77L447,71.97L447.09,72.55L447.22,72.71L447.3,72.17L447.45,71.18L448.55,75.67L448.67,75.19L448.72,74.56L449.05,76.84L449.46,74.5L449.61,74.91L449.82,75.36L450,74.57L450.2,73.83L450.48,73.57L450.66,73.88L450.85,75.27L451.23,73.3L451.4,72.87L451.49,73.42L451.67,72.82L452.07,73.18L452.3,72L452.52,71.52L452.96,71.98L453.11,72.35L453.62,73L453.76,73.26L453.93,73.04L454.14,73.91L454.32,73.6L454.46,73.65L454.81,74.59L454.89,73.25L455.01,72.93L455.43,72.79L455.63,72.4L456.59,70.31L456.67,70.76L456.84,70.67L457.87,71.32L458.04,70.44L458.8,70.17L458.91,70.65L458.96,70.97L459.12,68.95L459.22,66.35L459.56,51.85L460.06,55.66L460.09,55.91L460.17,57.51L460.48,54.9L460.7,56.03L460.76,53.75L461.41,58.95L461.54,57.4L461.63,57.53L462,56.88L462.19,59.23L462.42,58.15L462.53,57.39L462.64,58.48L463.08,55.84L463.11,56.28L463.16,53.78L463.31,54.73L463.55,52.43L463.69,52.87L463.78,51.87L463.92,53.21L464.85,42.57L464.9,44.75L464.94,45.21L465.16,44.23L465.56,47.92L465.6,47.02L465.66,47.75L466.27,48.64L466.57,45.67L466.66,45.85L466.81,45.29L466.95,46.56L467.09,46.27L467.22,44.77L467.45,45.71L468.25,40.43L468.46,41.78L468.54,42.52L468.81,41.27L468.94,43.95L468.98,44.43L469.25,43.91L469.33,44.67L469.41,44.49L469.52,45.88L469.85,45.81L470.21,48.71L470.29,48.31L470.36,47.18L470.78,45.31L470.99,46.41L471.08,47.64L471.26,50.47L471.59,47.67L471.67,46.33L471.71,47.05L472.18,45.33L472.31,46.35L472.41,44.47L472.46,44.12L472.82,46.63L472.86,46.22L472.91,46.7L473.05,44.67L473.36,45.21L473.45,46.65L473.52,46.82L473.62,46.05L473.73,45.36L474.01,42.71L474.2,43.82L474.32,44.49L474.61,43.74L474.7,45.24L474.81,44.68L474.92,43.11L475.07,43.06L475.12,43.79L475.23,43.81L475.34,42.68L475.77,45.65L475.89,44.56L476.07,44.6L476.75,46.84L476.83,45.19L476.89,44.92L477.28,47.48L477.69,46.07L477.8,45.55L477.97,45.48L478.12,46.16L478.17,46.78L478.27,45.09L478.77,48.71L478.82,48.44L478.86,47.86L479.1,47.88L479.24,46.8L479.58,47.04L480.46,44.76L480.71,45.14L480.78,46.39L481.83,43.55L481.93,44.95L481.98,45.31L483.01,52.17L483.13,48.74L483.18,47.97L484,50.92L484.03,50.07L484.56,55.15L484.86,53.12L484.95,52.11L485.15,52.64L485.48,51.07L485.55,51.34L485.67,51.11L485.77,50.8L486.21,51.79L486.29,52.36L486.56,50.7L486.84,51.77L486.99,52.35L487.11,53.1L487.47,51.25L487.6,50.86L488.34,50.38L488.48,51.67L488.83,51.24L489.19,54.09L489.27,53.38L489.41,52.67L490.11,51.35L490.29,51.59L490.57,49.68L490.59,49.2L491.18,52.67L491.37,51.52L491.74,52.87L491.95,52.62L492.08,50.79L492.62,52.11L492.72,52.02L492.87,51.04L493.14,51.39L493.29,50.97L493.4,49.98L494.06,46.61L494.48,46.76L494.55,47.96L495.35,39.25L495.46,41.73L495.52,41.67L495.64,42.74L496.07,40.24L496.18,41.23L496.25,41.42L496.55,40.2L496.86,42.29L496.95,42.66L497.16,43.59L497.75,41.04L497.84,41.59L497.9,42.21L498.3,41.08L498.52,41.83L498.59,40.82L498.79,38.51L498.9,41.01L498.97,42.97L499.19,45.33L499.73,43.47L499.82,42.72L500.65,37.47L500.95,39.59L501.01,41.2L501.36,39.41L501.7,40.52L501.83,41.47L502.14,41.5L502.26,42.67L502.4,42.17L502.57,43.54L502.7,44.41L503.01,42.63L503.45,43.93L503.57,44.74L503.78,42.34L504.4,42.91L504.52,42.94L504.72,42.31L504.97,43.81L505.18,43.02L505.35,43.19L506.25,41.51L506.29,41.97L506.44,42.46L506.6,42.48L506.67,41.22L507.07,40.53L507.79,44.49L507.83,46.02L507.89,46.79L508.56,43.22L508.66,42.36L508.74,41.07L509.43,41.86L509.57,43.11L509.72,42.69L509.81,43.96L510.26,43.39L510.44,43.59L511.3,40.81L511.68,41.28L511.97,42.12L512.32,43.31L512.7,42.49L512.87,41.86L513.5,41.94L513.74,41.07L513.88,40.75L514.3,41.58L514.48,41.6L514.65,41.32L514.9,41.6L515.14,42.69L515.3,41.17L515.86,42.28L516.05,42.46L516.46,44.99L516.83,42.82L517,42.74L517.99,46.31L518.09,45.25L518.15,44.69L518.31,46.45L518.63,43.96L518.89,45.56L518.96,44.42L519.2,44.22L519.61,45.28L519.71,44.9L519.85,43.74L520,44.26L520.46,43.61L520.57,43.72L520.65,44.33L520.74,43.43L521.19,44.4L521.36,44.94L521.68,45L521.91,44.26L522.09,44.76L522.27,44.88L522.7,44.43L522.91,44.85L523.12,43.78L523.3,43.28L523.53,44.44L523.76,43.52L523.97,43.9L525.02,42.19L525.23,43.09L525.31,42.12L526,42.75L526.27,43.06L526.4,43.19L526.6,42.5L526.78,42.12L527.28,38.4L527.31,38.8L527.34,37.91L527.36,36.44L527.84,38.78L528.09,37.52L528.17,38.71L529.21,36.84L529.28,37.12L529.39,37.19L529.47,36.67L529.85,38.21L530.07,37.43L530.21,37.32L530.49,35.27L530.94,36.72L531.03,36.72L532.08,40.08L532.19,39.52L532.31,38.86L532.72,37.25L533.01,37.86L533.18,38.34L533.37,38.33L533.56,39.25L534.53,37.87L534.73,37.92L535.09,38.22L535.33,37.09L535.51,36.93L535.77,37.54L535.94,38.25L536.49,37.78L537.09,41.94L537.12,40.58L537.17,40.34L537.44,45.21L537.47,48.48L537.92,43.72L538.18,44.59L538.32,45.61L538.56,46.39L538.65,44.87L538.95,46.04L539.06,45.8L539.93,43.33L540.03,43.6L540.68,42.21L540.87,42.49L541.01,43.6L541.91,41.45L542.01,41.57L542.49,42.33L542.59,41.72L542.71,40.92L542.79,40.21L543.02,41.14L543.27,41.13L543.4,41.68L543.69,42.41L543.84,41.57L543.96,41.32L544.84,38.55L545.09,39.19L545.21,39.19L545.75,39.12L545.93,38.65L546.53,39.04L546.72,40.12L546.89,39.19L547.21,40.9L547.27,41.73L547.77,39.82L548.01,40.93L548.11,41.1L548.49,43.96L548.58,41.89L548.64,41.75L549.15,40.23L549.26,39.31L549.4,39.58L549.66,38.73L549.85,37.78L550.25,33.98L550.61,36.24L550.71,37.17L550.79,36.22L551.37,38.13L551.39,38.96L552.18,36.68L552.24,37.28L552.83,37.6L553,36.6L553.15,36.94L554.07,38.72L554.2,38.01L554.25,37.12L554.45,32.41L554.97,37.13L555,37.16L555.18,38.09L555.79,36.26L555.88,36.67L557.23,41.33L557.3,40.04L557.35,39.72L557.97,38.48L558.06,39.78L558.18,40.1L558.32,39.99L558.44,38.6L558.77,39.3L559.05,38.75L559.21,38.39L560.35,35.9L560.49,36.58L560.59,37.39L561.32,33.58L561.46,34.7L561.54,35.25L561.83,36.4L561.96,35.65L562.06,34.78L562.37,36.83L562.74,35.49L562.89,35.56L564.52,29.84L564.62,30.4L564.99,28.73L565.34,29.26L565.43,29.98L565.94,28.45L566.3,29.17L566.39,30.45L566.83,31.82L567.02,30.05L567.09,30.17L567.36,31.26L567.6,29.24L567.64,28.8L568.15,31.09L568.36,30.61L568.49,29.92L568.96,29.38L569.05,28.99L569.37,29.25L570.19,25.67L570.33,26.09L570.42,26.47L570.79,25.58L570.89,26.32L570.99,27.05L572.17,25.72L572.31,26.21L572.96,27.08L573.11,26.76L573.22,26.03L573.55,26.77L573.77,26.97L574.06,27.82L574.32,26.82L574.5,26.59L575.13,26.88L575.37,27.66L575.68,28.45L575.71,28.83L575.76,29.11L576,27.11L576.26,28.26L576.35,27.63L576.49,28.94L577.09,27.51L577.21,28.17L577.51,28.79L577.61,28.91L577.82,29.19L577.86,29.92L578.11,30.82L578.61,28.53L578.74,28.32L579.44,26.86L579.58,27.31L579.67,28.11L579.83,28.8L580.31,27.44L580.43,27.73L581.13,26.86L581.26,27.52L581.46,27.87L581.68,27.74L581.92,28.72L582.65,26.66L582.85,27.11L583.49,28.89L583.82,28.64L583.99,28.48L584.08,27.81L584.48,29.59L584.61,29.11L584.74,29.83L585.03,31.14L585.38,29.79L585.49,29.4L586.17,30.28L586.27,30.2L586.36,29.56L588.45,26.32L588.48,24.89L588.59,23.96L588.83,25.15L589.14,24.08L589.32,24.92L589.55,24.54L589.82,25.15L589.99,25.43L590.44,25.78L590.87,24.12L590.96,24.37L591.05,25.05L592.21,17.84L592.31,18.46L592.35,19.72L593.33,15.95L593.36,15.99L593.41,14.58L593.74,18.08L593.82,16.49L593.89,17.39L593.99,17.53L594.13,16.36L594.51,13.09L594.87,15.37L594.94,16.53L595.89,12.58L595.93,14.28L596,15.85L596.39,11.77L596.6,12.55L596.68,13.28L596.92,12.75L597.83,14.7L597.93,14.2L598.09,13.47L598.36,14.25L598.58,15.08L599.12,14.3L599.33,14.79L599.46,15.1L600.37,16.66L600.48,15.58L600.59,15.93L600.76,15.18L600.93,15.15L601.11,14.17L601.43,14.35L601.57,13.96L601.75,13.39L602.54,8.65L602.75,9.62L602.87,9.47L603.32,12.8L603.42,12.63L603.49,13.89L604.44,9.27L604.55,9.9L604.65,10L605.81,11.6L605.9,11.06L606.03,10.98L606.18,11.54L606.34,12.09L606.62,10.95L607.02,15.54L607.14,15.34L607.15,20.27L607.7,13.45L607.87,15.31L607.97,14.57L609.37,10.95L609.42,11.92L609.75,12.75L609.86,12.54L609.93,11.86L610.3,10.7L610.54,11.93L610.69,11.83L611.65,13.62L611.85,13.39L611.99,12.57L612.94,7.46L613.2,8.52L613.32,9.19L613.75,9.85L613.93,9.11L614.04,10.52L614.14,11.32L614.56,9.66L614.73,9.56L614.82,10.8L615.29,8.89L615.38,9.26L615.48,9.12L615.82,9.91L616,8.81L616.08,8.37L616.16,8.01L616.62,8.72L616.78,8.47L616.98,7.85L617.23,5.7L617.46,6.65L617.6,6.65L617.95,7.07L618.09,8.7L618.32,7.32L618.66,9.17L618.76,8.89L618.91,9.85L619,10.32L619.27,8.67L619.48,8.91L619.62,8.78L620.2,13.53L620.5,10.6L620.55,10.89L620.61,12.23L620.93,9.55L621.2,10.95L621.33,11.41L622.02,16.38L622.22,13.95L622.3,14.56L622.62,14.67L623.02,12.84L623.12,14.49L623.76,12.24L623.84,13.44L623.98,14.62L624.03,14.06L624.46,16.73L624.55,16.34L624.61,17.9L624.79,20.54L625.16,16.55L625.36,18.64L625.4,17.83L625.43,16.84L625.86,23.91L625.98,20.91L626.01,22.77L626.19,20.44L626.76,28.99L626.77,28.46L626.78,31.66L626.81,41.14L627.53,21.45L627.69,24L627.73,23.07L627.92,21.48L628.25,26.15L628.39,24.85L628.48,25.62L628.7,28.46L628.93,24.34L628.98,22.58L629.08,23.82L629.56,21.37L629.69,19.92L630.04,21.05L630.24,19.48L630.35,20.1L630.46,18.67L630.61,17.59L630.87,21.18L630.99,20.31L631.13,21.11L631.3,22.62L631.42,21.03L631.52,20.22L632.57,26.13L632.63,25.61L632.68,24.82L633.06,29.86L633.09,30.79L633.54,25.73L633.84,28.42L633.91,30.58L634.34,38.51L634.68,32.99L634.71,31.28L634.75,30.3L635.1,35.93L635.37,33.17L635.4,33.81L635.45,32.88L635.75,40.65L635.79,40.33L635.82,40.98L635.93,38.5L636.21,51.38L636.52,41.37L636.56,40.63L636.65,38.62L636.94,45.56L637.21,43.17L637.25,44.52L637.48,50.92L637.91,42.81L637.93,39.52L637.95,41.23L638.21,35.93L638.62,37.67L638.69,38L639,47.68L639.2,42.18L639.23,40.34L639.44,36.79L639.93,43.02L639.96,43.09L640.31,40.94L640.44,44.19L640.53,43.18L640.6,44.41L640.83,42L641.56,50.01L641.6,46.98L641.62,46.82L641.66,48.67L642.09,39.84L642.19,40.72L642.25,40.95L642.51,41.73L643.14,38.52L643.23,40.38L643.51,37.63L643.71,42.53L643.74,43.82L644.59,32.97L644.67,34.46L644.73,34.3L645.63,30.07L645.7,30.49L645.75,31.94L645.8,31.6L646.22,33.66L646.35,32.89L646.45,32.4L647.05,35.3L647.24,34.25L647.33,33.82L648.36,30.07L648.47,31.34L648.57,31.66L648.93,33.96L649.39,33.3L649.48,31.8L649.76,30.36L649.98,31L650.04,32.36L650.07,32.11L650.11,35.46L650.2,34.66L650.24,37.07L650.4,35.28L650.79,36.45L650.85,38.34L651.15,39.04L651.48,34.23L651.65,35.7L651.72,35.78L651.85,36.21L652.08,34.86L652.18,35.43L652.31,34.54L653.81,38.43L653.9,37.11L654.3,40.29L654.72,38.51L654.8,38.33L655.98,31.64L656.2,31.67L656.33,32.77L656.44,31.57L656.94,32.6L657.1,33.35L657.25,32.83L657.52,34.28L657.58,33.36L657.69,34.5L657.91,35.45L658.14,34.22L658.25,33.73L658.3,34.12L658.5,32.82L658.89,33.58L659.02,32.64L659.71,34.19L659.81,35.11L660.31,38.47L660.61,37.19L660.72,36.15L661.9,30.2L661.91,29.09L661.99,27.2L662.2,30.2L662.47,29.41L662.54,30.58L662.96,30.31L663.33,32.43L663.43,31.7L663.51,30.19L664.84,36.44L664.87,35.97L664.94,34.32L665.71,39.07L665.74,38.32L665.82,37.17L666.07,36.77L666.29,40.01L666.32,40.27L666.46,42.5L666.56,39.1L666.64,38.36L667.4,45.75L667.48,42.79L667.52,44.34L667.66,47.46L668.02,43.99L668.08,43.44L668.36,46.82L668.5,44.29L668.56,43.34L668.62,44.98L668.69,42.29L669.22,43.08L669.33,42.12L670.29,49.17L670.68,47.44L670.77,46.93L670.85,46.66L670.94,48.63L671.01,50.3L671.11,49.25L671.23,54.32L671.45,50.02L671.51,50.18L672.27,46.23L672.32,46.87L672.41,46.5L672.76,45.53L673.04,47.6L673.08,47.28L673.15,48.12L673.55,43.73L673.94,45.84L674.01,47.22L674.39,48.23L674.64,43.51L674.88,45.47L674.92,45.99L675.01,46.39L675.83,39.72L675.93,41.41L676,41.41L677.11,45.36L677.23,44.63L677.31,44.58L678.38,50.53L678.42,49.17L678.49,49.29L679.35,44.97L679.41,45.09L679.54,43.95L680.52,41.13L680.6,42.65L680.68,43.29L681.09,41.52L681.3,43.16L681.39,41.93L681.89,42.51L682,41.91L682.17,41.46L682.34,41.8L682.55,39.96L683.78,46.47L683.89,45.58L684.1,46.45L684.31,44.71L684.46,45.2L684.61,44.77L684.74,45.16L684.88,43.3L684.97,42.76L685.04,42.61L685.21,43.49L685.31,44.43L685.45,44.95L685.48,44.06L685.55,41.81L686,43.15L686.21,42.85L686.36,43.45L687.17,46.69L687.32,45.07L687.44,45.63L688.47,43.46L688.58,43.86L688.77,43.41L689.15,42.83L689.26,43.14L689.44,44.32L689.73,44.02L689.98,45.34L690.11,45.26L690.22,45.92L690.35,46L690.66,48.01L690.73,48.91L690.93,51.01L691.33,46.3L691.38,46.89L691.44,47.83L691.54,46.11L692.16,46.36L692.28,47.75L693.63,53.35L693.71,52.24L693.8,49.69L694.24,54.29L694.26,53.58L694.28,55.1L694.41,51.68L694.89,52.96L694.97,53.49L696.31,49.89L696.49,50.21L696.6,51.01L696.97,49.83L697.32,51.08L697.35,51.29L698.25,55.25L698.29,54.87L698.32,54.32L698.58,52.67L698.94,56.15L698.95,55.35L698.99,56.66L699.15,57.42L699.19,56.7L699.2,55L699.35,56.81L699.93,56.57L700.03,56.87L700.12,57.43L700.46,55.64L700.59,55.56L700.74,56.16L700.99,54.09L701.06,53.42L701.25,53.32L701.35,53.71L701.54,51.91L701.68,50.18L702.22,50.97L702.43,51.22L702.68,48.66L703.03,51.57L703.09,50.04\" style=\"vector-effect: none; fill: none; stroke: rgb(31, 119, 180); stroke-opacity: 1; stroke-width: 2px; opacity: 1;\"/></g><g class=\"points\"/><g class=\"text\"/></g></g></g></g><path class=\"xlines-above crisp\" d=\"M0,0\" style=\"fill: none;\"/><path class=\"ylines-above crisp\" d=\"M0,0\" style=\"fill: none;\"/><g class=\"overlines-above\"><path class=\"xy2-x crisp\" d=\"M0,0\" style=\"fill: none;\"/><path class=\"xy2-y crisp\" d=\"M0,0\" style=\"fill: none;\"/></g><g class=\"xaxislayer-above\"><g class=\"xtick\"><text text-anchor=\"middle\" x=\"0\" y=\"170\" transform=\"translate(69.9,0)\" style=\"font-family: 'Open Sans', verdana, arial, sans-serif; font-size: 12px; fill: rgb(214, 223, 239); fill-opacity: 1; white-space: pre; opacity: 1;\"><tspan class=\"line\" dy=\"0em\" x=\"0\" y=\"170\">Jan 3</tspan><tspan class=\"line\" dy=\"1.3em\" x=\"0\" y=\"170\">2021</tspan></text></g><g class=\"xtick\"><text text-anchor=\"middle\" x=\"0\" y=\"170\" style=\"font-family: 'Open Sans', verdana, arial, sans-serif; font-size: 12px; fill: rgb(214, 223, 239); fill-opacity: 1; white-space: pre; opacity: 1;\" transform=\"translate(153.31,0)\">Jan 10</text></g><g class=\"xtick\"><text text-anchor=\"middle\" x=\"0\" y=\"170\" style=\"font-family: 'Open Sans', verdana, arial, sans-serif; font-size: 12px; fill: rgb(214, 223, 239); fill-opacity: 1; white-space: pre; opacity: 1;\" transform=\"translate(236.73,0)\">Jan 17</text></g><g class=\"xtick\"><text text-anchor=\"middle\" x=\"0\" y=\"170\" style=\"font-family: 'Open Sans', verdana, arial, sans-serif; font-size: 12px; fill: rgb(214, 223, 239); fill-opacity: 1; white-space: pre; opacity: 1;\" transform=\"translate(320.15,0)\">Jan 24</text></g><g class=\"xtick\"><text text-anchor=\"middle\" x=\"0\" y=\"170\" style=\"font-family: 'Open Sans', verdana, arial, sans-serif; font-size: 12px; fill: rgb(214, 223, 239); fill-opacity: 1; white-space: pre; opacity: 1;\" transform=\"translate(403.57,0)\">Jan 31</text></g><g class=\"xtick\"><text text-anchor=\"middle\" x=\"0\" y=\"170\" style=\"font-family: 'Open Sans', verdana, arial, sans-serif; font-size: 12px; fill: rgb(214, 223, 239); fill-opacity: 1; white-space: pre; opacity: 1;\" transform=\"translate(486.99,0)\">Feb 7</text></g><g class=\"xtick\"><text text-anchor=\"middle\" x=\"0\" y=\"170\" style=\"font-family: 'Open Sans', verdana, arial, sans-serif; font-size: 12px; fill: rgb(214, 223, 239); fill-opacity: 1; white-space: pre; opacity: 1;\" transform=\"translate(570.4,0)\">Feb 14</text></g><g class=\"xtick\"><text text-anchor=\"middle\" x=\"0\" y=\"170\" style=\"font-family: 'Open Sans', verdana, arial, sans-serif; font-size: 12px; fill: rgb(214, 223, 239); fill-opacity: 1; white-space: pre; opacity: 1;\" transform=\"translate(653.82,0)\">Feb 21</text></g><g class=\"xtick\"><text text-anchor=\"middle\" x=\"0\" y=\"170\" style=\"font-family: 'Open Sans', verdana, arial, sans-serif; font-size: 12px; fill: rgb(214, 223, 239); fill-opacity: 1; white-space: pre; opacity: 1;\" transform=\"translate(737.24,0)\">Feb 28</text></g></g><g class=\"yaxislayer-above\"><g class=\"ytick\"><text text-anchor=\"end\" x=\"45\" y=\"4.199999999999999\" transform=\"translate(0,100)\" style=\"font-family: 'Open Sans', verdana, arial, sans-serif; font-size: 12px; fill: rgb(214, 223, 239); fill-opacity: 1; white-space: pre; opacity: 1;\">preds</text></g></g><g class=\"overaxes-above\"><g class=\"xy2-x\"/><g class=\"xy2-y\"><g class=\"y2tick\"><text text-anchor=\"start\" x=\"750.12\" y=\"4.199999999999999\" transform=\"translate(0,145.13)\" style=\"font-family: 'Open Sans', verdana, arial, sans-serif; font-size: 12px; fill: rgb(214, 223, 239); fill-opacity: 1; white-space: pre; opacity: 1;\">30k</text></g><g class=\"y2tick\"><text text-anchor=\"start\" x=\"750.12\" y=\"4.199999999999999\" style=\"font-family: 'Open Sans', verdana, arial, sans-serif; font-size: 12px; fill: rgb(214, 223, 239); fill-opacity: 1; white-space: pre; opacity: 1;\" transform=\"translate(0,111.25)\">40k</text></g><g class=\"y2tick\"><text text-anchor=\"start\" x=\"750.12\" y=\"4.199999999999999\" style=\"font-family: 'Open Sans', verdana, arial, sans-serif; font-size: 12px; fill: rgb(214, 223, 239); fill-opacity: 1; white-space: pre; opacity: 1;\" transform=\"translate(0,77.37)\">50k</text></g><g class=\"y2tick\"><text text-anchor=\"start\" x=\"750.12\" y=\"4.199999999999999\" style=\"font-family: 'Open Sans', verdana, arial, sans-serif; font-size: 12px; fill: rgb(214, 223, 239); fill-opacity: 1; white-space: pre; opacity: 1;\" transform=\"translate(0,43.48)\">60k</text></g></g></g></g><g class=\"subplot xy2\"/></g><g class=\"polarlayer\"/><g class=\"smithlayer\"/><g class=\"ternarylayer\"/><g class=\"geolayer\"/><g class=\"funnelarealayer\"/><g class=\"pielayer\"/><g class=\"iciclelayer\"/><g class=\"treemaplayer\"/><g class=\"sunburstlayer\"/><g class=\"glimages\"/><defs id=\"topdefs-116e2b\"><g class=\"clips\"/><clipPath id=\"legend116e2b\"><rect width=\"78\" height=\"29\" x=\"0\" y=\"0\"/></clipPath></defs><g class=\"layer-above\"><g class=\"imagelayer\"/><g class=\"shapelayer\"/></g><g class=\"infolayer\"><g class=\"legend\" pointer-events=\"all\" transform=\"translate(716,11.719999999999999)\"><rect class=\"bg\" shape-rendering=\"crispEdges\" width=\"78\" height=\"29\" x=\"0\" y=\"0\" style=\"stroke: rgb(68, 68, 68); stroke-opacity: 1; fill: rgb(33, 34, 38); fill-opacity: 1; stroke-width: 0px;\"/><g class=\"scrollbox\" transform=\"\" clip-path=\"url(#legend116e2b)\"><g class=\"groups\"><g class=\"traces\" transform=\"translate(0,14.5)\" style=\"opacity: 1;\"><text class=\"legendtext\" text-anchor=\"start\" x=\"40\" y=\"4.680000000000001\" style=\"font-family: 'Open Sans', verdana, arial, sans-serif; font-size: 12px; fill: rgb(214, 223, 239); fill-opacity: 1; white-space: pre;\">Close</text><g class=\"layers\" style=\"opacity: 1;\"><g class=\"legendfill\"/><g class=\"legendlines\"><path class=\"js-line\" d=\"M5,0h30\" style=\"fill: none; stroke: rgb(31, 119, 180); stroke-opacity: 1; stroke-width: 2px;\"/></g><g class=\"legendsymbols\"><g class=\"legendpoints\"/></g></g><rect class=\"legendtoggle\" x=\"0\" y=\"-9.5\" width=\"74.859375\" height=\"19\" style=\"fill: rgb(0, 0, 0); fill-opacity: 0;\"/></g></g></g><rect class=\"scrollbar\" rx=\"20\" ry=\"3\" width=\"0\" height=\"0\" x=\"0\" y=\"0\" style=\"fill: rgb(128, 139, 164); fill-opacity: 1;\"/></g><g class=\"cb3ecafdc6-ccff-492f-8f39-0fcb28fbe957 colorbar\" transform=\"translate(46,43)\"><rect class=\"cbbg\" x=\"763\" y=\"0\" width=\"79.453125\" height=\"114\" style=\"fill: rgb(0, 0, 0); fill-opacity: 0; stroke: rgb(68, 68, 68); stroke-opacity: 1; stroke-width: 0;\"/><g class=\"cbfills\" transform=\"translate(0,10)\"><rect class=\"cbfill gradient_filled\" x=\"773\" y=\"0\" width=\"30\" height=\"94\" style=\"fill: url('#g116e2b-cb3ecafdc6-ccff-492f-8f39-0fcb28fbe957');\"/></g><g class=\"cblines\" transform=\"translate(0,10)\"/><g class=\"cbaxis crisp\" transform=\"translate(0,-43)\"><g class=\"ycb3ecafdc6-ccff-492f-8f39-0fcb28fbe957tick\"><text text-anchor=\"start\" x=\"805.9\" y=\"4.199999999999999\" transform=\"translate(0,117.96000000000001)\" style=\"font-family: 'Open Sans', verdana, arial, sans-serif; font-size: 12px; fill: rgb(214, 223, 239); fill-opacity: 1; white-space: pre; opacity: 1;\">âˆ’0.1</text></g><g class=\"ycb3ecafdc6-ccff-492f-8f39-0fcb28fbe957tick\"><text text-anchor=\"start\" x=\"805.9\" y=\"4.199999999999999\" style=\"font-family: 'Open Sans', verdana, arial, sans-serif; font-size: 12px; fill: rgb(214, 223, 239); fill-opacity: 1; white-space: pre; opacity: 1;\" transform=\"translate(0,87.29)\">0</text></g><g class=\"ycb3ecafdc6-ccff-492f-8f39-0fcb28fbe957tick\"><text text-anchor=\"start\" x=\"805.9\" y=\"4.199999999999999\" style=\"font-family: 'Open Sans', verdana, arial, sans-serif; font-size: 12px; fill: rgb(214, 223, 239); fill-opacity: 1; white-space: pre; opacity: 1;\" transform=\"translate(0,56.63000000000001)\">0.1</text></g></g><g class=\"cbtitleunshift\" transform=\"translate(-46,-43)\"><g class=\"cbtitle\"/></g><rect class=\"cboutline\" x=\"773\" y=\"10\" width=\"30\" height=\"94\" style=\"stroke: rgb(68, 68, 68); stroke-opacity: 1; fill: none; stroke-width: 0;\"/></g><g class=\"g-gtitle\"/><g class=\"g-xtitle\"/><g class=\"g-ytitle\"/><g class=\"g-y2title\"/></g></svg>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Fit and predict with the best estimator\n",
    "test_labels = []\n",
    "test_preds = []\n",
    "for split in X_slices.index.unique(level=\"split\"):  \n",
    "    X_train_slice = X_slices[(split, \"train\")]  \n",
    "    y_train_slice = y_slices[(split, \"train\")]\n",
    "    X_test_slice = X_slices[(split, \"test\")]\n",
    "    y_test_slice = y_slices[(split, \"test\")]\n",
    "\n",
    "    slice_pipeline = random_search.best_estimator_.fit(X_train_slice, y_train_slice)  \n",
    "    test_pred = slice_pipeline.predict(X_test_slice)  \n",
    "    test_pred = pd.Series(test_pred, index=y_test_slice.index)\n",
    "    test_labels.append(y_test_slice)\n",
    "    test_preds.append(test_pred)\n",
    "\n",
    "test_labels = pd.concat(test_labels).rename(\"labels\")  \n",
    "test_preds = pd.concat(test_preds).rename(\"preds\")\n",
    "\n",
    "# Show the accuracy of the predictions\n",
    "# Assuming test_labels and test_preds are your true and predicted values\n",
    "mse = mean_squared_error(test_labels, test_preds)\n",
    "rmse = np.sqrt(mse)  # or use mean_squared_error with squared=False\n",
    "mae = mean_absolute_error(test_labels, test_preds)\n",
    "r2 = r2_score(test_labels, test_preds)\n",
    "\n",
    "print(f\"Mean Squared Error (MSE): {mse}\")\n",
    "print(f\"Root Mean Squared Error (RMSE): {rmse}\")\n",
    "print(f\"Mean Absolute Error (MAE): {mae}\")\n",
    "print(f\"R-squared: {r2}\")\n",
    "\n",
    "# Visualize the predictions as a heatmap plotted against the price\n",
    "data.close.vbt.overlay_with_heatmap(test_preds).show_svg()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "58082fd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start                         2021-01-05 00:43:00+00:00\n",
      "End                           2021-02-26 20:44:00+00:00\n",
      "Period                                             7400\n",
      "Start Value                                       100.0\n",
      "Min Value                                     97.786713\n",
      "Max Value                                    127.232238\n",
      "End Value                                    117.421212\n",
      "Total Return [%]                              17.421212\n",
      "Benchmark Return [%]                          43.421736\n",
      "Total Time Exposure [%]                       19.864865\n",
      "Max Gross Exposure [%]                            100.0\n",
      "Max Drawdown [%]                              23.143133\n",
      "Max Drawdown Duration                            6461.0\n",
      "Total Orders                                        128\n",
      "Total Fees Paid                                     0.0\n",
      "Total Trades                                         64\n",
      "Win Rate [%]                                     40.625\n",
      "Best Trade [%]                                20.707568\n",
      "Worst Trade [%]                               -2.448487\n",
      "Avg Winning Trade [%]                          2.252628\n",
      "Avg Losing Trade [%]                           -1.03915\n",
      "Avg Winning Trade Duration                    38.961538\n",
      "Avg Losing Trade Duration                     12.026316\n",
      "Profit Factor                                    1.3966\n",
      "Expectancy                                     0.272206\n",
      "dtype: object\n"
     ]
    },
    {
     "data": {
      "image/svg+xml": [
       "<svg class=\"main-svg\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" width=\"850\" height=\"510\" style=\"\" viewBox=\"0 0 850 510\"><rect x=\"0\" y=\"0\" width=\"850\" height=\"510\" style=\"fill: rgb(33, 34, 38); fill-opacity: 1;\"/><defs id=\"defs-b122c5\"><g class=\"clips\"><clipPath id=\"clipb122c5xyplot\" class=\"plotclip\"><rect width=\"734\" height=\"104.54901960784314\"/></clipPath><clipPath id=\"clipb122c5x2y2plot\" class=\"plotclip\"><rect width=\"734\" height=\"104.54901960784312\"/></clipPath><clipPath id=\"clipb122c5x3y3plot\" class=\"plotclip\"><rect width=\"734\" height=\"104.54901960784314\"/></clipPath><clipPath class=\"axesclip\" id=\"clipb122c5x\"><rect x=\"86\" y=\"0\" width=\"734\" height=\"510\"/></clipPath><clipPath class=\"axesclip\" id=\"clipb122c5y\"><rect x=\"0\" y=\"70\" width=\"850\" height=\"104.54901960784314\"/></clipPath><clipPath class=\"axesclip\" id=\"clipb122c5xy\"><rect x=\"86\" y=\"70\" width=\"734\" height=\"104.54901960784314\"/></clipPath><clipPath class=\"axesclip\" id=\"clipb122c5y2\"><rect x=\"0\" y=\"203.72549019607845\" width=\"850\" height=\"104.54901960784312\"/></clipPath><clipPath class=\"axesclip\" id=\"clipb122c5xy2\"><rect x=\"86\" y=\"203.72549019607845\" width=\"734\" height=\"104.54901960784312\"/></clipPath><clipPath class=\"axesclip\" id=\"clipb122c5y3\"><rect x=\"0\" y=\"337.45098039215685\" width=\"850\" height=\"104.54901960784314\"/></clipPath><clipPath class=\"axesclip\" id=\"clipb122c5xy3\"><rect x=\"86\" y=\"337.45098039215685\" width=\"734\" height=\"104.54901960784314\"/></clipPath><clipPath class=\"axesclip\" id=\"clipb122c5x2\"><rect x=\"86\" y=\"0\" width=\"734\" height=\"510\"/></clipPath><clipPath class=\"axesclip\" id=\"clipb122c5x2y\"><rect x=\"86\" y=\"70\" width=\"734\" height=\"104.54901960784314\"/></clipPath><clipPath class=\"axesclip\" id=\"clipb122c5x2y2\"><rect x=\"86\" y=\"203.72549019607845\" width=\"734\" height=\"104.54901960784312\"/></clipPath><clipPath class=\"axesclip\" id=\"clipb122c5x2y3\"><rect x=\"86\" y=\"337.45098039215685\" width=\"734\" height=\"104.54901960784314\"/></clipPath><clipPath class=\"axesclip\" id=\"clipb122c5x3\"><rect x=\"86\" y=\"0\" width=\"734\" height=\"510\"/></clipPath><clipPath class=\"axesclip\" id=\"clipb122c5x3y\"><rect x=\"86\" y=\"70\" width=\"734\" height=\"104.54901960784314\"/></clipPath><clipPath class=\"axesclip\" id=\"clipb122c5x3y2\"><rect x=\"86\" y=\"203.72549019607845\" width=\"734\" height=\"104.54901960784312\"/></clipPath><clipPath class=\"axesclip\" id=\"clipb122c5x3y3\"><rect x=\"86\" y=\"337.45098039215685\" width=\"734\" height=\"104.54901960784314\"/></clipPath></g><g class=\"gradients\"/><g class=\"patterns\"/></defs><g class=\"bglayer\"/><g class=\"layer-below\"><g class=\"imagelayer\"/><g class=\"shapelayer\"/></g><g class=\"cartesianlayer\"><g class=\"subplot xy\"><g class=\"layer-subplot\"><g class=\"shapelayer\"/><g class=\"imagelayer\"/></g><g class=\"minor-gridlayer\"><g class=\"x\"/><g class=\"y\"/></g><g class=\"gridlayer\"><g class=\"x\"><path class=\"xgrid crisp\" transform=\"translate(174.66,0)\" d=\"M0,70v104.54901960784314\" style=\"stroke: rgb(49, 52, 57); stroke-opacity: 1; stroke-width: 1px;\"/><path class=\"xgrid crisp\" transform=\"translate(266.08000000000004,0)\" d=\"M0,70v104.54901960784314\" style=\"stroke: rgb(49, 52, 57); stroke-opacity: 1; stroke-width: 1px;\"/><path class=\"xgrid crisp\" transform=\"translate(357.49,0)\" d=\"M0,70v104.54901960784314\" style=\"stroke: rgb(49, 52, 57); stroke-opacity: 1; stroke-width: 1px;\"/><path class=\"xgrid crisp\" transform=\"translate(448.91,0)\" d=\"M0,70v104.54901960784314\" style=\"stroke: rgb(49, 52, 57); stroke-opacity: 1; stroke-width: 1px;\"/><path class=\"xgrid crisp\" transform=\"translate(540.3299999999999,0)\" d=\"M0,70v104.54901960784314\" style=\"stroke: rgb(49, 52, 57); stroke-opacity: 1; stroke-width: 1px;\"/><path class=\"xgrid crisp\" transform=\"translate(631.74,0)\" d=\"M0,70v104.54901960784314\" style=\"stroke: rgb(49, 52, 57); stroke-opacity: 1; stroke-width: 1px;\"/><path class=\"xgrid crisp\" transform=\"translate(723.16,0)\" d=\"M0,70v104.54901960784314\" style=\"stroke: rgb(49, 52, 57); stroke-opacity: 1; stroke-width: 1px;\"/><path class=\"xgrid crisp\" transform=\"translate(814.58,0)\" d=\"M0,70v104.54901960784314\" style=\"stroke: rgb(49, 52, 57); stroke-opacity: 1; stroke-width: 1px;\"/></g><g class=\"y\"><path class=\"ygrid crisp\" transform=\"translate(0,166.35)\" d=\"M86,0h734\" style=\"stroke: rgb(49, 52, 57); stroke-opacity: 1; stroke-width: 1px;\"/><path class=\"ygrid crisp\" transform=\"translate(0,134.76999999999998)\" d=\"M86,0h734\" style=\"stroke: rgb(49, 52, 57); stroke-opacity: 1; stroke-width: 1px;\"/><path class=\"ygrid crisp\" transform=\"translate(0,103.18)\" d=\"M86,0h734\" style=\"stroke: rgb(49, 52, 57); stroke-opacity: 1; stroke-width: 1px;\"/><path class=\"ygrid crisp\" transform=\"translate(0,71.6)\" d=\"M86,0h734\" style=\"stroke: rgb(49, 52, 57); stroke-opacity: 1; stroke-width: 1px;\"/></g></g><g class=\"zerolinelayer\"/><path class=\"xlines-below\"/><path class=\"ylines-below\"/><g class=\"overlines-below\"/><g class=\"xaxislayer-below\"/><g class=\"yaxislayer-below\"/><g class=\"overaxes-below\"/><g class=\"plot\" transform=\"translate(86,70)\" clip-path=\"url(#clipb122c5xyplot)\"><g class=\"scatterlayer mlayer\"><g class=\"trace scatter trace174b3812-c3f1-4827-abd1-4746adb7ae16\" style=\"stroke-miterlimit: 2; opacity: 1;\"><g class=\"fills\"/><g class=\"errorbars\"/><g class=\"lines\"><path class=\"js-line\" d=\"M23.75,88.34L24,88.7L24.1,87.68L24.22,87.96L24.39,87.74L25.65,94.25L25.77,92.1L25.85,91.78L26.72,96.46L26.78,94.95L26.86,93.39L27.44,93.48L27.73,91.94L27.81,92L28.07,92.59L28.32,91.83L28.51,91.1L28.59,90.89L28.69,91.47L28.82,91.11L29.03,92.31L29.13,92.53L29.24,91.82L29.38,91.9L29.57,91.21L29.97,89.89L30.32,91.24L30.43,90.86L30.64,90.81L30.85,91.98L30.99,92.21L31.13,91.54L31.29,90.11L31.46,88.77L31.81,89.8L31.98,90.24L32.94,87.61L33.12,87.61L33.97,82.97L34.15,84.38L34.21,85.47L34.4,83.81L34.96,84.01L35.12,84.62L35.55,82.39L36.01,83.67L36.06,83.98L36.3,83.41L36.58,85.14L36.68,84.02L36.78,83.71L36.95,83.81L37.12,84.87L37.27,84.81L37.4,83.56L37.77,83.74L37.97,84.3L38.1,84.46L38.32,83.94L38.48,83.22L39.09,78.4L39.33,79.73L39.44,81.01L39.51,81.2L39.68,80.06L39.78,79.65L40.6,81.93L40.66,81.63L40.7,80.84L41.43,84.01L41.7,83.62L41.84,82.9L42.54,80.27L42.95,80.83L43.05,80.69L43.4,80.6L44.07,83.29L44.15,82.51L44.26,81.82L44.52,82.77L44.75,81.25L44.87,81.86L45.01,81.44L45.13,80.15L45.56,82.22L45.71,81.03L45.87,80.43L46,80.77L46.24,79.84L46.45,80L46.59,79.78L46.93,78.22L47.11,79.36L47.22,80.53L47.39,82.55L47.71,77.34L47.75,77.15L47.94,75.77L48.28,77.93L48.53,76.48L48.67,76.51L49.44,74.23L49.52,74.75L49.56,75.72L49.77,73.32L50.26,74.58L50.4,74.3L50.69,75.4L50.89,74.78L51.02,73.95L51.3,71.99L52,72.33L52.14,73.53L52.42,71.83L52.74,73.41L52.86,74.1L53.34,73.78L53.53,74.4L53.71,74.48L53.8,74.23L53.9,75.38L53.99,75.94L54.77,72.83L54.85,73.2L55.11,73.96L55.44,73.08L55.61,72.78L56.72,69.68L56.78,70.15L56.87,70.59L57.15,69.05L57.62,70.34L57.74,70.44L58.91,65.46L58.95,65.43L59.4,63.29L59.7,74.67L59.93,69.94L59.95,68.91L59.98,70.13L60.19,67.01L60.64,68.12L60.71,67.45L61.13,65.38L61.23,65.12L61.71,64.58L62.02,68.56L62.09,67.88L62.12,66.8L62.17,68.35L62.58,65.52L62.79,66.95L62.93,67.67L64,75.22L64.17,71.59L64.2,70.52L64.25,71.08L64.76,68.99L64.84,68.96L65.06,68.3L65.73,71.05L65.81,72.1L66.7,67.73L66.81,68.48L67.36,69.58L67.58,68.76L67.71,68.24L69.19,58.94L69.35,59.6L69.43,60.59L69.66,62.16L70.1,59.63L70.17,60.85L70.26,60.91L70.71,58.3L70.8,61.15L70.83,62.35L70.98,65.42L71.58,59.74L71.64,59.53L72.56,64.43L72.67,63.21L72.73,62.96L73.12,62.55L73.46,66.12L73.52,64.39L73.56,63.48L73.94,68.61L74.32,65.99L74.39,64.73L74.57,65.42L75.63,61.6L75.77,62.4L76.38,64.96L76.57,63.93L76.72,63.2L77.04,65.5L77.51,64.37L77.73,64.63L78.04,63.46L78.32,64.87L78.44,65.52L79.39,68.11L79.45,67.1L79.55,66.61L80.6,62.35L80.79,63.19L80.92,63.94L81.07,63.87L81.17,62.76L81.6,62.77L81.74,61.49L81.79,60.75L82,63.04L82.33,62.54L82.48,62.13L83.17,60.22L83.45,61.3L83.54,61.65L84.49,64.04L84.57,63.6L84.7,64.75L85.04,62.84L85.25,62.42L85.96,61.79L86.12,62.47L86.43,63.27L86.56,63.66L86.61,62.97L86.75,63.26L86.94,62.36L87.58,63.1L87.84,64.03L88.16,64.63L89.5,60.46L89.58,61.11L91.12,63.98L91.24,63.24L91.42,62.62L91.59,63.13L92.02,62.22L92.28,61.17L93.01,62.46L93.09,62.07L93.3,62.02L93.66,61.61L94.05,62.02L94.17,62.75L95.03,67.56L95.19,67.34L95.23,69.29L95.81,64.59L95.95,64.97L96.06,65.52L96.43,65.22L96.79,67.02L96.88,66.28L96.95,65.27L97.03,65.05L97.33,66.23L97.45,66.41L97.94,67.96L97.99,68.5L98.25,73.08L98.4,69.2L98.45,69.38L98.5,69.23L98.7,70.87L98.78,70.56L98.85,71.11L98.98,69.29L99.32,70.68L99.42,72.46L99.78,78.88L99.81,74.66L99.84,73.66L99.86,75.5L100.09,70.37L100.49,71.51L100.58,69.99L100.73,68.22L101.09,70.03L101.32,69.87L101.41,71.01L101.49,69.49L101.99,72.81L102.09,73.73L102.4,71.85L102.89,76.74L102.98,75.23L103.03,74.05L103.11,73.78L103.2,75.61L103.32,75.49L103.38,77.08L103.59,79.57L103.61,81.12L103.68,84.06L103.89,77.65L104.5,78L104.59,79.96L104.64,79.08L105.07,84.11L105.12,83.73L105.15,83.64L105.63,87.26L105.89,82.02L105.94,82.96L106.41,78.01L106.83,79.08L106.93,79.9L107.19,76.44L107.63,80.1L107.72,81.02L107.95,80.56L108.29,84.68L108.31,83.74L108.35,85.31L108.51,80.27L109.04,86.72L109.07,86.78L109.19,84.19L109.36,89.57L109.38,88.13L109.4,90.17L109.44,91.25L109.71,84.76L110.1,87.95L110.15,89.32L110.18,88.21L110.72,94.23L110.78,93.6L110.81,94.32L111.3,85.5L111.65,86.85L111.74,86.76L111.82,86.34L112.05,88.93L112.13,90.85L112.24,91.73L113.84,81.34L113.96,81.84L114.05,82.78L114.62,78.88L114.86,81.01L114.91,81.87L115.32,79.2L115.7,83.7L115.78,82.67L115.98,84.2L116.42,81.78L116.57,80.82L116.85,79.81L117.26,81.89L117.44,79.99L117.59,80.28L118.16,76.64L118.24,76.59L118.71,78.03L118.83,76.43L118.94,75.52L119.2,77.62L119.4,76.57L119.51,77.99L119.68,78.47L119.93,77.04L120.19,78.1L120.29,79.2L120.39,80.62L120.73,78.75L120.84,78.39L121.73,80.28L121.83,79.29L122.71,88.05L122.87,84.5L122.94,84.39L124.04,79.92L124.1,80.35L124.17,81.2L124.26,81.51L124.36,80.75L124.47,80.84L124.59,79.04L125.03,81.08L125.14,80.57L125.25,81.72L125.9,84.01L126.34,83.55L126.49,83.43L126.75,81.18L127.16,84.9L127.21,84.59L127.34,84.2L127.56,85.5L127.62,84.43L127.7,83.41L128.32,88.27L128.64,86.76L128.72,86.67L128.89,85.4L129.14,87.54L129.22,87.66L129.56,82.71L130.08,85.07L130.16,85.16L130.89,87.08L131,85.48L131.88,81.1L131.93,81.54L132.01,80.54L132.07,80.14L132.48,81.71L132.69,80.79L132.83,80.58L133.01,82.64L133.34,80.96L133.48,80.3L134.07,79.63L134.35,83.13L134.39,82.52L134.48,83.11L134.99,81.49L135.12,81.22L135.59,80.28L135.94,82.78L136.06,82.11L136.18,81.53L136.66,82.31L137.23,80.52L137.37,80.57L137.54,80.79L137.75,79.97L137.9,78.73L138.72,76.14L138.83,76.1L138.98,77.71L139.35,76L139.47,76.16L139.59,75.27L139.81,71.82L140.35,72.53L140.51,73.36L140.62,73.92L140.83,71.91L140.91,70.96L141.5,72.8L141.73,72.42L141.89,72.77L142.09,73.8L142.29,72.49L142.58,73.39L142.71,72.8L143.02,74.57L143.41,73.04L143.55,72.95L145.26,68.73L145.31,68.89L145.4,69.55L146.09,70.15L146.23,70.9L146.79,69.32L146.96,70.11L147.11,70.49L147.39,70.51L147.52,71.38L149.36,64.67L149.41,65.82L149.45,66.31L149.68,65.13L150.05,66.83L150.25,65.64L150.36,65.51L151.03,66.7L151.18,65.99L151.29,65.43L151.6,65.06L152.63,69.81L152.82,68.87L152.89,68.56L153,69.22L153.27,67.69L153.33,67.71L153.42,67.17L153.55,68.45L154,66.07L154.09,66.35L154.24,66.21L155.91,68.95L156.02,68.89L156.08,68.38L157.01,70.57L157.1,70.92L157.25,72.11L157.59,70.77L157.77,71.28L157.84,69.95L158.6,68.91L158.76,70.55L159.31,68.47L159.63,69.64L159.83,70.07L160.1,70.01L160.24,70.9L160.38,70.47L160.58,71.38L160.67,72.74L160.84,71.95L161.15,72.86L161.21,72.04L161.65,72.88L161.75,73.48L162.72,82.03L162.81,79.9L162.84,77.97L162.93,76.69L163.28,78.83L163.54,78.26L163.61,78.1L163.81,76.2L164.14,80.24L164.39,77.57L164.48,78.4L164.8,79.26L164.86,80.86L165.67,76.55L165.77,76.82L167.64,72.3L167.74,73.51L167.88,74.29L167.97,74.07L168.28,75.26L168.32,74.78L168.43,75.71L168.58,76.67L168.99,75.36L169.17,76.24L169.36,76.08L169.54,75.9L169.76,77.51L170.09,78.44L170.34,77.16L170.49,76.41L170.64,76.83L170.81,75.31L170.89,74.7L171.37,75.69L171.56,74.39L172.48,71.45L172.56,71.99L172.89,73.44L173.27,71.9L173.37,72.17L173.5,71.33L173.78,74.26L174.05,72.02L174.16,72.79L174.25,72.11L174.54,74.06L174.66,73.16L174.82,74.67L175.5,72.17L175.75,72.82L175.83,74.1L176.04,74.34L176.17,73.58L176.51,73.76L176.71,74.81L176.86,73.88L177.29,75.73L177.35,75.96L177.45,76.33L178.14,75.02L178.24,75.27L179.02,78.6L179.27,77.32L179.45,76.55L179.76,76.21L180.12,78.33L180.32,76.84L180.42,75.93L180.57,76.54L180.96,75.28L181.14,75.69L181.78,76.91L182.18,76.79L182.47,77.36L182.81,77.88L182.94,78.4L184.45,82.28L184.83,81.91L184.91,80.97L184.98,80.22L185.44,83.29L185.48,83.65L186.42,79.38L186.51,79.98L186.62,79.2L186.97,80.5L187.22,79.34L187.4,80.21L187.98,79.99L188.13,81.06L188.24,79.57L188.96,76.96L189.06,77.18L189.15,77.85L189.28,77.67L189.78,78.24L190.03,78.36L190.48,77.42L190.63,77.91L190.88,78.28L192.13,75.05L192.35,76.82L192.63,76.68L192.79,76.12L193.05,78.34L193.53,77.63L193.77,78.07L193.93,76.95L194.39,77.53L194.61,78.04L195.03,80.51L195.54,79.9L195.74,80L195.94,80.83L196.24,79.19L196.37,79.71L196.57,80.07L197.55,76.06L197.79,76.24L198.03,76.03L198.11,75.72L198.18,76.11L198.55,76.12L198.68,76.67L199.19,77.5L199.77,72.74L199.92,73.36L199.98,74.02L200.08,73.89L200.28,74.59L200.51,74.4L200.64,74.73L200.81,74.54L200.97,76.3L201.05,76.82L201.26,75.39L201.53,76.21L201.73,76.12L202.61,78.81L202.77,78.22L202.93,78.11L206.05,74.83L206.2,75.31L206.3,75.45L206.43,75.7L206.68,74.37L206.84,74.65L207.02,73.76L207.09,73.29L207.82,75.26L208.05,75.1L209.24,76.55L209.46,75.69L210.78,72.54L210.83,72.95L210.93,73.48L211.02,72.71L211.67,73.4L211.91,74.5L212.72,73.02L212.77,73.3L212.92,73.9L213.11,74.85L213.48,74.09L213.68,73.38L214.29,74.25L214.43,73.68L214.55,73.21L214.87,73.06L214.92,71.82L214.94,71.46L215.36,73.54L215.49,73.28L215.65,73.33L216.85,76.64L217.16,76.25L217.29,75.86L217.6,75.27L217.76,75.67L217.91,76.16L218.4,74.93L218.63,76.14L218.85,76.63L219.03,76.23L219.16,77.74L219.25,78.23L219.63,76.54L219.99,77.08L220.09,76.16L221.4,80.45L221.43,79.78L221.5,80.81L222.07,79.19L222.26,79.13L222.95,79.86L223.03,78.74L223.61,79.07L223.77,77.64L223.85,78.6L223.97,78.96L224.67,82.39L224.92,81.29L225.01,80.62L225.4,83.31L225.79,82.99L225.84,81.59L226.03,81.29L226.47,82.24L226.57,81.19L227.06,80.52L227.28,80.83L227.44,81.23L227.99,85.16L228.11,82.93L228.14,82.48L228.38,81.51L228.45,81.09L228.59,81.54L228.88,80.39L229.03,80.52L229.2,80.83L229.97,79.84L230.06,80.23L230.19,80.62L230.4,80.23L230.56,81.33L230.76,81.81L232,78.46L232.12,78.93L233.56,82.11L233.83,81.39L233.97,81.7L234.13,82.72L234.55,80.89L234.79,82.42L234.91,82.42L234.99,83.34L235.48,81.47L235.62,81.64L236.21,80.64L236.36,81.01L236.5,81.78L237.13,85.48L237.17,86.04L237.19,85.72L237.52,87.91L237.78,87.75L237.85,88.58L237.91,89.46L238.06,86.9L238.59,87.83L238.69,88.23L238.94,91.75L239.26,87.9L239.33,88.42L239.39,88.16L239.58,87.59L239.8,88.92L239.89,88.73L239.99,90.2L240.06,89.73L240.29,92.55L240.79,91.4L240.84,90.64L241.21,89.4L241.49,92.68L241.65,92.2L241.72,91.56L242.44,90.03L242.54,91L243.03,88.08L243.34,89.25L243.46,89.45L244.57,95.53L244.71,93.65L244.8,91.77L245.65,98.02L245.74,97.2L245.79,95.99L246.03,99.32L246.43,96.66L246.51,94.62L247.04,95.31L247.16,94.1L247.29,93.95L248.51,90.35L248.59,91.01L248.82,90.22L249.22,91.56L249.38,92.5L249.73,94.37L250.04,93.55L250.16,91.65L250.21,91L250.27,91.91L250.79,91.07L250.88,92.24L251,92.62L251.25,91.48L251.36,90.66L251.88,90.28L251.93,91.2L252.05,90.97L252.19,91.2L252.28,91.74L252.48,90.29L252.56,90.63L252.64,89.33L253.5,88.06L253.7,88.65L253.82,88.83L254.08,89.74L254.25,88.19L254.6,88.57L254.74,88.8L254.92,89.33L255.23,88.42L255.4,87.99L256.38,84.49L256.5,84.73L256.67,85.22L256.94,85.06L257.62,86.39L257.81,87.18L257.97,86.56L258.38,87.73L258.45,88.09L258.73,87.78L259.04,88.74L259.15,88.02L259.32,87.88L259.74,89.26L259.87,88.94L260,88.5L260.68,87.72L260.82,88.05L261.04,88.8L261.6,85.67L262.02,86.9L262.21,87.54L262.3,86.52L262.66,87.92L262.84,86.88L263.03,87.73L263.24,86.52L263.58,88.13L263.68,87.81L263.83,88.77L264.3,88.54L265.51,91.74L265.56,90.42L265.77,89.39L265.96,90.73L266.06,90.55L266.24,90.34L266.45,90.89L266.6,89.81L266.88,90.2L267.1,90.27L268.01,89.15L268.13,89.21L268.26,90.17L268.98,88.43L269.21,89.45L269.38,89.78L270.15,89.12L270.26,88.69L271.34,90.99L271.61,90.24L271.84,89.98L272.89,89.48L273.23,88.87L274.12,87.7L274.23,87.25L275.37,87.73L275.57,87.39L275.84,87.09L275.89,87.8L276.07,88.05L277.12,87.71L277.44,87.07L278.97,89.36L279.07,89.24L279.97,90.28L280.13,89.64L280.38,91.32L280.88,90.43L281.12,90.35L281.73,91.07L281.93,92.27L282.05,93.28L282.38,92.1L282.57,91.25L283.12,90.39L283.39,90.97L283.65,89.37L284.41,89.24L284.58,88.64L285.51,87.22L285.63,87.41L285.92,87.23L286.19,88.09L286.67,84.22L287.1,85.59L287.29,85.47L287.91,86.17L288.12,85.09L288.67,86.33L288.96,85.77L289.14,85.47L289.34,85.4L289.5,85.86L289.68,86.58L290.01,87.34L290.13,86.73L290.25,86.51L290.71,86.29L290.84,86.57L291.12,85.3L291.32,83.63L291.48,82.83L291.51,83.08L291.85,81.93L291.98,82.19L292.1,81.32L292.23,81.1L292.29,81.76L292.4,81.75L292.57,82.35L292.75,82.73L292.93,82.52L293.15,81.76L293.55,84.58L294.05,84.08L294.22,83.83L294.37,83.69L294.54,84.06L294.74,84.9L294.88,84.25L295.22,85.48L295.43,86.08L295.76,85.48L296.24,89.22L296.48,88.98L296.6,89.03L296.68,89.79L297.1,88.36L297.22,89.24L297.39,88.55L297.5,90.41L297.67,88.27L298.1,88.71L298.27,88.75L298.46,87.39L298.93,89.15L299.13,89.45L299.64,91.36L300.03,90.46L300.21,89.9L300.67,89.44L300.79,90.41L300.93,90.55L301.07,90.36L301.24,92.16L301.59,92.75L301.99,90.94L302.13,90.63L302.42,90.05L302.78,91.52L302.94,90.86L303.03,89.78L303.19,88.92L303.82,90.56L303.91,90.74L304.43,91.15L304.52,92.02L305.09,90.76L305.31,91.31L305.42,92.09L305.62,93.44L305.9,91.36L306.01,90.73L306.34,89.78L306.37,91.09L306.42,92L306.81,89.27L307.29,89.5L307.42,89.88L307.55,88.94L308.11,89.7L308.3,89.5L308.47,88.84L308.75,90.19L309.07,89.24L309.29,89.58L309.48,89.85L309.7,89.14L309.93,87.93L310.1,87.39L310.42,88.19L310.61,88.96L311.49,89.99L311.65,89.53L311.89,89.52L312.85,91.28L312.98,90.51L313.39,91.06L313.55,91.53L313.82,91.98L314.06,91.2L314.24,91.1L314.5,90.72L315.04,91.16L315.21,92.05L315.78,93.29L315.88,92.59L315.98,92.19L316.49,92.41L316.63,91.6L316.82,91.58L317.01,92.83L317.27,94.89L317.81,94.54L317.91,94.45L318.61,97.04L318.63,96.97L318.65,97.93L318.73,98.42L318.99,96.77L319.08,96.82L319.16,96.27L319.61,93.86L320.01,94.24L320.12,94.91L320.28,94.69L320.81,97.66L320.92,96.66L321.01,95.23L321.75,91.78L321.89,91.94L321.98,91.7L323.8,96.32L323.89,95.71L323.99,94.84L324.28,95.11L325.41,92.59L325.53,92.96L325.81,91.37L326.32,92.68L326.48,92.74L326.94,90.84L327.26,91.15L327.46,91.95L328.51,93.27L328.66,93.16L328.77,92.36L329.02,91.79L329.27,92.72L329.39,92.15L329.6,91.69L329.93,92.49L330.17,91.28L330.68,91.8L330.82,92.43L331.39,89.53L331.81,89.66L331.93,90.87L332.66,89.7L332.77,89.47L332.93,88.78L333.34,89L333.55,89.63L334.2,88.15L334.41,88.25L334.6,87.44L334.96,88.23L335.13,87.26L335.41,86.76L335.59,86.13L336.35,84.42L336.49,85.4L336.59,86.19L336.97,83.03L337.47,83.93L337.56,84.35L338.46,83.5L338.59,83.96L339.2,87.12L339.74,86.57L339.84,86.56L340.86,90.1L340.96,89.11L341.06,88.92L341.28,89.47L341.52,85.73L341.54,84.67L341.98,70.98L342.25,75.13L342.3,75.53L342.48,78L343.03,73.44L343.08,74.01L343.15,74.77L343.23,75.58L343.67,72.92L343.75,71.91L343.88,73.38L344.35,69.24L344.56,70.58L344.65,74.08L344.79,74.92L344.97,72.92L345.25,73.72L345.33,74.54L345.5,72.93L345.91,76.5L345.95,76.67L346.15,76.18L346.71,79.9L346.78,79.64L346.81,80.33L346.84,79.25L347.47,82.78L347.51,83.28L347.55,84.89L347.96,80.81L348.19,81.36L348.29,82.43L348.8,79.61L349.06,82.03L349.22,82.18L349.5,84.07L349.85,81.36L349.9,81.07L350.92,84.09L351.07,82.82L351.16,82.22L351.51,84.83L351.62,85.22L351.84,87.01L351.94,85.91L352.01,85.35L352.48,85.88L352.61,85.08L352.78,84.19L352.92,84.08L352.94,84.83L353.07,85.88L354.19,82.66L354.43,83.32L354.55,84.25L355.07,82.59L355.36,83.38L355.54,82.94L355.65,82.4L355.77,83.22L355.94,83.07L356.07,84.45L356.43,84.93L357.21,83.01L357.4,82.73L357.89,83.31L358.1,82.64L358.32,82.14L358.62,84.62L359.19,83.38L359.32,82.96L359.95,82.42L360.19,83.3L360.62,82.34L360.91,82.74L361.08,83.1L361.89,81.58L362.13,82.33L362.47,82.59L363.62,83.75L363.91,83.28L364.33,84.17L364.59,83.67L364.9,83.3L365.94,84.77L366.18,84.32L367.22,85.21L367.28,84.47L368.09,85.63L368.32,85.23L368.42,84.84L368.82,84.76L368.99,85.15L369.33,85.4L369.7,83.25L370.07,84.41L370.3,84.58L370.98,85.32L371.14,86.53L371.38,87.95L371.76,87.3L371.93,87.05L372.41,87.4L372.56,88.5L372.67,89.15L372.99,87.7L373.18,87.44L373.82,87.68L374.04,87.25L374.68,87.71L375,86.56L375.67,86.05L375.92,87.88L376.12,88.76L376.54,86.97L376.73,86.31L377.09,84.57L377.38,84.91L377.63,85L378.21,83.98L378.54,84.66L378.81,84.9L379.4,83.43L379.62,84.38L379.64,85.22L379.67,85.57L380.29,84.35L380.44,84.17L380.88,81.45L381.19,82.49L381.38,82.98L381.53,82.35L381.92,83.45L382.1,83.3L382.43,82.47L382.68,83.3L382.86,84.11L383.26,83.77L383.59,85.11L383.69,84.97L383.77,84.13L384.58,86.31L384.67,85.73L384.79,85.21L385.27,84.94L385.52,84.24L385.69,83.56L386.26,84.16L386.52,83.75L387.27,84.21L387.59,84.61L387.84,84.41L388.09,85.22L389,84.12L389.15,83.54L389.94,84.63L390.15,84.47L390.79,85.11L391.21,84.17L392.61,82.76L392.77,82.43L393.28,82.3L393.58,82.98L393.74,82.16L394.04,78.34L394.46,79.83L394.6,79.61L395.3,80.49L395.44,81.23L395.53,81.55L395.64,80.62L396.03,80.74L396.19,79.73L396.85,81.98L397,81.05L397.18,80.2L397.35,79.93L397.38,81.17L397.45,81.45L397.78,81.61L397.89,80.52L398.01,79.96L398.66,80.85L398.92,80.46L399.87,77.57L400.3,77.84L400.46,78.46L400.62,77.95L401,78.13L401.28,78.39L402.02,79.07L402.13,77.64L402.4,76.59L402.88,77.36L403.02,77.59L403.48,77.62L403.7,76.75L404.27,74.87L404.65,75.27L404.82,75.74L405.06,76.01L405.31,75.25L405.49,74.91L407.1,78.27L407.46,78.13L407.59,77.74L409.72,75.3L409.92,75.86L411.2,73.59L411.38,73.75L411.5,74.16L411.65,73.93L411.8,74.05L411.96,74.97L412.25,73.63L412.65,74.43L412.85,74.9L416.02,69.89L416.17,71L417.24,72.73L417.32,71.95L417.87,71.34L418.02,71.83L418.2,72.33L418.73,70.92L419,71.32L419.24,71.26L419.72,68.67L419.9,70.46L419.95,71.35L420.14,74.29L420.7,72.74L420.84,71.86L421.24,71.49L421.67,73.71L421.74,72.44L421.89,71.98L422.01,71.88L422.15,72.28L422.31,73.16L422.69,72.13L422.84,72.51L423,73.64L423.49,76.36L423.93,75.09L424.08,74.98L425.09,73.08L425.14,73.2L425.23,74.26L426.01,71.81L426.17,72.43L426.31,72.79L426.67,73.11L426.84,72.15L427.03,72.83L427.24,73.78L427.65,73.06L427.92,74.41L428.62,73.41L428.86,73.87L429.1,75.12L429.43,74.63L429.69,74.12L430.13,73.05L430.55,73.19L430.8,73.8L432.52,71.73L432.64,72.61L432.99,71.8L433.2,72.29L433.37,72.93L433.63,73.01L433.68,72.12L434.04,72.51L434.3,71.85L434.47,72.04L434.74,72.03L434.91,71.08L435.32,71.27L435.73,70.05L435.77,70.34L436.29,70.79L436.42,70.67L436.53,69.94L436.9,71.87L437.49,71.31L437.7,71.28L438.58,73.36L438.75,72.25L438.95,72.3L441,70.32L441.22,69.73L441.35,69.74L442.03,66.44L442.16,66.8L442.19,67.99L442.26,69.78L442.65,66.67L442.72,66.45L442.97,65.89L443.86,68.04L444.23,67.54L444.49,67.28L445.62,65.86L445.7,65.76L445.94,66.51L446.1,65.13L446.43,65.66L446.55,65.11L446.85,65.63L447.11,64.62L447.18,64.55L447.37,63.5L447.92,63.64L448.05,63.69L448.27,64.65L448.67,63.98L448.89,63.67L449.3,63.82L449.95,61.64L450.07,62.35L450.19,62.43L451.04,64.15L451.1,64.02L451.22,63.48L451.32,63.36L451.46,63.74L451.63,63.7L451.82,64.41L451.95,64.07L452.04,64.5L452.2,65.62L453.24,63.28L453.36,63.7L453.52,64.6L454.28,68.18L454.44,67.18L454.52,66.4L454.64,66.28L455.1,66.77L455.26,68.02L455.52,69.5L455.9,68.32L456.07,68.41L456.87,70.77L457.15,70.26L457.32,68.97L457.75,68.78L457.94,69.47L458.14,68.24L458.24,68.51L458.57,67.5L458.68,66.99L459.5,65.81L459.64,66.3L459.75,66.04L459.93,67L460.08,66.65L460.21,67.15L461.16,68.93L461.25,68.42L461.41,67.5L462.62,71.68L462.74,71.24L462.81,70.65L463.17,72.77L463.54,70.67L463.61,70.59L464,71.4L464.2,70.66L464.42,69.96L464.73,69.72L464.93,70.01L465.14,71.31L466.24,69.07L466.47,69.36L466.97,67.82L467.45,68.24L467.61,68.58L468.18,69.19L468.32,69.44L468.51,69.24L468.75,70.04L468.94,69.75L469.09,69.8L469.47,70.68L469.56,69.42L469.7,69.13L470.15,69L470.38,68.64L471.43,66.69L471.51,67.1L471.7,67.03L472.83,67.63L473.02,66.81L473.84,66.56L473.97,67L474.02,67.3L474.2,65.42L474.31,62.99L474.69,49.48L475.04,53.2L475.09,52.85L475.19,51.77L475.35,54.75L475.76,53.1L475.84,53L475.99,51.25L476.71,56.1L477.08,55.44L477.23,55.46L477.35,54.17L477.56,56.36L477.93,54.64L478.05,55.66L479.34,49.03L479.4,50.2L479.46,50.74L480.48,40.83L480.85,42.71L480.92,43.04L481.59,46.24L481.72,45.43L481.83,45.03L482.03,46.49L482.37,43.72L482.46,43.89L482.54,44.09L482.79,44.55L483.15,42.63L483.33,43.76L483.49,43.4L484.21,38.84L484.44,40.09L484.53,40.78L484.82,39.62L485.01,42.57L485.08,42.6L485.3,42.08L485.6,43.91L485.63,44.37L485.96,43.85L486.35,46.56L486.44,46.18L486.52,45.12L486.98,43.39L487.21,44.41L487.3,45.56L487.5,48.2L487.86,45.58L487.95,44.34L487.99,45.01L488.51,43.41L488.65,44.35L488.76,42.6L488.82,42.28L489.12,43.33L489.17,42.7L489.22,44.61L489.32,44.68L489.47,42.79L489.9,44.63L489.98,44.79L490.52,40.96L490.86,42.62L490.97,43.02L491.27,43.32L491.97,40.93L492.09,41.76L492.24,41.6L492.38,42.45L492.44,43.71L492.58,42.69L492.92,44.81L493.03,44.14L493.19,43.85L493.68,43.02L494.1,45.41L494.25,45.01L494.41,44.7L495.18,43.18L495.28,44.31L495.74,46.56L496.1,45.78L496.25,44.77L496.62,45L497.59,42.87L497.86,43.23L497.94,44.4L499.09,41.74L499.14,42.13L499.2,43.05L500.38,49.78L500.47,47.12L500.52,46.58L500.56,45.87L500.6,46.96L501.19,46.22L501.28,47.19L502.08,52.56L502.27,50.58L502.29,50.13L502.41,50.66L503.09,48.75L503.16,49.01L503.3,48.79L503.41,48.5L503.5,48.97L503.76,48.83L503.89,49.42L503.97,49.95L504.27,48.41L504.58,49.4L504.74,49.95L504.87,50.65L505.27,48.92L505.41,48.56L506.22,48.11L506.37,49.31L506.76,48.91L507.15,51.57L507.24,50.9L507.39,50.25L508.16,49.01L508.36,49.24L508.67,47.46L508.69,47.01L509.07,49.81L509.2,49.25L509.33,50.25L509.54,49.17L509.95,50.43L510.17,50.2L510.32,48.49L510.91,49.72L511.02,49.64L512.49,44.6L512.55,45.04L512.6,45.13L513.02,45.86L513.76,40.92L513.77,39.42L513.9,37.74L514.22,40.99L514.51,39.47L514.55,38.84L514.69,38.66L514.79,40.32L515.33,39.32L515.41,39.39L515.89,41.78L516.17,41.31L516.28,40.78L516.37,41.09L516.53,39.4L516.69,40.49L516.85,39.82L517.6,38.48L517.67,37.04L518.11,43.4L518.55,42.16L518.7,41.67L519.71,36.08L519.92,37.44L520.04,38.05L520.1,39.55L520.49,37.89L520.73,38.51L520.87,38.92L521.95,42.54L522.03,41.39L522.3,40.89L522.92,42.85L522.98,42.25L523.14,40.62L523.54,42.58L523.82,41.15L523.95,41.18L524.17,40.59L524.45,41.99L524.68,41.25L524.86,41.4L525.85,39.84L525.89,40.27L526.05,40.73L526.23,40.75L526.31,39.57L526.74,38.93L527.21,40.66L527.27,40.09L527.65,44.77L528.05,42.41L528.14,42.32L528.38,41.44L528.48,40.64L528.58,39.43L529.18,39.53L529.33,40.17L529.75,42.12L530.24,41.59L530.43,41.78L531.39,39.19L531.79,39.63L532.12,40.41L532.5,41.52L532.92,40.76L533.1,40.17L533.79,40.25L534.05,39.43L534.21,39.14L534.45,39.73L534.67,39.91L535.33,39.92L535.59,40.94L535.77,39.53L536.21,40.36L536.37,40.56L536.9,41.61L536.99,42.29L537.04,43.09L537.63,40.99L537.81,41.78L538.33,42.11L538.46,42.89L538.53,42.39L538.71,44.32L538.94,43.49L539.06,44.45L539.41,42.13L539.95,42.78L540.04,42.37L540.49,43.36L540.6,43L540.76,41.92L540.92,42.41L541.42,41.8L541.54,41.9L541.63,42.47L541.73,41.64L542.22,42.54L542.41,43.04L543.01,42.41L543.2,42.87L543.4,42.99L544.11,42.96L544.34,41.95L544.53,41.49L544.78,42.58L545.04,41.72L545.26,42.07L546.42,40.47L546.65,41.31L546.73,40.41L547.3,41.22L547.49,41L547.93,41.41L548.15,40.76L548.35,40.41L548.88,37.63L548.9,36.95L548.98,35.12L549.51,37.3L549.62,36.87L549.78,36.13L549.87,37.23L550.56,36.97L550.62,36.63L551.41,35.37L551.57,35.97L551.71,36.77L552.41,34.03L552.78,34.7L552.91,35.38L553.77,37.63L553.81,36.72L553.88,36.39L554.15,38.51L554.67,36.78L554.86,35.87L555.77,37.74L555.91,37.13L556.2,37.42L556.84,36.45L557.06,36.49L557.45,36.77L557.71,35.73L557.91,35.57L558.2,36.15L558.39,36.8L558.99,36.37L559.45,38.59L559.52,38.31L560.06,46.34L560.49,42.62L560.55,41.91L561.25,44.4L561.69,44.06L561.8,43.84L562.76,41.54L562.87,41.79L563.58,40.5L563.79,40.75L563.94,41.79L564.92,39.78L565.04,39.9L565.57,40.61L565.67,40.04L565.8,39.29L565.89,38.63L566.14,39.5L566.42,39.49L566.56,40.01L566.88,40.68L567.05,39.89L567.17,39.66L568.14,37.08L568.42,37.68L568.54,37.68L569.13,37.62L569.33,37.18L569.99,37.55L570.2,38.54L570.38,37.68L570.74,39.28L570.8,40.05L571.35,38.27L571.51,38.51L571.62,39.3L571.91,41L571.96,40.14L572.03,41.32L572.14,42.13L572.41,39.94L572.57,38.87L572.7,38.98L572.86,38.65L572.99,37.79L573.13,38.04L573.42,37.25L573.63,36.37L574.07,32.82L574.44,34.65L574.47,34.93L575.32,37.47L575.35,36.7L575.41,36.36L575.63,35.98L575.72,36.78L575.87,37.12L576.55,35.13L576.74,35.94L577.08,35.27L577.88,36.52L577.96,36.48L578.26,37.24L578.45,35.75L578.48,34.48L578.67,31.36L579.27,35.79L579.32,35.35L579.47,36.65L579.84,35.05L580,35.09L580.13,34.95L581.71,39.67L581.79,38.48L581.85,38.17L582.53,37.02L582.63,38.23L582.75,38.53L582.91,38.43L583.04,37.13L583.41,37.78L583.71,37.27L583.89,36.94L585.14,34.61L585.28,35.25L585.39,36L586.2,32.45L586.35,33.49L586.44,34.01L586.76,35.08L586.9,34.38L587.01,33.57L587.35,35.48L587.75,34.23L587.92,34.29L589.24,29.29L589.34,30.25L589.4,30.71L590.22,27.93L590.36,28.63L590.43,28.92L590.83,29.15L591.26,27.67L591.35,28.47L591.66,28.34L592.24,30.82L592.36,29.62L592.44,29.16L592.82,30.29L592.93,29.71L593.04,28.47L593.12,27.99L593.28,29.36L593.56,28.61L593.64,29.62L593.68,30.13L594.05,29.04L594.22,29.07L594.35,29L596.58,24.99L596.68,25.69L597.24,26.33L597.36,26.09L597.53,25.72L597.82,25.93L597.98,25.24L598.09,25.13L598.95,26.39L599.11,26.09L599.24,25.42L599.6,26.1L599.84,26.29L600.16,27.08L600.45,26.15L600.64,25.94L601.33,26.2L601.59,26.93L601.97,28.02L602.03,28.28L602.29,26.43L602.67,26.91L602.82,28.12L603.48,26.8L603.79,27.4L603.94,27.99L604.57,29.37L604.6,29.88L605.42,27.1L605.52,27.49L606.05,26.18L606.21,26.61L606.31,27.35L606.49,27.99L606.89,26.98L607.01,26.73L607.49,26.98L607.68,26.64L607.91,26.19L608.77,27.92L608.86,26.83L609.57,26.01L609.79,26.42L610,27.51L610.17,27.59L610.31,26.89L610.5,28.08L611.14,27.07L611.32,27.45L611.44,28.18L611.62,27.82L612.18,30.18L612.37,29.66L612.45,28.86L613.07,28.74L613.27,28.9L613.43,29.38L614.74,27.21L614.89,27.58L615.93,25.69L615.97,24.35L616.08,23.48L616.35,24.59L616.68,23.6L616.88,24.38L617.14,24.03L617.43,24.59L617.62,24.86L618.11,25.18L618.59,23.64L618.68,23.87L618.78,24.5L619.1,22.78L619.27,23.01L619.38,22.63L620.05,17.78L620.52,18.66L620.64,18.18L620.79,18.34L621.03,18.07L621.14,17.07L621.36,14.75L621.53,17.72L621.62,17.53L621.72,18L622.57,13.35L622.68,13.88L622.75,13.97L623.04,16.56L623.43,14.94L623.6,14.73L623.76,15.06L623.92,14.35L624.08,12.87L624.2,15.93L624.63,12.12L624.76,13.79L624.86,12.85L625.08,13.8L625.54,13.48L625.72,13.32L626.21,14.85L626.61,14.37L626.78,14.43L627.03,15.21L627.41,14.91L627.62,14.48L629,16.68L629.12,15.67L629.23,16L629.42,15.3L629.61,15.27L629.8,14.36L630.15,14.53L630.3,14.16L630.5,13.63L631.37,9.22L631.48,9.78L631.6,10.12L631.91,10.5L632,10.23L632.13,11.34L632.42,14.1L632.85,12.49L632.94,12.94L633.45,9.79L633.88,10.9L634.04,10.7L634.37,10.61L634.48,11.41L634.59,10.77L634.96,11.96L635.2,11.38L635.36,11.91L635.84,11.36L636.14,14.11L636.23,13.48L636.28,15.64L636.41,15.45L636.43,20.04L637.02,13.69L637.16,15.14L637.21,15.42L638.38,12.28L638.48,12.42L638.86,11.36L638.91,12.27L639.06,12.35L639.27,13.04L639.66,11.78L639.87,11.12L640.52,12.52L640.71,12.84L641.07,13.45L641.18,13.69L641.35,13.85L641.89,11.87L641.96,11.96L642.08,12.59L642.58,11.23L642.66,10.32L642.77,8.11L643.38,9.88L643.55,9.77L643.85,9.64L644.08,11.7L644.29,10.79L644.42,10.18L644.73,10.06L644.83,11.22L645.34,9.44L645.55,9.66L645.69,9.94L645.92,10.39L646.12,9.36L646.21,8.96L646.29,8.62L646.8,9.28L646.97,9.05L647.47,6.47L647.87,7.35L648.06,7.51L648.13,7.23L648.26,7.74L648.41,9.26L648.66,7.97L649.04,9.7L649.07,9.42L649.15,9.44L649.41,10.77L649.7,9.24L649.78,9.36L649.94,9.46L650.08,9.34L650.22,10.5L650.73,13.76L650.98,11.14L651.05,11.03L651.17,12.55L651.4,11.02L651.53,10.06L652.72,16.42L652.81,15.4L652.88,14.46L653.38,14.82L653.81,13.12L653.93,14.66L654.63,12.56L654.72,13.68L654.86,14.78L654.93,14.26L655.04,15.39L655.28,15.01L655.4,16.74L655.45,15.86L655.75,20.29L656.16,16.58L656.23,16.9L656.46,16.85L657.56,23.78L657.59,22.85L657.63,22.86L657.96,32.93L657.97,39.5L658.76,21.15L658.8,22.26L659.19,21.18L659.55,25.53L659.62,23.59L659.7,24.32L660.04,27.68L660.24,24.76L660.3,23.84L661.17,19.63L661.23,20.09L661.51,20.78L661.63,20.25L661.73,19.31L661.85,19.89L662.05,17.85L662.14,17.55L662.89,22.23L663.02,20.76L663.12,20L664.05,24.01L664.1,23.87L664.21,24.7L664.4,24.29L664.85,29.85L665.21,27.95L665.24,27.77L665.35,25.13L665.78,30.47L665.81,31.36L665.83,30.6L666.22,37.05L666.48,33.31L666.53,34.63L666.67,29.39L667.28,33.24L667.35,32.07L667.44,31.8L668.27,49.04L668.38,39.69L668.4,38.69L668.75,37.15L668.99,41.94L669.02,41.07L669.04,42.43L669.25,38.95L669.66,48.62L669.81,44.36L669.83,43.7L670.09,45.91L670.23,37.73L670.25,38.3L670.27,35.52L670.46,34.64L670.71,38.33L671.05,37.36L671.13,38.26L671.33,45.59L671.58,38.75L671.61,37.12L671.81,35.44L672.6,42.17L672.65,41.22L672.77,39.31L673.18,43.52L673.39,40.92L673.47,41.8L674.13,47.76L674.31,43.46L674.36,43L675.3,38.18L675.4,38.05L675.47,39.68L675.87,37.06L676.13,37.75L676.27,36.22L676.52,42L676.95,37.2L677,36.37L677.13,36.58L677.45,31.89L678.06,32.22L678.15,32.31L678.59,29.18L678.78,30.6L678.85,31.61L679.05,30.78L679.24,32.53L679.49,31.35L679.61,32.26L679.98,32.19L680.15,34.05L680.36,33.08L680.46,32.68L681.59,29.18L681.63,30.31L681.71,30.36L682.21,32.81L682.39,31.63L682.52,30.66L682.71,32.19L683.12,29.45L683.25,30.34L683.36,30.04L684.31,36.89L684.36,35.71L684.65,37.55L685.01,33.06L685.19,34.42L685.27,34.5L685.41,34.9L685.66,33.65L685.77,34.18L685.92,33.34L687.56,36.97L687.66,35.74L688.09,38.7L688.43,37.66L688.55,37.05L688.95,35L689.06,35.15L689.16,34.14L690.44,30.58L690.52,30.74L690.67,31.24L690.8,31.03L690.98,31.54L691.17,32.24L691.33,31.75L691.62,33.11L691.69,32.25L691.81,33.31L692.05,34.2L692.3,33.05L692.43,32.59L692.48,32.95L692.7,31.75L693.13,32.45L693.27,31.58L693.77,32.47L693.87,33.1L694.02,33.02L694.13,33.88L694.68,37.01L695.01,35.82L695.13,34.85L696.42,29.31L696.44,28.26L696.53,26.5L696.75,29.3L697.04,28.56L697.12,29.66L697.27,29.47L697.99,31.38L698.02,30.02L698.19,29.29L699.12,34.96L699.16,33.9L699.2,33.63L699.65,35.12L699.75,33.14L700.07,34.51L700.24,35.25L700.42,35.12L701.14,37.75L701.23,38.44L701.42,40.76L701.53,37.59L701.61,36.91L702.45,43.79L702.48,42.69L702.5,41.58L702.54,41.04L702.74,45.39L703.23,41.82L703.3,42.95L703.5,44.79L703.72,41.55L703.79,43.08L703.86,40.57L704.35,42.51L704.56,40.41L704.67,41L704.75,40.44L705.04,42.66L705.14,43.78L705.31,43.25L705.39,44.05L705.49,44.79L706.23,44.64L706.41,48.04L706.43,48.19L706.65,51.78L707.06,45.98L707.12,47.08L707.19,46.69L707.27,47.24L707.45,44.47L707.64,45.47L707.71,44.45L707.84,44.84L708.33,43.59L708.43,43.96L708.54,44.68L708.75,46.01L709.06,43.38L709.14,42.23L709.19,41.91L709.44,43.86L709.55,44.59L710.11,46.11L710.38,41.71L710.48,42.24L710.56,42.97L710.79,44.4L711.02,39.9L711.09,40.33L711.16,39.66L711.69,38.17L711.98,40.3L712.07,40.37L712.29,41.02L712.51,40.21L712.61,40.69L712.74,41.92L712.84,41.76L712.94,42.47L713.1,43.43L713.31,42.71L713.54,44.81L713.74,43.72\" style=\"vector-effect: none; fill: none; stroke: rgb(31, 119, 180); stroke-opacity: 1; stroke-width: 2px; opacity: 1;\"/></g><g class=\"points\"/><g class=\"text\"/></g><g class=\"trace scatter tracee5ecb9ed-2eab-438b-b183-044261f02c7b\" style=\"stroke-miterlimit: 2; opacity: 1;\"><g class=\"fills\"/><g class=\"errorbars\"/><g class=\"lines\"/><g class=\"points\"><path class=\"point plotly-customdata\" transform=\"translate(41.7,83.62)\" d=\"M-4.62,2H4.62L0,-4Z\" style=\"opacity: 1; stroke-width: 1px; fill: rgb(55, 177, 63); fill-opacity: 1; stroke: rgb(38, 123, 44); stroke-opacity: 1;\"/><path class=\"point plotly-customdata\" transform=\"translate(81.79,60.75)\" d=\"M-4.62,2H4.62L0,-4Z\" style=\"opacity: 1; stroke-width: 1px; fill: rgb(55, 177, 63); fill-opacity: 1; stroke: rgb(38, 123, 44); stroke-opacity: 1;\"/><path class=\"point plotly-customdata\" transform=\"translate(89.39,60.7)\" d=\"M-4.62,2H4.62L0,-4Z\" style=\"opacity: 1; stroke-width: 1px; fill: rgb(55, 177, 63); fill-opacity: 1; stroke: rgb(38, 123, 44); stroke-opacity: 1;\"/><path class=\"point plotly-customdata\" transform=\"translate(99.78,78.88)\" d=\"M-4.62,2H4.62L0,-4Z\" style=\"opacity: 1; stroke-width: 1px; fill: rgb(55, 177, 63); fill-opacity: 1; stroke: rgb(38, 123, 44); stroke-opacity: 1;\"/><path class=\"point plotly-customdata\" transform=\"translate(107.55,79.14)\" d=\"M-4.62,2H4.62L0,-4Z\" style=\"opacity: 1; stroke-width: 1px; fill: rgb(55, 177, 63); fill-opacity: 1; stroke: rgb(38, 123, 44); stroke-opacity: 1;\"/><path class=\"point plotly-customdata\" transform=\"translate(148.04,69.39)\" d=\"M-4.62,2H4.62L0,-4Z\" style=\"opacity: 1; stroke-width: 1px; fill: rgb(55, 177, 63); fill-opacity: 1; stroke: rgb(38, 123, 44); stroke-opacity: 1;\"/><path class=\"point plotly-customdata\" transform=\"translate(149.32,64.78)\" d=\"M-4.62,2H4.62L0,-4Z\" style=\"opacity: 1; stroke-width: 1px; fill: rgb(55, 177, 63); fill-opacity: 1; stroke: rgb(38, 123, 44); stroke-opacity: 1;\"/><path class=\"point plotly-customdata\" transform=\"translate(150.15,65.99)\" d=\"M-4.62,2H4.62L0,-4Z\" style=\"opacity: 1; stroke-width: 1px; fill: rgb(55, 177, 63); fill-opacity: 1; stroke: rgb(38, 123, 44); stroke-opacity: 1;\"/><path class=\"point plotly-customdata\" transform=\"translate(160.38,70.47)\" d=\"M-4.62,2H4.62L0,-4Z\" style=\"opacity: 1; stroke-width: 1px; fill: rgb(55, 177, 63); fill-opacity: 1; stroke: rgb(38, 123, 44); stroke-opacity: 1;\"/><path class=\"point plotly-customdata\" transform=\"translate(163.92,77.44)\" d=\"M-4.62,2H4.62L0,-4Z\" style=\"opacity: 1; stroke-width: 1px; fill: rgb(55, 177, 63); fill-opacity: 1; stroke: rgb(38, 123, 44); stroke-opacity: 1;\"/><path class=\"point plotly-customdata\" transform=\"translate(167.1,73.64)\" d=\"M-4.62,2H4.62L0,-4Z\" style=\"opacity: 1; stroke-width: 1px; fill: rgb(55, 177, 63); fill-opacity: 1; stroke: rgb(38, 123, 44); stroke-opacity: 1;\"/><path class=\"point plotly-customdata\" transform=\"translate(172.48,71.45)\" d=\"M-4.62,2H4.62L0,-4Z\" style=\"opacity: 1; stroke-width: 1px; fill: rgb(55, 177, 63); fill-opacity: 1; stroke: rgb(38, 123, 44); stroke-opacity: 1;\"/><path class=\"point plotly-customdata\" transform=\"translate(173.5,71.33)\" d=\"M-4.62,2H4.62L0,-4Z\" style=\"opacity: 1; stroke-width: 1px; fill: rgb(55, 177, 63); fill-opacity: 1; stroke: rgb(38, 123, 44); stroke-opacity: 1;\"/><path class=\"point plotly-customdata\" transform=\"translate(175.5,72.17)\" d=\"M-4.62,2H4.62L0,-4Z\" style=\"opacity: 1; stroke-width: 1px; fill: rgb(55, 177, 63); fill-opacity: 1; stroke: rgb(38, 123, 44); stroke-opacity: 1;\"/><path class=\"point plotly-customdata\" transform=\"translate(188.84,77.72)\" d=\"M-4.62,2H4.62L0,-4Z\" style=\"opacity: 1; stroke-width: 1px; fill: rgb(55, 177, 63); fill-opacity: 1; stroke: rgb(38, 123, 44); stroke-opacity: 1;\"/><path class=\"point plotly-customdata\" transform=\"translate(191.27,77.09)\" d=\"M-4.62,2H4.62L0,-4Z\" style=\"opacity: 1; stroke-width: 1px; fill: rgb(55, 177, 63); fill-opacity: 1; stroke: rgb(38, 123, 44); stroke-opacity: 1;\"/><path class=\"point plotly-customdata\" transform=\"translate(199.73,73.37)\" d=\"M-4.62,2H4.62L0,-4Z\" style=\"opacity: 1; stroke-width: 1px; fill: rgb(55, 177, 63); fill-opacity: 1; stroke: rgb(38, 123, 44); stroke-opacity: 1;\"/><path class=\"point plotly-customdata\" transform=\"translate(200.81,74.54)\" d=\"M-4.62,2H4.62L0,-4Z\" style=\"opacity: 1; stroke-width: 1px; fill: rgb(55, 177, 63); fill-opacity: 1; stroke: rgb(38, 123, 44); stroke-opacity: 1;\"/><path class=\"point plotly-customdata\" transform=\"translate(207.09,73.29)\" d=\"M-4.62,2H4.62L0,-4Z\" style=\"opacity: 1; stroke-width: 1px; fill: rgb(55, 177, 63); fill-opacity: 1; stroke: rgb(38, 123, 44); stroke-opacity: 1;\"/><path class=\"point plotly-customdata\" transform=\"translate(210.46,73.53)\" d=\"M-4.62,2H4.62L0,-4Z\" style=\"opacity: 1; stroke-width: 1px; fill: rgb(55, 177, 63); fill-opacity: 1; stroke: rgb(38, 123, 44); stroke-opacity: 1;\"/><path class=\"point plotly-customdata\" transform=\"translate(211.02,72.71)\" d=\"M-4.62,2H4.62L0,-4Z\" style=\"opacity: 1; stroke-width: 1px; fill: rgb(55, 177, 63); fill-opacity: 1; stroke: rgb(38, 123, 44); stroke-opacity: 1;\"/><path class=\"point plotly-customdata\" transform=\"translate(285.74,87.5)\" d=\"M-4.62,2H4.62L0,-4Z\" style=\"opacity: 1; stroke-width: 1px; fill: rgb(55, 177, 63); fill-opacity: 1; stroke: rgb(38, 123, 44); stroke-opacity: 1;\"/><path class=\"point plotly-customdata\" transform=\"translate(286.67,84.22)\" d=\"M-4.62,2H4.62L0,-4Z\" style=\"opacity: 1; stroke-width: 1px; fill: rgb(55, 177, 63); fill-opacity: 1; stroke: rgb(38, 123, 44); stroke-opacity: 1;\"/><path class=\"point plotly-customdata\" transform=\"translate(341.64,78.41)\" d=\"M-4.62,2H4.62L0,-4Z\" style=\"opacity: 1; stroke-width: 1px; fill: rgb(55, 177, 63); fill-opacity: 1; stroke: rgb(38, 123, 44); stroke-opacity: 1;\"/><path class=\"point plotly-customdata\" transform=\"translate(341.82,77.22)\" d=\"M-4.62,2H4.62L0,-4Z\" style=\"opacity: 1; stroke-width: 1px; fill: rgb(55, 177, 63); fill-opacity: 1; stroke: rgb(38, 123, 44); stroke-opacity: 1;\"/><path class=\"point plotly-customdata\" transform=\"translate(357.21,83.01)\" d=\"M-4.62,2H4.62L0,-4Z\" style=\"opacity: 1; stroke-width: 1px; fill: rgb(55, 177, 63); fill-opacity: 1; stroke: rgb(38, 123, 44); stroke-opacity: 1;\"/><path class=\"point plotly-customdata\" transform=\"translate(393.95,79.64)\" d=\"M-4.62,2H4.62L0,-4Z\" style=\"opacity: 1; stroke-width: 1px; fill: rgb(55, 177, 63); fill-opacity: 1; stroke: rgb(38, 123, 44); stroke-opacity: 1;\"/><path class=\"point plotly-customdata\" transform=\"translate(396.27,80.85)\" d=\"M-4.62,2H4.62L0,-4Z\" style=\"opacity: 1; stroke-width: 1px; fill: rgb(55, 177, 63); fill-opacity: 1; stroke: rgb(38, 123, 44); stroke-opacity: 1;\"/><path class=\"point plotly-customdata\" transform=\"translate(402.27,76.75)\" d=\"M-4.62,2H4.62L0,-4Z\" style=\"opacity: 1; stroke-width: 1px; fill: rgb(55, 177, 63); fill-opacity: 1; stroke: rgb(38, 123, 44); stroke-opacity: 1;\"/><path class=\"point plotly-customdata\" transform=\"translate(407.17,77.48)\" d=\"M-4.62,2H4.62L0,-4Z\" style=\"opacity: 1; stroke-width: 1px; fill: rgb(55, 177, 63); fill-opacity: 1; stroke: rgb(38, 123, 44); stroke-opacity: 1;\"/><path class=\"point plotly-customdata\" transform=\"translate(411.11,74.14)\" d=\"M-4.62,2H4.62L0,-4Z\" style=\"opacity: 1; stroke-width: 1px; fill: rgb(55, 177, 63); fill-opacity: 1; stroke: rgb(38, 123, 44); stroke-opacity: 1;\"/><path class=\"point plotly-customdata\" transform=\"translate(415.18,71.18)\" d=\"M-4.62,2H4.62L0,-4Z\" style=\"opacity: 1; stroke-width: 1px; fill: rgb(55, 177, 63); fill-opacity: 1; stroke: rgb(38, 123, 44); stroke-opacity: 1;\"/><path class=\"point plotly-customdata\" transform=\"translate(419.44,70.76)\" d=\"M-4.62,2H4.62L0,-4Z\" style=\"opacity: 1; stroke-width: 1px; fill: rgb(55, 177, 63); fill-opacity: 1; stroke: rgb(38, 123, 44); stroke-opacity: 1;\"/><path class=\"point plotly-customdata\" transform=\"translate(432.52,71.73)\" d=\"M-4.62,2H4.62L0,-4Z\" style=\"opacity: 1; stroke-width: 1px; fill: rgb(55, 177, 63); fill-opacity: 1; stroke: rgb(38, 123, 44); stroke-opacity: 1;\"/><path class=\"point plotly-customdata\" transform=\"translate(434.95,70.77)\" d=\"M-4.62,2H4.62L0,-4Z\" style=\"opacity: 1; stroke-width: 1px; fill: rgb(55, 177, 63); fill-opacity: 1; stroke: rgb(38, 123, 44); stroke-opacity: 1;\"/><path class=\"point plotly-customdata\" transform=\"translate(436.53,69.94)\" d=\"M-4.62,2H4.62L0,-4Z\" style=\"opacity: 1; stroke-width: 1px; fill: rgb(55, 177, 63); fill-opacity: 1; stroke: rgb(38, 123, 44); stroke-opacity: 1;\"/><path class=\"point plotly-customdata\" transform=\"translate(441,70.32)\" d=\"M-4.62,2H4.62L0,-4Z\" style=\"opacity: 1; stroke-width: 1px; fill: rgb(55, 177, 63); fill-opacity: 1; stroke: rgb(38, 123, 44); stroke-opacity: 1;\"/><path class=\"point plotly-customdata\" transform=\"translate(441.86,67.8)\" d=\"M-4.62,2H4.62L0,-4Z\" style=\"opacity: 1; stroke-width: 1px; fill: rgb(55, 177, 63); fill-opacity: 1; stroke: rgb(38, 123, 44); stroke-opacity: 1;\"/><path class=\"point plotly-customdata\" transform=\"translate(442.65,66.67)\" d=\"M-4.62,2H4.62L0,-4Z\" style=\"opacity: 1; stroke-width: 1px; fill: rgb(55, 177, 63); fill-opacity: 1; stroke: rgb(38, 123, 44); stroke-opacity: 1;\"/><path class=\"point plotly-customdata\" transform=\"translate(444.8,66.84)\" d=\"M-4.62,2H4.62L0,-4Z\" style=\"opacity: 1; stroke-width: 1px; fill: rgb(55, 177, 63); fill-opacity: 1; stroke: rgb(38, 123, 44); stroke-opacity: 1;\"/><path class=\"point plotly-customdata\" transform=\"translate(449.75,62.56)\" d=\"M-4.62,2H4.62L0,-4Z\" style=\"opacity: 1; stroke-width: 1px; fill: rgb(55, 177, 63); fill-opacity: 1; stroke: rgb(38, 123, 44); stroke-opacity: 1;\"/><path class=\"point plotly-customdata\" transform=\"translate(467.45,68.24)\" d=\"M-4.62,2H4.62L0,-4Z\" style=\"opacity: 1; stroke-width: 1px; fill: rgb(55, 177, 63); fill-opacity: 1; stroke: rgb(38, 123, 44); stroke-opacity: 1;\"/><path class=\"point plotly-customdata\" transform=\"translate(473.62,66.53)\" d=\"M-4.62,2H4.62L0,-4Z\" style=\"opacity: 1; stroke-width: 1px; fill: rgb(55, 177, 63); fill-opacity: 1; stroke: rgb(38, 123, 44); stroke-opacity: 1;\"/><path class=\"point plotly-customdata\" transform=\"translate(480.12,44.47)\" d=\"M-4.62,2H4.62L0,-4Z\" style=\"opacity: 1; stroke-width: 1px; fill: rgb(55, 177, 63); fill-opacity: 1; stroke: rgb(38, 123, 44); stroke-opacity: 1;\"/><path class=\"point plotly-customdata\" transform=\"translate(480.57,43.29)\" d=\"M-4.62,2H4.62L0,-4Z\" style=\"opacity: 1; stroke-width: 1px; fill: rgb(55, 177, 63); fill-opacity: 1; stroke: rgb(38, 123, 44); stroke-opacity: 1;\"/><path class=\"point plotly-customdata\" transform=\"translate(481.72,45.43)\" d=\"M-4.62,2H4.62L0,-4Z\" style=\"opacity: 1; stroke-width: 1px; fill: rgb(55, 177, 63); fill-opacity: 1; stroke: rgb(38, 123, 44); stroke-opacity: 1;\"/><path class=\"point plotly-customdata\" transform=\"translate(500.36,48.32)\" d=\"M-4.62,2H4.62L0,-4Z\" style=\"opacity: 1; stroke-width: 1px; fill: rgb(55, 177, 63); fill-opacity: 1; stroke: rgb(38, 123, 44); stroke-opacity: 1;\"/><path class=\"point plotly-customdata\" transform=\"translate(501.61,49.07)\" d=\"M-4.62,2H4.62L0,-4Z\" style=\"opacity: 1; stroke-width: 1px; fill: rgb(55, 177, 63); fill-opacity: 1; stroke: rgb(38, 123, 44); stroke-opacity: 1;\"/><path class=\"point plotly-customdata\" transform=\"translate(504.74,49.95)\" d=\"M-4.62,2H4.62L0,-4Z\" style=\"opacity: 1; stroke-width: 1px; fill: rgb(55, 177, 63); fill-opacity: 1; stroke: rgb(38, 123, 44); stroke-opacity: 1;\"/><path class=\"point plotly-customdata\" transform=\"translate(506.91,51.54)\" d=\"M-4.62,2H4.62L0,-4Z\" style=\"opacity: 1; stroke-width: 1px; fill: rgb(55, 177, 63); fill-opacity: 1; stroke: rgb(38, 123, 44); stroke-opacity: 1;\"/><path class=\"point plotly-customdata\" transform=\"translate(509.33,50.25)\" d=\"M-4.62,2H4.62L0,-4Z\" style=\"opacity: 1; stroke-width: 1px; fill: rgb(55, 177, 63); fill-opacity: 1; stroke: rgb(38, 123, 44); stroke-opacity: 1;\"/><path class=\"point plotly-customdata\" transform=\"translate(509.95,50.43)\" d=\"M-4.62,2H4.62L0,-4Z\" style=\"opacity: 1; stroke-width: 1px; fill: rgb(55, 177, 63); fill-opacity: 1; stroke: rgb(38, 123, 44); stroke-opacity: 1;\"/><path class=\"point plotly-customdata\" transform=\"translate(512.81,44.97)\" d=\"M-4.62,2H4.62L0,-4Z\" style=\"opacity: 1; stroke-width: 1px; fill: rgb(55, 177, 63); fill-opacity: 1; stroke: rgb(38, 123, 44); stroke-opacity: 1;\"/><path class=\"point plotly-customdata\" transform=\"translate(549.01,35.37)\" d=\"M-4.62,2H4.62L0,-4Z\" style=\"opacity: 1; stroke-width: 1px; fill: rgb(55, 177, 63); fill-opacity: 1; stroke: rgb(38, 123, 44); stroke-opacity: 1;\"/><path class=\"point plotly-customdata\" transform=\"translate(574.18,33.26)\" d=\"M-4.62,2H4.62L0,-4Z\" style=\"opacity: 1; stroke-width: 1px; fill: rgb(55, 177, 63); fill-opacity: 1; stroke: rgb(38, 123, 44); stroke-opacity: 1;\"/><path class=\"point plotly-customdata\" transform=\"translate(586.17,32.96)\" d=\"M-4.62,2H4.62L0,-4Z\" style=\"opacity: 1; stroke-width: 1px; fill: rgb(55, 177, 63); fill-opacity: 1; stroke: rgb(38, 123, 44); stroke-opacity: 1;\"/><path class=\"point plotly-customdata\" transform=\"translate(589.25,29.71)\" d=\"M-4.62,2H4.62L0,-4Z\" style=\"opacity: 1; stroke-width: 1px; fill: rgb(55, 177, 63); fill-opacity: 1; stroke: rgb(38, 123, 44); stroke-opacity: 1;\"/><path class=\"point plotly-customdata\" transform=\"translate(616.46,23.94)\" d=\"M-4.62,2H4.62L0,-4Z\" style=\"opacity: 1; stroke-width: 1px; fill: rgb(55, 177, 63); fill-opacity: 1; stroke: rgb(38, 123, 44); stroke-opacity: 1;\"/><path class=\"point plotly-customdata\" transform=\"translate(619.74,21.29)\" d=\"M-4.62,2H4.62L0,-4Z\" style=\"opacity: 1; stroke-width: 1px; fill: rgb(55, 177, 63); fill-opacity: 1; stroke: rgb(38, 123, 44); stroke-opacity: 1;\"/><path class=\"point plotly-customdata\" transform=\"translate(630.86,10.23)\" d=\"M-4.62,2H4.62L0,-4Z\" style=\"opacity: 1; stroke-width: 1px; fill: rgb(55, 177, 63); fill-opacity: 1; stroke: rgb(38, 123, 44); stroke-opacity: 1;\"/><path class=\"point plotly-customdata\" transform=\"translate(662.29,18.67)\" d=\"M-4.62,2H4.62L0,-4Z\" style=\"opacity: 1; stroke-width: 1px; fill: rgb(55, 177, 63); fill-opacity: 1; stroke: rgb(38, 123, 44); stroke-opacity: 1;\"/><path class=\"point plotly-customdata\" transform=\"translate(670.25,38.3)\" d=\"M-4.62,2H4.62L0,-4Z\" style=\"opacity: 1; stroke-width: 1px; fill: rgb(55, 177, 63); fill-opacity: 1; stroke: rgb(38, 123, 44); stroke-opacity: 1;\"/><path class=\"point plotly-customdata\" transform=\"translate(678.06,32.22)\" d=\"M-4.62,2H4.62L0,-4Z\" style=\"opacity: 1; stroke-width: 1px; fill: rgb(55, 177, 63); fill-opacity: 1; stroke: rgb(38, 123, 44); stroke-opacity: 1;\"/><path class=\"point plotly-customdata\" transform=\"translate(690.52,30.74)\" d=\"M-4.62,2H4.62L0,-4Z\" style=\"opacity: 1; stroke-width: 1px; fill: rgb(55, 177, 63); fill-opacity: 1; stroke: rgb(38, 123, 44); stroke-opacity: 1;\"/></g><g class=\"text\"/></g><g class=\"trace scatter tracef8a00db1-c3e3-4911-82f6-47b997881d2b\" style=\"stroke-miterlimit: 2; opacity: 1;\"><g class=\"fills\"/><g class=\"errorbars\"/><g class=\"lines\"/><g class=\"points\"><path class=\"point plotly-customdata\" transform=\"translate(70.85,61.37)\" d=\"M-4.62,-2H4.62L0,4Z\" style=\"opacity: 1; stroke-width: 1px; fill: rgb(234, 67, 53); fill-opacity: 1; stroke: rgb(181, 31, 18); stroke-opacity: 1;\"/><path class=\"point plotly-customdata\" transform=\"translate(86.75,63.26)\" d=\"M-4.62,-2H4.62L0,4Z\" style=\"opacity: 1; stroke-width: 1px; fill: rgb(234, 67, 53); fill-opacity: 1; stroke: rgb(181, 31, 18); stroke-opacity: 1;\"/><path class=\"point plotly-customdata\" transform=\"translate(90.48,63.1)\" d=\"M-4.62,-2H4.62L0,4Z\" style=\"opacity: 1; stroke-width: 1px; fill: rgb(234, 67, 53); fill-opacity: 1; stroke: rgb(181, 31, 18); stroke-opacity: 1;\"/><path class=\"point plotly-customdata\" transform=\"translate(104.04,80.07)\" d=\"M-4.62,-2H4.62L0,4Z\" style=\"opacity: 1; stroke-width: 1px; fill: rgb(234, 67, 53); fill-opacity: 1; stroke: rgb(181, 31, 18); stroke-opacity: 1;\"/><path class=\"point plotly-customdata\" transform=\"translate(107.63,80.1)\" d=\"M-4.62,-2H4.62L0,4Z\" style=\"opacity: 1; stroke-width: 1px; fill: rgb(234, 67, 53); fill-opacity: 1; stroke: rgb(181, 31, 18); stroke-opacity: 1;\"/><path class=\"point plotly-customdata\" transform=\"translate(149.05,66.52)\" d=\"M-4.62,-2H4.62L0,4Z\" style=\"opacity: 1; stroke-width: 1px; fill: rgb(234, 67, 53); fill-opacity: 1; stroke: rgb(181, 31, 18); stroke-opacity: 1;\"/><path class=\"point plotly-customdata\" transform=\"translate(149.45,66.31)\" d=\"M-4.62,-2H4.62L0,4Z\" style=\"opacity: 1; stroke-width: 1px; fill: rgb(234, 67, 53); fill-opacity: 1; stroke: rgb(181, 31, 18); stroke-opacity: 1;\"/><path class=\"point plotly-customdata\" transform=\"translate(151.72,65.17)\" d=\"M-4.62,-2H4.62L0,4Z\" style=\"opacity: 1; stroke-width: 1px; fill: rgb(234, 67, 53); fill-opacity: 1; stroke: rgb(181, 31, 18); stroke-opacity: 1;\"/><path class=\"point plotly-customdata\" transform=\"translate(160.67,72.74)\" d=\"M-4.62,-2H4.62L0,4Z\" style=\"opacity: 1; stroke-width: 1px; fill: rgb(234, 67, 53); fill-opacity: 1; stroke: rgb(181, 31, 18); stroke-opacity: 1;\"/><path class=\"point plotly-customdata\" transform=\"translate(163.99,78.35)\" d=\"M-4.62,-2H4.62L0,4Z\" style=\"opacity: 1; stroke-width: 1px; fill: rgb(234, 67, 53); fill-opacity: 1; stroke: rgb(181, 31, 18); stroke-opacity: 1;\"/><path class=\"point plotly-customdata\" transform=\"translate(168.32,74.78)\" d=\"M-4.62,-2H4.62L0,4Z\" style=\"opacity: 1; stroke-width: 1px; fill: rgb(234, 67, 53); fill-opacity: 1; stroke: rgb(181, 31, 18); stroke-opacity: 1;\"/><path class=\"point plotly-customdata\" transform=\"translate(172.89,73.44)\" d=\"M-4.62,-2H4.62L0,4Z\" style=\"opacity: 1; stroke-width: 1px; fill: rgb(234, 67, 53); fill-opacity: 1; stroke: rgb(181, 31, 18); stroke-opacity: 1;\"/><path class=\"point plotly-customdata\" transform=\"translate(173.78,74.26)\" d=\"M-4.62,-2H4.62L0,4Z\" style=\"opacity: 1; stroke-width: 1px; fill: rgb(234, 67, 53); fill-opacity: 1; stroke: rgb(181, 31, 18); stroke-opacity: 1;\"/><path class=\"point plotly-customdata\" transform=\"translate(176.3,74.36)\" d=\"M-4.62,-2H4.62L0,4Z\" style=\"opacity: 1; stroke-width: 1px; fill: rgb(234, 67, 53); fill-opacity: 1; stroke: rgb(181, 31, 18); stroke-opacity: 1;\"/><path class=\"point plotly-customdata\" transform=\"translate(189.46,78.04)\" d=\"M-4.62,-2H4.62L0,4Z\" style=\"opacity: 1; stroke-width: 1px; fill: rgb(234, 67, 53); fill-opacity: 1; stroke: rgb(181, 31, 18); stroke-opacity: 1;\"/><path class=\"point plotly-customdata\" transform=\"translate(192.63,76.68)\" d=\"M-4.62,-2H4.62L0,4Z\" style=\"opacity: 1; stroke-width: 1px; fill: rgb(234, 67, 53); fill-opacity: 1; stroke: rgb(181, 31, 18); stroke-opacity: 1;\"/><path class=\"point plotly-customdata\" transform=\"translate(200.24,74.39)\" d=\"M-4.62,-2H4.62L0,4Z\" style=\"opacity: 1; stroke-width: 1px; fill: rgb(234, 67, 53); fill-opacity: 1; stroke: rgb(181, 31, 18); stroke-opacity: 1;\"/><path class=\"point plotly-customdata\" transform=\"translate(200.97,76.3)\" d=\"M-4.62,-2H4.62L0,4Z\" style=\"opacity: 1; stroke-width: 1px; fill: rgb(234, 67, 53); fill-opacity: 1; stroke: rgb(181, 31, 18); stroke-opacity: 1;\"/><path class=\"point plotly-customdata\" transform=\"translate(207.82,75.26)\" d=\"M-4.62,-2H4.62L0,4Z\" style=\"opacity: 1; stroke-width: 1px; fill: rgb(234, 67, 53); fill-opacity: 1; stroke: rgb(181, 31, 18); stroke-opacity: 1;\"/><path class=\"point plotly-customdata\" transform=\"translate(210.93,73.48)\" d=\"M-4.62,-2H4.62L0,4Z\" style=\"opacity: 1; stroke-width: 1px; fill: rgb(234, 67, 53); fill-opacity: 1; stroke: rgb(181, 31, 18); stroke-opacity: 1;\"/><path class=\"point plotly-customdata\" transform=\"translate(211.14,72.9)\" d=\"M-4.62,-2H4.62L0,4Z\" style=\"opacity: 1; stroke-width: 1px; fill: rgb(234, 67, 53); fill-opacity: 1; stroke: rgb(181, 31, 18); stroke-opacity: 1;\"/><path class=\"point plotly-customdata\" transform=\"translate(285.92,87.23)\" d=\"M-4.62,-2H4.62L0,4Z\" style=\"opacity: 1; stroke-width: 1px; fill: rgb(234, 67, 53); fill-opacity: 1; stroke: rgb(181, 31, 18); stroke-opacity: 1;\"/><path class=\"point plotly-customdata\" transform=\"translate(288.31,85.73)\" d=\"M-4.62,-2H4.62L0,4Z\" style=\"opacity: 1; stroke-width: 1px; fill: rgb(234, 67, 53); fill-opacity: 1; stroke: rgb(181, 31, 18); stroke-opacity: 1;\"/><path class=\"point plotly-customdata\" transform=\"translate(341.76,75.68)\" d=\"M-4.62,-2H4.62L0,4Z\" style=\"opacity: 1; stroke-width: 1px; fill: rgb(234, 67, 53); fill-opacity: 1; stroke: rgb(181, 31, 18); stroke-opacity: 1;\"/><path class=\"point plotly-customdata\" transform=\"translate(342.08,75.94)\" d=\"M-4.62,-2H4.62L0,4Z\" style=\"opacity: 1; stroke-width: 1px; fill: rgb(234, 67, 53); fill-opacity: 1; stroke: rgb(181, 31, 18); stroke-opacity: 1;\"/><path class=\"point plotly-customdata\" transform=\"translate(357.4,82.73)\" d=\"M-4.62,-2H4.62L0,4Z\" style=\"opacity: 1; stroke-width: 1px; fill: rgb(234, 67, 53); fill-opacity: 1; stroke: rgb(181, 31, 18); stroke-opacity: 1;\"/><path class=\"point plotly-customdata\" transform=\"translate(395.01,80.13)\" d=\"M-4.62,-2H4.62L0,4Z\" style=\"opacity: 1; stroke-width: 1px; fill: rgb(234, 67, 53); fill-opacity: 1; stroke: rgb(181, 31, 18); stroke-opacity: 1;\"/><path class=\"point plotly-customdata\" transform=\"translate(397,81.05)\" d=\"M-4.62,-2H4.62L0,4Z\" style=\"opacity: 1; stroke-width: 1px; fill: rgb(234, 67, 53); fill-opacity: 1; stroke: rgb(181, 31, 18); stroke-opacity: 1;\"/><path class=\"point plotly-customdata\" transform=\"translate(405.89,75.78)\" d=\"M-4.62,-2H4.62L0,4Z\" style=\"opacity: 1; stroke-width: 1px; fill: rgb(234, 67, 53); fill-opacity: 1; stroke: rgb(181, 31, 18); stroke-opacity: 1;\"/><path class=\"point plotly-customdata\" transform=\"translate(408.43,77.29)\" d=\"M-4.62,-2H4.62L0,4Z\" style=\"opacity: 1; stroke-width: 1px; fill: rgb(234, 67, 53); fill-opacity: 1; stroke: rgb(181, 31, 18); stroke-opacity: 1;\"/><path class=\"point plotly-customdata\" transform=\"translate(412.13,73.72)\" d=\"M-4.62,-2H4.62L0,4Z\" style=\"opacity: 1; stroke-width: 1px; fill: rgb(234, 67, 53); fill-opacity: 1; stroke: rgb(181, 31, 18); stroke-opacity: 1;\"/><path class=\"point plotly-customdata\" transform=\"translate(416.38,72.04)\" d=\"M-4.62,-2H4.62L0,4Z\" style=\"opacity: 1; stroke-width: 1px; fill: rgb(234, 67, 53); fill-opacity: 1; stroke: rgb(181, 31, 18); stroke-opacity: 1;\"/><path class=\"point plotly-customdata\" transform=\"translate(420,72.66)\" d=\"M-4.62,-2H4.62L0,4Z\" style=\"opacity: 1; stroke-width: 1px; fill: rgb(234, 67, 53); fill-opacity: 1; stroke: rgb(181, 31, 18); stroke-opacity: 1;\"/><path class=\"point plotly-customdata\" transform=\"translate(433.37,72.93)\" d=\"M-4.62,-2H4.62L0,4Z\" style=\"opacity: 1; stroke-width: 1px; fill: rgb(234, 67, 53); fill-opacity: 1; stroke: rgb(181, 31, 18); stroke-opacity: 1;\"/><path class=\"point plotly-customdata\" transform=\"translate(435.97,70.8)\" d=\"M-4.62,-2H4.62L0,4Z\" style=\"opacity: 1; stroke-width: 1px; fill: rgb(234, 67, 53); fill-opacity: 1; stroke: rgb(181, 31, 18); stroke-opacity: 1;\"/><path class=\"point plotly-customdata\" transform=\"translate(436.83,71.06)\" d=\"M-4.62,-2H4.62L0,4Z\" style=\"opacity: 1; stroke-width: 1px; fill: rgb(234, 67, 53); fill-opacity: 1; stroke: rgb(181, 31, 18); stroke-opacity: 1;\"/><path class=\"point plotly-customdata\" transform=\"translate(441.35,69.74)\" d=\"M-4.62,-2H4.62L0,4Z\" style=\"opacity: 1; stroke-width: 1px; fill: rgb(234, 67, 53); fill-opacity: 1; stroke: rgb(181, 31, 18); stroke-opacity: 1;\"/><path class=\"point plotly-customdata\" transform=\"translate(442.26,69.78)\" d=\"M-4.62,-2H4.62L0,4Z\" style=\"opacity: 1; stroke-width: 1px; fill: rgb(234, 67, 53); fill-opacity: 1; stroke: rgb(181, 31, 18); stroke-opacity: 1;\"/><path class=\"point plotly-customdata\" transform=\"translate(443.86,68.04)\" d=\"M-4.62,-2H4.62L0,4Z\" style=\"opacity: 1; stroke-width: 1px; fill: rgb(234, 67, 53); fill-opacity: 1; stroke: rgb(181, 31, 18); stroke-opacity: 1;\"/><path class=\"point plotly-customdata\" transform=\"translate(449.66,62.95)\" d=\"M-4.62,-2H4.62L0,4Z\" style=\"opacity: 1; stroke-width: 1px; fill: rgb(234, 67, 53); fill-opacity: 1; stroke: rgb(181, 31, 18); stroke-opacity: 1;\"/><path class=\"point plotly-customdata\" transform=\"translate(449.98,62.03)\" d=\"M-4.62,-2H4.62L0,4Z\" style=\"opacity: 1; stroke-width: 1px; fill: rgb(234, 67, 53); fill-opacity: 1; stroke: rgb(181, 31, 18); stroke-opacity: 1;\"/><path class=\"point plotly-customdata\" transform=\"translate(469.09,69.8)\" d=\"M-4.62,-2H4.62L0,4Z\" style=\"opacity: 1; stroke-width: 1px; fill: rgb(234, 67, 53); fill-opacity: 1; stroke: rgb(181, 31, 18); stroke-opacity: 1;\"/><path class=\"point plotly-customdata\" transform=\"translate(475.09,52.85)\" d=\"M-4.62,-2H4.62L0,4Z\" style=\"opacity: 1; stroke-width: 1px; fill: rgb(234, 67, 53); fill-opacity: 1; stroke: rgb(181, 31, 18); stroke-opacity: 1;\"/><path class=\"point plotly-customdata\" transform=\"translate(480.35,44.78)\" d=\"M-4.62,-2H4.62L0,4Z\" style=\"opacity: 1; stroke-width: 1px; fill: rgb(234, 67, 53); fill-opacity: 1; stroke: rgb(181, 31, 18); stroke-opacity: 1;\"/><path class=\"point plotly-customdata\" transform=\"translate(480.7,42.93)\" d=\"M-4.62,-2H4.62L0,4Z\" style=\"opacity: 1; stroke-width: 1px; fill: rgb(234, 67, 53); fill-opacity: 1; stroke: rgb(181, 31, 18); stroke-opacity: 1;\"/><path class=\"point plotly-customdata\" transform=\"translate(499.14,42.13)\" d=\"M-4.62,-2H4.62L0,4Z\" style=\"opacity: 1; stroke-width: 1px; fill: rgb(234, 67, 53); fill-opacity: 1; stroke: rgb(181, 31, 18); stroke-opacity: 1;\"/><path class=\"point plotly-customdata\" transform=\"translate(500.47,47.12)\" d=\"M-4.62,-2H4.62L0,4Z\" style=\"opacity: 1; stroke-width: 1px; fill: rgb(234, 67, 53); fill-opacity: 1; stroke: rgb(181, 31, 18); stroke-opacity: 1;\"/><path class=\"point plotly-customdata\" transform=\"translate(503.02,49.13)\" d=\"M-4.62,-2H4.62L0,4Z\" style=\"opacity: 1; stroke-width: 1px; fill: rgb(234, 67, 53); fill-opacity: 1; stroke: rgb(181, 31, 18); stroke-opacity: 1;\"/><path class=\"point plotly-customdata\" transform=\"translate(506.66,49.94)\" d=\"M-4.62,-2H4.62L0,4Z\" style=\"opacity: 1; stroke-width: 1px; fill: rgb(234, 67, 53); fill-opacity: 1; stroke: rgb(181, 31, 18); stroke-opacity: 1;\"/><path class=\"point plotly-customdata\" transform=\"translate(508.83,48.9)\" d=\"M-4.62,-2H4.62L0,4Z\" style=\"opacity: 1; stroke-width: 1px; fill: rgb(234, 67, 53); fill-opacity: 1; stroke: rgb(181, 31, 18); stroke-opacity: 1;\"/><path class=\"point plotly-customdata\" transform=\"translate(509.54,49.17)\" d=\"M-4.62,-2H4.62L0,4Z\" style=\"opacity: 1; stroke-width: 1px; fill: rgb(234, 67, 53); fill-opacity: 1; stroke: rgb(181, 31, 18); stroke-opacity: 1;\"/><path class=\"point plotly-customdata\" transform=\"translate(511.64,48.66)\" d=\"M-4.62,-2H4.62L0,4Z\" style=\"opacity: 1; stroke-width: 1px; fill: rgb(234, 67, 53); fill-opacity: 1; stroke: rgb(181, 31, 18); stroke-opacity: 1;\"/><path class=\"point plotly-customdata\" transform=\"translate(514.51,39.47)\" d=\"M-4.62,-2H4.62L0,4Z\" style=\"opacity: 1; stroke-width: 1px; fill: rgb(234, 67, 53); fill-opacity: 1; stroke: rgb(181, 31, 18); stroke-opacity: 1;\"/><path class=\"point plotly-customdata\" transform=\"translate(551.01,35.49)\" d=\"M-4.62,-2H4.62L0,4Z\" style=\"opacity: 1; stroke-width: 1px; fill: rgb(234, 67, 53); fill-opacity: 1; stroke: rgb(181, 31, 18); stroke-opacity: 1;\"/><path class=\"point plotly-customdata\" transform=\"translate(575.3,36.69)\" d=\"M-4.62,-2H4.62L0,4Z\" style=\"opacity: 1; stroke-width: 1px; fill: rgb(234, 67, 53); fill-opacity: 1; stroke: rgb(181, 31, 18); stroke-opacity: 1;\"/><path class=\"point plotly-customdata\" transform=\"translate(586.55,34.26)\" d=\"M-4.62,-2H4.62L0,4Z\" style=\"opacity: 1; stroke-width: 1px; fill: rgb(234, 67, 53); fill-opacity: 1; stroke: rgb(181, 31, 18); stroke-opacity: 1;\"/><path class=\"point plotly-customdata\" transform=\"translate(589.47,30.12)\" d=\"M-4.62,-2H4.62L0,4Z\" style=\"opacity: 1; stroke-width: 1px; fill: rgb(234, 67, 53); fill-opacity: 1; stroke: rgb(181, 31, 18); stroke-opacity: 1;\"/><path class=\"point plotly-customdata\" transform=\"translate(618.47,24.38)\" d=\"M-4.62,-2H4.62L0,4Z\" style=\"opacity: 1; stroke-width: 1px; fill: rgb(234, 67, 53); fill-opacity: 1; stroke: rgb(181, 31, 18); stroke-opacity: 1;\"/><path class=\"point plotly-customdata\" transform=\"translate(629,16.68)\" d=\"M-4.62,-2H4.62L0,4Z\" style=\"opacity: 1; stroke-width: 1px; fill: rgb(234, 67, 53); fill-opacity: 1; stroke: rgb(181, 31, 18); stroke-opacity: 1;\"/><path class=\"point plotly-customdata\" transform=\"translate(633.21,11.9)\" d=\"M-4.62,-2H4.62L0,4Z\" style=\"opacity: 1; stroke-width: 1px; fill: rgb(234, 67, 53); fill-opacity: 1; stroke: rgb(181, 31, 18); stroke-opacity: 1;\"/><path class=\"point plotly-customdata\" transform=\"translate(662.7,20.83)\" d=\"M-4.62,-2H4.62L0,4Z\" style=\"opacity: 1; stroke-width: 1px; fill: rgb(234, 67, 53); fill-opacity: 1; stroke: rgb(181, 31, 18); stroke-opacity: 1;\"/><path class=\"point plotly-customdata\" transform=\"translate(671.2,39.47)\" d=\"M-4.62,-2H4.62L0,4Z\" style=\"opacity: 1; stroke-width: 1px; fill: rgb(234, 67, 53); fill-opacity: 1; stroke: rgb(181, 31, 18); stroke-opacity: 1;\"/><path class=\"point plotly-customdata\" transform=\"translate(679.17,31.85)\" d=\"M-4.62,-2H4.62L0,4Z\" style=\"opacity: 1; stroke-width: 1px; fill: rgb(234, 67, 53); fill-opacity: 1; stroke: rgb(181, 31, 18); stroke-opacity: 1;\"/><path class=\"point plotly-customdata\" transform=\"translate(692.3,33.05)\" d=\"M-4.62,-2H4.62L0,4Z\" style=\"opacity: 1; stroke-width: 1px; fill: rgb(234, 67, 53); fill-opacity: 1; stroke: rgb(181, 31, 18); stroke-opacity: 1;\"/></g><g class=\"text\"/></g></g></g><g class=\"overplot\"/><path class=\"xlines-above crisp\" d=\"M0,0\" style=\"fill: none;\"/><path class=\"ylines-above crisp\" d=\"M0,0\" style=\"fill: none;\"/><g class=\"overlines-above\"/><g class=\"xaxislayer-above\"/><g class=\"yaxislayer-above\"><g class=\"ytick\"><text text-anchor=\"end\" x=\"85\" y=\"4.199999999999999\" transform=\"translate(0,166.35)\" style=\"font-family: 'Open Sans', verdana, arial, sans-serif; font-size: 12px; fill: rgb(214, 223, 239); fill-opacity: 1; white-space: pre; opacity: 1;\">30k</text></g><g class=\"ytick\"><text text-anchor=\"end\" x=\"85\" y=\"4.199999999999999\" style=\"font-family: 'Open Sans', verdana, arial, sans-serif; font-size: 12px; fill: rgb(214, 223, 239); fill-opacity: 1; white-space: pre; opacity: 1;\" transform=\"translate(0,134.76999999999998)\">40k</text></g><g class=\"ytick\"><text text-anchor=\"end\" x=\"85\" y=\"4.199999999999999\" style=\"font-family: 'Open Sans', verdana, arial, sans-serif; font-size: 12px; fill: rgb(214, 223, 239); fill-opacity: 1; white-space: pre; opacity: 1;\" transform=\"translate(0,103.18)\">50k</text></g><g class=\"ytick\"><text text-anchor=\"end\" x=\"85\" y=\"4.199999999999999\" style=\"font-family: 'Open Sans', verdana, arial, sans-serif; font-size: 12px; fill: rgb(214, 223, 239); fill-opacity: 1; white-space: pre; opacity: 1;\" transform=\"translate(0,71.6)\">60k</text></g></g><g class=\"overaxes-above\"/></g><g class=\"subplot x2y2\"><g class=\"layer-subplot\"><g class=\"shapelayer\"/><g class=\"imagelayer\"/></g><g class=\"minor-gridlayer\"><g class=\"x2\"/><g class=\"y2\"/></g><g class=\"gridlayer\"><g class=\"x2\"><path class=\"x2grid crisp\" transform=\"translate(174.66,0)\" d=\"M0,203.72549019607845v104.54901960784312\" style=\"stroke: rgb(49, 52, 57); stroke-opacity: 1; stroke-width: 1px;\"/><path class=\"x2grid crisp\" transform=\"translate(266.08000000000004,0)\" d=\"M0,203.72549019607845v104.54901960784312\" style=\"stroke: rgb(49, 52, 57); stroke-opacity: 1; stroke-width: 1px;\"/><path class=\"x2grid crisp\" transform=\"translate(357.49,0)\" d=\"M0,203.72549019607845v104.54901960784312\" style=\"stroke: rgb(49, 52, 57); stroke-opacity: 1; stroke-width: 1px;\"/><path class=\"x2grid crisp\" transform=\"translate(448.91,0)\" d=\"M0,203.72549019607845v104.54901960784312\" style=\"stroke: rgb(49, 52, 57); stroke-opacity: 1; stroke-width: 1px;\"/><path class=\"x2grid crisp\" transform=\"translate(540.3299999999999,0)\" d=\"M0,203.72549019607845v104.54901960784312\" style=\"stroke: rgb(49, 52, 57); stroke-opacity: 1; stroke-width: 1px;\"/><path class=\"x2grid crisp\" transform=\"translate(631.74,0)\" d=\"M0,203.72549019607845v104.54901960784312\" style=\"stroke: rgb(49, 52, 57); stroke-opacity: 1; stroke-width: 1px;\"/><path class=\"x2grid crisp\" transform=\"translate(723.16,0)\" d=\"M0,203.72549019607845v104.54901960784312\" style=\"stroke: rgb(49, 52, 57); stroke-opacity: 1; stroke-width: 1px;\"/><path class=\"x2grid crisp\" transform=\"translate(814.58,0)\" d=\"M0,203.72549019607845v104.54901960784312\" style=\"stroke: rgb(49, 52, 57); stroke-opacity: 1; stroke-width: 1px;\"/></g><g class=\"y2\"><path class=\"y2grid crisp\" transform=\"translate(0,254.90549019607846)\" d=\"M86,0h734\" style=\"stroke: rgb(49, 52, 57); stroke-opacity: 1; stroke-width: 1px;\"/><path class=\"y2grid crisp\" transform=\"translate(0,220.16549019607845)\" d=\"M86,0h734\" style=\"stroke: rgb(49, 52, 57); stroke-opacity: 1; stroke-width: 1px;\"/></g></g><g class=\"zerolinelayer\"><path class=\"y2zl zl crisp\" transform=\"translate(0,289.64549019607847)\" d=\"M86,0h734\" style=\"stroke: rgb(49, 52, 57); stroke-opacity: 1; stroke-width: 2px;\"/></g><path class=\"xlines-below\"/><path class=\"ylines-below\"/><g class=\"overlines-below\"/><g class=\"xaxislayer-below\"/><g class=\"yaxislayer-below\"/><g class=\"overaxes-below\"/><g class=\"plot\" transform=\"translate(86,203.72549019607845)\" clip-path=\"url(#clipb122c5x2y2plot)\"><g class=\"scatterlayer mlayer\"><g class=\"trace scatter traced9f804f4-abe8-4961-a6b9-8f75865691c2\" style=\"stroke-miterlimit: 2; opacity: 1;\"><g class=\"fills\"/><g class=\"errorbars\"/><g class=\"lines\"/><g class=\"points\"><path class=\"point plotly-customdata\" transform=\"translate(70.85,13.98)\" d=\"M7,0A7,7 0 1,1 0,-7A7,7 0 0,1 7,0Z\" style=\"opacity: 0.9; stroke-width: 1px; fill: rgb(55, 177, 63); fill-opacity: 1; stroke: rgb(38, 123, 44); stroke-opacity: 1;\"/><path class=\"point plotly-customdata\" transform=\"translate(149.05,77.74)\" d=\"M3.9,0A3.9,3.9 0 1,1 0,-3.9A3.9,3.9 0 0,1 3.9,0Z\" style=\"opacity: 0.767041; stroke-width: 1px; fill: rgb(55, 177, 63); fill-opacity: 1; stroke: rgb(38, 123, 44); stroke-opacity: 1;\"/><path class=\"point plotly-customdata\" transform=\"translate(151.72,83.66)\" d=\"M3.61,0A3.61,3.61 0 1,1 0,-3.61A3.61,3.61 0 0,1 3.61,0Z\" style=\"opacity: 0.754694; stroke-width: 1px; fill: rgb(55, 177, 63); fill-opacity: 1; stroke: rgb(38, 123, 44); stroke-opacity: 1;\"/><path class=\"point plotly-customdata\" transform=\"translate(192.63,84.67)\" d=\"M3.56,0A3.56,3.56 0 1,1 0,-3.56A3.56,3.56 0 0,1 3.56,0Z\" style=\"opacity: 0.752577; stroke-width: 1px; fill: rgb(55, 177, 63); fill-opacity: 1; stroke: rgb(38, 123, 44); stroke-opacity: 1;\"/><path class=\"point plotly-customdata\" transform=\"translate(210.93,85.79)\" d=\"M3.51,0A3.51,3.51 0 1,1 0,-3.51A3.51,3.51 0 0,1 3.51,0Z\" style=\"opacity: 0.750245; stroke-width: 1px; fill: rgb(55, 177, 63); fill-opacity: 1; stroke: rgb(38, 123, 44); stroke-opacity: 1;\"/><path class=\"point plotly-customdata\" transform=\"translate(285.92,85.01)\" d=\"M3.54,0A3.54,3.54 0 1,1 0,-3.54A3.54,3.54 0 0,1 3.54,0Z\" style=\"opacity: 0.751881; stroke-width: 1px; fill: rgb(55, 177, 63); fill-opacity: 1; stroke: rgb(38, 123, 44); stroke-opacity: 1;\"/><path class=\"point plotly-customdata\" transform=\"translate(341.76,77.53)\" d=\"M3.91,0A3.91,3.91 0 1,1 0,-3.91A3.91,3.91 0 0,1 3.91,0Z\" style=\"opacity: 0.767476; stroke-width: 1px; fill: rgb(55, 177, 63); fill-opacity: 1; stroke: rgb(38, 123, 44); stroke-opacity: 1;\"/><path class=\"point plotly-customdata\" transform=\"translate(342.08,82.04)\" d=\"M3.69,0A3.69,3.69 0 1,1 0,-3.69A3.69,3.69 0 0,1 3.69,0Z\" style=\"opacity: 0.758064; stroke-width: 1px; fill: rgb(55, 177, 63); fill-opacity: 1; stroke: rgb(38, 123, 44); stroke-opacity: 1;\"/><path class=\"point plotly-customdata\" transform=\"translate(357.4,85.01)\" d=\"M3.54,0A3.54,3.54 0 1,1 0,-3.54A3.54,3.54 0 0,1 3.54,0Z\" style=\"opacity: 0.751865; stroke-width: 1px; fill: rgb(55, 177, 63); fill-opacity: 1; stroke: rgb(38, 123, 44); stroke-opacity: 1;\"/><path class=\"point plotly-customdata\" transform=\"translate(405.89,82.97)\" d=\"M3.64,0A3.64,3.64 0 1,1 0,-3.64A3.64,3.64 0 0,1 3.64,0Z\" style=\"opacity: 0.756138; stroke-width: 1px; fill: rgb(55, 177, 63); fill-opacity: 1; stroke: rgb(38, 123, 44); stroke-opacity: 1;\"/><path class=\"point plotly-customdata\" transform=\"translate(408.43,85.32)\" d=\"M3.53,0A3.53,3.53 0 1,1 0,-3.53A3.53,3.53 0 0,1 3.53,0Z\" style=\"opacity: 0.751219; stroke-width: 1px; fill: rgb(55, 177, 63); fill-opacity: 1; stroke: rgb(38, 123, 44); stroke-opacity: 1;\"/><path class=\"point plotly-customdata\" transform=\"translate(412.13,84.66)\" d=\"M3.56,0A3.56,3.56 0 1,1 0,-3.56A3.56,3.56 0 0,1 3.56,0Z\" style=\"opacity: 0.752594; stroke-width: 1px; fill: rgb(55, 177, 63); fill-opacity: 1; stroke: rgb(38, 123, 44); stroke-opacity: 1;\"/><path class=\"point plotly-customdata\" transform=\"translate(441.35,84.24)\" d=\"M3.58,0A3.58,3.58 0 1,1 0,-3.58A3.58,3.58 0 0,1 3.58,0Z\" style=\"opacity: 0.75347; stroke-width: 1px; fill: rgb(55, 177, 63); fill-opacity: 1; stroke: rgb(38, 123, 44); stroke-opacity: 1;\"/><path class=\"point plotly-customdata\" transform=\"translate(449.66,75.03)\" d=\"M4.03,0A4.03,4.03 0 1,1 0,-4.03A4.03,4.03 0 0,1 4.03,0Z\" style=\"opacity: 0.772681; stroke-width: 1px; fill: rgb(55, 177, 63); fill-opacity: 1; stroke: rgb(38, 123, 44); stroke-opacity: 1;\"/><path class=\"point plotly-customdata\" transform=\"translate(449.98,84.47)\" d=\"M3.57,0A3.57,3.57 0 1,1 0,-3.57A3.57,3.57 0 0,1 3.57,0Z\" style=\"opacity: 0.752991; stroke-width: 1px; fill: rgb(55, 177, 63); fill-opacity: 1; stroke: rgb(38, 123, 44); stroke-opacity: 1;\"/><path class=\"point plotly-customdata\" transform=\"translate(475.09,47.75)\" d=\"M5.36,0A5.36,5.36 0 1,1 0,-5.36A5.36,5.36 0 0,1 5.36,0Z\" style=\"opacity: 0.829567; stroke-width: 1px; fill: rgb(55, 177, 63); fill-opacity: 1; stroke: rgb(38, 123, 44); stroke-opacity: 1;\"/><path class=\"point plotly-customdata\" transform=\"translate(480.7,85.08)\" d=\"M3.54,0A3.54,3.54 0 1,1 0,-3.54A3.54,3.54 0 0,1 3.54,0Z\" style=\"opacity: 0.751729; stroke-width: 1px; fill: rgb(55, 177, 63); fill-opacity: 1; stroke: rgb(38, 123, 44); stroke-opacity: 1;\"/><path class=\"point plotly-customdata\" transform=\"translate(499.14,78.05)\" d=\"M3.88,0A3.88,3.88 0 1,1 0,-3.88A3.88,3.88 0 0,1 3.88,0Z\" style=\"opacity: 0.766385; stroke-width: 1px; fill: rgb(55, 177, 63); fill-opacity: 1; stroke: rgb(38, 123, 44); stroke-opacity: 1;\"/><path class=\"point plotly-customdata\" transform=\"translate(500.47,82.99)\" d=\"M3.64,0A3.64,3.64 0 1,1 0,-3.64A3.64,3.64 0 0,1 3.64,0Z\" style=\"opacity: 0.756078; stroke-width: 1px; fill: rgb(55, 177, 63); fill-opacity: 1; stroke: rgb(38, 123, 44); stroke-opacity: 1;\"/><path class=\"point plotly-customdata\" transform=\"translate(506.66,85.91)\" d=\"M3.5,0A3.5,3.5 0 1,1 0,-3.5A3.5,3.5 0 0,1 3.5,0Z\" style=\"opacity: 0.75; stroke-width: 1px; fill: rgb(55, 177, 63); fill-opacity: 1; stroke: rgb(38, 123, 44); stroke-opacity: 1;\"/><path class=\"point plotly-customdata\" transform=\"translate(508.83,79.33)\" d=\"M3.82,0A3.82,3.82 0 1,1 0,-3.82A3.82,3.82 0 0,1 3.82,0Z\" style=\"opacity: 0.763715; stroke-width: 1px; fill: rgb(55, 177, 63); fill-opacity: 1; stroke: rgb(38, 123, 44); stroke-opacity: 1;\"/><path class=\"point plotly-customdata\" transform=\"translate(509.54,83.27)\" d=\"M3.63,0A3.63,3.63 0 1,1 0,-3.63A3.63,3.63 0 0,1 3.63,0Z\" style=\"opacity: 0.755505; stroke-width: 1px; fill: rgb(55, 177, 63); fill-opacity: 1; stroke: rgb(38, 123, 44); stroke-opacity: 1;\"/><path class=\"point plotly-customdata\" transform=\"translate(511.64,81.55)\" d=\"M3.71,0A3.71,3.71 0 1,1 0,-3.71A3.71,3.71 0 0,1 3.71,0Z\" style=\"opacity: 0.759092; stroke-width: 1px; fill: rgb(55, 177, 63); fill-opacity: 1; stroke: rgb(38, 123, 44); stroke-opacity: 1;\"/><path class=\"point plotly-customdata\" transform=\"translate(514.51,72.84)\" d=\"M4.14,0A4.14,4.14 0 1,1 0,-4.14A4.14,4.14 0 0,1 4.14,0Z\" style=\"opacity: 0.77725; stroke-width: 1px; fill: rgb(55, 177, 63); fill-opacity: 1; stroke: rgb(38, 123, 44); stroke-opacity: 1;\"/><path class=\"point plotly-customdata\" transform=\"translate(629,76.49)\" d=\"M3.96,0A3.96,3.96 0 1,1 0,-3.96A3.96,3.96 0 0,1 3.96,0Z\" style=\"opacity: 0.769643; stroke-width: 1px; fill: rgb(55, 177, 63); fill-opacity: 1; stroke: rgb(38, 123, 44); stroke-opacity: 1;\"/><path class=\"point plotly-customdata\" transform=\"translate(679.17,85.11)\" d=\"M3.54,0A3.54,3.54 0 1,1 0,-3.54A3.54,3.54 0 0,1 3.54,0Z\" style=\"opacity: 0.751658; stroke-width: 1px; fill: rgb(55, 177, 63); fill-opacity: 1; stroke: rgb(38, 123, 44); stroke-opacity: 1;\"/></g><g class=\"text\"/></g><g class=\"trace scatter tracebb323d60-7ce7-4a92-b3c3-0726425baf95\" style=\"stroke-miterlimit: 2; opacity: 1;\"><g class=\"fills\"/><g class=\"errorbars\"/><g class=\"lines\"/><g class=\"points\"><path class=\"point plotly-customdata\" transform=\"translate(86.75,92.63)\" d=\"M3.83,0A3.83,3.83 0 1,1 0,-3.83A3.83,3.83 0 0,1 3.83,0Z\" style=\"opacity: 0.763954; stroke-width: 1px; fill: rgb(234, 67, 53); fill-opacity: 1; stroke: rgb(181, 31, 18); stroke-opacity: 1;\"/><path class=\"point plotly-customdata\" transform=\"translate(90.48,92.31)\" d=\"M3.81,0A3.81,3.81 0 1,1 0,-3.81A3.81,3.81 0 0,1 3.81,0Z\" style=\"opacity: 0.763285; stroke-width: 1px; fill: rgb(234, 67, 53); fill-opacity: 1; stroke: rgb(181, 31, 18); stroke-opacity: 1;\"/><path class=\"point plotly-customdata\" transform=\"translate(104.04,89.62)\" d=\"M3.68,0A3.68,3.68 0 1,1 0,-3.68A3.68,3.68 0 0,1 3.68,0Z\" style=\"opacity: 0.757671; stroke-width: 1px; fill: rgb(234, 67, 53); fill-opacity: 1; stroke: rgb(181, 31, 18); stroke-opacity: 1;\"/><path class=\"point plotly-customdata\" transform=\"translate(107.63,88.91)\" d=\"M3.64,0A3.64,3.64 0 1,1 0,-3.64A3.64,3.64 0 0,1 3.64,0Z\" style=\"opacity: 0.756203; stroke-width: 1px; fill: rgb(234, 67, 53); fill-opacity: 1; stroke: rgb(181, 31, 18); stroke-opacity: 1;\"/><path class=\"point plotly-customdata\" transform=\"translate(149.45,90.13)\" d=\"M3.7,0A3.7,3.7 0 1,1 0,-3.7A3.7,3.7 0 0,1 3.7,0Z\" style=\"opacity: 0.758733; stroke-width: 1px; fill: rgb(234, 67, 53); fill-opacity: 1; stroke: rgb(181, 31, 18); stroke-opacity: 1;\"/><path class=\"point plotly-customdata\" transform=\"translate(160.67,92.46)\" d=\"M3.82,0A3.82,3.82 0 1,1 0,-3.82A3.82,3.82 0 0,1 3.82,0Z\" style=\"opacity: 0.763605; stroke-width: 1px; fill: rgb(234, 67, 53); fill-opacity: 1; stroke: rgb(181, 31, 18); stroke-opacity: 1;\"/><path class=\"point plotly-customdata\" transform=\"translate(163.99,88.7)\" d=\"M3.63,0A3.63,3.63 0 1,1 0,-3.63A3.63,3.63 0 0,1 3.63,0Z\" style=\"opacity: 0.75576; stroke-width: 1px; fill: rgb(234, 67, 53); fill-opacity: 1; stroke: rgb(181, 31, 18); stroke-opacity: 1;\"/><path class=\"point plotly-customdata\" transform=\"translate(168.32,89.29)\" d=\"M3.66,0A3.66,3.66 0 1,1 0,-3.66A3.66,3.66 0 0,1 3.66,0Z\" style=\"opacity: 0.756991; stroke-width: 1px; fill: rgb(234, 67, 53); fill-opacity: 1; stroke: rgb(181, 31, 18); stroke-opacity: 1;\"/><path class=\"point plotly-customdata\" transform=\"translate(172.89,91.71)\" d=\"M3.78,0A3.78,3.78 0 1,1 0,-3.78A3.78,3.78 0 0,1 3.78,0Z\" style=\"opacity: 0.762031; stroke-width: 1px; fill: rgb(234, 67, 53); fill-opacity: 1; stroke: rgb(181, 31, 18); stroke-opacity: 1;\"/><path class=\"point plotly-customdata\" transform=\"translate(173.78,94.43)\" d=\"M3.91,0A3.91,3.91 0 1,1 0,-3.91A3.91,3.91 0 0,1 3.91,0Z\" style=\"opacity: 0.76771; stroke-width: 1px; fill: rgb(234, 67, 53); fill-opacity: 1; stroke: rgb(181, 31, 18); stroke-opacity: 1;\"/><path class=\"point plotly-customdata\" transform=\"translate(176.3,92.34)\" d=\"M3.81,0A3.81,3.81 0 1,1 0,-3.81A3.81,3.81 0 0,1 3.81,0Z\" style=\"opacity: 0.763352; stroke-width: 1px; fill: rgb(234, 67, 53); fill-opacity: 1; stroke: rgb(181, 31, 18); stroke-opacity: 1;\"/><path class=\"point plotly-customdata\" transform=\"translate(189.46,86.91)\" d=\"M3.55,0A3.55,3.55 0 1,1 0,-3.55A3.55,3.55 0 0,1 3.55,0Z\" style=\"opacity: 0.752018; stroke-width: 1px; fill: rgb(234, 67, 53); fill-opacity: 1; stroke: rgb(181, 31, 18); stroke-opacity: 1;\"/><path class=\"point plotly-customdata\" transform=\"translate(200.24,88.92)\" d=\"M3.65,0A3.65,3.65 0 1,1 0,-3.65A3.65,3.65 0 0,1 3.65,0Z\" style=\"opacity: 0.756228; stroke-width: 1px; fill: rgb(234, 67, 53); fill-opacity: 1; stroke: rgb(181, 31, 18); stroke-opacity: 1;\"/><path class=\"point plotly-customdata\" transform=\"translate(200.97,91.16)\" d=\"M3.75,0A3.75,3.75 0 1,1 0,-3.75A3.75,3.75 0 0,1 3.75,0Z\" style=\"opacity: 0.760886; stroke-width: 1px; fill: rgb(234, 67, 53); fill-opacity: 1; stroke: rgb(181, 31, 18); stroke-opacity: 1;\"/><path class=\"point plotly-customdata\" transform=\"translate(207.82,91.73)\" d=\"M3.78,0A3.78,3.78 0 1,1 0,-3.78A3.78,3.78 0 0,1 3.78,0Z\" style=\"opacity: 0.76207; stroke-width: 1px; fill: rgb(234, 67, 53); fill-opacity: 1; stroke: rgb(181, 31, 18); stroke-opacity: 1;\"/><path class=\"point plotly-customdata\" transform=\"translate(211.14,86.48)\" d=\"M3.53,0A3.53,3.53 0 1,1 0,-3.53A3.53,3.53 0 0,1 3.53,0Z\" style=\"opacity: 0.751142; stroke-width: 1px; fill: rgb(234, 67, 53); fill-opacity: 1; stroke: rgb(181, 31, 18); stroke-opacity: 1;\"/><path class=\"point plotly-customdata\" transform=\"translate(288.31,90.83)\" d=\"M3.74,0A3.74,3.74 0 1,1 0,-3.74A3.74,3.74 0 0,1 3.74,0Z\" style=\"opacity: 0.760194; stroke-width: 1px; fill: rgb(234, 67, 53); fill-opacity: 1; stroke: rgb(181, 31, 18); stroke-opacity: 1;\"/><path class=\"point plotly-customdata\" transform=\"translate(395.01,87.44)\" d=\"M3.57,0A3.57,3.57 0 1,1 0,-3.57A3.57,3.57 0 0,1 3.57,0Z\" style=\"opacity: 0.753133; stroke-width: 1px; fill: rgb(234, 67, 53); fill-opacity: 1; stroke: rgb(181, 31, 18); stroke-opacity: 1;\"/><path class=\"point plotly-customdata\" transform=\"translate(397,86.55)\" d=\"M3.53,0A3.53,3.53 0 1,1 0,-3.53A3.53,3.53 0 0,1 3.53,0Z\" style=\"opacity: 0.751284; stroke-width: 1px; fill: rgb(234, 67, 53); fill-opacity: 1; stroke: rgb(181, 31, 18); stroke-opacity: 1;\"/><path class=\"point plotly-customdata\" transform=\"translate(416.38,88.43)\" d=\"M3.62,0A3.62,3.62 0 1,1 0,-3.62A3.62,3.62 0 0,1 3.62,0Z\" style=\"opacity: 0.75519; stroke-width: 1px; fill: rgb(234, 67, 53); fill-opacity: 1; stroke: rgb(181, 31, 18); stroke-opacity: 1;\"/><path class=\"point plotly-customdata\" transform=\"translate(420,91.41)\" d=\"M3.77,0A3.77,3.77 0 1,1 0,-3.77A3.77,3.77 0 0,1 3.77,0Z\" style=\"opacity: 0.761411; stroke-width: 1px; fill: rgb(234, 67, 53); fill-opacity: 1; stroke: rgb(181, 31, 18); stroke-opacity: 1;\"/><path class=\"point plotly-customdata\" transform=\"translate(433.37,89.42)\" d=\"M3.67,0A3.67,3.67 0 1,1 0,-3.67A3.67,3.67 0 0,1 3.67,0Z\" style=\"opacity: 0.757258; stroke-width: 1px; fill: rgb(234, 67, 53); fill-opacity: 1; stroke: rgb(181, 31, 18); stroke-opacity: 1;\"/><path class=\"point plotly-customdata\" transform=\"translate(435.97,86.03)\" d=\"M3.5,0A3.5,3.5 0 1,1 0,-3.5A3.5,3.5 0 0,1 3.5,0Z\" style=\"opacity: 0.750183; stroke-width: 1px; fill: rgb(234, 67, 53); fill-opacity: 1; stroke: rgb(181, 31, 18); stroke-opacity: 1;\"/><path class=\"point plotly-customdata\" transform=\"translate(436.83,89.13)\" d=\"M3.66,0A3.66,3.66 0 1,1 0,-3.66A3.66,3.66 0 0,1 3.66,0Z\" style=\"opacity: 0.756658; stroke-width: 1px; fill: rgb(234, 67, 53); fill-opacity: 1; stroke: rgb(181, 31, 18); stroke-opacity: 1;\"/><path class=\"point plotly-customdata\" transform=\"translate(442.26,91.51)\" d=\"M3.77,0A3.77,3.77 0 1,1 0,-3.77A3.77,3.77 0 0,1 3.77,0Z\" style=\"opacity: 0.761629; stroke-width: 1px; fill: rgb(234, 67, 53); fill-opacity: 1; stroke: rgb(181, 31, 18); stroke-opacity: 1;\"/><path class=\"point plotly-customdata\" transform=\"translate(443.86,89.75)\" d=\"M3.69,0A3.69,3.69 0 1,1 0,-3.69A3.69,3.69 0 0,1 3.69,0Z\" style=\"opacity: 0.757948; stroke-width: 1px; fill: rgb(234, 67, 53); fill-opacity: 1; stroke: rgb(181, 31, 18); stroke-opacity: 1;\"/><path class=\"point plotly-customdata\" transform=\"translate(469.09,90.34)\" d=\"M3.71,0A3.71,3.71 0 1,1 0,-3.71A3.71,3.71 0 0,1 3.71,0Z\" style=\"opacity: 0.759185; stroke-width: 1px; fill: rgb(234, 67, 53); fill-opacity: 1; stroke: rgb(181, 31, 18); stroke-opacity: 1;\"/><path class=\"point plotly-customdata\" transform=\"translate(480.35,86.67)\" d=\"M3.54,0A3.54,3.54 0 1,1 0,-3.54A3.54,3.54 0 0,1 3.54,0Z\" style=\"opacity: 0.751531; stroke-width: 1px; fill: rgb(234, 67, 53); fill-opacity: 1; stroke: rgb(181, 31, 18); stroke-opacity: 1;\"/><path class=\"point plotly-customdata\" transform=\"translate(503.02,86.07)\" d=\"M3.51,0A3.51,3.51 0 1,1 0,-3.51A3.51,3.51 0 0,1 3.51,0Z\" style=\"opacity: 0.75028; stroke-width: 1px; fill: rgb(234, 67, 53); fill-opacity: 1; stroke: rgb(181, 31, 18); stroke-opacity: 1;\"/><path class=\"point plotly-customdata\" transform=\"translate(551.01,86.18)\" d=\"M3.51,0A3.51,3.51 0 1,1 0,-3.51A3.51,3.51 0 0,1 3.51,0Z\" style=\"opacity: 0.750505; stroke-width: 1px; fill: rgb(234, 67, 53); fill-opacity: 1; stroke: rgb(181, 31, 18); stroke-opacity: 1;\"/><path class=\"point plotly-customdata\" transform=\"translate(575.3,93.47)\" d=\"M3.87,0A3.87,3.87 0 1,1 0,-3.87A3.87,3.87 0 0,1 3.87,0Z\" style=\"opacity: 0.7657; stroke-width: 1px; fill: rgb(234, 67, 53); fill-opacity: 1; stroke: rgb(181, 31, 18); stroke-opacity: 1;\"/><path class=\"point plotly-customdata\" transform=\"translate(586.55,88.77)\" d=\"M3.64,0A3.64,3.64 0 1,1 0,-3.64A3.64,3.64 0 0,1 3.64,0Z\" style=\"opacity: 0.755909; stroke-width: 1px; fill: rgb(234, 67, 53); fill-opacity: 1; stroke: rgb(181, 31, 18); stroke-opacity: 1;\"/><path class=\"point plotly-customdata\" transform=\"translate(589.47,86.81)\" d=\"M3.54,0A3.54,3.54 0 1,1 0,-3.54A3.54,3.54 0 0,1 3.54,0Z\" style=\"opacity: 0.751821; stroke-width: 1px; fill: rgb(234, 67, 53); fill-opacity: 1; stroke: rgb(181, 31, 18); stroke-opacity: 1;\"/><path class=\"point plotly-customdata\" transform=\"translate(618.47,86.84)\" d=\"M3.54,0A3.54,3.54 0 1,1 0,-3.54A3.54,3.54 0 0,1 3.54,0Z\" style=\"opacity: 0.751876; stroke-width: 1px; fill: rgb(234, 67, 53); fill-opacity: 1; stroke: rgb(181, 31, 18); stroke-opacity: 1;\"/><path class=\"point plotly-customdata\" transform=\"translate(633.21,89.13)\" d=\"M3.66,0A3.66,3.66 0 1,1 0,-3.66A3.66,3.66 0 0,1 3.66,0Z\" style=\"opacity: 0.756663; stroke-width: 1px; fill: rgb(234, 67, 53); fill-opacity: 1; stroke: rgb(181, 31, 18); stroke-opacity: 1;\"/><path class=\"point plotly-customdata\" transform=\"translate(662.7,90.28)\" d=\"M3.71,0A3.71,3.71 0 1,1 0,-3.71A3.71,3.71 0 0,1 3.71,0Z\" style=\"opacity: 0.759047; stroke-width: 1px; fill: rgb(234, 67, 53); fill-opacity: 1; stroke: rgb(181, 31, 18); stroke-opacity: 1;\"/><path class=\"point plotly-customdata\" transform=\"translate(671.2,88.58)\" d=\"M3.63,0A3.63,3.63 0 1,1 0,-3.63A3.63,3.63 0 0,1 3.63,0Z\" style=\"opacity: 0.755517; stroke-width: 1px; fill: rgb(234, 67, 53); fill-opacity: 1; stroke: rgb(181, 31, 18); stroke-opacity: 1;\"/><path class=\"point plotly-customdata\" transform=\"translate(692.3,90.92)\" d=\"M3.74,0A3.74,3.74 0 1,1 0,-3.74A3.74,3.74 0 0,1 3.74,0Z\" style=\"opacity: 0.760393; stroke-width: 1px; fill: rgb(234, 67, 53); fill-opacity: 1; stroke: rgb(181, 31, 18); stroke-opacity: 1;\"/></g><g class=\"text\"/></g></g></g><g class=\"overplot\"/><path class=\"xlines-above crisp\" d=\"M0,0\" style=\"fill: none;\"/><path class=\"ylines-above crisp\" d=\"M0,0\" style=\"fill: none;\"/><g class=\"overlines-above\"/><g class=\"xaxislayer-above\"/><g class=\"yaxislayer-above\"><g class=\"y2tick\"><text text-anchor=\"end\" x=\"85\" y=\"4.199999999999999\" transform=\"translate(0,289.64549019607847)\" style=\"font-family: 'Open Sans', verdana, arial, sans-serif; font-size: 12px; fill: rgb(214, 223, 239); fill-opacity: 1; white-space: pre; opacity: 1;\">0.00%</text></g><g class=\"y2tick\"><text text-anchor=\"end\" x=\"85\" y=\"4.199999999999999\" style=\"font-family: 'Open Sans', verdana, arial, sans-serif; font-size: 12px; fill: rgb(214, 223, 239); fill-opacity: 1; white-space: pre; opacity: 1;\" transform=\"translate(0,254.90549019607846)\">10.00%</text></g><g class=\"y2tick\"><text text-anchor=\"end\" x=\"85\" y=\"4.199999999999999\" style=\"font-family: 'Open Sans', verdana, arial, sans-serif; font-size: 12px; fill: rgb(214, 223, 239); fill-opacity: 1; white-space: pre; opacity: 1;\" transform=\"translate(0,220.16549019607845)\">20.00%</text></g></g><g class=\"overaxes-above\"/></g><g class=\"subplot x3y3\"><g class=\"layer-subplot\"><g class=\"shapelayer\"/><g class=\"imagelayer\"/></g><g class=\"minor-gridlayer\"><g class=\"x3\"/><g class=\"y3\"/></g><g class=\"gridlayer\"><g class=\"x3\"><path class=\"x3grid crisp\" transform=\"translate(174.66,0)\" d=\"M0,337.45098039215685v104.54901960784314\" style=\"stroke: rgb(49, 52, 57); stroke-opacity: 1; stroke-width: 1px;\"/><path class=\"x3grid crisp\" transform=\"translate(266.08000000000004,0)\" d=\"M0,337.45098039215685v104.54901960784314\" style=\"stroke: rgb(49, 52, 57); stroke-opacity: 1; stroke-width: 1px;\"/><path class=\"x3grid crisp\" transform=\"translate(357.49,0)\" d=\"M0,337.45098039215685v104.54901960784314\" style=\"stroke: rgb(49, 52, 57); stroke-opacity: 1; stroke-width: 1px;\"/><path class=\"x3grid crisp\" transform=\"translate(448.91,0)\" d=\"M0,337.45098039215685v104.54901960784314\" style=\"stroke: rgb(49, 52, 57); stroke-opacity: 1; stroke-width: 1px;\"/><path class=\"x3grid crisp\" transform=\"translate(540.3299999999999,0)\" d=\"M0,337.45098039215685v104.54901960784314\" style=\"stroke: rgb(49, 52, 57); stroke-opacity: 1; stroke-width: 1px;\"/><path class=\"x3grid crisp\" transform=\"translate(631.74,0)\" d=\"M0,337.45098039215685v104.54901960784314\" style=\"stroke: rgb(49, 52, 57); stroke-opacity: 1; stroke-width: 1px;\"/><path class=\"x3grid crisp\" transform=\"translate(723.16,0)\" d=\"M0,337.45098039215685v104.54901960784314\" style=\"stroke: rgb(49, 52, 57); stroke-opacity: 1; stroke-width: 1px;\"/><path class=\"x3grid crisp\" transform=\"translate(814.58,0)\" d=\"M0,337.45098039215685v104.54901960784314\" style=\"stroke: rgb(49, 52, 57); stroke-opacity: 1; stroke-width: 1px;\"/></g><g class=\"y3\"><path class=\"y3grid crisp\" transform=\"translate(0,425.64098039215685)\" d=\"M86,0h734\" style=\"stroke: rgb(49, 52, 57); stroke-opacity: 1; stroke-width: 1px;\"/><path class=\"y3grid crisp\" transform=\"translate(0,373.58098039215685)\" d=\"M86,0h734\" style=\"stroke: rgb(49, 52, 57); stroke-opacity: 1; stroke-width: 1px;\"/></g></g><g class=\"zerolinelayer\"/><path class=\"xlines-below\"/><path class=\"ylines-below\"/><g class=\"overlines-below\"/><g class=\"xaxislayer-below\"/><g class=\"yaxislayer-below\"/><g class=\"overaxes-below\"/><g class=\"plot\" transform=\"translate(86,337.45098039215685)\" clip-path=\"url(#clipb122c5x3y3plot)\"><g class=\"scatterlayer mlayer\"><g class=\"trace scatter trace2f2c8cd8-a336-43f6-92dc-6a9b0017b32a\" style=\"stroke-miterlimit: 2; opacity: 1;\"><g class=\"fills\"/><g class=\"errorbars\"/><g class=\"lines\"><path class=\"js-line\" d=\"M23.75,88.19L24,88.56L24.1,87.53L24.22,87.81L24.39,87.59L25.65,94.18L25.77,92L25.85,91.68L26.72,96.42L26.78,94.89L26.86,93.31L27.44,93.4L27.73,91.84L27.81,91.9L28.07,92.5L28.32,91.73L28.51,90.99L28.59,90.77L28.69,91.37L28.82,91L29.03,92.22L29.13,92.44L29.24,91.72L29.38,91.8L29.57,91.1L29.97,89.77L30.32,91.13L30.43,90.75L30.64,90.7L30.85,91.89L30.99,92.12L31.13,91.44L31.29,89.99L31.46,88.63L31.81,89.68L31.98,90.12L32.94,87.46L33.12,87.45L33.97,82.75L34.15,84.18L34.21,85.29L34.4,83.6L34.96,83.8L35.12,84.42L35.55,82.17L36.01,83.46L36.06,83.77L36.3,83.2L36.58,84.95L36.68,83.82L36.78,83.5L36.95,83.6L37.12,84.68L37.27,84.62L37.4,83.35L37.77,83.53L37.97,84.1L38.1,84.26L38.32,83.73L38.48,83.01L39.09,78.12L39.33,79.47L39.44,80.77L39.51,80.96L39.68,79.8L39.78,79.39L40.6,81.7L40.66,81.4L40.7,80.59L41.43,83.81L41.7,83.41L41.84,82.68L42.54,80.02L42.95,80.58L43.05,80.44L43.4,80.35L44.07,83.07L44.15,82.29L44.26,81.59L44.52,82.55L44.75,81.01L44.87,81.63L45.01,81.2L45.13,79.9L45.56,81.99L45.71,80.79L45.87,80.17L46,80.52L46.24,79.58L46.45,79.74L46.59,79.52L46.93,77.94L47.11,79.09L47.22,80.28L47.39,82.33L47.71,77.05L47.75,76.85L47.94,75.45L48.28,77.64L48.53,76.17L48.67,76.21L49.44,73.89L49.52,74.42L49.56,75.41L49.77,72.97L50.26,74.25L50.4,73.97L50.69,75.08L50.89,74.45L51.02,73.61L51.3,71.63L52,71.97L52.14,73.18L52.42,71.47L52.74,73.07L52.86,73.77L53.34,73.44L53.53,74.06L53.71,74.15L53.8,73.9L53.9,75.06L53.99,75.63L54.77,72.48L54.85,72.85L55.11,73.62L55.44,72.73L55.61,72.42L56.72,69.29L56.78,69.76L56.87,70.21L57.15,68.65L57.62,69.96L57.74,70.05L58.91,65.01L58.95,64.98L59.4,62.81L59.7,74.34L59.93,69.55L59.95,68.5L59.98,69.74L60.19,66.57L60.64,67.71L60.71,67.02L61.13,64.92L61.23,64.66L61.71,64.12L62.02,68.15L62.09,67.46L62.12,66.36L62.17,67.94L62.58,65.07L62.79,66.52L62.93,67.25L64,74.9L64.17,71.22L64.2,70.14L64.25,70.71L64.76,68.59L64.84,68.55L65.06,67.89L65.73,70.67L65.81,71.74L66.7,67.31L66.81,68.07L67.36,69.18L67.58,68.35L67.71,67.83L69.19,58.4L69.35,59.07L69.43,60.07L69.66,61.67L70.1,59.1L70.17,60.34L70.26,60.4L70.71,57.75L70.8,60.64L70.83,61.86L70.98,64.97L71.58,59.21L71.64,59L72.56,63.97L72.67,62.72L72.73,62.48L73.12,62.06L73.46,65.67L73.52,63.92L73.56,63L73.94,68.2L74.32,65.54L74.39,64.27L74.57,64.96L75.63,61.09L75.77,61.9L76.38,64.5L76.57,63.45L76.72,62.72L77.04,65.04L77.51,63.91L77.73,64.17L78.04,62.98L78.32,64.41L78.44,65.07L79.39,67.69L79.45,66.67L79.55,66.18L80.6,61.86L80.79,62.7L80.92,63.47L81.07,63.39L81.17,62.27L81.6,62.28L81.74,60.98L81.79,60.23L82,62.56L82.33,62.05L82.48,61.63L83.17,59.7L83.45,60.79L83.54,61.14L84.49,63.57L84.57,63.12L84.7,64.29L85.04,62.35L85.25,61.92L85.96,61.29L86.12,61.98L86.43,62.79L86.56,63.18L86.61,62.48L86.75,62.78L86.94,61.87L87.58,62.61L87.84,63.55L88.16,64.17L89.5,59.94L89.58,60.6L89.69,60.78L90.01,60.67L91.12,63.5L91.24,62.75L92.28,60.66L92.33,61.41L92.49,61.18L92.86,60.84L93.01,61.96L93.3,61.52L93.47,61.25L94.05,61.52L94.17,62.26L95.03,67.14L95.19,66.92L95.23,68.89L95.81,64.13L95.95,64.51L96.06,65.07L96.43,64.77L96.79,66.59L96.88,65.84L96.95,64.81L97.03,64.6L97.33,65.79L97.45,65.97L97.73,65.82L97.94,67.54L97.99,68.09L98.25,72.73L98.4,68.79L98.45,68.98L98.5,68.83L98.7,70.49L98.78,70.18L98.85,70.74L98.98,68.89L99.32,70.3L99.42,72.1L99.78,78.6L99.81,74.33L99.84,73.32L99.86,75.19L100.09,69.98L100.49,71.14L100.58,69.6L100.73,67.81L101.09,69.64L101.32,69.48L101.41,70.63L101.49,69.09L101.99,72.46L102.09,73.39L102.4,71.49L102.89,76.44L102.98,74.91L103.03,73.71L103.11,73.44L103.2,75.29L103.32,75.17L103.38,76.79L103.59,79.31L103.61,80.88L103.68,83.86L103.89,77.36L104.5,77.72L104.59,79.7L104.64,78.81L105.07,83.91L105.12,83.52L105.15,83.43L105.63,87.1L105.89,81.79L105.94,82.74L106.41,77.73L106.83,78.81L106.93,79.64L107.19,76.13L107.63,79.85L107.72,80.77L107.95,80.31L108.35,85.13L108.41,82.53L108.43,81.77L108.51,80.02L108.99,86.17L109.01,84.51L109.04,86.55L109.19,83.98L109.23,85.63L109.27,86.73L109.44,91.14L109.71,84.56L110.02,86.62L110.1,87.79L110.81,94.25L111.01,92.88L111.03,92.59L111.3,85.31L111.82,86.17L111.9,87.21L112.24,91.63L112.88,90.72L112.97,88.31L113.84,81.1L113.89,81.82L113.96,81.61L114.05,82.56L114.33,79.68L114.45,80.38L114.53,79.52L114.62,78.6L114.95,82.03L115.32,78.93L115.43,79.92L115.98,84L116.29,81.89L116.42,81.54L116.85,79.55L117.1,81.19L117.26,81.66L118.24,76.29L118.33,76.55L118.41,77.13L118.71,77.74L118.83,76.13L118.94,75.2L119.68,78.19L119.82,77.74L119.93,76.74L120.39,80.37L120.73,78.48L120.84,78.11L121.73,80.02L121.83,79.02L122.71,87.9L122.87,84.31L122.94,84.19L124.04,79.66L124.1,80.1L124.17,80.95L124.26,81.28L124.36,80.5L124.47,80.6L124.59,78.77L125.25,81.48L125.38,82L125.47,81.47L125.75,83.28L125.83,82.57L125.9,83.81L126.75,80.94L126.84,82.12L127.01,82.95L127.56,85.31L127.82,85L127.88,83.93L128.32,88.12L128.72,86.5L128.81,86.11L129.22,87.5L129.56,82.48L129.72,83.22L129.81,84.11L130.89,86.92L131,85.3L132.01,80.29L132.07,79.89L132.48,81.47L132.83,80.33L132.94,80.96L133.01,82.42L133.48,80.05L133.62,81.26L133.75,80.69L134.07,79.36L134.35,82.92L134.67,82.18L134.87,81.8L135.34,81.91L135.59,80.02L135.68,80.74L135.79,81.56L135.94,82.56L136.34,80.86L136.47,80.76L136.66,82.09L137.09,80.54L137.23,80.27L137.54,80.54L137.75,79.71L138.83,75.79L138.92,77.12L138.98,77.43L139.35,75.68L139.47,75.85L139.81,71.45L140.35,72.18L140.51,73.02L140.62,73.58L140.83,71.55L140.91,70.58L141.5,72.44L141.73,72.06L141.89,72.42L142.09,73.46L142.29,72.13L142.58,73.04L142.71,72.44L143.02,74.24L143.41,72.69L143.55,72.6L145.26,68.32L145.31,68.49L145.4,69.15L145.93,69.9L146.01,69.93L146.23,70.52L146.79,68.92L146.88,69.19L146.96,69.72L147.52,71.01L147.68,70.11L147.79,69.6L148.39,67.93L148.43,67.49L148.48,67.72L148.73,66.11L148.8,66.11L148.82,65.44L149.05,66.08L149.36,64.21L149.45,65.87L149.5,65.99L149.68,64.67L150.05,66.4L150.25,65.19L150.36,65.06L151.03,66.26L151.18,65.55L151.29,64.98L151.6,64.61L152.63,69.41L153,68.82L153.11,68.58L154,65.63L154.09,65.91L154.24,65.77L155.91,68.55L156.02,68.48L156.08,67.97L157.01,70.18L157.1,70.55L157.25,71.75L157.59,70.39L157.77,70.91L157.84,69.56L158.6,68.51L158.76,70.17L159.31,68.06L159.63,69.24L159.83,69.68L160.1,69.62L160.24,70.52L160.38,70.08L160.58,71.01L160.67,72.38L160.84,71.59L161.15,72.51L161.21,71.68L161.65,72.53L161.75,73.14L162.72,81.8L162.81,79.64L162.84,77.69L162.93,76.38L163.28,78.55L163.54,77.98L163.61,77.82L163.81,75.89L164.14,79.99L164.39,77.28L164.48,78.12L164.8,78.99L164.86,80.61L165.67,76.24L165.77,76.52L167.64,71.94L167.74,73.17L167.88,73.96L167.97,73.73L168.28,74.94L168.32,74.45L168.43,75.39L168.58,76.37L168.99,75.04L169.17,75.93L169.36,75.77L169.54,75.58L169.76,77.22L170.09,78.16L170.34,76.87L170.49,76.11L170.64,76.53L170.81,74.99L170.89,74.37L171.37,75.38L171.56,74.06L172.48,71.08L172.56,71.62L172.89,73.1L173.27,71.54L173.37,71.81L173.5,70.95L173.78,73.92L174.05,71.65L174.16,72.43L174.25,71.75L174.54,73.72L174.66,72.81L174.82,74.34L175.5,71.8L175.75,72.47L175.83,73.76L176.04,74.01L176.17,73.24L176.51,73.42L176.71,74.48L176.86,73.54L177.29,75.41L177.35,75.65L177.45,76.03L178.14,74.7L178.24,74.95L179.02,78.32L179.27,77.02L179.45,76.25L179.76,75.9L180.12,78.05L180.32,76.54L180.42,75.62L180.57,76.24L180.96,74.96L181.14,75.37L181.78,76.61L182.01,76.24L182.18,76.49L184.17,81.03L184.32,80.65L184.4,81.71L184.45,82.05L184.91,80.73L184.98,79.96L185.48,83.44L185.74,80.65L185.84,80.16L185.94,80.62L186.33,79.55L186.42,79.11L186.62,78.93L186.97,80.25L187.11,79.24L187.22,79.07L188.13,80.82L188.24,79.31L188.96,76.66L189.06,76.88L189.15,77.57L189.28,77.38L189.78,77.96L190.03,78.08L190.48,77.12L190.63,77.63L190.88,78L192.13,74.72L192.35,76.52L192.63,76.38L192.79,75.81L193.05,78.06L193.53,77.34L193.77,77.79L193.93,76.65L194.39,77.24L194.61,77.76L195.03,80.26L195.54,79.64L195.74,79.74L195.94,80.58L196.24,78.92L196.37,79.45L196.57,79.81L197.55,75.75L197.79,75.93L198.03,75.72L198.18,75.8L198.31,75.46L198.55,75.81L198.68,76.37L199.19,77.21L199.77,72.39L199.92,73.01L199.98,73.68L200.08,73.55L200.28,74.26L200.51,74.07L200.64,74.4L200.81,74.21L200.97,75.99L201.05,76.52L201.26,75.07L201.53,75.9L201.73,75.81L202.61,78.54L202.77,77.94L202.93,77.83L206.05,74.5L206.2,74.99L206.3,75.13L206.43,75.38L206.68,74.04L206.84,74.33L207.02,73.42L207.09,72.95L207.82,74.94L208.05,74.78L209.24,76.24L209.46,75.37L210.78,72.19L210.83,72.6L210.93,73.14L211.02,72.36L211.67,73.06L211.91,74.17L212.62,72.66L212.77,72.95L212.92,73.56L213.11,74.52L213.48,73.76L213.68,73.03L214.29,73.91L214.43,73.34L214.55,72.86L214.87,72.71L214.92,71.46L214.94,71.09L215.36,73.19L215.49,72.93L215.65,72.98L216.85,76.34L217.16,75.95L217.29,75.55L217.6,74.95L217.76,75.36L217.91,75.85L218.4,74.61L218.63,75.83L218.85,76.32L219.03,75.92L219.16,77.45L219.25,77.95L219.63,76.24L219.99,76.78L220.09,75.85L221.4,80.2L221.43,79.52L221.5,80.56L222.07,78.92L222.26,78.86L222.95,79.6L223.03,78.47L223.61,78.8L223.77,77.35L223.85,78.32L223.97,78.69L224.67,82.16L224.92,81.05L225.01,80.37L225.4,83.1L225.79,82.77L225.84,81.35L226.03,81.05L226.47,82.01L226.57,80.95L227.06,80.27L227.28,80.58L227.44,80.99L227.99,84.97L228.11,82.71L228.14,82.26L228.38,81.27L228.45,80.85L228.59,81.3L228.88,80.14L229.03,80.27L229.2,80.58L229.97,79.58L230.06,79.98L230.19,80.37L230.4,79.97L230.56,81.09L230.76,81.58L232,78.18L232.12,78.66L234.13,82.5L234.25,81.66L234.55,80.65L234.79,82.2L234.91,82.19L234.99,83.13L236.21,80.39L236.36,80.76L236.5,81.54L237.13,85.3L237.17,85.86L237.19,85.54L237.52,87.76L237.78,87.6L237.85,88.44L237.91,89.33L238.06,86.74L238.59,87.68L238.69,88.08L238.94,91.65L239.26,87.74L239.33,88.28L239.39,88.01L239.58,87.43L239.8,88.78L239.89,88.59L239.99,90.07L240.06,89.6L240.29,92.46L240.79,91.3L240.84,90.53L241.21,89.27L241.49,92.59L241.65,92.1L241.72,91.46L242.44,89.91L242.54,90.88L243.03,87.93L243.34,89.11L243.46,89.31L244.57,95.48L244.71,93.58L244.8,91.67L245.65,98L245.74,97.18L245.79,95.94L246.03,99.32L246.43,96.62L246.51,94.56L247.04,95.25L247.16,94.03L247.29,93.88L248.51,90.23L248.59,90.89L248.82,90.09L249.22,91.46L249.38,92.41L249.73,94.3L250.04,93.47L250.16,91.55L250.21,90.89L250.27,91.82L250.79,90.96L250.88,92.14L251,92.53L251.25,91.37L251.36,90.55L251.88,90.16L251.93,91.09L252.05,90.86L252.19,91.09L252.28,91.64L252.64,89.2L252.69,89.07L253.06,88.68L253.15,88.21L253.24,89L253.5,87.91L253.82,88.69L253.95,88.29L254.08,89.61L254.25,88.04L254.74,88.66L254.92,89.2L256.38,84.29L256.5,84.53L256.67,85.04L256.94,84.87L257.62,86.21L257.81,87.02L257.97,86.39L258.38,87.57L258.45,87.94L258.73,87.63L259.04,88.6L259.15,87.87L259.32,87.72L259.74,89.13L259.87,88.8L260,88.35L260.68,87.56L260.82,87.9L261.04,88.66L261.6,85.48L262.02,86.73L262.21,87.39L262.3,86.35L262.66,87.77L262.84,86.72L263.03,87.58L263.24,86.35L263.58,87.98L263.68,87.65L263.83,88.63L264.3,88.39L265.51,91.64L265.56,90.3L265.77,89.26L265.96,90.62L266.06,90.44L266.24,90.22L266.45,90.78L266.6,89.68L266.88,90.08L267.1,90.15L268.01,89.01L268.13,89.07L268.26,90.05L268.98,88.29L269.21,89.32L269.38,89.65L270.15,88.98L270.26,88.55L271.34,90.88L271.51,90.26L271.61,90.12L274.61,87.01L274.78,87.65L275.84,86.93L275.89,87.65L276.07,87.9L277.12,87.55L277.44,86.91L278.97,89.23L279.07,89.11L279.97,90.16L280.13,89.51L280.38,91.21L280.88,90.31L281.12,90.23L281.41,90.22L281.73,90.96L282.05,93.2L282.38,92L282.57,91.14L283.12,90.27L283.39,90.86L283.65,89.23L284.41,89.11L284.58,88.5L285.51,87.05L285.63,87.25L285.92,87.07L286.19,87.94L286.67,84.02L287.1,85.41L287.29,85.29L287.91,86L288.12,84.9L288.67,86.16L288.96,85.59L289.14,85.29L289.34,85.21L289.5,85.68L289.68,86.42L290.01,87.18L290.13,86.56L290.25,86.34L290.71,86.11L290.84,86.4L291.12,85.12L291.32,83.42L291.48,82.61L291.51,82.87L291.85,81.7L291.98,81.96L292.1,81.08L292.23,80.86L292.29,81.53L292.4,81.52L292.57,82.12L292.75,82.51L292.93,82.29L293.15,81.52L293.55,84.39L294.05,83.88L294.22,83.62L294.37,83.48L294.54,83.86L294.74,84.71L294.88,84.05L295.22,85.29L295.43,85.91L295.76,85.3L296.24,89.09L296.48,88.84L296.6,88.9L296.68,89.67L297.1,88.21L297.22,89.11L297.39,88.41L297.5,90.29L297.67,88.12L298.1,88.57L298.27,88.61L298.46,87.23L298.93,89.01L299.13,89.31L299.64,91.25L300.03,90.34L300.21,89.77L300.67,89.31L300.79,90.3L300.93,90.43L301.07,90.24L301.24,92.07L301.59,92.67L301.99,90.83L302.13,90.52L302.42,89.93L302.78,91.42L302.94,90.74L303.03,89.65L303.19,88.78L303.82,90.44L303.91,90.62L304.43,91.04L304.52,91.92L305.09,90.65L305.31,91.2L305.42,91.99L305.62,93.37L305.9,91.25L306.01,90.61L306.34,89.65L306.37,90.98L306.42,91.9L306.81,89.14L307.29,89.37L307.42,89.75L307.55,88.81L308.11,89.58L308.3,89.37L308.47,88.7L308.75,90.07L309.07,89.11L309.29,89.45L309.48,89.72L309.7,89.01L309.93,87.78L310.1,87.23L310.42,88.04L310.61,88.82L311.49,89.86L311.65,89.4L311.89,89.39L312.85,91.18L312.98,90.4L313.39,90.95L313.55,91.42L313.82,91.88L314.06,91.09L314.24,90.99L314.5,90.6L315.04,91.05L315.21,91.96L315.78,93.21L315.88,92.5L315.98,92.09L316.49,92.32L316.63,91.5L316.82,91.48L317.01,92.75L317.27,94.83L317.81,94.47L317.91,94.38L318.61,97.01L318.63,96.93L318.65,97.91L318.73,98.41L318.99,96.74L319.08,96.79L319.16,96.23L319.61,93.79L320.01,94.17L320.12,94.85L320.28,94.63L320.81,97.64L320.92,96.62L321.01,95.18L321.75,91.68L321.89,91.84L321.98,91.6L323.8,96.28L323.89,95.66L323.99,94.78L324.28,95.05L325.41,92.5L325.53,92.87L325.81,91.26L326.32,92.6L326.48,92.65L326.94,90.73L327.26,91.04L327.46,91.85L328.51,93.19L328.66,93.07L328.77,92.27L329.02,91.69L329.27,92.63L329.39,92.05L329.6,91.59L329.93,92.4L330.17,91.17L330.68,91.7L330.82,92.34L331.39,89.4L331.81,89.53L331.93,90.75L332.66,89.57L332.77,89.34L332.93,88.64L333.34,88.86L333.55,89.5L334.2,88L334.41,88.11L334.6,87.28L334.96,88.08L335.13,87.1L335.41,86.59L335.59,85.96L336.35,84.22L336.49,85.22L336.59,86.01L336.97,82.82L337.47,83.72L337.56,84.15L338.46,83.29L338.59,83.75L339.2,86.95L339.74,86.4L339.84,86.39L340.86,89.97L340.96,88.98L341.06,88.78L341.28,89.34L341.52,85.55L341.54,84.48L341.98,70.6L342.25,74.81L342.3,75.21L342.48,77.71L343.03,73.09L343.08,73.67L343.15,74.44L343.23,75.26L343.67,72.57L343.75,71.55L343.88,73.04L344.35,68.84L344.56,70.2L344.65,73.75L344.79,74.59L344.97,72.56L345.25,73.38L345.33,74.2L345.5,72.58L345.91,76.2L345.95,76.36L346.15,75.87L346.71,79.64L346.78,79.37L346.81,80.08L346.84,78.98L347.47,82.56L347.51,83.07L347.55,84.7L347.96,80.56L348.19,81.12L348.29,82.2L348.8,79.35L349.06,81.8L349.22,81.95L349.5,83.87L349.85,81.12L349.9,80.83L350.92,83.88L351.07,82.6L351.16,81.99L351.51,84.64L351.62,85.03L351.84,86.85L351.94,85.73L352.01,85.17L352.48,85.7L352.61,84.89L352.78,83.99L352.92,83.88L352.94,84.64L353.07,85.7L354.19,82.43L354.43,83.11L354.55,84.05L355.07,82.37L355.36,83.17L355.54,82.72L355.65,82.18L355.77,83.01L355.94,82.86L356.07,84.25L356.43,84.74L357.21,82.79L357.4,82.51L357.89,83.1L358.1,82.42L358.32,81.91L358.62,84.42L359.19,83.17L359.32,82.74L359.95,82.19L360.19,83.09L360.62,82.11L360.91,82.52L361.08,82.89L361.89,81.34L362.13,82.1L362.47,82.37L363.62,83.55L363.91,83.06L364.33,83.96L364.59,83.46L364.9,83.09L365.94,84.57L366.18,84.11L367.22,85.02L367.28,84.27L368.09,85.45L368.32,85.04L368.42,84.64L368.82,84.56L368.99,84.96L369.33,85.22L369.7,83.04L370.07,84.21L370.3,84.38L370.98,85.13L371.14,86.36L371.38,87.8L371.76,87.14L371.93,86.89L372.41,87.24L372.56,88.36L372.67,89.02L372.99,87.54L373.18,87.28L373.82,87.53L374.04,87.09L374.68,87.55L375,86.39L375.67,85.87L375.92,87.73L376.12,88.62L376.54,86.8L376.73,86.13L377.09,84.37L377.38,84.71L377.63,84.81L378.21,83.77L378.54,84.47L378.81,84.71L379.4,83.22L379.62,84.18L379.64,85.03L379.67,85.39L380.29,84.15L380.44,83.96L380.88,81.22L381.19,82.27L381.38,82.76L381.53,82.13L381.92,83.24L382.1,83.08L382.43,82.24L382.68,83.09L382.86,83.91L383.26,83.56L383.59,84.92L383.69,84.78L383.77,83.92L384.58,86.14L384.67,85.55L384.79,85.02L385.27,84.75L385.52,84.04L385.69,83.35L386.26,83.95L386.52,83.55L387.27,84.01L387.59,84.41L387.84,84.21L388.09,85.03L389,83.91L389.15,83.33L389.94,84.44L390.15,84.27L390.79,84.92L391.21,83.96L392.61,82.54L392.77,82.2L392.87,82.87L393.28,82.08L393.58,82.76L393.74,81.93L394.04,78.06L394.46,79.57L394.6,79.35L395.3,80.24L395.44,80.99L395.53,81.31L395.64,80.37L396.03,80.49L396.19,79.47L396.85,81.75L397,80.8L397.18,79.94L397.35,79.67L397.38,80.93L397.45,81.21L397.78,81.37L397.89,80.27L398.01,79.7L398.66,80.6L398.92,80.21L399.87,77.28L400.3,77.56L400.46,78.18L400.62,77.66L401,77.85L401.28,78.11L402.02,78.8L402.13,77.35L402.4,76.29L402.88,77.07L403.02,77.3L403.48,77.34L403.7,76.44L404.27,74.55L404.65,74.95L404.82,75.42L405.06,75.7L405.31,74.93L405.49,74.59L407.1,77.99L407.46,77.84L407.59,77.45L409.72,74.98L409.92,75.55L411.2,73.25L411.38,73.41L411.5,73.82L411.65,73.6L411.8,73.71L411.96,74.65L412.25,73.29L412.65,74.1L412.85,74.57L416.02,69.5L416.17,70.63L417.24,72.38L417.32,71.59L417.87,70.97L418.02,71.46L418.2,71.97L418.89,70.57L419,70.95L419.24,70.88L419.72,68.26L419.9,70.07L419.95,70.98L420.14,73.96L420.7,72.39L420.84,71.49L421.24,71.12L421.67,73.37L421.74,72.08L421.89,71.62L422.01,71.51L422.15,71.92L422.31,72.81L422.69,71.77L422.84,72.15L423,73.3L423.49,76.05L423.93,74.76L424.08,74.65L425.09,72.73L425.14,72.85L425.23,73.92L426.01,71.45L426.17,72.07L426.31,72.44L426.67,72.76L426.84,71.79L427.03,72.48L427.24,73.43L427.65,72.71L427.92,74.07L428.62,73.06L428.86,73.53L429.1,74.8L429.43,74.3L429.69,73.78L430.13,72.7L430.55,72.84L430.8,73.46L432.52,71.36L432.64,72.25L432.99,71.44L433.2,71.93L433.37,72.58L433.63,72.66L433.68,71.76L434.04,72.15L434.3,71.48L434.47,71.68L434.74,71.66L434.91,70.71L435.32,70.9L435.73,69.66L435.77,69.96L436.29,70.41L436.42,70.29L436.53,69.55L436.9,71.5L437.49,70.94L437.7,70.91L438.58,73.02L438.75,71.89L438.95,71.94L441,69.94L441.22,69.33L441.35,69.34L442.03,66.01L442.16,66.37L442.19,67.57L442.26,69.39L442.65,66.24L442.72,66.01L442.97,65.44L443.86,67.62L444.23,67.11L444.49,66.86L445.62,65.41L445.7,65.31L445.94,66.07L446.1,64.68L446.43,65.21L446.55,64.66L446.85,65.18L447.11,64.16L447.18,64.08L447.37,63.02L447.92,63.17L448.05,63.22L448.27,64.19L448.67,63.5L448.89,63.19L449.3,63.35L449.95,61.14L450.07,61.86L450.19,61.94L451.04,63.68L451.1,63.55L451.22,63L451.32,62.88L451.46,63.27L451.63,63.22L451.82,63.94L451.95,63.59L452.04,64.04L452.2,65.17L453.24,62.8L453.36,63.22L453.52,64.13L454.28,67.77L454.44,66.75L454.52,65.96L454.64,65.84L455.1,66.34L455.26,67.6L455.52,69.1L455.9,67.91L456.07,68L456.87,70.39L457.15,69.87L457.32,68.56L457.75,68.37L457.94,69.07L458.14,67.83L458.24,68.1L458.57,67.07L458.68,66.56L459.5,65.37L459.64,65.86L459.75,65.59L459.93,66.57L460.08,66.21L460.21,66.72L461.16,68.52L461.25,68.01L461.41,67.07L462.62,71.31L462.74,70.86L462.81,70.27L463.17,72.42L463.54,70.28L463.61,70.21L464,71.03L464.2,70.28L464.42,69.57L464.73,69.33L464.93,69.62L465.14,70.94L466.24,68.66L466.47,68.96L466.97,67.4L467.45,67.83L467.61,68.17L468.18,68.79L468.32,69.04L468.51,68.83L468.75,69.65L468.94,69.36L469.09,69.41L469.47,70.3L469.56,69.03L469.7,68.73L470.15,68.59L470.38,68.23L471.43,66.26L471.51,66.67L471.7,66.6L472.83,67.21L473.02,66.37L473.84,66.12L473.97,66.57L474.02,66.88L474.2,64.97L474.31,62.51L474.69,48.81L475.04,52.59L475.09,52.23L475.19,51.13L475.35,54.16L475.76,52.48L475.84,52.39L475.99,50.61L476.71,55.52L477.08,54.86L477.23,54.87L477.35,53.57L477.56,55.79L477.93,54.05L478.05,55.08L479.34,48.36L479.4,49.54L479.46,50.1L480.48,40.05L480.85,41.96L480.92,42.29L481.59,45.53L481.72,44.71L481.83,44.3L482.03,45.78L482.37,42.98L482.46,43.15L482.54,43.36L482.79,43.82L483.15,41.87L483.33,43.02L483.49,42.65L484.21,38.03L484.44,39.3L484.53,40L484.82,38.83L485.01,41.81L485.08,41.84L485.3,41.32L485.6,43.17L485.63,43.63L485.96,43.11L486.35,45.85L486.44,45.47L486.52,44.4L486.98,42.64L487.21,43.68L487.3,44.84L487.5,47.51L487.86,44.86L487.95,43.6L487.99,44.28L488.51,42.66L488.65,43.62L488.76,41.84L488.82,41.52L489.12,42.59L489.17,41.94L489.22,43.88L489.32,43.95L489.47,42.03L489.9,43.9L489.98,44.06L490.52,40.18L490.86,41.86L490.97,42.27L491.27,42.57L491.97,40.15L492.09,40.99L492.24,40.83L492.38,41.69L492.44,42.96L492.58,41.93L492.92,44.08L493.03,43.4L493.19,43.11L493.68,42.27L494.1,44.69L494.25,44.29L494.41,43.97L495.18,42.44L495.28,43.57L495.74,45.85L496.1,45.07L496.25,44.05L497.59,42.12L497.86,42.48L497.94,43.66L499.09,40.97L499.14,41.37L499.2,42.3L500.38,49.12L500.47,46.42L500.52,45.88L500.56,45.15L500.6,46.26L501.19,45.52L501.28,46.5L502.08,51.93L502.27,49.93L502.29,49.47L502.41,50.01L503.09,48.08L503.16,48.33L503.3,48.12L503.41,47.82L503.5,48.3L503.76,48.15L503.89,48.76L503.97,49.29L504.27,47.73L504.58,48.74L504.74,49.29L504.87,50L505.27,48.25L505.41,47.88L506.22,47.43L506.37,48.65L506.76,48.24L507.15,50.93L507.24,50.26L507.39,49.59L508.16,48.34L508.36,48.57L508.67,46.77L508.69,46.32L509.07,49.15L509.2,48.58L509.33,49.59L509.54,48.5L509.95,49.78L510.17,49.54L510.32,47.81L510.91,49.06L511.02,48.97L512.49,43.87L512.55,44.32L512.6,44.4L513.02,45.14L513.76,40.14L513.77,38.62L513.9,36.92L514.22,40.21L514.51,38.67L514.55,38.03L514.69,37.85L514.79,39.53L515.33,38.52L515.41,38.59L515.89,41.02L516.17,40.54L516.28,40L516.37,40.32L516.53,38.6L516.69,39.71L516.85,39.02L517.37,39.36L517.6,37.67L517.67,36.21L518.11,42.65L518.55,41.4L518.7,40.9L519.71,35.24L519.92,36.61L520.04,37.23L520.1,38.76L520.49,37.07L520.73,37.7L520.87,38.11L521.95,41.79L522.03,40.62L522.3,40.11L522.92,42.1L522.98,41.49L523.14,39.84L523.54,41.82L523.82,40.38L523.95,40.4L524.17,39.81L524.45,41.23L524.68,40.47L524.86,40.63L525.85,39.05L525.89,39.48L526.05,39.94L526.23,39.97L526.31,38.77L526.74,38.13L527.21,39.87L527.27,39.3L527.65,44.04L528.05,41.65L528.14,41.55L528.38,40.67L528.48,39.85L528.58,38.63L529.18,38.73L529.33,39.38L529.75,41.36L530.24,40.82L530.43,41.02L531.39,38.39L531.79,38.83L532.12,39.63L532.5,40.75L532.92,39.97L533.1,39.38L533.79,39.46L534.05,38.63L534.21,38.34L534.45,38.93L534.67,39.12L535.33,39.13L535.59,40.16L535.77,38.73L536.21,39.57L536.37,39.77L536.9,40.84L536.99,41.53L537.04,42.34L537.63,40.21L537.81,41.01L538.33,41.34L538.46,42.13L538.53,41.63L538.71,43.59L538.94,42.74L539.06,43.72L539.41,41.36L539.95,42.03L540.04,41.61L540.49,42.61L540.6,42.25L540.76,41.15L540.92,41.65L541.42,41.03L541.54,41.13L541.63,41.71L541.73,40.87L542.22,41.78L542.41,42.29L542.76,42.35L543.01,41.65L543.2,42.12L544.11,42.2L544.34,41.19L544.53,40.72L544.78,41.82L545.04,40.95L545.26,41.31L546.42,39.69L546.65,40.54L546.73,39.63L547.3,40.45L547.49,40.22L547.93,40.64L548.15,39.98L548.35,39.63L548.88,36.81L548.9,36.11L548.98,34.27L549.51,36.47L549.62,36.04L549.78,35.28L549.87,36.4L550.56,36.14L550.62,35.79L551.41,34.52L551.57,35.13L551.71,35.93L552.41,33.16L552.78,33.84L552.91,34.52L553.77,36.8L553.81,35.89L553.88,35.55L554.15,37.69L554.67,35.95L554.86,35.02L555.77,36.92L555.91,36.3L556.2,36.6L556.84,35.61L557.06,35.65L557.45,35.94L557.71,34.88L557.91,34.72L558.2,35.3L558.39,35.97L558.99,35.53L559.45,37.77L559.52,37.5L560.06,45.63L560.49,41.86L560.55,41.14L561.25,43.66L561.69,43.33L561.8,43.1L562.76,40.77L562.87,41.02L563.58,39.72L563.79,39.97L563.94,41.02L564.92,38.99L565.04,39.1L565.57,39.83L565.67,39.25L565.8,38.49L565.89,37.82L566.14,38.7L566.42,38.69L566.56,39.21L566.88,39.9L567.05,39.1L567.17,38.87L568.14,36.25L568.42,36.86L568.54,36.86L569.13,36.79L569.33,36.35L570.2,37.73L570.38,36.86L570.8,39.26L571.02,38.2L571.14,37.66L571.35,37.46L571.51,37.7L571.62,38.5L571.91,40.22L571.96,39.35L572.03,40.55L572.14,41.36L572.41,39.15L572.57,38.06L572.7,38.17L572.86,37.85L572.99,36.97L573.13,37.22L573.42,36.42L573.63,35.53L574.07,31.93L574.44,33.78L574.47,34.07L575.32,36.64L575.35,35.87L575.41,35.52L575.63,35.14L575.72,35.94L575.87,36.29L576.55,34.28L576.74,35.1L577.08,34.42L577.88,35.68L577.96,35.64L578.26,36.41L578.45,34.91L578.48,33.61L578.67,30.45L579.27,34.94L579.32,34.49L579.47,35.82L579.84,34.19L580,34.24L580.13,34.09L581.71,38.88L581.79,37.66L581.85,37.35L582.53,36.19L582.63,37.42L582.75,37.72L582.91,37.61L583.04,36.3L583.41,36.96L583.71,36.44L583.89,36.1L585.14,33.75L585.28,34.39L585.39,35.16L586.2,31.56L586.35,32.61L586.44,33.14L586.76,34.22L586.9,33.51L587.01,32.69L587.35,34.63L587.75,33.36L587.92,33.43L589.24,28.36L589.34,29.33L589.4,29.79L590.22,26.98L590.36,27.69L590.43,27.98L590.83,28.22L591.26,26.72L591.35,27.53L591.66,27.39L592.24,29.9L592.36,28.69L592.44,28.23L592.82,29.36L592.93,28.78L593.04,27.53L593.12,27.04L593.28,28.42L593.56,27.67L593.64,28.69L593.68,29.2L594.05,28.1L594.22,28.13L594.35,28.06L596.58,24L596.68,24.71L597.24,25.36L597.36,25.11L597.53,24.74L597.82,24.95L597.98,24.26L598.09,24.14L598.95,25.42L599.11,25.11L599.24,24.43L599.6,25.13L599.84,25.32L600.16,26.12L600.45,25.18L600.64,24.96L601.33,25.23L601.59,25.97L601.94,26.71L601.97,27.07L602.03,27.33L602.29,25.45L602.57,26.54L602.67,25.94L602.82,27.17L603.33,25.91L603.48,25.83L604.6,28.95L604.68,28.41L604.79,27.58L605.93,25.23L605.96,25.55L606.05,25.21L606.49,27.04L606.75,26.28L606.89,26.01L607.91,25.22L608.05,25.83L608.77,26.97L608.86,25.86L609.01,25.51L609.34,25.85L609.57,25.03L609.79,25.45L610.5,27.13L610.66,27.02L610.86,26.9L611.14,26.11L611.32,26.49L611.44,27.23L611.62,26.86L612.18,29.26L612.37,28.73L612.45,27.92L613.07,27.8L613.27,27.96L613.43,28.44L614.74,26.25L614.89,26.62L615.93,24.7L615.97,23.35L616.08,22.47L616.35,23.6L616.68,22.59L616.88,23.38L617.14,23.02L617.43,23.6L617.62,23.87L618.11,24.19L618.59,22.63L618.68,22.86L618.78,23.5L619.1,21.75L619.27,21.99L619.38,21.61L620.05,16.7L620.52,17.58L620.64,17.1L620.79,17.26L621.03,16.99L621.14,15.98L621.36,13.62L621.53,16.63L621.62,16.44L621.72,16.92L622.57,12.2L622.68,12.74L622.75,12.83L623.04,15.46L623.43,13.82L623.6,13.61L623.76,13.94L623.92,13.22L624.08,11.72L624.2,14.82L624.63,10.96L624.76,12.65L624.86,11.69L625.08,12.65L625.54,12.33L625.72,12.17L626.21,13.73L626.61,13.24L626.78,13.3L627.03,14.08L627.41,13.78L627.62,13.35L629,15.58L629.12,14.56L629.23,14.89L629.42,14.18L629.61,14.15L629.8,13.23L630.15,13.4L630.3,13.03L630.5,12.49L631.37,8.02L631.48,8.58L631.6,8.93L631.91,9.31L632,9.04L632.13,10.17L632.42,12.96L632.85,11.33L632.94,11.79L633.45,8.6L633.8,9.54L633.88,9.72L634.37,9.43L634.48,10.24L634.59,9.58L634.96,10.8L635.2,10.21L635.36,10.74L635.84,10.19L636.14,12.97L636.23,12.34L636.28,14.52L636.41,14.33L636.43,18.99L637.02,12.55L637.16,14.02L637.21,14.3L638.38,11.12L638.48,11.26L638.86,10.19L638.91,11.1L639.06,11.19L639.27,11.89L639.66,10.62L639.87,9.95L640.02,10.06L640.14,11.11L640.52,11.36L640.71,11.69L641.07,12.3L641.18,12.55L641.35,12.71L641.89,10.7L641.96,10.8L642.08,11.44L642.58,10.06L642.66,9.13L642.77,6.89L643.38,8.69L643.55,8.58L643.85,8.45L644.08,10.53L644.29,9.61L644.42,8.99L644.73,8.87L644.83,10.04L645.34,8.24L645.55,8.46L645.69,8.75L645.92,9.2L646.12,8.16L646.21,7.75L646.29,7.41L646.8,8.08L646.97,7.85L647.47,5.23L647.87,6.12L648.06,6.28L648.13,6L648.26,6.52L648.41,8.06L648.66,6.76L649.04,8.51L649.07,8.22L649.15,8.24L649.41,9.59L649.7,8.04L649.78,8.16L649.94,8.26L650.08,8.14L650.22,9.32L650.73,12.62L650.98,9.96L651.05,9.85L651.17,11.39L651.4,9.84L651.53,8.87L652.72,15.31L652.81,14.28L652.88,13.33L653.38,13.7L653.81,11.97L653.93,13.53L654.63,11.4L654.72,12.54L654.86,13.65L654.93,13.13L655.04,14.27L655.28,13.89L655.4,15.64L655.45,14.75L655.75,19.24L656.16,15.48L656.23,15.8L656.46,15.75L657.56,22.77L657.59,21.83L657.63,21.84L657.96,32.05L657.97,38.7L658.76,20.1L658.8,21.23L659.19,20.13L659.55,24.55L659.62,22.58L659.7,23.31L660.04,26.73L660.24,23.77L660.3,22.84L661.17,18.57L661.23,19.03L661.51,19.73L661.63,19.19L661.73,18.25L661.85,18.83L662.05,16.77L662.14,16.46L662.89,21.2L663.02,19.71L663.12,18.94L664.05,23.01L664.1,22.86L664.21,23.7L664.4,23.29L664.85,28.92L665.21,26.99L665.24,26.81L665.35,24.14L665.78,29.56L665.81,30.46L665.83,29.69L666.22,36.22L666.48,32.43L666.53,33.77L666.67,28.46L667.28,32.36L667.35,31.17L667.44,30.9L668.27,48.37L668.38,38.89L668.4,37.88L668.75,36.32L668.99,41.17L669.02,40.29L669.04,41.67L669.25,38.15L669.66,47.94L669.81,43.63L669.83,42.96L670.09,45.2L670.23,36.9L670.25,37.49L670.27,34.67L670.46,33.78L670.71,37.51L671.05,36.53L671.13,37.45L671.33,44.88L671.58,37.94L671.61,36.29L671.81,34.59L672.6,41.41L672.65,40.45L672.77,38.51L673.18,42.78L673.39,40.14L673.47,41.03L674.13,47.08L674.31,42.71L674.36,42.25L675.3,37.36L675.4,37.23L675.47,38.88L675.87,36.23L676.13,36.93L676.27,35.38L676.52,41.23L676.95,36.37L677,35.53L677.13,35.74L677.45,30.99L678.06,31.33L678.15,31.42L678.59,28.24L678.78,29.69L678.85,30.71L679.05,29.86L679.24,31.64L679.49,30.45L679.61,31.37L679.98,31.29L680.15,33.18L680.36,32.19L680.46,31.79L681.59,28.25L681.63,29.39L681.71,29.44L682.21,31.92L682.39,30.73L682.52,29.74L682.71,31.29L683.12,28.52L683.25,29.42L683.36,29.12L684.31,36.06L684.36,34.86L684.65,36.72L685.01,32.18L685.19,33.56L685.27,33.63L685.41,34.04L685.66,32.77L685.77,33.31L685.92,32.46L687.56,36.14L687.66,34.89L688.09,37.89L688.43,36.84L688.55,36.22L688.95,34.15L689.06,34.29L689.16,33.27L690.44,29.66L690.52,29.83L690.67,30.33L690.8,30.11L690.98,30.64L691.17,31.34L691.33,30.85L691.62,32.22L691.69,31.36L691.81,32.43L692.05,33.33L692.3,32.16L692.43,31.7L692.48,32.07L692.7,30.84L693.13,31.56L693.27,30.67L694.02,32.14L694.13,33.01L694.68,36.18L695.01,34.97L695.13,33.99L695.86,31.39L695.91,29.76L696.01,31.64L696.5,26.32L696.53,25.53L697.4,29.61L697.42,29.23L697.59,28.47L697.91,29.77L697.99,30.47L698.19,28.36L698.68,31.51L698.73,32.42L698.8,31.42L699.12,34.11L699.35,32.7L699.42,33.67L699.65,34.26L699.75,32.26L700.07,33.64L700.24,34.4L700.42,34.26L701.14,36.93L701.23,37.63L701.42,39.98L701.53,36.77L701.61,36.08L702.45,43.05L702.48,41.93L702.5,40.8L702.54,40.26L702.74,44.67L703.23,41.05L703.3,42.2L703.5,44.07L703.72,40.78L703.79,42.33L703.86,39.79L704.35,41.75L704.56,39.63L704.67,40.22L704.75,39.65L705.04,41.9L705.14,43.04L705.31,42.5L705.39,43.32L705.49,44.06L706.23,43.91L706.41,47.36L706.43,47.51L706.65,51.15L707.06,45.27L707.12,46.38L707.19,45.99L707.27,46.55L707.45,43.74L707.64,44.75L707.71,43.72L707.84,44.11L708.33,42.85L708.43,43.23L708.54,43.95L708.75,45.3L709.06,42.64L709.14,41.47L709.19,41.15L709.44,43.12L709.55,43.86L710.11,45.4L710.38,40.94L710.48,41.48L710.56,42.21L710.79,43.66L711.02,39.1L711.09,39.54L711.16,38.86L711.69,37.36L711.98,39.51L712.07,39.59L712.29,40.24L712.51,39.42L712.61,39.91L712.74,41.15L712.84,40.99L712.94,41.71L713.1,42.69L713.31,41.95L713.54,44.08L713.74,42.98\" style=\"vector-effect: none; fill: none; stroke: rgb(127, 127, 127); stroke-opacity: 1; stroke-width: 2px; opacity: 1;\"/></g><g class=\"points\"/><g class=\"text\"/></g><g class=\"trace scatter trace085cb16b-65ec-4324-8672-fad525e5d72b\" style=\"stroke-miterlimit: 2;\"><g class=\"fills\"><g><path class=\"js-fill\" d=\"M23.75,88.19L41.84,87.49L41.91,87.12L42.54,84.95L43.05,85.35L43.21,85.99L43.4,85.27L43.65,87.15L43.79,86.78L44.07,87.87L44.26,86.45L44.52,87.36L44.63,85.99L44.87,86.48L45.01,86.07L45.13,84.83L45.56,86.83L45.87,85.09L46,85.43L46.93,82.96L47.04,83.82L47.39,87.16L47.45,85.5L47.5,84.27L47.58,84.53L47.94,80.58L48.53,81.27L48.67,81.3L49.44,79.09L49.52,79.59L49.56,80.54L49.77,78.21L50.26,79.43L50.4,79.16L50.69,80.22L50.89,79.62L51.02,78.82L51.3,76.93L52,77.25L52.14,78.41L52.42,76.77L52.74,78.3L52.86,78.97L53.34,78.66L53.53,79.25L53.71,79.33L53.8,79.1L53.9,80.2L53.99,80.75L54.77,77.74L54.85,78.09L55.11,78.83L55.44,77.97L55.61,77.69L56.72,74.69L56.78,75.13L56.87,75.57L57.15,74.08L57.62,75.32L57.74,75.42L58.91,70.6L58.95,70.57L59.4,68.49L59.7,79.52L59.93,74.93L59.95,73.94L59.98,75.12L60.19,72.09L60.64,73.18L60.71,72.52L61.23,70.27L61.34,70.37L61.4,71.59L61.71,69.75L61.95,71.62L62.02,73.59L62.58,70.65L62.79,72.04L62.93,72.73L64,80.05L64.17,76.53L64.2,75.5L64.25,76.04L64.76,74.02L64.84,73.98L65.06,73.35L65.73,76.01L65.81,77.03L66.47,72.97L66.61,73.21L66.7,72.8L67.36,74.58L67.58,73.79L67.71,73.29L69.19,64.28L69.35,64.92L69.43,65.87L69.66,67.4L70.1,64.95L70.17,66.13L70.26,66.19L70.71,63.66L70.8,66.41L70.83,67.58L71.58,66.63L71.64,66.63L81.87,67.22L81.98,68.05L82,68.84L82.62,67.57L82.71,67.99L82.86,67.49L83.17,66.12L83.54,67.5L83.7,69.23L84,68.26L84.17,69.1L84.32,69.33L84.7,70.49L84.91,68.99L85.04,68.65L85.96,67.64L86.12,68.29L86.56,69.44L87.11,69.06L87.32,69.06L89.58,69.44L89.69,69.61L90.01,69.51L90.92,71.32L91.12,71.32L99.78,71.32L99.79,70.12L100.58,61.74L100.68,60.22L100.73,59.84L101.09,61.79L101.22,61.36L101.32,61.61L101.49,61.2L102.15,66.37L102.21,65.71L102.26,63.86L102.4,63.75L102.53,65.26L103.61,73.74L103.63,73.4L103.65,76.25L103.68,76.91L103.89,70L104.2,72.61L104.24,72.61L107.55,72.61L107.63,73.64L148.15,73.08L148.22,72.79L148.25,73.35L148.82,70.22L148.86,70.04L150.15,72.31L150.25,71.97L150.36,71.85L150.44,72.4L150.7,72.56L150.88,72.55L151.03,72.99L151.29,71.78L151.45,72.36L151.6,71.43L152.89,71.53L153,71.53L160.5,72.12L160.58,72.45L161.4,73.8L161.52,73.8L163.92,73.8L163.99,74.75L167.33,74.64L167.5,73.82L167.64,73.4L167.74,74.62L167.88,75.4L167.97,75.17L168.28,76.37L168.43,75.89L168.5,75.89L172.56,76.41L172.69,76.91L174.25,80.63L174.34,80.63L175.75,81.25L175.83,82.44L176.04,82.67L176.17,81.96L176.51,82.69L176.71,82.69L189.06,82.17L189.15,82.82L189.78,83L190.03,83L191.44,82.45L191.5,81.79L192.13,81.04L192.35,82.74L193.93,82.61L194.2,82.61L199.92,82.59L199.98,83.21L200.08,83.09L200.19,83.63L200.64,83.56L200.81,83.56L201.53,85.2L201.73,85.2L207.09,85.2L207.17,86L208.05,86.98L208.27,86.98L210.58,87.1L210.68,86.41L210.78,86.1L211.14,87.12L211.29,87.12L286.73,87.58L286.83,87.93L287.53,88.19L287.71,87.95L287.91,88.19L288.12,87.7L288.67,88.19L288.85,88.19L341.65,88.19L341.66,86.88L341.72,88.19L341.98,79.98L342.4,84.62L342.44,84.62L393.95,84.34L393.97,83.81L394.04,83.09L394.46,84.52L394.67,84.23L394.81,84.41L395.78,84.81L396.03,84.81L396.76,85.29L396.85,85.92L397.68,85.01L397.78,85.01L402.88,85.58L403.02,85.79L403.48,85.83L403.7,85L404.27,83.24L404.65,83.62L404.82,84.05L405.06,84.31L405.31,83.6L405.49,83.28L406.56,84.09L406.68,84.09L407.59,84.34L407.87,83.92L408.43,83.91L408.57,83.91L411.8,83.82L411.96,84.68L412.65,83.52L412.85,83.52L415.45,83.85L415.57,82.83L416.02,82.35L416.69,84.3L416.83,84.3L419.44,84.3L419.57,83.47L419.72,82.42L419.95,84.83L420,86.01L432.52,86.01L432.64,86.78L432.99,86.07L433.2,86.5L433.37,87.07L435.52,87.34L435.69,86.63L435.73,86.45L435.85,87.12L436.29,87.11L436.42,87.11L437.7,88.08L437.98,88.08L441.22,87.56L441.27,86.95L441.86,87.57L441.97,86.7L442.03,86.42L442.88,88.19L442.97,88.19L449.02,87.44L449.13,87.35L449.3,87.91L449.55,87.16L449.75,87.2L449.81,87.04L449.95,86.44L450.54,86.76L450.67,86.76L467.98,87.42L468.18,87.58L469.29,88.1L469.47,88.1L474.02,88.19L474.2,87.17L474.69,73.83L475.14,76.65L475.19,76.65L480.14,76.53L480.15,77.7L480.25,77.74L480.6,76.26L480.95,76.62L481,76.62L481.83,76.3L481.91,77.19L482.03,77.46L482.17,76.22L482.28,75.38L482.79,75.92L483.15,74.4L483.2,75.11L483.33,75.29L483.86,73.93L483.93,74.07L484.01,72.69L484.04,73.05L484.21,71.38L484.69,72.7L484.76,72.41L484.82,72.01L485.08,74.37L485.22,74.02L485.3,73.96L486.35,77.52L486.44,77.22L486.52,76.38L486.98,75L487.21,75.81L487.3,76.72L487.5,78.82L487.86,76.74L487.95,75.75L487.99,76.28L488.51,75.01L488.65,75.76L488.76,74.37L488.82,74.12L489.12,74.95L489.17,74.45L489.22,75.97L489.32,76.03L489.47,74.52L489.9,75.99L489.98,76.11L490.52,73.07L490.86,74.39L490.97,74.71L491.27,74.95L491.97,73.05L492.09,73.71L492.24,73.58L492.38,74.25L492.44,75.25L492.58,74.44L492.92,76.13L493.03,75.6L493.19,75.36L493.68,74.71L494.1,76.6L494.25,76.29L494.41,76.04L495.18,74.84L495.28,75.73L495.41,76L495.74,77.51L496.1,76.9L496.25,76.1L497.59,74.59L497.86,74.87L497.94,75.8L499.09,73.69L499.32,74L499.45,74L500.36,74L500.38,75.21L501.14,73L501.19,73L501.68,73.11L501.71,74.08L501.79,72.53L502.08,75.94L502.41,74.34L502.5,73.55L502.73,73.97L503.02,73.06L503.16,73.06L503.3,73.06L504.97,73.36L505.11,72.51L506.22,71.5L506.37,72.52L506.58,73.25L507.15,73.07L507.24,72.5L508.69,69.18L508.72,70.21L509.33,70.79L509.54,69.86L510.17,69.66L510.32,68.17L511.02,69.17L511.18,68.37L512.15,68.32L512.27,68.32L512.95,68.12L513.02,69.07L513.9,62.18L513.99,63.78L514.03,64.14L514.22,64.94L514.45,63.64L514.51,63.65L514.55,63.65L549.12,64.23L549.17,64.83L549.51,65.24L549.78,64.27L549.87,65.18L549.97,64.91L551.2,63.74L551.29,63.74L574.18,63.74L574.2,64.93L574.26,64.31L574.74,65.87L574.87,65.61L575.02,65.78L576.07,66.54L576.18,66.54L586.29,66.86L586.35,66.95L587.23,67.57L587.35,67.57L589.27,68.05L589.3,68.34L590.04,67.88L590.11,67.88L617.43,68.37L617.62,68.57L618.11,68.81L618.47,68.21L618.59,68.21L619.8,67.94L619.9,66.59L620.05,65.65L620.2,66.93L620.52,66.29L620.64,65.94L621.03,65.86L621.14,65.13L621.36,63.43L621.53,65.6L621.62,65.47L621.72,65.81L622.57,62.41L622.68,62.79L622.75,62.86L623.04,64.75L623.43,63.57L623.6,63.42L623.76,63.66L623.92,63.14L624.08,62.06L624.2,64.29L624.63,61.51L624.76,62.73L624.86,62.04L625.08,62.73L625.54,62.5L625.72,62.39L626.21,63.51L626.61,63.16L626.78,63.2L627.03,63.77L627.41,63.55L627.62,63.24L629.23,64.84L629.42,64.84L630.97,64.42L631.01,64.29L631.23,65.19L631.37,64.13L631.91,65.03L632,64.85L632.42,67.57L632.85,66.43L632.94,66.75L633.16,65.63L633.69,66.02L633.8,66.02L662.29,66.02L662.42,67.65L662.54,67.05L663.12,67.6L663.23,67.6L670.25,67.6L670.27,65.33L670.46,64.61L670.71,67.62L671.05,66.83L671.13,67.57L671.95,68.56L671.99,68.56L678.26,68.29L678.36,67.26L678.59,66.19L678.85,68.08L679.05,67.43L679.17,68.27L690.98,68.89L691.17,69.43L691.33,69.05L691.62,70.1L691.69,69.44L691.81,70.26L692.05,70.94L692.43,70.05L692.48,70.05L713.74,70.05L713.74,88.19L23.75,88.19Z\" style=\"fill: rgb(0, 128, 0); fill-opacity: 0.25; stroke-width: 0;\"/></g></g><g class=\"errorbars\"/><g class=\"lines\"><path class=\"js-line\" d=\"M23.75,88.19L713.74,88.19\" style=\"vector-effect: none; fill: none; stroke: rgb(0, 0, 0); stroke-opacity: 0; stroke-width: 0px; opacity: 1;\"/></g><g class=\"points\"/><g class=\"text\"/></g><g class=\"trace scatter trace7eecafb4-ceac-4eef-827f-5475c0af6d8b\" style=\"stroke-miterlimit: 2;\"><g class=\"fills\"/><g class=\"errorbars\"/><g class=\"lines\"><path class=\"js-line\" d=\"M23.75,88.19L41.84,87.49L41.91,87.12L42.54,84.95L43.05,85.35L43.21,85.99L43.4,85.27L43.65,87.15L43.79,86.78L44.07,87.87L44.26,86.45L44.52,87.36L44.63,85.99L44.87,86.48L45.01,86.07L45.13,84.83L45.56,86.83L45.87,85.09L46,85.43L46.93,82.96L47.04,83.82L47.39,87.16L47.45,85.5L47.5,84.27L47.58,84.53L47.94,80.58L48.53,81.27L48.67,81.3L49.44,79.09L49.52,79.59L49.56,80.54L49.77,78.21L50.26,79.43L50.4,79.16L50.69,80.22L50.89,79.62L51.02,78.82L51.3,76.93L52,77.25L52.14,78.41L52.42,76.77L52.74,78.3L52.86,78.97L53.34,78.66L53.53,79.25L53.71,79.33L53.8,79.1L53.9,80.2L53.99,80.75L54.77,77.74L54.85,78.09L55.11,78.83L55.44,77.97L55.61,77.69L56.72,74.69L56.78,75.13L56.87,75.57L57.15,74.08L57.62,75.32L57.74,75.42L58.91,70.6L58.95,70.57L59.4,68.49L59.7,79.52L59.93,74.93L59.95,73.94L59.98,75.12L60.19,72.09L60.64,73.18L60.71,72.52L61.23,70.27L61.34,70.37L61.4,71.59L61.71,69.75L61.95,71.62L62.02,73.59L62.58,70.65L62.79,72.04L62.93,72.73L64,80.05L64.17,76.53L64.2,75.5L64.25,76.04L64.76,74.02L64.84,73.98L65.06,73.35L65.73,76.01L65.81,77.03L66.47,72.97L66.61,73.21L66.7,72.8L67.36,74.58L67.58,73.79L67.71,73.29L69.19,64.28L69.35,64.92L69.43,65.87L69.66,67.4L70.1,64.95L70.17,66.13L70.26,66.19L70.71,63.66L70.8,66.41L70.83,67.58L71.58,66.63L71.64,66.63L81.87,67.22L81.98,68.05L82,68.84L82.62,67.57L82.71,67.99L82.86,67.49L83.17,66.12L83.54,67.5L83.7,69.23L84,68.26L84.17,69.1L84.32,69.33L84.7,70.49L84.91,68.99L85.04,68.65L85.96,67.64L86.12,68.29L86.56,69.44L87.11,69.06L87.32,69.06L89.58,69.44L89.69,69.61L90.01,69.51L90.92,71.32L91.12,71.32L99.78,71.32L99.79,70.12L100.58,61.74L100.68,60.22L100.73,59.84L101.09,61.79L101.22,61.36L101.32,61.61L101.49,61.2L102.15,66.37L102.21,65.71L102.26,63.86L102.4,63.75L102.53,65.26L103.61,73.74L103.63,73.4L103.65,76.25L103.68,76.91L103.89,70L104.2,72.61L104.24,72.61L107.55,72.61L107.63,73.64L148.15,73.08L148.22,72.79L148.25,73.35L148.82,70.22L148.86,70.04L150.15,72.31L150.25,71.97L150.36,71.85L150.44,72.4L150.7,72.56L150.88,72.55L151.03,72.99L151.29,71.78L151.45,72.36L151.6,71.43L152.89,71.53L153,71.53L160.5,72.12L160.58,72.45L161.4,73.8L161.52,73.8L163.92,73.8L163.99,74.75L167.33,74.64L167.5,73.82L167.64,73.4L167.74,74.62L167.88,75.4L167.97,75.17L168.28,76.37L168.43,75.89L168.5,75.89L172.56,76.41L172.69,76.91L174.25,80.63L174.34,80.63L175.75,81.25L175.83,82.44L176.04,82.67L176.17,81.96L176.51,82.69L176.71,82.69L189.06,82.17L189.15,82.82L189.78,83L190.03,83L191.44,82.45L191.5,81.79L192.13,81.04L192.35,82.74L193.93,82.61L194.2,82.61L199.92,82.59L199.98,83.21L200.08,83.09L200.19,83.63L200.64,83.56L200.81,83.56L201.53,85.2L201.73,85.2L207.09,85.2L207.17,86L208.05,86.98L208.27,86.98L210.58,87.1L210.68,86.41L210.78,86.1L211.14,87.12L211.29,87.12L286.73,87.58L286.83,87.93L287.53,88.19L287.71,87.95L287.91,88.19L288.12,87.7L288.67,88.19L288.85,88.19L341.65,88.19L341.66,86.88L341.72,88.19L341.98,79.98L342.4,84.62L342.44,84.62L393.95,84.34L393.97,83.81L394.04,83.09L394.46,84.52L394.67,84.23L394.81,84.41L395.78,84.81L396.03,84.81L396.76,85.29L396.85,85.92L397.68,85.01L397.78,85.01L402.88,85.58L403.02,85.79L403.48,85.83L403.7,85L404.27,83.24L404.65,83.62L404.82,84.05L405.06,84.31L405.31,83.6L405.49,83.28L406.56,84.09L406.68,84.09L407.59,84.34L407.87,83.92L408.43,83.91L408.57,83.91L411.8,83.82L411.96,84.68L412.65,83.52L412.85,83.52L415.45,83.85L415.57,82.83L416.02,82.35L416.69,84.3L416.83,84.3L419.44,84.3L419.57,83.47L419.72,82.42L419.95,84.83L420,86.01L432.52,86.01L432.64,86.78L432.99,86.07L433.2,86.5L433.37,87.07L435.52,87.34L435.69,86.63L435.73,86.45L435.85,87.12L436.29,87.11L436.42,87.11L437.7,88.08L437.98,88.08L441.22,87.56L441.27,86.95L441.86,87.57L441.97,86.7L442.03,86.42L442.88,88.19L442.97,88.19L449.02,87.44L449.13,87.35L449.3,87.91L449.55,87.16L449.75,87.2L449.81,87.04L449.95,86.44L450.54,86.76L450.67,86.76L467.98,87.42L468.18,87.58L469.29,88.1L469.47,88.1L474.02,88.19L474.2,87.17L474.69,73.83L475.14,76.65L475.19,76.65L480.14,76.53L480.15,77.7L480.25,77.74L480.6,76.26L480.95,76.62L481,76.62L481.83,76.3L481.91,77.19L482.03,77.46L482.17,76.22L482.28,75.38L482.79,75.92L483.15,74.4L483.2,75.11L483.33,75.29L483.86,73.93L483.93,74.07L484.01,72.69L484.04,73.05L484.21,71.38L484.69,72.7L484.76,72.41L484.82,72.01L485.08,74.37L485.22,74.02L485.3,73.96L486.35,77.52L486.44,77.22L486.52,76.38L486.98,75L487.21,75.81L487.3,76.72L487.5,78.82L487.86,76.74L487.95,75.75L487.99,76.28L488.51,75.01L488.65,75.76L488.76,74.37L488.82,74.12L489.12,74.95L489.17,74.45L489.22,75.97L489.32,76.03L489.47,74.52L489.9,75.99L489.98,76.11L490.52,73.07L490.86,74.39L490.97,74.71L491.27,74.95L491.97,73.05L492.09,73.71L492.24,73.58L492.38,74.25L492.44,75.25L492.58,74.44L492.92,76.13L493.03,75.6L493.19,75.36L493.68,74.71L494.1,76.6L494.25,76.29L494.41,76.04L495.18,74.84L495.28,75.73L495.41,76L495.74,77.51L496.1,76.9L496.25,76.1L497.59,74.59L497.86,74.87L497.94,75.8L499.09,73.69L499.32,74L499.45,74L500.36,74L500.38,75.21L501.14,73L501.19,73L501.68,73.11L501.71,74.08L501.79,72.53L502.08,75.94L502.41,74.34L502.5,73.55L502.73,73.97L503.02,73.06L503.16,73.06L503.3,73.06L504.97,73.36L505.11,72.51L506.22,71.5L506.37,72.52L506.58,73.25L507.15,73.07L507.24,72.5L508.69,69.18L508.72,70.21L509.33,70.79L509.54,69.86L510.17,69.66L510.32,68.17L511.02,69.17L511.18,68.37L512.15,68.32L512.27,68.32L512.95,68.12L513.02,69.07L513.9,62.18L513.99,63.78L514.03,64.14L514.22,64.94L514.45,63.64L514.51,63.65L514.55,63.65L549.12,64.23L549.17,64.83L549.51,65.24L549.78,64.27L549.87,65.18L549.97,64.91L551.2,63.74L551.29,63.74L574.18,63.74L574.2,64.93L574.26,64.31L574.74,65.87L574.87,65.61L575.02,65.78L576.07,66.54L576.18,66.54L586.29,66.86L586.35,66.95L587.23,67.57L587.35,67.57L589.27,68.05L589.3,68.34L590.04,67.88L590.11,67.88L617.43,68.37L617.62,68.57L618.11,68.81L618.47,68.21L618.59,68.21L619.8,67.94L619.9,66.59L620.05,65.65L620.2,66.93L620.52,66.29L620.64,65.94L621.03,65.86L621.14,65.13L621.36,63.43L621.53,65.6L621.62,65.47L621.72,65.81L622.57,62.41L622.68,62.79L622.75,62.86L623.04,64.75L623.43,63.57L623.6,63.42L623.76,63.66L623.92,63.14L624.08,62.06L624.2,64.29L624.63,61.51L624.76,62.73L624.86,62.04L625.08,62.73L625.54,62.5L625.72,62.39L626.21,63.51L626.61,63.16L626.78,63.2L627.03,63.77L627.41,63.55L627.62,63.24L629.23,64.84L629.42,64.84L630.97,64.42L631.01,64.29L631.23,65.19L631.37,64.13L631.91,65.03L632,64.85L632.42,67.57L632.85,66.43L632.94,66.75L633.16,65.63L633.69,66.02L633.8,66.02L662.29,66.02L662.42,67.65L662.54,67.05L663.12,67.6L663.23,67.6L670.25,67.6L670.27,65.33L670.46,64.61L670.71,67.62L671.05,66.83L671.13,67.57L671.95,68.56L671.99,68.56L678.26,68.29L678.36,67.26L678.59,66.19L678.85,68.08L679.05,67.43L679.17,68.27L690.98,68.89L691.17,69.43L691.33,69.05L691.62,70.1L691.69,69.44L691.81,70.26L692.05,70.94L692.43,70.05L692.48,70.05L713.74,70.05\" style=\"vector-effect: none; fill: none; stroke: rgb(0, 0, 0); stroke-opacity: 0; stroke-width: 0px; opacity: 1;\"/></g><g class=\"points\"/><g class=\"text\"/></g><g class=\"trace scatter trace8d88b946-0ea1-452d-9f64-fad77f455689\" style=\"stroke-miterlimit: 2;\"><g class=\"fills\"><g><path class=\"js-fill\" d=\"M23.75,88.19L341.72,88.19L341.72,89.01L341.73,89.57L341.76,88.19L342.44,88.19L342.48,88.19L442.24,88.19L442.26,89.26L443.2,89.26L443.36,89.75L443.61,89.56L443.86,90.39L445.43,90.08L445.62,89.59L445.94,90.12L446.1,88.99L446.25,89.65L446.85,89.4L446.99,89.14L447.92,88.19L448.05,88.19L448.27,88.6L448.89,88.19L449.02,88.19L713.74,88.19L713.74,88.19L23.75,88.19Z\" style=\"fill: rgb(255, 0, 0); fill-opacity: 0.25; stroke-width: 0;\"/></g></g><g class=\"errorbars\"/><g class=\"lines\"><path class=\"js-line\" d=\"M23.75,88.19L713.74,88.19\" style=\"vector-effect: none; fill: none; stroke: rgb(0, 0, 0); stroke-opacity: 0; stroke-width: 0px; opacity: 1;\"/></g><g class=\"points\"/><g class=\"text\"/></g><g class=\"trace scatter tracefd6067dd-3873-43b2-a581-aaf484b1f381\" style=\"stroke-miterlimit: 2;\"><g class=\"fills\"/><g class=\"errorbars\"/><g class=\"lines\"><path class=\"js-line\" d=\"M23.75,88.19L341.72,88.19L341.72,89.01L341.73,89.57L341.76,88.19L342.44,88.19L342.48,88.19L442.24,88.19L442.26,89.26L443.2,89.26L443.36,89.75L443.61,89.56L443.86,90.39L445.43,90.08L445.62,89.59L445.94,90.12L446.1,88.99L446.25,89.65L446.85,89.4L446.99,89.14L447.92,88.19L448.05,88.19L448.27,88.6L448.89,88.19L449.02,88.19L713.74,88.19\" style=\"vector-effect: none; fill: none; stroke: rgb(0, 0, 0); stroke-opacity: 0; stroke-width: 0px; opacity: 1;\"/></g><g class=\"points\"/><g class=\"text\"/></g><g class=\"trace scatter tracedd817b95-1dab-4d76-a6a7-c316622c8d13\" style=\"stroke-miterlimit: 2; opacity: 1;\"><g class=\"fills\"/><g class=\"errorbars\"/><g class=\"lines\"><path class=\"js-line\" d=\"M23.75,88.19L41.84,87.49L41.91,87.12L42.54,84.95L43.05,85.35L43.21,85.99L43.4,85.27L43.65,87.15L43.79,86.78L44.07,87.87L44.26,86.45L44.52,87.36L44.63,85.99L44.87,86.48L45.01,86.07L45.13,84.83L45.56,86.83L45.87,85.09L46,85.43L46.93,82.96L47.04,83.82L47.39,87.16L47.45,85.5L47.5,84.27L47.58,84.53L47.94,80.58L48.53,81.27L48.67,81.3L49.44,79.09L49.52,79.59L49.56,80.54L49.77,78.21L50.26,79.43L50.4,79.16L50.69,80.22L50.89,79.62L51.02,78.82L51.3,76.93L52,77.25L52.14,78.41L52.42,76.77L52.74,78.3L52.86,78.97L53.34,78.66L53.53,79.25L53.71,79.33L53.8,79.1L53.9,80.2L53.99,80.75L54.77,77.74L54.85,78.09L55.11,78.83L55.44,77.97L55.61,77.69L56.72,74.69L56.78,75.13L56.87,75.57L57.15,74.08L57.62,75.32L57.74,75.42L58.91,70.6L58.95,70.57L59.4,68.49L59.7,79.52L59.93,74.93L59.95,73.94L59.98,75.12L60.19,72.09L60.64,73.18L60.71,72.52L61.23,70.27L61.34,70.37L61.4,71.59L61.71,69.75L61.95,71.62L62.02,73.59L62.58,70.65L62.79,72.04L62.93,72.73L64,80.05L64.17,76.53L64.2,75.5L64.25,76.04L64.76,74.02L64.84,73.98L65.06,73.35L65.73,76.01L65.81,77.03L66.47,72.97L66.61,73.21L66.7,72.8L67.36,74.58L67.58,73.79L67.71,73.29L69.19,64.28L69.35,64.92L69.43,65.87L69.66,67.4L70.1,64.95L70.17,66.13L70.26,66.19L70.71,63.66L70.8,66.41L70.83,67.58L71.58,66.63L71.64,66.63L81.87,67.22L81.98,68.05L82,68.84L82.62,67.57L82.71,67.99L82.86,67.49L83.17,66.12L83.54,67.5L83.7,69.23L84,68.26L84.17,69.1L84.32,69.33L84.7,70.49L84.91,68.99L85.04,68.65L85.96,67.64L86.12,68.29L86.56,69.44L87.11,69.06L87.32,69.06L89.58,69.44L89.69,69.61L90.01,69.51L90.92,71.32L91.12,71.32L99.78,71.32L99.79,70.12L100.58,61.74L100.68,60.22L100.73,59.84L101.09,61.79L101.22,61.36L101.32,61.61L101.49,61.2L102.15,66.37L102.21,65.71L102.26,63.86L102.4,63.75L102.53,65.26L103.61,73.74L103.63,73.4L103.65,76.25L103.68,76.91L103.89,70L104.2,72.61L104.24,72.61L107.55,72.61L107.63,73.64L148.15,73.08L148.22,72.79L148.25,73.35L148.82,70.22L148.86,70.04L150.15,72.31L150.25,71.97L150.36,71.85L150.44,72.4L150.7,72.56L150.88,72.55L151.03,72.99L151.29,71.78L151.45,72.36L151.6,71.43L152.89,71.53L153,71.53L160.5,72.12L160.58,72.45L161.4,73.8L161.52,73.8L163.92,73.8L163.99,74.75L167.33,74.64L167.5,73.82L167.64,73.4L167.74,74.62L167.88,75.4L167.97,75.17L168.28,76.37L168.43,75.89L168.5,75.89L172.56,76.41L172.69,76.91L174.25,80.63L174.34,80.63L175.75,81.25L175.83,82.44L176.04,82.67L176.17,81.96L176.51,82.69L176.71,82.69L189.06,82.17L189.15,82.82L189.78,83L190.03,83L191.44,82.45L191.5,81.79L192.13,81.04L192.35,82.74L193.93,82.61L194.2,82.61L199.92,82.59L199.98,83.21L200.08,83.09L200.19,83.63L200.64,83.56L200.81,83.56L201.53,85.2L201.73,85.2L207.09,85.2L207.17,86L208.05,86.98L208.27,86.98L210.58,87.1L210.68,86.41L210.78,86.1L211.14,87.12L211.29,87.12L286.73,87.58L286.83,87.93L287.91,88.76L288.12,87.7L288.96,88.33L289.14,88.33L341.65,88.56L341.66,86.88L341.73,89.57L341.98,79.98L342.4,84.62L342.44,84.62L393.95,84.34L393.97,83.81L394.04,83.09L394.46,84.52L394.67,84.23L394.81,84.41L395.78,84.81L396.03,84.81L396.76,85.29L396.85,85.92L397.68,85.01L397.78,85.01L402.88,85.58L403.02,85.79L403.48,85.83L403.7,85L404.27,83.24L404.65,83.62L404.82,84.05L405.06,84.31L405.31,83.6L405.49,83.28L406.56,84.09L406.68,84.09L407.59,84.34L407.87,83.92L408.43,83.91L408.57,83.91L411.8,83.82L411.96,84.68L412.65,83.52L412.85,83.52L415.45,83.85L415.57,82.83L416.02,82.35L416.69,84.3L416.83,84.3L419.44,84.3L419.57,83.47L419.72,82.42L419.95,84.83L420,86.01L432.52,86.01L432.64,86.78L432.99,86.07L433.2,86.5L433.37,87.07L435.52,87.34L435.69,86.63L435.73,86.45L435.85,87.12L436.29,87.11L436.42,87.11L437.7,88.08L437.98,88.08L441.22,87.56L441.27,86.95L441.86,87.57L441.97,86.7L442.03,86.42L442.65,89.26L442.88,89.23L442.97,88.61L444.23,90.39L444.49,90.39L445.43,90.08L445.62,89.59L445.94,90.12L446.1,88.99L446.25,89.65L446.85,89.4L446.99,89.14L447.37,87.65L447.92,87.77L448.05,87.81L448.27,88.6L448.67,88.04L448.89,87.79L449.95,86.44L450.07,86.76L450.19,86.76L467.98,87.42L468.18,87.58L469.29,88.1L469.47,88.1L474.02,88.75L474.2,87.17L474.69,73.83L475.14,76.65L475.19,76.65L480.14,76.53L480.15,77.7L480.25,77.74L480.6,76.26L480.95,76.62L481,76.62L481.83,76.3L481.91,77.19L482.03,77.46L482.17,76.22L482.28,75.38L482.79,75.92L483.15,74.4L483.2,75.11L483.33,75.29L483.86,73.93L483.93,74.07L484.01,72.69L484.04,73.05L484.21,71.38L484.69,72.7L484.76,72.41L484.82,72.01L485.08,74.37L485.22,74.02L485.3,73.96L486.35,77.52L486.44,77.22L486.52,76.38L486.98,75L487.21,75.81L487.3,76.72L487.5,78.82L487.86,76.74L487.95,75.75L487.99,76.28L488.51,75.01L488.65,75.76L488.76,74.37L488.82,74.12L489.12,74.95L489.17,74.45L489.22,75.97L489.32,76.03L489.47,74.52L489.9,75.99L489.98,76.11L490.52,73.07L490.86,74.39L490.97,74.71L491.27,74.95L491.97,73.05L492.09,73.71L492.24,73.58L492.38,74.25L492.44,75.25L492.58,74.44L492.92,76.13L493.03,75.6L493.19,75.36L493.68,74.71L494.1,76.6L494.25,76.29L494.41,76.04L495.18,74.84L495.28,75.73L495.41,76L495.74,77.51L496.1,76.9L496.25,76.1L497.59,74.59L497.86,74.87L497.94,75.8L499.09,73.69L499.32,74L499.45,74L500.36,74L500.38,75.21L501.14,73L501.19,73L501.68,73.11L501.71,74.08L501.79,72.53L502.08,75.94L502.41,74.34L502.5,73.55L502.73,73.97L503.02,73.06L503.16,73.06L503.3,73.06L504.97,73.36L505.11,72.51L506.22,71.5L506.37,72.52L506.58,73.25L507.15,73.07L507.24,72.5L508.69,69.18L508.72,70.21L509.33,70.79L509.54,69.86L510.17,69.66L510.32,68.17L511.02,69.17L511.18,68.37L512.15,68.32L512.27,68.32L512.95,68.12L513.02,69.07L513.9,62.18L513.99,63.78L514.03,64.14L514.22,64.94L514.45,63.64L514.51,63.65L514.55,63.65L549.12,64.23L549.17,64.83L549.51,65.24L549.78,64.27L549.87,65.18L549.97,64.91L551.2,63.74L551.29,63.74L574.18,63.74L574.2,64.93L574.26,64.31L574.74,65.87L574.87,65.61L575.02,65.78L576.07,66.54L576.18,66.54L586.29,66.86L586.35,66.95L587.23,67.57L587.35,67.57L589.27,68.05L589.3,68.34L590.04,67.88L590.11,67.88L617.43,68.37L617.62,68.57L618.11,68.81L618.47,68.21L618.59,68.21L619.8,67.94L619.9,66.59L620.05,65.65L620.2,66.93L620.52,66.29L620.64,65.94L621.03,65.86L621.14,65.13L621.36,63.43L621.53,65.6L621.62,65.47L621.72,65.81L622.57,62.41L622.68,62.79L622.75,62.86L623.04,64.75L623.43,63.57L623.6,63.42L623.76,63.66L623.92,63.14L624.08,62.06L624.2,64.29L624.63,61.51L624.76,62.73L624.86,62.04L625.08,62.73L625.54,62.5L625.72,62.39L626.21,63.51L626.61,63.16L626.78,63.2L627.03,63.77L627.41,63.55L627.62,63.24L629.23,64.84L629.42,64.84L630.97,64.42L631.01,64.29L631.23,65.19L631.37,64.13L631.91,65.03L632,64.85L632.42,67.57L632.85,66.43L632.94,66.75L633.16,65.63L633.69,66.02L633.8,66.02L662.29,66.02L662.42,67.65L662.54,67.05L663.12,67.6L663.23,67.6L670.25,67.6L670.27,65.33L670.46,64.61L670.71,67.62L671.05,66.83L671.13,67.57L671.95,68.56L671.99,68.56L678.26,68.29L678.36,67.26L678.59,66.19L678.85,68.08L679.05,67.43L679.17,68.27L690.98,68.89L691.17,69.43L691.33,69.05L691.62,70.1L691.69,69.44L691.81,70.26L692.05,70.94L692.43,70.05L692.48,70.05L713.74,70.05\" style=\"vector-effect: none; fill: none; stroke: rgb(148, 103, 189); stroke-opacity: 1; stroke-width: 2px; opacity: 1;\"/></g><g class=\"points\"/><g class=\"text\"/></g><g class=\"trace scatter trace0c070de5-d44f-43ce-bb5a-038bf19c9cb1\" style=\"stroke-miterlimit: 2; opacity: 0;\"><g class=\"fills\"/><g class=\"errorbars\"/><g class=\"lines\"><path class=\"js-line\" d=\"M23.75,88.19L713.74,88.19\" style=\"vector-effect: none; fill: none; stroke: rgb(0, 0, 0); stroke-opacity: 0; stroke-width: 0px; opacity: 1;\"/></g><g class=\"points\"/><g class=\"text\"/></g></g></g><g class=\"overplot\"/><path class=\"xlines-above crisp\" d=\"M0,0\" style=\"fill: none;\"/><path class=\"ylines-above crisp\" d=\"M0,0\" style=\"fill: none;\"/><g class=\"overlines-above\"/><g class=\"xaxislayer-above\"><g class=\"x3tick\"><text text-anchor=\"middle\" x=\"0\" y=\"455\" transform=\"translate(174.66,0)\" style=\"font-family: 'Open Sans', verdana, arial, sans-serif; font-size: 12px; fill: rgb(214, 223, 239); fill-opacity: 1; white-space: pre; opacity: 1;\"><tspan class=\"line\" dy=\"0em\" x=\"0\" y=\"455\">Jan 10</tspan><tspan class=\"line\" dy=\"1.3em\" x=\"0\" y=\"455\">2021</tspan></text></g><g class=\"x3tick\"><text text-anchor=\"middle\" x=\"0\" y=\"455\" style=\"font-family: 'Open Sans', verdana, arial, sans-serif; font-size: 12px; fill: rgb(214, 223, 239); fill-opacity: 1; white-space: pre; opacity: 1;\" transform=\"translate(266.08000000000004,0)\">Jan 17</text></g><g class=\"x3tick\"><text text-anchor=\"middle\" x=\"0\" y=\"455\" style=\"font-family: 'Open Sans', verdana, arial, sans-serif; font-size: 12px; fill: rgb(214, 223, 239); fill-opacity: 1; white-space: pre; opacity: 1;\" transform=\"translate(357.49,0)\">Jan 24</text></g><g class=\"x3tick\"><text text-anchor=\"middle\" x=\"0\" y=\"455\" style=\"font-family: 'Open Sans', verdana, arial, sans-serif; font-size: 12px; fill: rgb(214, 223, 239); fill-opacity: 1; white-space: pre; opacity: 1;\" transform=\"translate(448.91,0)\">Jan 31</text></g><g class=\"x3tick\"><text text-anchor=\"middle\" x=\"0\" y=\"455\" style=\"font-family: 'Open Sans', verdana, arial, sans-serif; font-size: 12px; fill: rgb(214, 223, 239); fill-opacity: 1; white-space: pre; opacity: 1;\" transform=\"translate(540.3299999999999,0)\">Feb 7</text></g><g class=\"x3tick\"><text text-anchor=\"middle\" x=\"0\" y=\"455\" style=\"font-family: 'Open Sans', verdana, arial, sans-serif; font-size: 12px; fill: rgb(214, 223, 239); fill-opacity: 1; white-space: pre; opacity: 1;\" transform=\"translate(631.74,0)\">Feb 14</text></g><g class=\"x3tick\"><text text-anchor=\"middle\" x=\"0\" y=\"455\" style=\"font-family: 'Open Sans', verdana, arial, sans-serif; font-size: 12px; fill: rgb(214, 223, 239); fill-opacity: 1; white-space: pre; opacity: 1;\" transform=\"translate(723.16,0)\">Feb 21</text></g><g class=\"x3tick\"><text text-anchor=\"middle\" x=\"0\" y=\"455\" style=\"font-family: 'Open Sans', verdana, arial, sans-serif; font-size: 12px; fill: rgb(214, 223, 239); fill-opacity: 1; white-space: pre; opacity: 1;\" transform=\"translate(814.58,0)\">Feb 28</text></g></g><g class=\"yaxislayer-above\"><g class=\"y3tick\"><text text-anchor=\"end\" x=\"85\" y=\"4.199999999999999\" transform=\"translate(0,425.64098039215685)\" style=\"font-family: 'Open Sans', verdana, arial, sans-serif; font-size: 12px; fill: rgb(214, 223, 239); fill-opacity: 1; white-space: pre; opacity: 1;\">1</text></g><g class=\"y3tick\"><text text-anchor=\"end\" x=\"85\" y=\"4.199999999999999\" style=\"font-family: 'Open Sans', verdana, arial, sans-serif; font-size: 12px; fill: rgb(214, 223, 239); fill-opacity: 1; white-space: pre; opacity: 1;\" transform=\"translate(0,373.58098039215685)\">1.5</text></g></g><g class=\"overaxes-above\"/></g></g><g class=\"polarlayer\"/><g class=\"smithlayer\"/><g class=\"ternarylayer\"/><g class=\"geolayer\"/><g class=\"funnelarealayer\"/><g class=\"pielayer\"/><g class=\"iciclelayer\"/><g class=\"treemaplayer\"/><g class=\"sunburstlayer\"/><g class=\"glimages\"/><defs id=\"topdefs-b122c5\"><g class=\"clips\"/><clipPath id=\"legendb122c5\"><rect width=\"660\" height=\"29\" x=\"0\" y=\"0\"/></clipPath></defs><g class=\"layer-above\"><g class=\"imagelayer\"/><g class=\"shapelayer\"><g class=\"shape-group\" data-index=\"0\" clip-path=\"url(#clipb122c5y2)\"><path data-index=\"0\" fill-rule=\"evenodd\" d=\"M86,289.64549019607847L820,289.64549019607847\" style=\"opacity: 1; stroke: rgb(128, 128, 128); stroke-opacity: 1; fill: rgb(0, 0, 0); fill-opacity: 0; stroke-dasharray: 9px, 9px; stroke-width: 2px;\"/></g><g class=\"shape-group\" data-index=\"1\" clip-path=\"url(#clipb122c5y3)\"><path data-index=\"1\" fill-rule=\"evenodd\" d=\"M86,425.64098039215685L820,425.64098039215685\" style=\"opacity: 1; stroke: rgb(128, 128, 128); stroke-opacity: 1; fill: rgb(0, 0, 0); fill-opacity: 0; stroke-dasharray: 9px, 9px; stroke-width: 2px;\"/></g></g></g><g class=\"infolayer\"><g class=\"legend\" pointer-events=\"all\" transform=\"translate(160,11.823529411764724)\"><rect class=\"bg\" shape-rendering=\"crispEdges\" width=\"660\" height=\"29\" x=\"0\" y=\"0\" style=\"stroke: rgb(68, 68, 68); stroke-opacity: 1; fill: rgb(33, 34, 38); fill-opacity: 1; stroke-width: 0px;\"/><g class=\"scrollbox\" transform=\"\" clip-path=\"url(#legendb122c5)\"><g class=\"groups\"><g class=\"traces\" transform=\"translate(0,14.5)\" style=\"opacity: 1;\"><text class=\"legendtext\" text-anchor=\"start\" x=\"40\" y=\"4.680000000000001\" style=\"font-family: 'Open Sans', verdana, arial, sans-serif; font-size: 12px; fill: rgb(214, 223, 239); fill-opacity: 1; white-space: pre;\">Close</text><g class=\"layers\" style=\"opacity: 1;\"><g class=\"legendfill\"/><g class=\"legendlines\"><path class=\"js-line\" d=\"M5,0h30\" style=\"fill: none; stroke: rgb(31, 119, 180); stroke-opacity: 1; stroke-width: 2px;\"/></g><g class=\"legendsymbols\"><g class=\"legendpoints\"/></g></g><rect class=\"legendtoggle\" x=\"0\" y=\"-9.5\" width=\"74.859375\" height=\"19\" style=\"fill: rgb(0, 0, 0); fill-opacity: 0;\"/></g><g class=\"traces\" transform=\"translate(77.359375,14.5)\" style=\"opacity: 1;\"><text class=\"legendtext\" text-anchor=\"start\" x=\"40\" y=\"4.680000000000001\" style=\"font-family: 'Open Sans', verdana, arial, sans-serif; font-size: 12px; fill: rgb(214, 223, 239); fill-opacity: 1; white-space: pre;\">Buy</text><g class=\"layers\" style=\"opacity: 1;\"><g class=\"legendfill\"/><g class=\"legendlines\"/><g class=\"legendsymbols\"><g class=\"legendpoints\"><path class=\"scatterpts\" transform=\"translate(20,0)\" d=\"M-4.62,2H4.62L0,-4Z\" style=\"opacity: 1; stroke-width: 1px; fill: rgb(55, 177, 63); fill-opacity: 1; stroke: rgb(38, 123, 44); stroke-opacity: 1;\"/></g></g></g><rect class=\"legendtoggle\" x=\"0\" y=\"-9.5\" width=\"65.421875\" height=\"19\" style=\"fill: rgb(0, 0, 0); fill-opacity: 0;\"/></g><g class=\"traces\" transform=\"translate(145.28125,14.5)\" style=\"opacity: 1;\"><text class=\"legendtext\" text-anchor=\"start\" x=\"40\" y=\"4.680000000000001\" style=\"font-family: 'Open Sans', verdana, arial, sans-serif; font-size: 12px; fill: rgb(214, 223, 239); fill-opacity: 1; white-space: pre;\">Sell</text><g class=\"layers\" style=\"opacity: 1;\"><g class=\"legendfill\"/><g class=\"legendlines\"/><g class=\"legendsymbols\"><g class=\"legendpoints\"><path class=\"scatterpts\" transform=\"translate(20,0)\" d=\"M-4.62,-2H4.62L0,4Z\" style=\"opacity: 1; stroke-width: 1px; fill: rgb(234, 67, 53); fill-opacity: 1; stroke: rgb(181, 31, 18); stroke-opacity: 1;\"/></g></g></g><rect class=\"legendtoggle\" x=\"0\" y=\"-9.5\" width=\"64.4375\" height=\"19\" style=\"fill: rgb(0, 0, 0); fill-opacity: 0;\"/></g><g class=\"traces\" transform=\"translate(212.21875,14.5)\" style=\"opacity: 1;\"><text class=\"legendtext\" text-anchor=\"start\" x=\"40\" y=\"4.680000000000001\" style=\"font-family: 'Open Sans', verdana, arial, sans-serif; font-size: 12px; fill: rgb(214, 223, 239); fill-opacity: 1; white-space: pre;\">Closed - Profit</text><g class=\"layers\" style=\"opacity: 1;\"><g class=\"legendfill\"/><g class=\"legendlines\"/><g class=\"legendsymbols\"><g class=\"legendpoints\"><path class=\"scatterpts\" transform=\"translate(20,0)\" d=\"M3.88,0A3.88,3.88 0 1,1 0,-3.88A3.88,3.88 0 0,1 3.88,0Z\" style=\"opacity: 0.766291; stroke-width: 1px; fill: rgb(55, 177, 63); fill-opacity: 1; stroke: rgb(38, 123, 44); stroke-opacity: 1;\"/></g></g></g><rect class=\"legendtoggle\" x=\"0\" y=\"-9.5\" width=\"128.109375\" height=\"19\" style=\"fill: rgb(0, 0, 0); fill-opacity: 0;\"/></g><g class=\"traces\" transform=\"translate(342.828125,14.5)\" style=\"opacity: 1;\"><text class=\"legendtext\" text-anchor=\"start\" x=\"40\" y=\"4.680000000000001\" style=\"font-family: 'Open Sans', verdana, arial, sans-serif; font-size: 12px; fill: rgb(214, 223, 239); fill-opacity: 1; white-space: pre;\">Closed - Loss</text><g class=\"layers\" style=\"opacity: 1;\"><g class=\"legendfill\"/><g class=\"legendlines\"/><g class=\"legendsymbols\"><g class=\"legendpoints\"><path class=\"scatterpts\" transform=\"translate(20,0)\" d=\"M3.67,0A3.67,3.67 0 1,1 0,-3.67A3.67,3.67 0 0,1 3.67,0Z\" style=\"opacity: 0.757499; stroke-width: 1px; fill: rgb(234, 67, 53); fill-opacity: 1; stroke: rgb(181, 31, 18); stroke-opacity: 1;\"/></g></g></g><rect class=\"legendtoggle\" x=\"0\" y=\"-9.5\" width=\"122.6875\" height=\"19\" style=\"fill: rgb(0, 0, 0); fill-opacity: 0;\"/></g><g class=\"traces\" transform=\"translate(468.015625,14.5)\" style=\"opacity: 1;\"><text class=\"legendtext\" text-anchor=\"start\" x=\"40\" y=\"4.680000000000001\" style=\"font-family: 'Open Sans', verdana, arial, sans-serif; font-size: 12px; fill: rgb(214, 223, 239); fill-opacity: 1; white-space: pre;\">Benchmark</text><g class=\"layers\" style=\"opacity: 1;\"><g class=\"legendfill\"/><g class=\"legendlines\"><path class=\"js-line\" d=\"M5,0h30\" style=\"fill: none; stroke: rgb(127, 127, 127); stroke-opacity: 1; stroke-width: 2px;\"/></g><g class=\"legendsymbols\"><g class=\"legendpoints\"/></g></g><rect class=\"legendtoggle\" x=\"0\" y=\"-9.5\" width=\"110.421875\" height=\"19\" style=\"fill: rgb(0, 0, 0); fill-opacity: 0;\"/></g><g class=\"traces\" transform=\"translate(580.9375,14.5)\" style=\"opacity: 1;\"><text class=\"legendtext\" text-anchor=\"start\" x=\"40\" y=\"4.680000000000001\" style=\"font-family: 'Open Sans', verdana, arial, sans-serif; font-size: 12px; fill: rgb(214, 223, 239); fill-opacity: 1; white-space: pre;\">Value</text><g class=\"layers\" style=\"opacity: 1;\"><g class=\"legendfill\"/><g class=\"legendlines\"><path class=\"js-line\" d=\"M5,0h30\" style=\"fill: none; stroke: rgb(148, 103, 189); stroke-opacity: 1; stroke-width: 2px;\"/></g><g class=\"legendsymbols\"><g class=\"legendpoints\"/></g></g><rect class=\"legendtoggle\" x=\"0\" y=\"-9.5\" width=\"75.953125\" height=\"19\" style=\"fill: rgb(0, 0, 0); fill-opacity: 0;\"/></g></g></g><rect class=\"scrollbar\" rx=\"20\" ry=\"3\" width=\"0\" height=\"0\" x=\"0\" y=\"0\" style=\"fill: rgb(128, 139, 164); fill-opacity: 1;\"/></g><g class=\"g-gtitle\"/><g class=\"g-xtitle\"/><g class=\"g-x2title\"/><g class=\"g-x3title\"><text class=\"x3title\" x=\"453\" y=\"497.409375\" text-anchor=\"middle\" style=\"font-family: 'Open Sans', verdana, arial, sans-serif; font-size: 14px; fill: rgb(214, 223, 239); opacity: 1; font-weight: normal; white-space: pre;\">Index</text></g><g class=\"g-ytitle\"><text class=\"ytitle\" transform=\"rotate(-90,38.340625,122.27450980392157)\" x=\"38.340625\" y=\"122.27450980392157\" text-anchor=\"middle\" style=\"font-family: 'Open Sans', verdana, arial, sans-serif; font-size: 14px; fill: rgb(214, 223, 239); opacity: 1; font-weight: normal; white-space: pre;\">Price</text></g><g class=\"g-y2title\" transform=\"translate(1.0966796875,0)\"><text class=\"y2title\" transform=\"rotate(-90,12.903125000000003,256)\" x=\"12.903125000000003\" y=\"256\" text-anchor=\"middle\" style=\"font-family: 'Open Sans', verdana, arial, sans-serif; font-size: 14px; fill: rgb(214, 223, 239); opacity: 1; font-weight: normal; white-space: pre;\">Trade PnL</text></g><g class=\"g-y3title\"><text class=\"y3title\" transform=\"rotate(-90,41.075,389.7254901960784)\" x=\"41.075\" y=\"389.7254901960784\" text-anchor=\"middle\" style=\"font-family: 'Open Sans', verdana, arial, sans-serif; font-size: 14px; fill: rgb(214, 223, 239); opacity: 1; font-weight: normal; white-space: pre;\">Cumulative returns</text></g><g class=\"annotation\" data-index=\"0\" style=\"opacity: 1;\"><g class=\"annotation-text-g\" transform=\"rotate(0,453,58)\"><g class=\"cursor-pointer\" transform=\"translate(424,46)\"><rect class=\"bg\" x=\"0.5\" y=\"0.5\" width=\"57\" height=\"23\" style=\"stroke-width: 1px; stroke: rgb(0, 0, 0); stroke-opacity: 0; fill: rgb(0, 0, 0); fill-opacity: 0;\"/><text class=\"annotation-text\" text-anchor=\"middle\" x=\"29.046875\" y=\"18\" style=\"font-family: 'Open Sans', verdana, arial, sans-serif; font-size: 16px; fill: rgb(214, 223, 239); fill-opacity: 1; white-space: pre;\">Orders</text></g></g></g><g class=\"annotation\" data-index=\"1\" style=\"opacity: 1;\"><g class=\"annotation-text-g\" transform=\"rotate(0,453,191.72549019607845)\"><g class=\"cursor-pointer\" transform=\"translate(411,180)\"><rect class=\"bg\" x=\"0.5\" y=\"0.5\" width=\"83\" height=\"23\" style=\"stroke-width: 1px; stroke: rgb(0, 0, 0); stroke-opacity: 0; fill: rgb(0, 0, 0); fill-opacity: 0;\"/><text class=\"annotation-text\" text-anchor=\"middle\" x=\"42.0625\" y=\"18\" style=\"font-family: 'Open Sans', verdana, arial, sans-serif; font-size: 16px; fill: rgb(214, 223, 239); fill-opacity: 1; white-space: pre;\">Trade PnL</text></g></g></g><g class=\"annotation\" data-index=\"2\" style=\"opacity: 1;\"><g class=\"annotation-text-g\" transform=\"rotate(0,453,325.45098039215685)\"><g class=\"cursor-pointer\" transform=\"translate(372,313)\"><rect class=\"bg\" x=\"0.5\" y=\"0.5\" width=\"162\" height=\"23\" style=\"stroke-width: 1px; stroke: rgb(0, 0, 0); stroke-opacity: 0; fill: rgb(0, 0, 0); fill-opacity: 0;\"/><text class=\"annotation-text\" text-anchor=\"middle\" x=\"81.34375\" y=\"18\" style=\"font-family: 'Open Sans', verdana, arial, sans-serif; font-size: 16px; fill: rgb(214, 223, 239); fill-opacity: 1; white-space: pre;\">Cumulative Returns</text></g></g></g></g></svg>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pf = vbt.Portfolio.from_signals(\n",
    "    data.close[test_preds.index], # use only the test set\n",
    "    test_preds > 0.05, # long when probability of price increase is greater than 2%\n",
    "    test_preds < 0.02, # short when probability prediction is less than -5%\n",
    "    direction=\"LongOnly\" # long and short\n",
    ")\n",
    "print(pf.stats())\n",
    "pf.plot().show_svg()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b74572df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Exit Trade Id</th>\n",
       "      <th>Column</th>\n",
       "      <th>Size</th>\n",
       "      <th>Entry Order Id</th>\n",
       "      <th>Entry Index</th>\n",
       "      <th>Avg Entry Price</th>\n",
       "      <th>Entry Fees</th>\n",
       "      <th>Exit Order Id</th>\n",
       "      <th>Exit Index</th>\n",
       "      <th>Avg Exit Price</th>\n",
       "      <th>Exit Fees</th>\n",
       "      <th>PnL</th>\n",
       "      <th>Return</th>\n",
       "      <th>Direction</th>\n",
       "      <th>Status</th>\n",
       "      <th>Position Id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.004411</td>\n",
       "      <td>0</td>\n",
       "      <td>2023-01-27 01:41:00+00:00</td>\n",
       "      <td>22670.3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2023-02-02 22:00:00+00:00</td>\n",
       "      <td>23494.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.633388</td>\n",
       "      <td>0.036334</td>\n",
       "      <td>Long</td>\n",
       "      <td>Closed</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.004411</td>\n",
       "      <td>1</td>\n",
       "      <td>2023-02-02 22:00:00+00:00</td>\n",
       "      <td>23494.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2023-02-03 11:12:00+00:00</td>\n",
       "      <td>23474.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.084692</td>\n",
       "      <td>0.000817</td>\n",
       "      <td>Short</td>\n",
       "      <td>Closed</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.004418</td>\n",
       "      <td>2</td>\n",
       "      <td>2023-02-03 11:12:00+00:00</td>\n",
       "      <td>23474.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2023-02-05 17:41:00+00:00</td>\n",
       "      <td>22912.3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-2.485279</td>\n",
       "      <td>-0.023962</td>\n",
       "      <td>Long</td>\n",
       "      <td>Closed</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0.004418</td>\n",
       "      <td>3</td>\n",
       "      <td>2023-02-05 17:41:00+00:00</td>\n",
       "      <td>22912.3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4</td>\n",
       "      <td>2023-02-05 22:26:00+00:00</td>\n",
       "      <td>23008.3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.424154</td>\n",
       "      <td>-0.004190</td>\n",
       "      <td>Short</td>\n",
       "      <td>Closed</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.004381</td>\n",
       "      <td>4</td>\n",
       "      <td>2023-02-05 22:26:00+00:00</td>\n",
       "      <td>23008.3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5</td>\n",
       "      <td>2023-02-08 16:18:00+00:00</td>\n",
       "      <td>22783.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.983625</td>\n",
       "      <td>-0.009757</td>\n",
       "      <td>Long</td>\n",
       "      <td>Closed</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>84</td>\n",
       "      <td>0</td>\n",
       "      <td>0.003476</td>\n",
       "      <td>84</td>\n",
       "      <td>2023-04-03 21:48:00+00:00</td>\n",
       "      <td>27714.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>85</td>\n",
       "      <td>2023-04-07 07:56:00+00:00</td>\n",
       "      <td>27829.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.398667</td>\n",
       "      <td>0.004139</td>\n",
       "      <td>Long</td>\n",
       "      <td>Closed</td>\n",
       "      <td>84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>85</td>\n",
       "      <td>0</td>\n",
       "      <td>0.003476</td>\n",
       "      <td>85</td>\n",
       "      <td>2023-04-07 07:56:00+00:00</td>\n",
       "      <td>27829.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>86</td>\n",
       "      <td>2023-04-07 12:01:00+00:00</td>\n",
       "      <td>27909.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.279449</td>\n",
       "      <td>-0.002889</td>\n",
       "      <td>Short</td>\n",
       "      <td>Closed</td>\n",
       "      <td>85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>86</td>\n",
       "      <td>0</td>\n",
       "      <td>0.003456</td>\n",
       "      <td>86</td>\n",
       "      <td>2023-04-07 12:01:00+00:00</td>\n",
       "      <td>27909.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>87</td>\n",
       "      <td>2023-04-12 05:00:00+00:00</td>\n",
       "      <td>29910.9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.915921</td>\n",
       "      <td>0.071707</td>\n",
       "      <td>Long</td>\n",
       "      <td>Closed</td>\n",
       "      <td>86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>87</td>\n",
       "      <td>0</td>\n",
       "      <td>0.003456</td>\n",
       "      <td>87</td>\n",
       "      <td>2023-04-12 05:00:00+00:00</td>\n",
       "      <td>29910.9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>88</td>\n",
       "      <td>2023-04-12 12:27:00+00:00</td>\n",
       "      <td>30318.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.407512</td>\n",
       "      <td>-0.013617</td>\n",
       "      <td>Short</td>\n",
       "      <td>Closed</td>\n",
       "      <td>87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>88</td>\n",
       "      <td>0</td>\n",
       "      <td>0.003363</td>\n",
       "      <td>88</td>\n",
       "      <td>2023-04-12 12:27:00+00:00</td>\n",
       "      <td>30318.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1</td>\n",
       "      <td>2023-04-13 16:00:00+00:00</td>\n",
       "      <td>30404.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.290552</td>\n",
       "      <td>0.002850</td>\n",
       "      <td>Long</td>\n",
       "      <td>Open</td>\n",
       "      <td>88</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>89 rows Ã— 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Exit Trade Id  Column      Size  Entry Order Id               Entry Index  \\\n",
       "0               0       0  0.004411               0 2023-01-27 01:41:00+00:00   \n",
       "1               1       0  0.004411               1 2023-02-02 22:00:00+00:00   \n",
       "2               2       0  0.004418               2 2023-02-03 11:12:00+00:00   \n",
       "3               3       0  0.004418               3 2023-02-05 17:41:00+00:00   \n",
       "4               4       0  0.004381               4 2023-02-05 22:26:00+00:00   \n",
       "..            ...     ...       ...             ...                       ...   \n",
       "84             84       0  0.003476              84 2023-04-03 21:48:00+00:00   \n",
       "85             85       0  0.003476              85 2023-04-07 07:56:00+00:00   \n",
       "86             86       0  0.003456              86 2023-04-07 12:01:00+00:00   \n",
       "87             87       0  0.003456              87 2023-04-12 05:00:00+00:00   \n",
       "88             88       0  0.003363              88 2023-04-12 12:27:00+00:00   \n",
       "\n",
       "    Avg Entry Price  Entry Fees  Exit Order Id                Exit Index  \\\n",
       "0           22670.3         0.0              1 2023-02-02 22:00:00+00:00   \n",
       "1           23494.0         0.0              2 2023-02-03 11:12:00+00:00   \n",
       "2           23474.8         0.0              3 2023-02-05 17:41:00+00:00   \n",
       "3           22912.3         0.0              4 2023-02-05 22:26:00+00:00   \n",
       "4           23008.3         0.0              5 2023-02-08 16:18:00+00:00   \n",
       "..              ...         ...            ...                       ...   \n",
       "84          27714.5         0.0             85 2023-04-07 07:56:00+00:00   \n",
       "85          27829.2         0.0             86 2023-04-07 12:01:00+00:00   \n",
       "86          27909.6         0.0             87 2023-04-12 05:00:00+00:00   \n",
       "87          29910.9         0.0             88 2023-04-12 12:27:00+00:00   \n",
       "88          30318.2         0.0             -1 2023-04-13 16:00:00+00:00   \n",
       "\n",
       "    Avg Exit Price  Exit Fees       PnL    Return Direction  Status  \\\n",
       "0          23494.0        0.0  3.633388  0.036334      Long  Closed   \n",
       "1          23474.8        0.0  0.084692  0.000817     Short  Closed   \n",
       "2          22912.3        0.0 -2.485279 -0.023962      Long  Closed   \n",
       "3          23008.3        0.0 -0.424154 -0.004190     Short  Closed   \n",
       "4          22783.8        0.0 -0.983625 -0.009757      Long  Closed   \n",
       "..             ...        ...       ...       ...       ...     ...   \n",
       "84         27829.2        0.0  0.398667  0.004139      Long  Closed   \n",
       "85         27909.6        0.0 -0.279449 -0.002889     Short  Closed   \n",
       "86         29910.9        0.0  6.915921  0.071707      Long  Closed   \n",
       "87         30318.2        0.0 -1.407512 -0.013617     Short  Closed   \n",
       "88         30404.6        0.0  0.290552  0.002850      Long    Open   \n",
       "\n",
       "    Position Id  \n",
       "0             0  \n",
       "1             1  \n",
       "2             2  \n",
       "3             3  \n",
       "4             4  \n",
       "..          ...  \n",
       "84           84  \n",
       "85           85  \n",
       "86           86  \n",
       "87           87  \n",
       "88           88  \n",
       "\n",
       "[89 rows x 16 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pf.trades.records_readable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08fdcb48",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
